{
  "download_status": "success",
  "num_samples": 4500,
  "features": [
    "title",
    "text",
    "topic"
  ],
  "sample_data": {
    "0": {
      "title": "(4) (Iisc Lecture Notes) Y Narahari - Game Theory and Mechanism Design-World Scientific Publishing Company _ Indian Inst of Science, India (2014).txt",
      "text": " Game Theory andMechanism Design\n8902_9789814525046_tp.indd 1\n7/1/14 5:32 pm\nIISc Lecture Notes Series\nISSN: 2010-2402\nEditor-in-Chief: Gadadhar MisraEditors: Chandrashekar S JogJoy KuriK L SebastianDiptiman SenSandhya Visweswariah\nPublished:Vol. 1: Introduction to Algebraic Geometry and Commutative Algebraby Dilip P Patil & Uwe StorchVol. 2: Schwarz’s Lemma from a Differential Geometric Veiwpointby Kang-Tae Kim & Hanjin LeeVol. 3: Noise and Vibration Controlby M L MunjalVol. 4: Game Theory and Mechanism Designby Y Narahari\nIISc Lecture Notes Series\nGame Theory andMechanism DesignY NarahariIndian Institute of Science, India\nWorld ScientificN E W J E R S E Y • L O N D O N • S I N G A P O R E • B E I J I N G • S H A N G H A I • H O N G K O N G • TA I P E I • C H E N N A I\n8902_9789814525046_tp.indd 2\n7/1/14 5:32 pm\nPublished byWorld Scientific Publishing Co. Pte. Ltd.5 Toh Tuck Link, Singapore 596224USA office: 27 Warren Street, Suite 401-402, Hackensack, NJ 07601UK office: 57 Shelton Street, Covent Garden, London WC2H 9HE\nBritish Library Cataloguing-in-Publication DataA catalogue record for this book is available from the British Library.\nIISc Lecture Notes Series — Vol. 4GAME THEORY AND MECHANISM DESIGNCopyright © 2014 by World Scientific Publishing Co. Pte. Ltd.All rights reserved. This book, or parts thereof, may not be reproduced in any form or by any means, electronicor mechanical, including photocopying, recording or any information storage and retrieval system now knownor to be invented, without written permission from the publisher.\nFor photocopying of material in this volume, please pay a copying fee through the Copyright Clearance Center,Inc., 222 Rosewood Drive, Danvers, MA 01923, USA. In this case permission to photocopy is not requiredfrom the publisher.\nISBN 978-981-4525-04-6\nPrinted in Singapore\nGameTheory.indd 2\n21/1/2014 9:28:16 AM\nSeries PrefaceWorld Scientific Publishing Company - Indian Institute of Science Collaboration\nIISc Press and WSPC are co-publishing books authored by world renowned scientists andengineers. This collaboration, started in 2008 during IISc’s centenary year under a Memorandum of Understanding between IISc and WSPC, has resulted in the establishment of threeSeries: IISc Centenary Lectures Series (ICLS), IISc Research Monographs Series (IRMS),and IISc Lecture Notes Series (ILNS).This pioneering collaboration will contribute significantly in disseminating current Indianscientific advancement worldwide.The “IISc Centenary Lectures Series” will comprise lectures by designated CentenaryLecturers - eminent teachers and researchers from all over the world.The “IISc Research Monographs Series” will comprise state-of-the-art monographswritten by experts in specific areas. They will include, but not limited to, the authors’ ownresearch work.The “IISc Lecture Notes Series” will consist of books that are reasonably self-containedand can be used either as textbooks or for self-study at the postgraduate level in science andengineering. The books will be based on material that has been class-tested for most part.Editorial Board for the IISc Lecture Notes Series (ILNS):Gadadhar Misra, Editor-in-Chief (gm@math.iisc.ernet.in)Chandrashekar S Jog (jogc@mecheng.iisc.ernet.in)Joy Kuri (kuri@cedt.iisc.ernet.in)K L Sebastian (kls@ipc.iisc.ernet.in)Diptiman Sen (diptiman@cts.iisc.ernet.in)Sandhya Visweswariah (sandhya@mrdg.iisc.ernet.in)\nGameTheory.indd 3\n21/1/2014 9:28:16 AM\nJanuary 3, 2014\n11:48\nWorld Scientific Book - 10.25in x 7.5in\nThis page intentionally left blank\nbook\nJanuary 3, 2014\n11:48\nWorld Scientific Book - 10.25in x 7.5in\nDedication\nTo My Beloved Parentsfor giving me this wonderful life,for teaching me the fundamentals of the game of life,and for continuously inspiring me in this lifethrough their exemplary mechanisms,\nand\nTo the 2007 Economic Sciences Nobel LaureatesLeonid Hurwicz, Eric S. Maskin, and Roger B. Myersonfor creating the wonderful edifice of mechanism designusing game theory building blocks.\nvii\nbook\nJanuary 3, 2014\n11:48\nWorld Scientific Book - 10.25in x 7.5in\nbook\nJanuary 3, 2014\n11:48\nWorld Scientific Book - 10.25in x 7.5in\nForeword\nGame theory and mechanism design have come a long way. Thirty-five yearsago, they were fringe subjects, taught – if at all – in specialty courses. Todaythey are at the center of economic theory and have become an important partof engineering disciplines such as computer science and electronic commerce.I am very pleased that Y. Narahari has written this lovely text, whichpresents the fundamentals of game theory and mechanism design clearly andconcisely. In doing so, Dr. Narahari has performed a great service to studentsand researchers interested in the lively interface between engineering sciencesand economics.Eric MaskinNobel Laureate in Economic Sciences - 2007Adams University ProfessorDepartment of EconomicsFaculty of Arts and SciencesHarvard UniversityCambridge, MA, USA16 July 2013ix\nbook\nJanuary 3, 2014\n11:48\nWorld Scientific Book - 10.25in x 7.5in\nThis page intentionally left blank\nbook\nJanuary 3, 2014\n11:48\nWorld Scientific Book - 10.25in x 7.5in\nOpinions on the Book\nThe theory of Games and Mechanism Design find today wide applications in Economics, Engineering, and Operations Research. This is one of the few books whichpresent a detailed account of both Non-Cooperative and Cooperative Games as wellas Mechanism Design, all under one cover. Proofs of important theorems are givenin a clear and succinct manner and the bibliographical and biographical referencesare particularly valuable. The book can serve both as a graduate text as well as areference volume. I highly recommend it.– Sanjoy K. Mitter, Massachusetts Institute of Technology, Cambridge, MA,USAThis is a splendid book for engineers by an engineer. It has the ideal choice of topicsand emphasis that reflects the driving themes in game theory, such as mechanismdesign, that have lead the revival of game theory in recent times and its multifariousapplications in cybercommerce and allied areas. The lucidly written byte-sizedchapters rich with examples and historical details make it an exciting read. This isthe right book at the right time.– Vivek Borkar, Indian Institute of Technology-Bombay, Mumbai, IndiaThis book covers a subject which now straddles at least three subjects – Economics,Mathematics and Computer Science. It is a comprehensive presentation for a widerange of readers from the novice to experts in related areas who want to informthemselves of Game Theory and Mechanism Design. The book has a very readablefrom-first-principles approach to topics which commendably illuminates while notsacrificing rigor.– Ravi Kannan, Microsoft Research and Indian Institute of Science, Bangalore, India\nxi\nbook\nJanuary 3, 2014\n11:48\nxii\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nNarahari’s book is a beautifully written text that handles both introductory materialand advanced topics well.– Preston McAfee, Google, Mountain View, CA, USAThis marvelous book on Game Theory and Mechanism Design is an essential reference for beginners and practitioners alike. The book covers the basic conceptsneeded to understand game theory and powerful practical implications of the theory embodied in mechanism design. Narahari excels at elucidating the essentials ofgame theory, while motivating the reader with a number of illustrative examples andreal-world applications from engineering, economics and networks. It is fun to readand should be on the shelf of any student or practitioner interested in the practicalapplications of game theory.– Krishna Pattipati, University of Connecticut, Storrs, CT, USAGame Theory is the formal analysis of strategic behavior. It originated with theclassic book of von Neumann and Morgenstern in the 1940’s and over the last 70years, has become a vital ingredient in both the social and engineering sciences.Professor Narahari is a leading expert in the burgeoning area of game theoreticapplications to computer science. His lucid and elegant book, packed with examplesand historical background, is a wonderful introduction to modern Game Theory. Itclearly lays out the central concepts and results of the theory while conveying itspotential for providing insights to a range of interesting practical problems. Thebook will be invaluable to students from diverse backgrounds such as economics,mathematics, and engineering.– Arunava Sen, Indian Statistical Institute, New Delhi, IndiaGame Theory and Mechanism Design is impressive in its broad coverage of cooperative games, non-cooperative games and mechanism design from an engineeringperspective. The book is rich in examples and exercises, and couples historical appraisals of the evolution of the field with careful mathematical proofs. It should bevaluable both as a graduate text and for reference.– Chris Dance, Xerox Research Centre Europe, Grenoble, France\nbook\nJanuary 3, 2014\n11:48\nWorld Scientific Book - 10.25in x 7.5in\nAbout the Author\nProfessor Y. Narahari is currently teaching at the Department of Computer Scienceand Automation, Indian Institute of Science, Bangalore, India. The focus of hisresearch in the last decade has been to explore problems at the interface of computer science and microeconomics. In particular, he is interested in applications ofgame theory and mechanism design to design of auctions and electronic markets,multiagent systems, and social network research. He has coauthored a large numberof influential research papers in these and other areas. Many of his doctoral andmaster’s students have bagged best thesis prizes for their dissertations.He is the lead author of a research monograph Game Theoretic Problems in Network Economics and Mechanism Design Solutions published by Springer, London,in 2009. He coauthored an acclaimed book earlier, Performance Modeling of Automated Manufacturing Systems (Prentice Hall, USA, 1992). He has also created aweb-based teaching resource on Data Structures and Algorithms.His work has been recognized through many fellowships and awards. He is anelected Fellow of the following Institutions and Academies: IEEE, New York; IndianNational Science Academy; Indian Academy of Sciences; Indian National Academyof Engineering; and the National Academy of Sciences. He has been a Senior Editorof the IEEE Transactions on Automation Science and Engineering and an AssociateEditor of several reputed journals. He is currently a J.C. Bose National Fellow, arecognition awarded to distinguished scientists by the Department of Science andTechnology, Government of India. In 2010, he received the Institute Award forResearch Excellence in Engineering at the Indian Institute of Science.During the past 15 years, he has been an active scientific collaborator with ahost of global R & D companies and research labs including General Motors R &D, IBM Research, Infosys Technologies, Intel, and Xerox Research.The current book represents a culmination of his teaching and research efforts ingame theory and mechanism design during the past decade.\nxiii\nbook\nJanuary 3, 2014\n11:48\nWorld Scientific Book - 10.25in x 7.5in\nThis page intentionally left blank\nbook\nJanuary 3, 2014\n11:48\nWorld Scientific Book - 10.25in x 7.5in\nPreface\nThe project of writing this book was conceived and conceptualized in December 2008during the Centenary Conference of the Indian Institute of Science, my Alma materthat has shaped my career, and life as well, for the past three and half decades. OnDecember 16, 2008, Professor Eric Maskin who had received the 2007 Sveriges Riksbank prize (aka Nobel Prize in Economic Sciences) (jointly with Professors LeonidHurwicz and Roger Myerson) gave a lively, lucid, enthralling, and inspirational talkentitled Mechanism Design: How to Implement Social Goals to an audience comprising more than 1500 scientists, engineers, and graduate students. Soon after this talk,it occurred to me that a book on game theory emphasizing not only non-cooperativegames and cooperative games but also mechanism design would be valuable for engineering audience (in general) and computer science audience (in particular). Ihad been teaching a game theory and mechanism design course to our master’s anddoctoral students in computer science since 2004. This coupled with the brief butbreathtakingly stimulating interaction with Professor Maskin sowed the seeds forundertaking this ambitious project of writing the book. It is therefore befittingthat the book is dedicated to Professor Eric Maskin and his co-laureates ProfessorsLeonid Hurwicz and Roger Myerson. This triumvirate, through their path-breakingwork on mechanism design, have opened up this discipline to numerous powerfulapplications cutting across boundaries of disciplines.Studying the rational behavior of entities interacting with each other in thecontext of a variety of contemporary applications such as Internet advertising, electronic marketplaces, social network monetization, crowdsourcing, and even carbonfootprint optimization, has been the bread and butter of our research group hereat the Game Theory Lab at the Department of Computer Science and Automation,Indian Institute of Science. Specifically, the application of game theoretic modelingand mechanism design principles to the area of Internet and network economics hasbeen an area of special interest to the group for a decade now.More than eight decades ago, the legendary John von Neumann played a significant role in the creation of two different exciting disciplines: Game Theory and Computer Science. Astonishingly, in the past fifteen years (1998-2013), There has beena spectacular convergence of the above two intellectual currents. The applications\nxv\nbook\nJanuary 3, 2014\n11:48\nxvi\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nof game theory and mechanism design to problem solving in engineering and computer science applications have exploded in these fifteen years. This phenomenoncertainly spurred us to dive into this area in the last decade.Further, during this period, there were other developments that made sure wegot locked into this area. Intel India, Bangalore, funded a collaborative project in2000 that required the development of a multi-attribute combinatorial procurementauction for their indirect materials procurement. General Motors R & D, Warren, Michigan, next collaborated with our group to develop procurement auctionmechanisms during 2002-2007. Meanwhile, Infosys Technologies, Bangalore, collaborated with us in 2006-07 on applying game theory and mechanism design to aninteresting web services composition problem. The current collaboration with theInfosys team is focused on using game theory and mechanism design techniques tocarbon footprint optimization. IBM India and IBM India Research Labs providedus with funding and a faculty award to make further explorations into this area. Allthis work culminated in a 2009 research monograph entitled Game Theoretic Problems in Network Economics and Mechanism Design Solutions (co-authored with mygraduate students Dinesh Garg, Ramasuri Narayanam, and Hastagiri Prakash) anda string of research papers. We are also currently engaged with Xerox Researchon fusing mechanism design with machine learning to extract superior performancefrom service markets. These projects have helped us to investigate deep practicalproblems, providing a perfect complement to our theoretical work in the area.We have also been fortunate to be working in this area during an eventful period when game theorists and mechanism designers have been awarded the NobelPrize in Economic Sciences. We were excited when Professors Robert Aumann andThomas Schelling were awarded the Prize 2005. In fact, we had an illuminating visitby Robert Aumann in January 2007 to the Indian Institute of Science. We weredelighted when, just two years later, Professors Leonid Hurwicz, Eric Maskin, andRoger Myerson were awarded the Prize in 2007 for their fundamental contributionsto mechanism design theory. Finally, our excitement knew no bounds in October2012 when Professors Lloyd Shapley and Professor Al Roth were announced as thewinners of the prize for 2012.Objectives of the BookSet in the above backdrop, this book strives to distill the key results in game theory and mechanism design and present them in a way that can be appreciated bystudents at senior undergraduate engineering level and above. The book includesa number of illustrative examples, carefully chosen from different domains including computer science, networks, engineering, and microeconomics; however they arefairly generic.There are numerous excellent textbooks and monographs available on game theory. This book has drawn inspiration from the following reference texts: Mas-Colell,\nbook\nJanuary 3, 2014\n11:48\nWorld Scientific Book - 10.25in x 7.5in\nPreface\nbook\nxvii\nWhinston, and Green [1]; Myerson [2]; Nisan, Roughgarden, Tardos, and Vazirani[3]; Shoham and Leyton Brown [4]; Straffin [5]; Osborne [6]; and the very recentbook by Maschler, Solan, and Zamir [7]. The dominating theme in many of theabove texts is social sciences, particularly microeconomics. Our book is different intwo ways. First, it has the primary objective of presenting the essentials of gametheory and mechanism design to an engineering audience. Since I happen to be froma computer science department, there is also an inevitable emphasis on computerscience based applications. Second, the book has a detailed coverage of mechanismdesign unlike most books on game theory. A precursor to this current book is anearlier monograph by Narahari, Garg, Narayanam, and Prakash [8].Outline and Organization of the BookThe book is structured into three parts: Non-cooperative game theory (Chapters2 to 13); Mechanism design (Chapters 14 to 24); and Cooperative game theory(Chapters 25 to 31). Chapter 1 is an introduction to the book and Chapter 32 is anepilogue while Chapter 33 attempts to provide a succinct discussion of mathematicalpreliminaries required for understanding the contents of the book.Each chapter commences with a motivation and central purpose of the chapter,and concludes with a crisp summary of key concepts and results in the chapter anda set of references to probe further. At the end of each chapter, a set of exerciseproblems is also included. In relevant chapters, programming assignments are alsosuggested. The book has a table of acronyms and notations at the beginning ofthe book. The book further contains, at relevant places, informative biographicalsketches of legendary researchers in game theory and mechanism design. We nowpresent a chapter-by-chapter outline of the book.Chapter Reading SequenceThe picture appearing overleaf depicts the sequential dependency among the mainchapters of the book. The rectangles corresponding to Part 1, Part 2, and Part 3 areshaded differently in the picture. The diagram is self-explanatory. Since Chapter32 (Epilogue) and Chapter 33 (Mathematical Preliminaries) have a special purpose,they are not depicted in the diagram.Part 1: Non-cooperative Game TheoryWe first introduce, in Chapter 2, key notions in game theory such as preferences,utilities, rationality, intelligence, and common knowledge. We then study two representations for non-cooperative games: extensive form representation (Chapter 3)and strategic form representation (Chapter 4).In Chapters 5,6, and 7, we describe different solution concepts which are fundamental to the analysis of strategic form games: dominant strategies and dominant\nJanuary 3, 2014\n11:48\nWorld Scientific Book - 10.25in x 7.5in\nxviii\nGame Theory and Mechanism Design\n1: Introduction\n2: Key Notions\n3: Extensive Form Games\n4: Strategic Form Games\n5: Dominant Strategy Equilibria\n6: Pure Strategy Nash Equilibrium\n10: Existence of Nash Equilibrium\n11: Computation of Nash Equilibrium\n7: Mixed Strategy Nash Equilibrium\n8: Utility Theory\n12: Complexity of ComputingNash Equlibrium\n13: Bayesian Games\n9: Matrix Games\n14: Introduction to Mechanism Design\n25: Correlated Strategies andCorrelated Equilibria\n15: Social Choice Functionsand Implementation\n26: Nash Bargaining Problem\n16: Incentive Compatibilityand Revelation Theorem\n27: Transferable Utility Games31: MatchingAlgorithms28: The Core\n17: Gibbard SatterthwaiteTheorem29: Shapley Value18: VCG Mechanisms\n30: Other Concepts inCooperative Game Theory\n19: Mechanism Design Spacein Quasilinear Environments\n20: Auctions\n21: Optimal Auctions\n22: Sponsored SearchAuctions\n23: Mechanism Design in CompleteInformation Settings\n24: Other Topics in Mechanism Design\nReading sequence of chapters in the book\nstrategy equilibria (Chapter 5); pure strategy Nash equilibrium (Chapter 6); andmixed strategy Nash equilibrium (Chapter 7). In Chapter 8, we introduce the utility theory of von Neumann and Morgenstern which forms the foundation for gametheory.Chapters 9, 10, 11, and 12 are devoted to studies on existence and computationof Nash equilibria. In Chapter 9, we focus on two player zero-sum games. In\nbook\nJanuary 3, 2014\n11:48\nWorld Scientific Book - 10.25in x 7.5in\nPreface\nbook\nxix\nChapter 10, we provide a detailed treatment of the Nash theorem that establishesthe existence of a mixed strategy Nash equilibrium in finite strategic form games.Chapter 11 is concerned with algorithmic computation of Nash equilibria whileChapter 12 deals with computational complexity of finding Nash equilibria.In Chapter 13, we introduce Bayesian games which are games with incompleteinformation. These games play a central role in mechanism design which is thesubject of Part 2 of the book.Part 2: Mechanism DesignMechanism design is the art of designing games so that they exhibit desirable equilibrium behavior. In this part (Chapters 14-24), we study fundamental principlesand key issues in mechanism design.In Chapter 14, we introduce mechanisms with simple, illustrative examples anddiscuss the key notions of social choice functions, direct mechanisms, and indirectmechanisms. In Chapter 15, we bring out the principles underlying implementationof social choice functions by mechanisms. In Chapter 16, we define the importantnotion of incentive compatibility and bring out the difference between dominantstrategy incentive compatibility (DSIC) and Bayesian incentive compatibility (BIC).We prove the revelation theorem, an important fundamental result. Chapter 17 isdevoted to two key impossibility results: the Gibbard-Satterwaite theorem and theArrow theorem.Chapters 18-22 are devoted to different classes of quasilinear mechanisms whichare either DSIC or BIC. In Chapter 18, we study VCG (Vickrey-Clarke-Groves)mechanisms, by far the most extensively investigated class of mechanisms. Chapter19 is devoted to an exploration of mechanism design space in quasilinear environment, including Bayesian mechanisms. In Chapter 20, we discuss auctions which area popular example of mechanisms. In Chapter 21, we study optimal mechanisms,in particular the Myerson auction. In Chapter 22, we study the sponsored searchauction problem in detail to illustrate a compelling application of mechanism design.In Chapter 23, we discuss implementation in Nash equilibrium which assumesa complete information setting. Finally, Chapter 24 provides a brief description ofimportant advanced topics in mechanism design.Part 3: Cooperative Game TheoryWe commence our study of cooperative game theory in Chapter 25 with a discussion on correlated strategies and correlated equilibrium. The Nash bargainingproblem represents one of the earliest and most influential results in cooperativegame theory. Chapter 26 describes the problem and proves the Nash bargainingresult. We introduce in Chapter 27, multiplayer coalitional games or characteristicform games. In particular, we introduce transferable utility games (TU games) withseveral illustrative examples.\nJanuary 3, 2014\n11:48\nWorld Scientific Book - 10.25in x 7.5in\nxx\nGame Theory and Mechanism Design\nChapters 28-30 are devoted to solution concepts in cooperative game theory. InChapter 28, we study the core, a central notion in cooperative game theory. TheShapley value is a popular solution concept that provides a unique allocation to aset of players in a cooperative game. In Chapter 29, we present the Shapley axiomsand prove the existence and uniqueness of the Shapley value. In Chapter 30, webriefly study five other important solution concepts in cooperative game theory:Stable sets, Bargaining sets, Kernel , Nucleolus, and Gately point. Chapter 31 isdevoted to the interesting topic of matching algorithms.We conclude the book in Chapter 32 with some thoughts on how best to utilize theinsights from the book. We have included, in Chapter 33, an appendix that containskey notions and results from probability theory, linear algebra, linear programming,mathematical analysis, and computational complexity, which are used in a crucialway at various points in this textbook.Intended AudienceThe primary audience for the book include: senior undergraduate, first year master’s, and first year research students studying computer science, networks, communications, electrical engineering, industrial engineering and operations research,microeconomics, and management science. Researchers and industry professionalswho wish to explore game theory and mechanism design in Internet and networkeconomics applications will find the book useful. After a thorough reading of thisbook, we expect that readers would be able to apply game theory and mechanismdesign in a principled and mature way to solve relevant problems. It is our sincerehope that the book will whet the appetite of the intended audience and arouse curiosity in this exciting subject. To provide an idea of how different types of audiencecould potentially benefit from this book, here are several examples:• Computer science students will be able to make forays into topical areas suchas algorithmic game theory, algorithmic mechanism design, computationalsocial choice, auctions and market design, electronic commerce, Internetmonetization, social network research, and mechanism design for multiagentsystems.• Computer science, electronics, and electrical engineering students would beable to explore research areas like network protocol design, dynamic resourceallocation in networked systems, design of multiagent smart grid networks,and network science.• Industrial engineering or management science students would be in a positionto undertake research in supply chain network design, logistics engineering,dynamic pricing in e-business, etc.• Researchers on inter-disciplinary topics such as cyberphysical systems, intelligent transportation, service science, green supply chains, and human\nbook\nJanuary 3, 2014\n11:48\nWorld Scientific Book - 10.25in x 7.5in\nPreface\nbook\nxxi\ncomputation systems (such as crowdsourcing networks) would be able toformulate and solve topical problems using the tools covered in this book.Possible Course OfferingsI have taught for several years a course on game theory to master’s and doctoralstudents at the Indian Institute of Science, Bangalore. About 80 percent of thestudents have been from a computer science background with the rest of the studentsdrawn from communications, electrical engineering, and management. In fact thebook can be considered as a culmination of my lovely experience with this coursespread over a number of years. The lecture notes of the course have survived thescrutiny of the talented students and in fact many of the students have contributedto this book by providing critical comments and suggestions. The course taught byme typically covers about 60 percent each of the contents in Part 1 (Non-cooperativegame theory); Part 2 (Mechanism design); and Part 3 (Cooperative game theory).With a judicious selection of topics, it is possible to design several courses basedon this book. We provide three possibilities below.Undergraduate Level Course on Game TheoryTo an audience consisting of third year or fourth year undergraduate students, thefollowing collection of topics would make an interesting course.• Non-cooperative game theory: Chapter 1, Chapter 2, Chapter 3, Chapter 4,Chapter 5, Chapter 6, Chapter 7, Chapter 9.• Cooperative game theory: Parts of Chapter 25, Chapter 26, Chapter 27,Chapter 28, Chapter 29, Chapter 31.• Mechanism design (optional): Parts of Chapter 13, Chapter 14, Chapter 15,Chapter 16, Chapter 20Master’s Level Course on Game TheoryTo an audience consisting of final year undergraduate students, master’s students,and first year graduate students, the entire book would be relevant. To cover theentire book as a one semester course would be challenging, so a judicious choice oftopics will be the key.Graduate Level Course on Game TheoryAbout 40 percent material of a graduate level course could be covered from this book.If the students have already gone through an undergraduate level course on gametheory (as explained above), then the remaining chapters of this book (especiallyChapter 10, Chapter 11, Chapter 12, Chapter 13, all chapters in mechanism design(Chapters 14-24), and all chapters in cooperative game theory (Chapters 25-31)\nJanuary 3, 2014\n11:48\nWorld Scientific Book - 10.25in x 7.5in\nxxii\nGame Theory and Mechanism Design\nwould provide the initial content. Appropriate material from advanced books andfrom the current literature should complement and complete such a course offering.\nConvention in Usage of Certain Common Words and PhrasesWe wish to draw the attention of the readers regarding use of certain words andphrases. We use the words players and agents interchangeably throughout the text.The words bidders, buyers, and sellers are often used to refer to players in anauction or a market. The words he and his are used symbolically to refer to boththe genders. This is not to be mistaken as gender bias. Occasionally we have alsoused the words she and her . We have also sporadically used the words it and itswhile referring to players or agents.Supplementary ResourcesThe URL http://lcm.csa.iisc.ernet.in/hari/book.html will take the interested readers to supplementary material which would be continuously updated. The materialincludes additional references, additional problems, solutions to selected exercises,and viewgraphs for selected chapters.\nFeedback is Welcome!No book is flawless. We invite you to report any flaws and provide your valuablecomments and suggestions by sending email to me at hari@csa.iisc.ernet.in. Wewould be delighted to post the clarifications on the website at the URL mentionedabove.\nReferences[1][2][3][4][5][6][7][8]\nAndreu Mas-Colell, Michael D. Whinst of this networkwould be happier if the time to travel from S to T is lower. Intuition tells us thatthe second configuration where we have an additional link should make the usershappier. However, game theoretic analysis proves, using equilibrium analysis, thatthe first configuration is in fact better for the users.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n4\nGame Theory and Mechanism Design\nA\n25\nm50\nS\nT\nSource\nDestination\n25\nm50\nB\nFig. 1.1: A transportation network with four nodes\nA25\nm50\n0\nS\nT\nSource\nDestination\n25\nm50\nB\nFig. 1.2: Transportation network with an additional high speed link from A to B\nThere is considerable evidence for the Braess paradox. For example, in Seoul,South Korea, traffic congestion around the city dramatically reduced when a particular high speed arterial link was closed for traffic as a part of the Cheonggyecheonrestoration project. In Stuttgart, Germany, a huge investment was made in decongesting the traffic on the roads by building additional roads but the traffic situationimproved only when some of the newly-built roads were closed for traffic. Gametheory could be used to obtain scientific predictions of what is likely to happen, bymodeling the situation as a game involving the users of the transportation networkand capturing their interactions. In chapters 4, 5, and 6, we study this example insome detail.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nIntroduction and Overview\nbook\n5\nVickrey AuctionConsider a seller who wishes to allocate an indivisible item to one of n prospectivebuyers in exchange for a payment. An example would be the sale of a spectrumlicense by the Government to one of several telecom service providers seeking to buythe license (See Figure 1.3). Each player has a certain valuation for the item onsale. For example, in the spectrum license case, imagine that there are four serviceproviders 1, 2, 3, 4 who value the license at Rs. 400 million, Rs. 500 million, Rs. 700million, and Rs. 1000 million. In a spectrum auction, the Government invites bidsfrom prospective buyers and allocates the license based on an auction protocol. Twosimple and common auction methods are first price sealed bid auction and secondprice sealed bid auction. In the first price auction, the one who bids highest will beallocated the item and the winning bidder will pay an amount equal to the bid. Inthe second price auction, the one who bids highest will be allocated the item butthe winning bidder will pay an amount equal to the second highest bid.\nSpectrumBuyer 1\n···...\n...\n···Buyer 2\nSeller\nBuyer n\nFig. 1.3: A spectrum auctionEach auction above can be modeled as a game involving the seller and the buyers.In the first price auction, the bidders will bid amounts which are less than theirvaluations. In the second price auction, the bidding will be more aggressive sincethe bidders know that they would be paying less than what they bid in case they win.William Vickrey, in his Nobel prize winning work, proved the remarkable result thatthe bids in the second price auction will be exactly equal to the respective valuations.In fact, Vickrey showed that it is best for every bidder to bid her true valuationirrespective of whatever is bid by the other players. In the example above, if secondprice auction is employed, then the players will bid their valuations and the license\nDecember 27, 2013\n11:21\n6\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nwill be awarded to player 4. This player will pay an amount equal to Rs. 700 millionwhich is the second highest bid. Thus the seller who does not know the valuationsof the bidders is able to extract these valuations in the form of their bids. Gametheory and mechanism design constitute the science behind the design of a wholegamut of auction protocols which are ubiquitous and extensively used these days.Divide the Dollar GameSuppose there are three individuals who wish to divide a total wealth of 300 amongthemselves. Each player can propose an allocation such that no player’s payoff isnegative and the sum of all the payoffs does not exceed 300. Assume that if two ormore players propose the same allocation, then that allocation will be implemented.For example, if players 1 and 2 propose an allocation (150, 150, 0) and player 3proposes (100, 100, 100), the allocation (150, 150, 0) will be implemented. However,player 3 may tempt player 2 with the allocation (0, 225, 75) and if players 2 and3 propose this, the original allocation (150, 150, 0) gets overturned. Note that thisallocation is strictly better for both 2 and 3. Player 1 may now entice player 3 andjointly propose with player 3 an allocation (200, 0, 100) which is better for both 1and 3. Bargaining of this kind can be never ending leading to the perpetual breakingand making of coalitions. This is a situation that is common in the real world (forexample in politics and business).Predicting the final outcome in such situations is hard using conventional techniques. Cooperative game theory helps us analyze such situations in a systematicand scientific way. For example, by modeling the above as a cooperative game, onecan show that the core of this game is empty implying that none of the allocationsis stable and can always by derailed by a pair of players coming together. One canalso show that the Shapley value of this game is (100, 100, 100) which provides a fairway of allocating the wealth among the three players in this case.Game Theory: A Rich HistoryGame theory, as a mathematical discipline and modeling tool, has a rich historyand its foundations and advances have been the contributions of some of the mostbrilliant minds of the twentieth century. Figure 1.4 shows the legends who havemade path breaking contributions to game theory and mechanism design. Johnvon Neumann and Oskar Morgenstern were the principal architects of game theoryin the late 1920s, 1930s, and early 1940s. Their marvelous collaboration built thefoundations of game theory and yielded a monumental book entitled The Theory ofGames and Economic Behavior [2]. This book continues to be an authentic sourceof early pioneering results in game theory. Following their work, several celebratedgame theorists have contributed to developing game theory as the science of economics. The importance of the discipline of game theory and their contributionshave been recognized through a number of Sveriges Riksbank prizes (Nobel Prize\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nIntroduction and Overview\nbook\n7\nin Economic Sciences) being awarded to game theorists, including the 1994, 1996,2005, 2007, and 2012 prizes. In fact, between 1994 and 2012, as many as 11 gametheorists have been awarded the prize.\nFig. 1.4: Legends of game theory and mechanism design\nJohn Nash, John Harsanyi, and Reinhard Selten received the prize in 1994 fortheir path breaking work in equilibrium analysis of games. William Vickrey won theprize in 1996 for his influential work in auction theory. In 2005, Robert Aumannand Thomas Schelling received the prize for having enhanced the understandingof conflict and cooperation through game theory analysis. In 2007, the prize wasawarded to Leonid Hurwicz, Eric Maskin, and Roger Myerson for their fundamentalcontributions to mechanism design theory. More recently, in 2012, Lloyd Shapleyand Alvin Roth have been awarded the prize for advancing the theory of stable allocations and the practice of market design. Before all these contributions, KennethArrow had been awarded the prize in 1972 for his masterly work on social choicetheory which had been carried out as early as 1950s. Clearly, game theory andmechanism design have held the center-stage for several decades now in the area ofsocial sciences. The development of game theory can be truly described as one ofthe most significant achievements of the twentieth century since it has shown thatmathematical reasoning can be applied to studying complex human interactions.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n8\n1.2\nGame Theory and Mechanism Design\nCurrent Trends and Modern Applications\nSince the 1990s, two related threads have catapulted game theory to the centerstageof problem solving in modern times. The first thread is the emergence of theoreticalresearch areas at the interface of game theory and varied subjects like computerscience, network science, and other engineering sciences. The second thread is thenatural and often compelling use of game theory in breathtaking new applicationsin the Internet era. In the modern era, game theory has become a key ingredient forsolving problems in areas as diverse as electronic commerce and business, Internetadvertising, social network analysis and monetization, wireless networks, intelligenttransportation, smart grids, and carbon footprint optimization. We touch upon afew relevant current trends and modern applications.\nCurrent TrendsTo illustrate the first thread above, we allude to a lively new theoretical researcharea, algorithmic game theory, at the interface of game theory and computer science. The importance and limelight can be appreciated by the fact that the 2012Gödel Prize which recognizes outstanding papers in theoretical computer science hasbeen awarded to six researchers (Elias Koutsoupias, Christos Papadimitriou, TimRoughgarden, Eva Tardos, Noam Nisan, and Amir Ronen) in algorithmic game theory. The award has cited three papers [3, 4, 5] which have laid the foundations inthis area. Here is a brief overview of the three papers to get a quick idea of thecentral themes in this area.Koutsoupias and Papadimitriou [3] introduced the key notion of price of anarchyin their paper entitled Worst-case Equilibria. The price of anarchy measures theextent to which selfish behavior by decentralized agents affects the achievement ofa social optimum. In particular, the paper quantifies how much efficiency is lostdue to selfish behavior on the Internet which does not have a central monitor orauthority to coordinate or control the actions of its users. Their study is based ona game theoretic model of the Internet and they use the notion of Nash equilibriumto formalize the concept of price of anarchy.The concept of price of anarchy is used by Roughgarden and Tardos [4] to studythe specific problem of routing traffic in large scale transportation networks or communication networks. Their beautiful analysis explains the well known Braess’sparadox (see Chapters 4 and 5) in transportation science using a game theoreticmodel and establishes the relationship between centrally optimized routing and selfish routing in congested networks. Through such studies, game theory becomes avaluable tool for design of routing policies and traffic networks.The third Gödel prize winning paper by Nisan and Ronen [5] proposes a fascinating new problem domain which they call algorithmic mechanism design. In thispaper, the authors show how game theory and mechanism design could be used to\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nIntroduction and Overview\nbook\n9\nsolve algorithmic problems where the inputs to the problem constitute the privateinformation of rational and intelligent agents. Traditional computer science assumesthat algorithms once designed will work as per design when executed. The computing systems that execute the algorithms will follow the rules written for themfaithfully. However if self-interested participants are required to provide inputs tothe computing system during the execution of the algorithm, the inputs providedto the algorithm may or may not be truthful. Making algorithms robust to manipulation by strategic agents is the central theme of algorithmic mechanism design.Algorithmic game theory is now an active research area in many leading computerscience departments in the world. It represents one of many such recent researchtrends in which game theory is a key ingredient.We now take a look at the second thread which has pushed game theory to theforefront of problem solving. This thread is inspired by a natural relevance of gametheory to many emerging applications in the Internet era.Some Modern ApplicationsModern applications often involve the Internet which often encourages strategic behavior by the users due to its decentralized nature. Also, modern applications inthe social, economic, or business domain invariably involve individuals and organizations which have their own self-interests and act strategically. To make thesemodern applications perform as intended in spite of the presence of strategic usersin the system, one could use creative techniques offered by game theory and mechanism design as a part of system design. This explains the second trend that haspushed game theory and mechanism design to the forefront. To drive home thepoint that game theory has proved crucial for advancing the current art in modernday problem solving, we provide four examples below.Matching MarketsThis is a traditional problem setting that continues to throw up exciting new applications in modern times as well. Matching is the process of allocating one set ofresources or individuals to another set of resources or individuals. Examples includematching buyers to sellers in a market; matching resources to tasks; matching newdoctors to hospitals; matching job-seeking engineers to companies; and matchingstudents to schools (see Figure 1.5). There are also examples with deep societalimpact such as matching kidneys to patients (or in general organ donors to organrecipients). Such matching problems are broadly categorized into marriage problems and house allocation problems. In a marriage problem, the resources on eachside of the market have preferences over the resources on the other side. In houseallocation, only resources on one of the sides have preferences over the resourceson the other side. In either case, the matching has to be accomplished so that theindividual preferences are honored and performance is optimized.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n10\nGame Theory and Mechanism Design\nInc.\nCV\nInc.\nCV\n...\n...\nInc.\nCV\nStudents(Doctors / Engineers)\nMatching Market\nOrganizations(Hospitals / Companies)\nFig. 1.5: A matching market\nTwo key requirements of any solution to the matching problem are stability andincentive compatibility. Informally, a solution is said to be stable if the solutioncannot become strictly better through a reallocation. A solution is called incentivecompatible if the preferences are reported truthfully by all the agents. Game theoryhas been used to analyze in a rigorous manner both stability and incentive compatibility. Since the 1960s, game theory and game theorists have contributed immenselyto the development of a comprehensive theory of matching markets. The existenceof a large number of successful matching markets in real world applications is oneof the significant successes of game theory. In fact, the Nobel Prize in EconomicSciences for the year 2012 has been awarded to Lloyd Shapley and Alvin Roth fortheir pioneering work on matching theory and matching markets [6].Matching markets have many socially important applications such as competitivematching of colleges with students and hospitals with interns, leading to maximization of social welfare. They have also saved precious human lives through betterand faster matching of kidneys and human organs. Game theory and mechanismdesign have played a significant role in ensuring the success of these markets.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nIntroduction and Overview\nbook\n11\nSponsored Search AuctionsSponsored search is by now a well known example of an extremely successful businessmodel in Internet advertising. When a user searches a keyword, the search enginedelivers a page with numerous results containing the links that are relevant to thekeyword and also sponsored links that correspond to advertisements of selectedadvertisers. Figure 1.6 depicts a typical scenario.\nFig. 1.6: Keyword auction on a search engineWhen a sponsored link is clicked, the user is directed to the corresponding advertiser’s web page. In the commonly used pay-per-click model, the advertiser makes acertain payment to the search engine for directing the user to its web page. Againstevery search performed by any user on any keyword, the search engine faces theproblem of matching a set of advertisers to the (limited number of) sponsored slots.In addition, the search engine also needs to decide on a payment to be made by theadvertiser against each click. Most search engines currently use an auction mechanism for this purpose, known as sponsored search auction. A significant percentageof the revenue of Internet giants such as Google, Microsoft, Yahoo!, etc., accruesfrom sponsored search auctions. In a typical sponsored search auction, advertisersare invited to specify their willingness to pay for their preferred keywords, that is,the maximum amount they would be willing to pay when an Internet user clickson the respective sponsored slots. This willingness to pay is typically referred to ascost-per-click . Based on the bids submitted by the advertisers for a particular keyword, the search engine determines (1) a subset of advertisements to display; (2) the\nDecember 27, 2013\n11:21\n12\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\norder in which the selected advertisements are displayed; and (3) the payments tobe made by the selected advertisers when their respective slots are clicked by a user.The actual payment to be made depends on the bids submitted by the advertisers.The decisions (1), (2), and (3) constitute the sponsored search auction mechanism.The search engine would typically like to maximize its revenue whereas the advertisers would wish to achieve maximum payoffs within a given budget. This leadsto a classic game situation where the search engine and the advertisers are the players. The players are rational in the sense of trying to maximize their payoffs andthis induces the advertisers to bid strategically after computing their best possiblebids. The problem of designing a sponsored search auction mechanism becomes aproblem of designing a game involving the search engine and the advertisers. Therules of the game have to be designed in a way that a well defined set of criteriawould be realized by an equilibrium solution for the game.Crowdsourcing MechanismsIn the recent years, crowdsourcing has emerged as a major paradigm for getting workdone through a large group of human resources. It can be described as distributionof work to a possibly unknown group of human resources in the form of an open call.There is a proliferation of crowdsourcing platforms in the past few years. Some of theprominent ones are Amazon Mechanical Turk, CrowdCloud, CrowdFlower, Elance,Innocentive, Taskcn, Topcoder, etc. Examples of tasks typically performed usingcrowdsourcing include: labeling of images, graphical design of logos, preparation ofmarketing plans, design of websites, developing efficient code for algorithmic businessproblems, classification of documents (legal documents, patents, etc.), translationservices from one language to another, eliciting answers for questions, search andrescue missions in a wide geographical area, etc.A well known crowdsourcing experiment in the recent times is the DARPA redballoon challenge which involved discovering, in as short a time as possible, 10red balloons that were launched at ten undisclosed locations in the United States(locations shown in Figure 1.7). The total prize money was US$ 40000. The winningteam from the Massachusetts Institute of Technology (MIT) employed the followingmechanism. First a team of volunteers was recruited (first level volunteers) and eachmember of this team recruited second level volunteers. The second level volunteersrecruited third level volunteers, and so on. The volunteer (say X) who first discoversa red balloon and reports it will get an incentive of US$ 2000 while the volunteer (sayY) who recruited X will get an incentive of US$ 1000, the volunteer who recruitedY will get US$ 500, and so on. The above mechanism proved highly successful andthe MIT team was able to discover all ten red balloons in less than 10 hours time.The winning mechanism is an excellent example of application of game theory andmechanism design to this fascinating challenge.In general, there are many research questions involved in deriving success out of\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nIntroduction and Overview\nbook\n13\nFig. 1.7: Location of ten red balloons in the DARPA challengecrowdsourcing. These issues include: attracting participation in required numbers,deciding on the nature and extent of incentives (cash or kind), eliciting truthful reports from the participants, and ensuring quality, timeliness, and cost-effectivenessof task execution. Game theory and mechanism design prove to be critical ingredients in designing such crowdsourcing campaigns.Social Network AnalysisSocial networks are now ubiquitous and are useful for many applications includinginformation diffusion, electronic business, and search. Social network analysis is central to numerous Internet-based applications, for example, viral marketing, influencemaximization, and influence limitation, that are based on social networks. Existingmethods and tools for social network analysis have a lacuna: they do not capture thebehavior (such as rationality and intelligence) of individual nodes nor do they modelthe strategic interactions that occur among these nodes. Game theory is a naturaltool to overcome this inadequacy since it provides rigorous mathematical models ofstrategic interaction among autonomous, intelligent, and rational agents which formthe nodes of a social network. The books by Jackson [7] and Easley and Kleinberg[1] emphasize the use of game theory in studying several social network analysisproblems such as predicting topologies of social networks, modeling informationdiffusion, etc. For example, Figure 1.8 shows a social network in which the fourmost influential nodes have been identified using Shapley value, a solution concept\nDecember 27, 2013\n11:21\n14\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nin cooperative game theory [8]. Game theoretic approaches provide a suitable approach to designing scalable algorithms for social network analysis. Mechanismdesign has proved valuable in the area of social network monetization. Numerousapplications using social networks have emerged in the recent times which have beenenabled by the use of game theory and mechanism design.\nFig. 1.8: Influential nodes in a social network\n1.3\nOutline of this Book\nIn the foregoing discussion, we have seen the increasingly influential and usefulrole game theory and mechanism design have come to play in inter-disciplinaryresearch and modern applications. There is thus a heightened need to digest thefoundations of game theory and mechanism design to gain a deeper understandingand appreciation of the value of game theory in the emerging applications. Thistextbook strives to fulfill this need.After a thorough reading of the book, we expect that the reader will be ableto use game theory and mechanism design to model, analyze, and solve centralizedas well as decentralized design problems involving multiple autonomous agents thatinteract strategically in a rational and intelligent way. The book only assumesfamiliarity with an elementary course on calculus and probability. Familiarity withfoundational aspects of linear algebra, real analysis, and optimization will be useful.The mathematical appendix included in Chapter 33 presents the key mathematicalconcepts and results that are used in the book.There are numerous excellent textbooks and monographs available on game theory. Many of these textbooks are inspired by social sciences in general and microeconomics in particular. Our book has the primary objective of presenting theessentials of game theory and mechanism design to senior undergraduate studentsand above from various branches of engineering.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nIntroduction and Overview\nbook\n15\nThe book is structured into three parts:(1) Non-cooperative game theory (Chapters 2 to 13)(2) Mechanism design (Chapters 14 to 24)(3) Cooperative game theory (Chapters 25 to 31)In Part 1 (non-cooperative game theory), the chapters are devoted to key notions(such as utilities, rationality, intelligence, and common knowledge); extensive formgames; strategic form games; dominant strategy equilibria; pure strategy Nash equilibria; mixed strategy Nash equilibria; utility theory; two person zero-sum games;existence theorems for Nash equilibrium (including the Nash theorem); computationof Nash equilibria; complexity of computing Nash equilibria; and Bayesian games,Part 2 (mechanism design) is concerned with design of games. The chapters coverthe following topics: building blocks of mechanisms; social choice functions and theirimplementation using mechanisms; notion of incentive compatibility and the equivalence of direct mechanisms and indirect mechanisms; the Gibbard-Satterthwaitetheorem and the Arrow impossibility theorem; Vickrey-Clarke-Groves mechanisms;possibility and impossibility results in mechanism design; auctions and revenueequivalence theorem; optimal auctions; case study of sponsored search auctions;and mechanism implementation in ex-post Nash equilibrium.Cooperative game theory is covered in Part 3. The chapters are devoted tocorrelated strategies and correlated equilibrium; Nash bargaining theory; coalitionalgames in characteristic form; the core of coalitional games; Shapley value; othersolution concepts; and matching algorithms.Chapter 32 (Epilogue) brings out the value game theory and mechanism designprovide to a researcher in engineering sciences. Chapter 33 consists of a mathematical appendix that includes key concepts and results in probability, linear algebra,linear programming, mathematical analysis, and computational complexity whichare often used in the textbook.Each of the chapters commences with a motivating introduction to the chapter and concludes with a crisp summary of the chapter and a list of references toprobe further. A set of problems is included in every chapter. Concepts and resultsare illustrated using a number of examples. These examples are carefully chosenfrom different domains including computer science, networks, and microeconomics;however they are fairly generic. The chapters also contain, at relevant places, informative biographical sketches of game theorists and mechanism designers who havemadeWe need to emphasize that our book is inspired by, and, indeed, has immenselybenefited from the superb expositions available in the following books and monographs: Mas-Colell, Whinston, and Green [9]; Myerson [10]; Maschler, Solan, andZamir [11]; Nisan, Roughgarden, Tardos, and Vazirani [12]; Shoham and LeytonBrown [13]; Straffin [14]; and Osborne [15]. The monograph by Narahari, Garg,Narayanam, and Prakash [16] can be considered as a precursor to the current effort.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n16\nGame Theory and Mechanism Design\nA superb collection of classic papers in game theory brought out in 1997 [17] isa must read for passionate students and researchers. We also refer the readers to arecent, very comprehensive book by Maschler, Solan, and Zamir [11].References[1][2][3][4][5][6]\n[7][8]\n[9][10][11][12][13][14][15][16][17]\nDavid Easley and Jon Kleinberg. Networks, Crowds, and Markets: Reasoning About a HighlyConnected World. Cambridge University Press, 2010.John von Neumann and Oskar Morgenstern. Theory of Games and Economic Behavior.Princeton University Press, 1944.E. Koutsoupias and C. Papadimitriou. “Worst-case equilibria”. In: Computer Science Review3(2) (2009), pp. 65–69.T. Roughgarden and E. Tardos. “How bad is selfish routing?” In: Journal of ACM 49(2)(2002), pp. 236–259.N. Nisan and A. Ronen. “Algorithmic mechanism design”. In: Games and Economic Behavior35(1-2) (2001), pp. 166–196.The Economic Sciences Prize Committee. Stable matching: Theory, Evidence, and PracticalDesign - The Sveriges Riksbank Prize in Economic Sciences in Memory of Alfred Nobel 2012:Scientific Background. Tech. rep. The Nobel Foundation, Stockholm, Sweden, 2012.Mathew O. Jackson. Social and Economic Networks. Princeton University Press, Princeton,NJ, USA, 2007.Ramasuri Narayanam and Y. Narahari. “A Shapley value approach to discovering influentialnodes in social networks”. In: IEEE Transactions on Automation Science and Engineering8(1) (2011), pp. 130–147.Andreu Mas-Colell, Michael D. Whinston, and Jerry R. Green. Microeconomic Theory. Oxford University Press, 1995.Roger B. Myerson. Game Theory: Analysis of Conflict. Harvard University Press, Cambridge,Massachusetts, USA, 1997.Michael Maschler, Eilon Solan, and Shmuel Zamir. Game Theory. Cambridge UniversityPress, 2013.Noam Nisan, Tim Roughgarden, Eva Tardos, and Vijay Vazirani (Editors). Algorithmic GameTheory. Cambridge University Press, 2007.Yoam Shoham and Kevin Leyton-Brown. Multiagent Systems: Algorithmic, Game-Theoretic,and Logical Foundations. Cambridge University Press, New York, USA, 2009, 2009.Philip D. Straffin Jr. Game Theory and Strategy. The Mathematical Association of America,1993.Martin J. Osborne. An Introduction to Game Theory. The MIT Press, 2003.Y. Narahari, Dinesh Garg, Ramasuri Narayanam, and Hastagiri Prakash. Game TheoreticProblems in Network Economics and Mechanism Design Solutions. Springer, London, 2009.Harold W. Kuhn (Editor). Classics in Game Theory. Princeton University Press, 1997.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nPART 1\nNON-COOPERATIVE GAME THEORY\nInformally, non-cooperative games are those in which the actions of individual players formthe primitives while in cooperative games, joint actions of groups of players form the primitives. In this part, we study non-cooperative games spread over 12 chapters (Chapters2-13).• We first introduce, in Chapter 2, key notions in game theory such as preferences,utilities, rationality, intelligence, and common knowledge. We then study two representations for non-cooperative games: extensive form representation (Chapter 3) andstrategic form representation (Chapter 4).• In Chapters 5, 6, and 7, we describe different solution concepts which are fundamentalto the analysis of strategic form games: dominant strategies and dominant strategyequilibria (Chapter 5); pure strategy Nash equilibrium (Chapter 6); and mixed strategyNash equilibrium (Chapter 7). In Chapter 8, we introduce the utility theory of vonNeumann and Morgenstern which forms the foundation for game theory.• Chapters 9, 10, 11, and 12 are devoted to studies on existence and computation ofNash equilibria. In Chapter 9, we focus on two player zero-sum games. In Chapter10, we provide a detailed treatment of the Nash theorem that establishes the existenceof a mixed strategy Nash equilibrium in finite strategic form games. Chapter 11 isconcerned with algorithmic computation of Nash equilibria while Chapter 12 deals withcomputational complexity of finding Nash equilibria.• In Chapter 13, we introduce Bayesian games which are games with incomplete information. These games play a central role in mechanism design which is the subject ofPart 2 of the book.\n17\nbook\nJanuary 3, 2014\n11:48\nWorld Scientific Book - 10.25in x 7.5in\nThis page intentionally left blank\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nChapter 2\nKey Notions in Game Theory\nWe commence this chapter with a discussion of a simple coordination game toillustrate the building blocks of a strategic form game. Next we introduce thereaders to key notions which are fundamental to game theory. These notions includepreferences, utilities or payoffs, rationality, intelligence, and common knowledge.We also include a brief discussion on different types of games.\nGame theory may be defined as the study of mathematical models of interactionbetween rational, intelligent decision makers [1]. The decision makers are usuallyreferred to as players or agents. The interaction may involve conflict as well ascooperation. Game theory provides general mathematical techniques for analyzingsituations in which two or more players make decisions that influence one another’swelfare. A game could be considered as a mathematical model of a situation whereevery player strives to obtain her best possible outcome, knowing fully well that allother players are also striving to obtain their respective best possible outcomes [2].2.1\nStrategic Form Games\nBefore we describe key notions in game theory, we first introduce a representationof games called strategic form games or normal form games, a very commonly usedrepresentation for games. In fact, this book mostly deals with this representationof games.Example 2.1. Consider the example of the student coordination problem discussed inSection 1.1 of the previous chapter. For the sake of convenience, let us rename IISc as A andMG Road as B. We have two players, namely, students 1 and 2. Each of them can choose anyaction or strategy from the set {A, B}. They choose their individual actions simultaneously,independent of each other. Depending on the strategies chosen, the two players obtainpayoffs as shown in Table 2.1. This situation motivates the following definition.\u0003\nDefinition 2.1. (Strategic Form Game). A strategic form game Γ is a tuplehN, (Si )i∈N , (ui )i∈N i, where• N = {1, 2, . . . , n} is a set of players;19\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n20\nGame Theory and Mechanism Design\n21\nA\nB\nAB\n10, 100, 0\n0, 01, 1\nTable 2.1: Payoffs for the students in different outcomes\n• S1 , S2 , . . . , Sn are sets called the strategy sets of the players 1, . . . , n, respectively; and• ui : S1 × S2 × · · · × Sn → R for i = 1, 2, . . . , n are mappings called the utilityfunctions or payoff functions.Example 2.2. For the example being discussed, it is clear thatN = {1, 2}; S1 = S2 = {A, B};u1 (A, A) = 10; u1 (A, B) = 0; u1 (B, A) = 0; u1 (B, B) = 1;u2 (A, A) = 10; u2 (A, B) = 0; u2 (B, A) = 0; u2 (B, B) = 1.Note that the utilities of a player depend not only on his strategies but also on the strategiesplayed by the other players.\u0003\nThe strategies are also called actions or more specifically pure strategies. We denoteby S, the Cartesian product S1 × S2 × · · · × Sn . The set S is the collection of allstrategy profiles or strategy vectors (we use the phrase strategy profiles in the rest ofthe book) of the players. Every profile of strategies corresponds to an outcome in thegame. We use the phrases strategy profile and outcome synonymously. Also, we usethe terms players, individuals, persons, decision makers, and agents synonymously.A strategic form game is a simultaneous move game that captures each agent’sdecision problem of choosing a strategy that will counter the strategies adopted bythe other agents. Each player is faced with this problem and therefore the playerscan be thought of as simultaneously choosing their strategies from the respectivesets S1 , S2 , . . . , Sn . We can view the play of a strategic form game as follows: eachplayer simultaneously selects a strategy and informs this to a neutral observer whothen computes the outcome and the utilities. We will be presenting several examplesof strategic form games in Chapter 4.There are certain key notions which are fundamental to game theory. We nowdiscuss these notions and a few related issues.2.2\nPreferences\nThe student coordination game has four outcomes, namely (A, A), (A, B), (B, A),and (B, B) which are also the four strategy profiles. Each student has certain\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nKey Notions in Game Theory\nbook\n21\npreferences over these outcomes. Clearly, in this case, each student prefers outcome(A, A) over (B, B); prefers outcome (B, B) over outcomes (A, B) and (B, A); andhas no preference between (A, B) and (B, A). The preferences that a player hasover outcomes can be formalized as a preference relation over the set of outcomes S.We will be studying this relation formally in Chapter 8. In the current context, it isuseful to know that the preference relation of each player will be reflexive, transitive,and complete (that is, every pair of outcomes is covered by the relation). Obviously,in a general situation, the preference relations of different players will be different(though in the current example, both players have the same preference relation).\n2.3\nUtilities\nThe utility function or payoff function of a player is a real valued function definedon the set of all outcomes or strategy profiles. The utility function of each playermaps multi-dimensional information (strategy profiles) into real numbers to capturepreferences. It is important to note that the utility of a player in an outcome dependsnot only on his own strategy but also on the strategies of the rest of the players.One can ask the question whether it is possible at all to map preference profiles toreal numbers without losing any preference information. The utility theory of vonNeumann and Morgenstern [3] deals with this problem in a systematic and scientificway. In fact, von Neumann and Morgenstern stated and proved in [3] a significantresult that establishes that there must exist a way of assigning real numbers todifferent strategy profiles in a way that the decision maker would always choose theoption that maximizes her expected utility. This theorem holds under quite weakassumptions about how a rational decision maker behaves. We will defer a detaileddiscussion of this topic to Chapter 8.\n2.4\nRationality\nOne of the key assumptions in game theory is that the players are rational. Anagent is said to be rational if the agent always makes decisions in pursuit of her ownobjectives. In particular, it is assumed that each agent’s objective is to maximizethe expected value of her own payoff measured in some utility scale. The abovenotion of rationality (maximization of expected utility) was initially proposed byBernoulli (1738) and later formalized by von Neumann and Morgenstern (1944) [3].A key observation would be that rationality implies selfishness of the agent if herutility function captures her self-interest. It is important to note that self-interestdoes not mean that each player wants to harm the other players. It also doesnot necessarily mean that the players only care about themselves. Self-interest onlymeans that each player has certain individual preferences over the outcomes and theplayer consistently seeks to obtain these preferred outcomes. A player’s preferred\nDecember 27, 2013\n11:21\n22\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\noutcomes could include outcomes which are preferred by some other players as well.For example, if the utility function of a player captures the altruistic nature of thatplayer, then rationality would imply altruism.\nJohn von Neumann (1903 - 1957) is respected as one of theforemost mathematicians of the 20th century. He is regarded asthe founding father of game theory. He was born in Budapest,Hungary on December 28, 1903. He was a mathematical geniusfrom early childhood. Ironically and interestingly, however, hisfirst major degree was in chemical engineering from the SwissFederal Institute of Technology in Zurich. In 1926, he earneda Doctorate in Mathematics from the University of Budapest,working with Professor Leopold Fezer.During 1926 to 1930, he taught in Berlin and Hamburg, and from 1930 to 1933, hetaught at the Princeton University. In 1933, he was appointed as one of the six professors of the School of Mathematics at the Institute for Advanced Study in Princetonand he was the youngest among them. Albert Einstein and Kurt Godël were two ofhis distinguished colleagues at the center. During his glittering scientific career, vonNeumann created several intellectual currents, two of the major ones being game theory and computer science. The fact that these two disciplines have converged duringthe 1990s and 2000s, almost sixty years after von Neumann brilliantly created them,is a true example of his visionary genius. In addition to game theory and computerscience, he made stunning contributions to a wide array of disciplines including settheory, functional analysis, quantum mechanics, ergodic theory, continuous geometry,numerical analysis, hydrodynamics, and statistics. He is best known for his minimaxtheorem, utility theory, von Neumann algebras, von Neumann architecture, and cellular automata.In game theory, von Neumann’s first significant contribution wasthe minimax theorem, which proves the existence of a randomized saddle point in twoplayer zero sum games. His collaboration with Oskar Morgenstern at the Institutefor Advanced Study resulted in the classic book The Theory of Games and EconomicBehavior , which to this day continues to be an authentic source of early game theoryresults. This book contains a deep discussion of many fundamental notions of gametheory such as utilities, saddle points, coalitional games, bargaining sets, etc. vonNeumann was associated with the development of the first electronic computer in the1940s. He wrote a widely circulated paper entitled the First Draft of a Report onthe EDVAC in which he described a computer architecture (which is now famouslycalled the von Neumann architecture). He is also credited with the development ofthe notions of a computer algorithm and algorithm complexity.\nMaximizing expected utility is not necessarily the same as maximizing expectedmonetary returns. In general, utility and money are nonlinearly related. For example, a certain amount of money may provide different utilities to different playersdepending on how endowed or desperate they are.When there are two or more players, it would be the case that the solution to\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nKey Notions in Game Theory\nbook\n23\neach player’s decision problem depends on the others’ individual problems and viceversa. When such rational decision makers interact, their decision problems haveto be analyzed together, like a system of simultaneous equations [1]. Game theoryprovides an apt and natural mathematical framework to deal with such analysis.\nOskar Morgenstern (1902-1977) is widely known for his famous collaboration with John von Neumann which led to thecelebrated book The Theory of Games and Economic Behavior in 1944. Their collaboration at the Institute for AdvancedStudy is quite legendary and was spread over 1928 - 44. Theutility theory which is fundamental to game theory is rightlynamed after von Neumann and Morgenstern. Prior to this book,Morgenstern had authored another pioneering book EconomicPrediction.He also wrote a scholarly book in 1950, On the Accuracy of Economic Observations.In this book, he came down heavily on what he described as unscientific use of data onnational income to deduce far-reaching conclusions about the state of the economy andto formulate major government policies. He is well known for applying game theory tobusiness problems. Morgenstern was born in Germany in 1902 and studied economicsin Vienna. When Adolf Hitler invaded Vienna, he was fortunately at Princeton wherehe continued to work until retirement. He was initially in the Princeton Universityand later moved to the Institute for Advanced Study at Princeton to collaborate withvon Neumann. Morgenstern passed away in 1977.\n2.5\nIntelligence\nAnother key notion in game theory is that of intelligence of the players. This notionmeans that each player in the game knows everything about the game that a gametheorist knows, and the player is competent enough to make any inferences aboutthe game that a game theorist can make. In particular, an intelligent player isstrategic, that is, would fully take into account his knowledge or expectation ofbehavior of other agents in determining what his optimal response should be. Wecall such a strategy a best response strategy. Each player is assumed to have enoughresources to carry out the required computations involved in determining a bestresponse strategy.Myerson [1] provides a convincing explanation to show that the two assumptionsof rationality and intelligence are indeed logical and reasonable. The assumptionthat all individuals are rational and intelligent may not exactly be satisfied in atypical real-world situation. However, any theory that is not consistent with theassumptions of rationality and intelligence loses credibility on the following count:\nDecember 27, 2013\n11:21\n24\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\n“If a theory predicts that some individuals will be systematically fooled into making mistakes, then this theory will lose validity when individuals learn to betterunderstand the situations.” On the other hand, a theory based on rationality andintelligence assumptions would be sustainable.\nRobert Aumann is a celebrated game theorist who has madepath-breaking contributions to a wide spectrum of topics ingame theory such as repeated games, correlated equilibria, bargaining theory, cooperative game theory, etc. Aumann providedin 1976 [4] a convincing explanation of the notion of commonknowledge in game theory, in a classic paper entitled Agreeing to disagree (which appeared in the Annals of Statistics).Aumann’s work in the 1960s on repeated games clarified thedifference between infinitely and finitely repeated games.With Bezalel Peleg in 1960, Aumann formalized the notion of a coalitional gamewith non-transferable utility (NTU), a significant advance in cooperative game theory.With Michael Maschler (1963), he introduced the concept of a bargaining set, animportant solution concept in cooperative game theory. In 1974, Aumann went on todefine and formalize the notion of correlated equilibrium in Bayesian games. In 1975,he proved a convergence theorem for the Shapley value. In 1976, in an unpublishedpaper with Lloyd Shapley, Aumann provided the perfect folk theorem using the limitof means criterion. All of these contributions have advanced game theory in significantways. His book Values of Non-Atomic Games (1984) co-authored with Lloyd Shapleyand the book Repeated Games with Incomplete Information (1995) co-authored withMichael Maschler are widely regarded as game theory classics.Aumann was born in Frankfurt am Main, Germany on June 8, 1930. He earned anM.Sc. Degree in Mathematics in 1952 from the Massachusetts Institute of Technologywhere he also received his Ph.D. Degree in 1955. His doctoral adviser at MIT wasProfessor George Whitehead Jr. and his doctoral thesis was on knot theory. He hasbeen a professor at the Center for Rationality in the Hebrew University of Jerusalem,Israel, since 1956 and he also holds a visiting appointment with Stonybrook University, USA. Robert Aumann and Thomas Schelling received the 2005 Nobel Prize inEconomic Sciences for their contributions toward a clear understanding of conflictand cooperation through game theory analysis.\nCommon KnowledgeThe notion of common knowledge is an important implication of intelligence. Aumann [4] defines common knowledge as follows: A fact is common knowledge amongthe players if every player knows it, every player knows that every player knows it,and so on. That is, every statement of the form “every player knows that everyplayer knows that · · · every player knows it” is true forever. If it happens thata fact is known to all the players, without the requirement of all players knowingthat all players know it, etc., then such a fact is called mutual knowledge. In game\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nKey Notions in Game Theory\nbook\n25\ntheory, analysis often requires the assumption of common knowledge to be true;however, sometimes, the assumption of mutual knowledge suffices for the analysis.A player’s private information is any information that the player has that is notcommon knowledge or mutual knowledge among any of the players.The intelligence assumption means that whatever a game theorist knows aboutthe game must be known to or understood by the players of the game. Thus themodel of the game is also known to the players. Since all the players know the modeland they are intelligent, they also know that they all know the model; they all knowthat they all know that they all know the model, etc. Thus the model is commonknowledge.In a strategic form game with complete information, hN, (Si ), (ui )i, the set N , thestrategy sets S1 , . . . , Sn , and the utility functions u1 , . . . , un are common knowledge,that is every player knows them, every player knows that every player knows them,and so on. We will be studying strategic form games with complete information inthis and the next few chapters. We will study games with incomplete informationin Chapter 13.Example 2.3 (Common Knowledge). This example is a variant of the one presented by Myerson [1]. Assume that there are five rational and intelligent mothers A,B, C, D, and E and let a, b, c, d, and e be their daughters (or sons), respectively. Thekids go to the school every day, escorted by their respective mothers and the mothers get anopportunity everyday to indulge in some conservation. The conversation invariably centersaround the performance and behavior of the kids. Everyday when the five mothers meet,the conversation protocol is the following. If a mother thinks her kid is well behaved , shewill praise the virtues of her kid. On the other hand, if a mother knows that her kid is notwell behaved , she will cry. All mothers follow this protocol.The fact is that none of the kids is well behaved but their behaviors are unknown totheir respective mothers. However, whenever a mother finds that the kid of another motheris not well behaved, she would immediately report it to all mothers except the kid’s mother.For example, if A finds b was not well behaved, then A would report it to C, D, and E, butnot to B. This protocol is also known to all the mothers. Let us therefore take as fact thatthe knowledge that kid a is not well behaved is known to all the mothers except A (whobelieves that a is well behaved). Similar is the knowledge and belief about other kids’ wellbehavedness or lack thereof.Since each mother does not know that her kid is not well behaved, it turns out thatevery mother keeps praising her kid everyday. On a fine day, the class teacher meets all themothers and makes the following statement: “at least one of the kids is not well behaved.”Thus the fact that one of the kids is not well behaved is now common knowledge amongall the mothers. Subsequently, when the five mothers meet the next day, all of them praisetheir respective kids; the same happens on the 2nd day, 3rd day, and the 4th day. On the 5thday, however, all the mothers cry together because all of them realize that their respectivekids are not well behaved. The readers are urged to convince themselves why the above twostatements are true.Note that the announcement made by the class teacher is common knowledge and thatis what makes all the mothers cry on the fifth day.\u0003\nDecember 27, 2013\n11:21\n26\n2.6\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nClassification of Games\nAny well developed subject like game theory which has been extensively exploredfor more than eight decades will abound in numerous kinds of games being definedand studied. We only provide a listing of some of the well known ones here.Non-cooperative Games and Cooperative GamesNon-cooperative games are those in which the actions of individual players are theprimitives; in cooperative games, joint actions of groups of players are the primitives. John Harsanyi (1966) [5] explained that a game is cooperative if commitments(agreements, promises, threats) among players are enforceable and that a game becomes non-cooperative if the commitments are not enforceable.It would be false to say that non-cooperative game theory applies only to situations in which there is a conflict or non-cooperation among the players. It is justthat each individual player and the preferences of the player provide the basic modeling unit. In contrast, in cooperative games, the basic modeling unit is a group ofplayers. If all groups are singletons, then we have a non-cooperative game.Static Games and Dynamic GamesIn static games, players choose their actions simultaneously and no informationis received during the play. An immediate example is the situation in Example2.1 where two students simultaneously decide their strategies and receive a certainamount of reward based on the outcomes obtained. These are often called singlestage games. In a dynamic game which is often called a multi-stage game, thereis a temporal order in which actions are played by the players. Typically, in amulti-stage game, a certain player chooses an action before other players do and theplayer knows that the choice of actions by other players will be influenced by heraction. Players who choose their actions subsequently make their choices dependenton their knowledge of the actions that others have chosen. An immediate exampleof a dynamic game is Chess. In dynamic games, information is received and couldbe used by the players to plan their actions during the play of the game.Different Representational FormsA strategic form game (also called simultaneous move game or normal form game),which was introduced in this chapter, is a model or a situation where each playerchooses the plan of action once and for all, and all players exercise their decisionssimultaneously. Strategic form representation does not capture sequence of movesby the players and does not capture any information accrual to the players duringthe play of a game. This representation is therefore very convenient for static games.If used for dynamic games, it is to be noted that the strategic form representationcould suppress the dynamics of the game.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nKey Notions in Game Theory\nbook\n27\nAn extensive form game specifies a possible order of events and each player canconsider his plan of action whenever a decision has to be made by him. The extensiveform representation can capture the sequence of moves by the players and can alsocapture the information accrual to the players during the play of a game. It istherefore a suitable form of representation for dynamic games. Strategic form canbe considered as a static equivalent of extensive form.A coalitional form game or characteristic form game is one where every subsetof players is represented with an associated value. This form is appropriate forcooperative games.Games with Perfect Information and Games with Imperfect InformationWhen the players are fully informed about the entire past history (each player,before making a move, knows the past moves of all other players as well as his ownpast moves), the game is said to be of perfect information. Otherwise it is called agame with imperfect information.Complete Information and Incomplete Information GamesA game with incomplete information is one in which, at the first point in timewhen the players can begin to plan their moves, some players have private information about the game that other players do not know. In a game with completeinformation, every aspect of the game is common knowledge.Other CategoriesThere are many other categories of games, such as repeated games, evolutionarygames, stochastic games, multi-level games (Stackelberg games), differential games,etc. We do not get into the details of these games in this book. We refer the readerto the books by Osborne [6] and by Maschler, Solan, and Zamir [2] for a discussionof other categories of games.2.7\nSummary and References\nIn this chapter, we have introduced several fundamental notions and assumptionswhich are key to game theory. These include: preferences, utilities or payoffs, rationality, intelligence, and common knowledge.• Preferences of a player specify qualitatively the player’s ranking of the differentoutcomes of the game.• Utilities are real valued payoffs that players receive when they play differentactions. The utility of a player depends not only on the action played by thatplayer but also on the actions played by the rest of the players.• Rationality intuitively means that players always choose their actions so as to\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n28\nGame Theory and Mechanism Design\nmaximize their expected utilities. Depending on how the utility function isdefined, rationality could mean self-interest, altruism, indifference, etc.• Intelligence means that the players are as knowledgeable as game theorists andhave enough computational power to compute their best response actions.• Common knowledge is an implication of intelligence and means that all playersknow the entire structure of the game, all players know that all players knowthe game, all players know that all players know that all players know thegame, etc.Game theory is founded on the above notions. Some of the above assumptions mayor may not be valid in real world situations, however the abstractions provided bygame theory under the above assumptions will provide a perfect starting point fora scientific investigation into strategic situations.The material discussed in this chapter draws mainly upon the following sources,namely the books by Myerson [1], Mas-Colell, Whinston, and Green [7], Osborne[6], Osborne and Rubinstein [8], and Maschler, Solan, and Zamir [2].A detailed discussion of the notion of common knowledge can be found in theoriginal paper by Aumann [4]. The book by Maschler, Solan, and Zamir [2] discussesthis notion extensively with several illustrative examples.For an undergraduate level treatment of game theory, we recommend the booksby Osborne [6], Straffin [9], and Binmore [10]. For a graduate level treatment, werecommend the books by Myerson [1], Maschler, Solan, and Zamir [2], and Osborneand Rubinstein [8].We also refer the readers to books by Rasmussen [11], Gibbons [12], Basar andOlsder [13], and Fudenberg and Tirole [14] for a scholarly treatment of game theory.The classic treatise by John von Neumann and Oskar Morgenstern [3], publishedin 1944, provides a comprehensive foundation for game theory. To this day, evenafter many decades of its first appearance, the book continues to be a valuablereference.References[1][2][3][4][5][6][7]\nRoger B. Myerson. Game Theory: Analysis of Conflict. Harvard University Press, Cambridge,Massachusetts, USA, 1997.Michael Maschler, Eilon Solan, and Shmuel Zamir. Game Theory. Cambridge UniversityPress, 2013.John von Neumann and Oskar Morgenstern. Theory of Games and Economic Behavior.Princeton University Press, 1944.Robert J. Aumann. “Agreeing to disagree”. In: The Annals of Statistics 4(6) (1976), pp. 1236–1239.John C. Harsanyi. “Games with incomplete information played by Bayesian players. Part I:The basic model”. In: Management Science 14 (1967), pp. 159–182.Martin J. Osborne. An Introduction to Game Theory. The MIT Press, 2003.Andreu Mas-Colell, Michael D. Whinston, and Jerry R. Green. Microeconomic Theory. Oxford University Press, 1995.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nKey Notions in Game Theory[8][9][10][11][12][13][14]\nbook\n29\nMartin J. Osborne and Ariel Rubinstein. A Course in Game Theory. Oxford University Press,1994.Philip D. Straffin Jr. Game Theory and Strategy. The Mathematical Association of America,1993.Ken Binmore. Fun and Games : A Text On Game Theory. D. C. Heath & Company, 1992.Eric Rasmussen. Games and Information. Blackwell Publishing, Fourth Edition, 2007.Robert Gibbons. Game Theory for Applied Economists. Princeton University Press, Princeton, NJ, USA, 1992.Tamer Basar and Geert Jan Olsder. Dynamic Non-cooperative Game Theory. SIAM, SecondEdition, Philadelphia, PA, USA, 1999.Drew Fudenberg and Jean Tirole. Game Theory. MIT Press, Cambridge and London, 1991.\nJanuary 3, 2014\n11:48\nWorld Scientific Book - 10.25in x 7.5in\nThis page intentionally left blank\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nChapter 3\nExtensive Form Games\nIn this chapter, we study extensive form representation of a game, which provides a detailed representation of a game, including the sequence of moves andinformation accrual to players. We explain the important notions underlyingextensive form representation. In this book, we mostly deal with strategic formrepresentation; in this chapter, we bring out the connection between extensiveform and strategic form representations. We show how any extensive form gamecan be transformed into a strategic form game.\nThe extensive form representation of a game provides a detailed and richly structured way to describe a game. This form was first proposed by von Neumann andMorgenstern [1] and was later refined by Kuhn [2]. The extensive form capturescomplete sequential play of a game. Specifically it captures (1) who makes a moveat any given time (2) what actions each player may play (3) what the players knowbefore playing at each stage (4) what the outcomes are as a function of the actions,and (5) payoffs that players obtain from each outcome. Extensive form games with afinite number of players and with a finite number of actions available to each playerare depicted graphically using game trees.3.1\nIllustrative Examples\nWe first present several examples before we formally define an extensive form game.Example 3.1 (Matching Pennies with Observation). In the matching penniesgame, there are two players, 1 and 2, each of whom has a rupee coin. One of the playersputs down his rupee coin heads or tails up. The other player sees the outcome and putsdown her coin heads up or tails up. If both the coins show heads or both the coins showtails, player 2 gives one rupee to player 1 who thus becomes richer by one rupee. If oneof the coins shows heads and the other coin shows tails, then player 1 pays one rupee toplayer 2 who becomes richer by one rupee. Depending on whether player 1 or player 2 movesfirst, there are two versions of this game. Figure 3.1 shows the game tree when player 1moves first while Figure 3.2 shows the game tree when player 2 moves first. In the gametree representation, the nodes are of three types: (1) root node (initial decision node); (2)31\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n32\nGame Theory and Mechanism Design\ninternal nodes (which are decision nodes); and (3) leaf nodes or terminal nodes (which areoutcome nodes). Each possible sequence of events that could occur in the game is capturedby a path of links from the root node to one of the terminal nodes. When the game is played,the path that represents the sequence of events is called the path of play. Each decision nodeis labeled with the player who takes a decision at that node. Also note that each decisionnode can be uniquely identified by a sequence of actions leading to that decision node fromthe root node. The links that are outgoing at the decision node are labeled with the actionsthe player may select at that node. Note that each node represents not only the currentposition in the game but also how it was reached. The terminal nodes are labeled with thepayoffs that the players would get in the outcomes corresponding to those nodes.\u0003\n1\nH\nT2\n2\nH\nH\nT\n1,−1\n−1,1\nT\n−1,1\n1,−1\nFig. 3.1: Matching pennies game with observation when player 1 moves first\n2\nH\nT\n1\nH\n1,−1\n1H\nT\n−1,1\n−1,1\nT\n1,−1\nFig. 3.2: Matching pennies game with observation when player 2 moves first\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nExtensive Form Games\nbook\n33\nExample 3.2 (Matching Pennies without Observation). In this case, one ofthe players places his rupee coin heads up or tails up. The other player does not observe theoutcome and only puts down her rupee coin heads up or tails up. Depending on whetherplayer 1 moves first or player 2 moves first, we obtain the game tree of Figure 3.3 or Figure3.4, respectively. Note that the game trees of Figures 3.1 and 3.3 are virtually the sameexcept that the two decision nodes corresponding to player 2 in Figure 3.3 are connectedwith dotted lines. Similarly the game trees of Figures 3.2 and 3.4 are the same except thatthe two decision nodes corresponding to player 1 in Figure 3.4 are connected with dottedlines. A set of nodes that are connected with dotted lines is called an information set.When the game reaches a decision node in an information set, the player involved at thatnode does not know the node in the information set she is in. The reason for this is thatthe player cannot observe the previous moves in the game.\u00031\nH\nT\n2\nH\n2H\nT\n1,−1\n−1,1\nT\n−1,1\n1,−1\nFig. 3.3: Matching pennies game without observation when player 1 moves first2\nH\nT\n1\nH\n1,−1\n1H\nT\n−1,1\n−1,1\nT\n1,−1\nFig. 3.4: Matching pennies game without observation when player 2 moves first\nDecember 27, 2013\n11:21\n34\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nExample 3.3 (Matching Pennies with Simultaneous Play). In this version ofthe game, the two players put down their rupee coins simultaneously. Clearly, each playerhas no opportunity to observe the outcome of the move of the other player. The orderof play is obviously irrelevant here. Thus both the game trees depicted in Figure 3.3 andFigure 3.4 provide a valid representation of this version of the game.\u00033.2\nExtensive Form Games: Definitions\nWe now formally define an extensive form game. This definition follows closely theone given by Osborne [3]. First we define an information set.Definition 3.1 (Information Set). An information set of a player is a set of thatplayer’s decision nodes that are indistinguishable to her.An information set of a player describes a collection of all possible distinguishablecircumstances in which the player is called upon to make a move. Since each decisionnode corresponds uniquely to a sequence of actions from the root node to the decisionnode, each information set of a player consists of all proper subhistories relevant tothat player which are indistinguishable to that player. Clearly, in every node withina given information set, the corresponding player must have the same set of possibleactions.Example 3.4. In the matching pennies game shown in Figure 3.3, the only informationset of a player 1 is the singleton {ε} consisting of the empty history. The informationset of player 2 is the set {H, T } that consists of the proper histories H and T which areindistinguishable to player 2. On the other hand, in the game shown in Figure 3.1, player1 has only one information set namely {ε} whereas player 2 has two information sets {H}and {T } because these two proper subhistories are distinguishable to player 2.\u0003\nDefinition 3.2 (Extensive Form Game). An extensive form game Γ consists ofa tuple Γ = hN, (Ai )i∈N , H, P, (Ii )i∈N , (ui )i∈N i where• N = {1, 2, . . . , n} is a finite set of players• Ai for i = 1, 2, . . . , n is the set of actions available to player i (action set ofplayer i)• H is the set of all terminal histories where a terminal history is a path ofactions from the root to a terminal node such that it is not a proper subhistoryof any other terminal history. Denote by SH the set of all proper subhistories(including the empty history ε) of all terminal histories.• P : SH → N is a player function that associates each proper subhistory to acertain player• Ii for i = 1, 2, . . . , n is the set of all information sets of player i• ui : H → R for i = 1, 2, . . . , n gives the utility of player i corresponding to eachterminal history.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nExtensive Form Games\nbook\n35\nExample 3.5. We illustrate the above definition for the matching pennies game shown inFigure 3.1.N = {1, 2}A1 = A2 = {H, T }H = {(H, H), (H, T ), (T, H), (T, T )}SH = {ε, H, T }P (ε) = 1; P (H) = 2; P (T ) = 2I1 = {{ε}}; I2 = {{H}, {T }}u1 (HH) = 1; u1 (HT ) = −1; u1 (T H) = −1; u1 (T T ) = 1u2 (HH) = −1; u2 (HT ) = 1; u2 (T H) = 1; u2 (T T ) = −1It is clear that action sets of different players can be deduced from the terminal historiesand the player function.\u0003\nNote. Though the action sets of players can be deduced from terminal historiesand the player function, we explicitly include action sets as a part of definition ofan extensive form game for ease of understanding.\nExample 3.6 (Entry Game). In this game, there are two players, 1 and 2. Player 1 iscalled challenger and player 2 is called incumbent . Figure 3.5 shows the game tree. Player1challenger\n2incumbentaccept\n2, 1\nin\nout\nfight\n1, 2\n0, 0\nFig. 3.5: Game tree for entry game1 (challenger) either decides to challenge the incumbent (action: in) or drops out (action:out). Player 2 (incumbent) either decides to fight or accommodate the challenger in casethe challenger decides to confront the incumbent. The respective payoffs are shown in the\nDecember 27, 2013\n11:21\n36\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\ngame tree. For this game, we haveN = {1, 2}; A1 = {in, out}; A2 = {accept, fight}H = {(in, accept), (in, fight), (out)}SH = {\u000f, (in)}P (\u000f) = 1P (in) = 2I1 = {{ε}}; I2 = {{in}}u1 (in, accept) = 2; u1 (in, fight) = 0;\nu1 (out) = 1\nu2 (in, accept) = 1;\nu2 (out) = 2\nu2 (in, fight) = 0;\nNote again that the action sets A1 and A2 can be deduced from the terminal histories andthe player function.\u0003\n1\nC\n2\n1\nG\nE\nF\nH\n(1, 2)\nD\n(2,0)\n(3,1)\n(0, 0)\nFig. 3.6: Another game treeExample 3.7. Consider the game tree shown in Figure 3.6. For this game, it is easy tosee thatN = {1, 2};\nA1 = {C, D, G, H};\nA2 = {E, F }\nThe terminal histories are given byH = {(C, E, G), (C, E, H), (C, F ), (D)}The proper subhistories of terminal histories are given bySH = {\u000f, (C), (C, E)}The player function is given byP (\u000f) = 1;\nP (C) = 2;\nP (C, E) = 1\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nExtensive Form Games\nbook\n37\nThe information sets are given byI1 = {{ε}, {(C, E)}}; I2 = {{(C)}}The utility functions are given byu1 (C, E, G) = 1; u1 (C, E, H) = 0;u1 (C, F ) = 3; u1 (D) = 2;u2 (C, E, G) = 2; u2 (C, E, H) = 0;u2 (C, F ) = 1; u2 (D) = 0.This completes the description of the game shown in Figure 3.6.\n\u0003\nDefinition 3.3 (Perfect Information and Imperfect Information Games).An extensive form game with perfect information is one in which all the information sets are singletons. If at least one information set of at least one player hastwo or more elements, the game is said to be of imperfect information.In a game with perfect information, each player is able to observe all previous movesor the entire history thus far. Each player knows precisely where she is currentlyand also knows precisely how she has reached that node.Example 3.8. As immediate examples, the games depicted in Figures 3.1, 3.2, 3.5, and3.6 are games with perfect information while the games shown in Figures 3.3 and 3.4 aregames with imperfect information. The matching pennies game with simultaneous play isobviously a game with imperfect information.\u0003\n3.3\nTransforming Extensive Form to Strategic Form\nThe notion of a strategy is one of the most important notions in game theory. Astrategy can be described as a complete action plan that specifies what a player willdo at each of the information sets where he is called upon to play.Recall that Ii denotes the set of all information sets of player i in the given game.Let Ai as usual denote the actions available to player i. Given an information setJ ∈ Ii , let C(J) ⊆ Ai be the set of all actions possible to player i in the informationset J. Then we define a strategy of a player formally as follows.Definition 3.4 (Strategy). A strategy si of player i is a mapping si : Ii → Aisuch that si (J) ∈ C(J) ∀J ∈ Ii .The strategy si for player i is a complete contingent plan that specifies an actionfor every information set of the player. A strategy thus determines the action theplayer will choose in every stage or history of the game the player is called uponto play. In fact, the player can prepare a look-up table with two columns, one\nDecember 27, 2013\n11:21\n38\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nfor her information sets and the other for corresponding actions; the player or arepresentative of the player can then take over and play the game using table lookup. Different strategies of the player correspond to different contingent plans ofactions. We illustrate the notion of strategy through an example.Example 3.9 (Strategies in Matching Pennies with Observation).Consider the game shown in Figure 3.1. We have I1 = {{ε}}; I2 = {{H}, {T }}. Player 1has two strategies:s11 : {ε} → Hs12 : {ε} → TPlayer 2 has the following four strategies:s21 : {H} → H;\n{T } → H\ns22 : {H} → H;\n{T } → T\ns23 : {H} → T ;\n{T } → H\ns24 : {H} → T ;\n{T } → T\nThe payoffs obtained by the players 1 and 2 can now be described by Table 3.1. Note, forexample, that when the strategy of player 1 is s11 , the player plays H and when the strategyof player 2 is s21 , the player 2 plays H, leading to the payoffs 1, −1.\n21s11s12\ns211, −1−1, 1\ns221, −11, −1\ns23−1, 1−1, 1\ns24−1, 11, −1\nTable 3.1: Payoffs obtained in matching pennies with observation\nThe above game is a strategic form game equivalent of the original extensive form game.For the game shown in Figure 3.2, player 2 will have two strategies and player 1 will havefour strategies and a payoff matrix such as above can be easily derived.\u0003\nExample 3.10 (Strategies in Matching Pennies without Observation).Consider the game shown in Figure 3.3. It is easy to see that I1 = {{ε}} and I2 = {{H, T }}.Here player 1 has two strategies and player 2 has two strategies as shown below.s11 : {ε} → Hs12 : {ε} → Ts21 : {H, T } → Hs22 : {H, T } → TThe payoff matrix corresponding to all possible strategies that can be played by the playersis shown in Table 3.2.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nExtensive Form Games\nbook\n39\n21\ns21\ns22\ns11s12\n1, −1−1, 1\n−1, 11, −1\nTable 3.2: Payoffs obtained in matching pennies without observation\nClearly, the matching pennies game with simultaneous moves also will have the samestrategies and payoff matrix as above.\u0003\nExample 3.11. Consider the game in Figure 3.6. Player 1 has four strategies given bys11 : {ε} → C;\n{(C, E)} → G\ns12 : {ε} → C;\n{(C, E)} → H\ns13 : {ε} → D;\n{(C, E)} → G\ns14 : {ε} → D;\n{(C, E)} → H\nFor the sake of convenience, let us denote the above strategies by CG, CH, DG, and DH,respectively. Player 2 has two strategies given bys21 : {C} → Es21 : {C} → FFor the sake of convenience, let us denote the above strategies by E and F , respectively. IfS1 and S2 are the sets of strategies of players 1 and 2 respectively, it can be seen thatS1 = {CG, CH, DG, DH}S2 = {E, F }The set of strategy profiles, S1 × S2 , is given byS1 × S2 = {(CG, E), (CG, F ), (CH, E), (CH, F ), (DG, E), (DG, F ), (DH, E), (DH, F )}Note that a strategy profile uniquely determines a terminal history. For example, the profile(CG, E) corresponds to the terminal history (C, E, G); the profile (CG, F ) corresponds tothe terminal history (C, F ); the profiles (DH, E) as well as (DH, F ) correspond to theterminal history (D), etc. This example motivates the following definition.\u0003\nDefinition 3.5 (Outcome). Given an extensive form game Γ and a strategy profile s = (s1 , . . . , sn ) in the game, the outcome resulting out of the terminal historycorresponding to the strategy profile s is called the outcome of s and is denoted byO(s).\nDecember 27, 2013\n11:21\n40\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nNote. It is to be noted that every extensive form game has a unique strategic formrepresentation. The uniqueness is up to renaming or renumbering of strategies. Wecan also immediately observe that a given strategic form game may correspond tomultiple extensive form games.Note. We have seen that any given extensive form game has an equivalent strategicform game. However, the equivalent strategic form representation may or may notcontain all of the strategically relevant information present in the extensive formrepresentation. In fact, the strategic form representation suppresses the dynamicsof the game because of simultaneous play. In this book, we mostly focus on thestrategic form representation. It is to be noted that dynamic games where there issequential play as well as information accrual to the players during the play of thegame warrant extensive form representation.\n3.4\nSummary and References\nFollowing is a summary of salient points that we have covered in this chapter.• Extensive form games provide a detailed representation of sequence of playand information accrual by players in a game. Finite extensive form games canbe represented using game trees which consist of decision nodes and terminalnodes. Each decision node corresponds to a certain player and the player isrequired to choose an action in the decision node.• An important notion in an extensive form games is that of an information setof a player. An information set of a player is a set of decision nodes of theplayer that are indistinguishable to the player (the player does not know inwhich of these decision nodes she is in).• An extensive form game with perfect information is one in which all informationsets of all players are singletons. This implies that at every decision node, thecorresponding player has knowledge of the entire history until reaching thatdecision node. An extensive form game with imperfect information is onewhere at least one information set of at least one player is not a singleton.• An extensive form game can be transformed into an equivalent strategic formgame using the notion of a strategy. A strategy of a player is a complete actionplan that specifies which action the player will choose in each of her informationsets.• A strategic form game often suppresses the dynamics of the game. However, itsimplifies the analysis of games and it suffices to work with the strategic formrepresentation for finding answers to many useful analysis questions.• A given strategic form game could correspond to multiple extensive form gameswhile a given extensive form game when transformed into strategic form yieldsa representation that is unique in structure.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nExtensive Form Games\nbook\n41\nMuch of the material in this chapter is based on relevant discussions in the booksby Osborne [3] and by Mas-Colell, Whinston, and Green [4]. In this book, we willbe dealing mostly with strategic form games. In Chapter 6, we briefly return toextensive form games to introduce the notion of subgame perfect equilibrium. Fora detailed treatment of extensive form games, we refer the reader to the books byOsborne [3], Myerson [5], and Maschler, Solan, and Zamir [6].References[1][2][3][4][5][6]\n3.5\nJohn von Neumann and Oskar Morgenstern. Theory of Games and Economic Behavior.Princeton University Press, 1944.H.W. Kuhn. “Extensive form games and the problem of information”. In: Contributions tothe Theory of Games II. Princeton University Press, 1953, pp. 193–216.Martin J. Osborne. An Introduction to Game Theory. The MIT Press, 2003.Andreu Mas-Colell, Michael D. Whinston, and Jerry R. Green. Microeconomic Theory. Oxford University Press, 1995.Roger B. Myerson. Game Theory: Analysis of Conflict. Harvard University Press, Cambridge,Massachusetts, USA, 1997.Michael Maschler, Eilon Solan, and Shmuel Zamir. Game Theory. Cambridge UniversityPress, 2013.\nExercises\n(1) You might know the tic-tac-toe game. Sketch a game tree for this game.(2) In a game, a certain player has m information sets indexed by j = 1, 2, . . . , m.There are kj possible actions for information set j. How many strategies doesthe player have?(3) For game shown in Figure 3.7, write down the terminal histories, proper subhistories, information sets, and the strategic form representation.2\na1a2\n1\nL\n1,−1\na3\na41\n1\nR\nL\n−1,1\n1,−1\nR\n−1,1\nL\n1,−1\n1\nR\nL\n−1,1\n1,−1\nFig. 3.7: An extensive form game\nR\n−1,1\nJanuary 3, 2014\n11:48\nWorld Scientific Book - 10.25in x 7.5in\nThis page intentionally left blank\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nChapter 4\nStrategic Form Games\nStrategic form representation is the most extensively discussed representationfor games in this book. In this chapter, we provide a number of illustrativeexamples to help gain an intuitive understanding of strategic form games. Theexamples involve finite games as well as infinite games. The games discussedinclude matching pennies, rock-paper-scissors, Bach or Stravinsky, student’s coordination, prisoner’s dilemma, company’s dilemma, duopoly pricing, tragedyof the commons, bandwidth sharing, sealed bid auction, Pigou network routinggame, and Braess paradox. The examples are fairly representative of the widecanvas of applications where game theoretic modeling is relevant.\n4.1\nPreliminaries\nWe have seen in Chapter 2 (Definition 2.1) that a strategic form game Γ is a tuple Γ = hN, (Si )i∈N , (ui )i∈N i where N = {1, 2, . . . , n} is a finite set of players;S1 , S2 , . . . , Sn are the strategy sets of the players; and ui : S1 × S2 × · · · × Sn → Rfor i = 1, 2, . . . , n are utility functions. We have seen in Chapter 3 that games inextensive form can be transformed into strategic form games by mapping contingent action plans into strategies. The phrases strategic form games, strategic games,and normal form games are synonymous. When there is no confusion, we use thenotation Γ = hN, (Si ), (ui )i for a strategic form game.We denote by S, the set of all strategy profiles or strategy vectors, which isthe Cartesian product S1 × · · · × Sn . A typical strategy profile is represented by(s1 , . . . , sn ) where si is the strategy of player i (i = 1, . . . , n). We denote by S−ithe Cartesian product S1 × · · · × Si−1 × Si+1 × · · · Sn of strategy sets of all playersother than player i. We denote by s−i a typical strategy profile in S−i . When weare focusing on a particular player i, a convenient way of representing a strategyprofile is (si , s−i ) where si ∈ Si and s−i ∈ S−i .The idea behind the strategic form representation is that a player’s decisionproblem is to essentially choose a strategy that will counter most effectively thestrategies adopted by the other players. Such a strategy is called a best responsestrategy which is formally defined as follows.43\nbook\nDecember 27, 2013\n11:21\n44\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nDefinition 4.1 (Best Response Strategy). Given a strategic form game Γ =hN, (Si ), (ui )i and a strategy profile s−i ∈ S−i , we say si ∈ Si is a best responsestrategy of player i with respect to s−i if ui (si , s−i ) ≥ ui (s0i , s−i ) ∀s0i ∈ Si .Given a strategy profile s−i ∈ S−i of all players except player i, there could existmultiple best response strategies for player i.In a strategic form game, each player is faced with the problem of choosing hisbest response strategy and the players can be thought of as simultaneously choosingtheir strategies from the respective sets S1 , . . . , Sn .Many interpretations have been provided in the game theory literature for strategic form games. We present here two interpretations provided by Osborne andRubinstein [1].In the first interpretation, a strategic form game is a model of an event that occursonly once. Each player knows the details of the game and the fact that all playersare rational. The players choose their strategies simultaneously and independently.Each player is unaware of the choices being made by the other players.In the second interpretation, a player is assumed to form an expectation of theother players’ behavior on the basis of information about the way the game or asimilar game was played in the past. A strategic form game models a sequence ofplays of the game under the condition that there is no strategic link between theplays of the game. That is, a player who plays the game many times should onlyworry about his own instantaneous payoff and ignore the effects of his current actionon the future behavior of the other players. A class of games called repeated gamesis relevant if there is a strategic link between plays of a game.The extensive form representation, discussed in Chapter 3, is a more detailedrepresentation than the strategic form representation. A given strategic form gamecould correspond to multiple extensive form games. The strategic form game suppresses the dynamics of the game but is more convenient for certain kinds of analysisof games. It is enough to work with strategic form for finding answers to many usefulanalysis questions.4.2\nMatching Pennies with Simultaneous Moves\nWe have already studied this game in Chapter 3. Recall that in this game, twoplayers 1 and 2 put down their respective rupee coins, heads or tails up. If both thecoins match (both heads or both tails), then player 2 pays one rupee to player 1.Otherwise, player 1 pays one rupee to player 2. Let us say A denotes heads and Bdenotes tails. It is easy to see that:N = {1, 2}S1 = S2 = {A, B}S = S1 × S2 = {(A, A), (A, B), (B, A), (B, B)}\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nStrategic Form Games\nbook\n45\nThe payoff matrix is given by21A\nA1, −1\nB−1, 1\nB\n−1, 1\n1, −1\nThis is perhaps the simplest example of a two player game. This belongs to a classof games called two player zero-sum games (so called because the sum of utilities inevery outcome is equal to zero). In the above game, it is easy to see that the bestresponse strategy of player 1 is A (B) when player 2 plays A (B). On the otherhand, the best response strategy of player 2 is A (B) when player 1 plays B (A).To understand why a simple game such as the above is important to study, letus consider the following situation. There are two companies, call them 1 and 2.Each company is capable of producing two products A and B, but at any giventime, a company can only produce one product, due to high setup and switchovercosts. Company 1 is known to produce superior quality products but company 2scores over company 1 in terms of marketing and advertising. If both the companiesproduce the same product (A or B), it turns out that company 1 makes all the profitsand company 2 loses out, because of the superior quality of products produced bycompany 1. This is reflected in our model with a payoff of +1 for company 1 anda payoff of −1 for company 2, corresponding to the strategy profiles (A, A) and(B, B).On the other hand, if one company produces product A and the other producesproduct B, it may turn out that because of aggressive marketing by company 2 indifferentiating the product offerings A and B, company 2 captures all the market,resulting in a payoff of +1 for company 2 and a payoff of −1 for company 1.The two companies have to simultaneously decide (each one does not know thedecision of the other) which product to produce. This is the strategic decisionfacing the two companies. This situation is captured by a strategic form gameΓ = hN, S1 , S2 , u1 , u2 i, where N = {1, 2}; S1 = S2 = {A, B}, and the utilityfunctions are as described in the above table.4.3\nRock-Paper-Scissors Game\nThis is an example of another two player zero-sum game where each player hasthree strategies, called rock , paper , and scissors. Actually, this is a popular handgame played by two persons. Another name for this game is roshambo. Two playerssimultaneously display one of three symbols: a rock , a paper , or scissors. The rocksymbol beats scissors symbol; scissors symbol beats paper symbol; paper symbolbeats rock symbol (symbolically, rock can break scissors; scissors can cut paper; andpaper can cover rock). The payoff matrix for this game is given as follows.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n46\n4.4\nGame Theory and Mechanism Design\n1\nRock\n2Paper\nRockPaper\n0, 01, −1\n−1, 10, 0\n1, −1−1, 1\nScissors\n−1, 1\n1, −1\n0, 0\nScissors\nBOS (Bach or Stravinsky) Game\nThis game is named after the famous musicians Bach and Stravinsky. This is alsocalled the Battle of Sexes game. This is a game where the players want to coordinatewith each other; however, they have a disagreement about which of the outcomes isbetter. Let us say two players 1 and 2 wish to go out together to an event A or toan alternative event B. Player 1 prefers to go to event A and player 2 prefers to goto event B. The payoff matrix is as shown.21A\nA2, 1\nB0, 0\nB\n0, 0\n1, 2\nClearly, this game captures a situation where the players want to coordinate butthey have conflicting interests. The outcomes (A, B) and (B, A) are unfavorableto either player. The choice is essentially between (A, A) and (B, B). Recallingthe company analogy, suppose we have two companies, 1 and 2. Each companycan produce only one of two competing products A and B, but at any given time,a company can only produce one type of product. Assume product A is a nicheproduct of company 1 while product B is a niche product of company 2. If both thecompanies produce product A, the consumers are compelled to buy product A andwould naturally prefer to buy it from company 1 rather than from 2. Assume thatcompany 1 captures two thirds of the market. We can reflect this fact by makingthe payoff to company 1 twice that of company 2. If both the companies produceproduct B, the reverse situation will prevail and company 2 will make twice as muchpayoff as company 1.On the other hand, if the two companies decide to produce different products,then the market gets segmented and each company tries to outwit the other throughincreased spending on advertising. In fact, their competition may actually benefit athird company and, effectively, neither company 1 nor company 2 makes any payoff.The above table depicts the payoff structure for this game.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nStrategic Form Games\n4.5\nbook\n47\nA Coordination Game\nWe have already presented this game in Chapter 1 (student’s coordination game).This game is similar to the BOS game but the two players now have a preferencefor the same option, namely event A. The payoff matrix is as shown below; notethat the outcomes (A, A) and (B, B) in that order are preferred.21AB\nA10, 100, 0\nB0, 01, 1\nContinuing our analogy of companies, the above game corresponds to a situationwherein the two companies produce the same product, and they have equal marketshare. This market share is ten times as much for product A as for product B. Onthe other hand, if the two companies produce different products, a third companymay capture all the market share leaving nothing for companies 1 and 2.Since the payoffs are the same for both the players in all outcomes, such gamesare also called common payoff games.\n4.6\nPrisoner’s Dilemma Game\nThis is one of the most extensively studied problems in game theory, with many interesting interpretations in a wide variety of situations. Two individuals are arrestedfor allegedly committing a crime and are lodged in separate cells. The interrogatorquestions them separately. The interrogator privately tells each prisoner that if heis the only one to confess, he will get a light sentence of 1 year in jail while theother would be sentenced to 10 years in jail. If both players confess, they would get5 years each in jail. If neither confesses, then each would get 2 years in jail. Theinterrogator also informs each prisoner what has been told to the other prisoner.Thus the payoff matrix is common knowledge.21NC\nNC−2, −2\nC−10, −1\nC\n−1, −10\n−5, −5\nHow would the prisoners behave in such a situation? They would like to play astrategy that offers a best response to a best response strategy that the other playermay adopt, the latter player also would like to play a strategy that offers a bestresponse to the other player’s best response strategy, and so on. First observe that\nDecember 27, 2013\n11:21\n48\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nC is each player’s best response strategy regardless of what the other player plays:u1 (C, C) = −5 > u1 (N C, C) = −10; u1 (C, N C) = −1 > u1 (N C, N C) = −2.u2 (C, C) = −5 > u2 (C, N C) = −10; u2 (N C, C) = −1 > u2 (N C, N C) = −2.Thus (C, C) is a natural prediction for this game. However, the outcome (N C, N C)is the best outcome jointly for the players. Prisoner’s dilemma is a classic exampleof a game where rational, intelligent behavior does not lead to an outcome wherethe sum of utilities of the players is maximal. Also, each prisoner has a negativeeffect or externality on the other. When a prisoner moves away from (N C, N C)to reduce his jail term by 1 year, the jail term of the other prisoner increases by 8years.An alternate way of interpreting the strategies of the prisoners is also popular.In this interpretation, each prisoner has two strategies, cooperate and defect. Thestrategy cooperate corresponds to cooperating with the other player by not confessing and therefore is equivalent to the strategy N C. The strategy defect correspondsto betraying the other player by confessing to the crime and therefore is equivalentto the strategy C. In the rest of the book, we will consistently use the C and N Cstrategies and not the defect and cooperate nomenclature.4.7\nCompany’s Dilemma Game\nOn the lines of the prisoner’s dilemma problem, we present an analogous gameinvolving two companies. Consider two companies 1 and 2, each of which canproduce two competing products A and B, but only one at a time. The companiesare known better for product A than for product B. However, environmentalistshave launched a negative campaign on product A branding it as eco-unfriendly.If both the companies produce product A, then, in spite of the negative campaign,their payoff is quite high since product A happens to be a niche product of both thecompanies. On the other hand, if both the companies produce product B, they stillmake some profit, but not as much as they would if they both produced product A.On the other hand, if one company produces product A and the other companyproduces product B, then because of the negative campaign about product A, thecompany producing product A makes zero payoff while the other company capturesall the market and makes a high payoff. The table below depicts the payoff structurefor this game.21AB\nA6, 68, 0\nB0, 83, 3\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nStrategic Form Games\n4.8\nbook\n49\nA Non-Symmetric Company’s Dilemma Game\nThe examples we have provided so far, namely, matching pennies; rock-paperscissors; BOS; coordination; prisoner’s dilemma; and company’s dilemma are instances of symmetric games. A two player strategic form game is called symmetricif S1 = S2 and u1 (s1 , s2 ) = u2 (s2 , s1 ) ∀s1 ∈ S1 , ∀s2 ∈ S2 . We now provide anexample of a non-symmetric game involving two competing companies 1 and 2. Inthis game also, each company has to simultaneously decide which of the two products A, B, it will produce. Company 1 is better known for product A and if ithappens that both companies produce A, company 1 prospers. If both companiesproduce B, then they share the profits equally. If one of them produces A and theother produces B, then company 2 prospers (perhaps due to its more aggressivemarketing). The following payoff matrix captures the strategic situation facing thetwo companies.2\n4.9\n1\nA\nB\nAB\n4, 11, 5\n0, 41, 1\nA Duopoly Pricing Game\nThis is due to Bertrand (1883). There are two companies 1 and 2 which wishto maximize their profits. The demand as a function of a price p is given by acontinuous and strictly decreasing function x(p). The cost for producing each unitof product is c where c > 0. The companies simultaneously choose their prices p1and p2 . The amount of sales for each company is given by:x1 (p1 , p2 )\nx2 (p1 , p2 )\n===\nx(p1 )\n===\nx(p2 )\nx(p1 )2\n0\nx(p2 )2\n0\nififif\np1 < p2p1 = p2p1 > p2\nififif\np2 < p1p1 = p2p2 > p1\nIt is assumed that the firms incur production costs only for an output level equal totheir actual sales. Given prices p1 and p2 , the utilities of the two companies are:u1 (p1 , p2 ) = (p1 − c) x1 (p1 , p2 )u2 (p1 , p2 ) = (p2 − c) x2 (p1 , p2 )\nDecember 27, 2013\n11:21\n50\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nNote that for this game, N = {1, 2} and S1 = S2 = [0, ∞). This is an infinite gamesince the strategy sets are infinite.\n4.10\nTragedy of the Commons\nThe Tragedy of the Commons represents a type of social paradox or social tragedy.The problem involves a conflict over use of resources between individual interestsand social interests. A village has n farmers represented by the set N = {1, 2, . . . , n}.Each farmer has the option of keeping a sheep or not. If 1 corresponds to keepinga sheep and 0 corresponds to not keeping a sheep, the strategy sets are given byS1 = S2 = · · · = Sn = {0, 1}.The utility from keeping a sheep (that arises because of milk, wool, etc.) is equalto 1 unit. The village has a limited stretch of grassland and when a sheep grazes onthis, there is a damage to the environment, equal to 5 units. This damage to theenvironment is to be shared equally by the farmers.Let si be the strategy of each farmer. Then si ∈ {0, 1}. The payoff to farmer iis given by:\u0015\u00145(s1 + · · · + sn )ui (s1 , . . . , si , . . . , sn ) = si −nFor the case n = 2, the payoff matrix would be:210\n00, 0\n1−2.5, −1.5\n1\n−1.5, −2.5\n−4, −4\nIf n > 5, a farmer gains more utility by keeping a sheep rather than not having one.If n < 5, then the farmer gets less utility by keeping a sheep than not having one.If n = 5, the farmer can be indifferent between keeping a sheep and not keeping asheep.If the Government now imposes a pollution tax of 5 units to every farmer keepinga sheep, the payoff becomes:ui (s1 , . . . , si , . . . , sn ) = si − 5si −\n5(s1 + · · · + sn )n\nNow every farmer will prefer not to keep a sheep. We will be analyzing this gamein Chapters 5 and 6 to gain insights into this social situation.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nStrategic Form Games\n4.11\nbook\n51\nBandwidth Sharing Game\nThis problem is based on an example presented by Tardos and Vazirani [2]. Thereis a shared communication channel of maximum capacity 1. There are n users ofthis channel, and user i wishes to send xi units of flow, where xi ∈ [0, 1]. We haveN = {1, 2, . . . , n}S1 = S2 = . . . = Sn = [0, 1].P\nIf i∈N xi ≥ 1, then the transmission cannot happen since the capacity is exceeded,Pand the payoff to each player is zero. If i∈N xi < 1, then assume that the followingis the payoff to user i:X \u0001ui (x1 , . . . , xn ) = xi 1 −xj ∀i ∈ N.j∈N\nThe above expression models the fact that the payoff to a player is proportional tothe flow sent by the player but is negatively impacted by the total flow. The secondterm captures the fact that the quality of transmission deteriorates with the totalbandwidth used. Note that the above is an infinite game (since the strategy sets arereal intervals). We will show in Chapter 6 that an equilibrium outcome here is notsocially optimal.4.12\nA Sealed Bid Auction\nThere is a seller who wishes to allocate an indivisible item to one of n prospectivebuyers in exchange for a payment. Here, N = {1, 2, . . . , n} represents the set ofbuying agents. Let v1 , v2 , . . . , vn be the valuations of the players for the object.The n buying agents submit sealed bids and these bids need not be equal to thevaluations. Assume that the sealed bid from player i (i = 1, . . . , n) could be any realnumber greater than 0. Then the strategy sets of the players are: Si = (0, ∞) fori = 1, . . . , n. Assume that the object is awarded to the agent with the lowest indexamong those who bid the highest. Let b1 , . . . , bn be the bids from the n players.Then the allocation function will be:1yi (b1 , . . . , bn ) =0\nif bi > bj for j = 1, . . . , i − 1; bi ≥ bj for j = i + 1, . . . , notherwise.\nIn the first price sealed bid auction, the winner pays an amount equal to his bid, andthe losers do not pay anything. In the second price sealed bid auction, the winnerpays an amount equal to the highest bid among the players who do not win, and asusual the losers do not pay anything. The payoffs or utilities to the bidders in thesetwo auctions are of the form:ui (b1 , . . . , bn ) = yi (b1 , . . . , bn )(vi − ti (b1 , . . . , bn ))\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n52\nGame Theory and Mechanism Design\nwhere ti (b1 , . . . , bn ) is the amount to be paid by bidder i in the auction when playeri bids bi (i = 1, . . . , n). Assume that n = 4, and suppose the valuations are v1 =20; v2 = 20; v3 = 16; v4 = 16, and the bids are b1 = 10; b2 = 12; b3 = 8; b4 = 14.Then for both first price and second price auctions, we have the allocation y1 (b) =0; y2 (b) = 0; y3 (b) = 0; y4 (b) = 1, where b = (b1 , b2 , b3 , b4 ). The payments forthe first price auction are t1 (b) = 0; t2 (b) = 0; t3 (b) = 0; t4 (b) = 14 whereas thepayments for the second price auction would be: t1 (b) = 0; t2 (b) = 0; t3 (b) =0; t4 (b) = 12. The utilities can be easily computed from the valuations and thepayments.\n4.13\nPigou’s Network Game\nThis example captures the effect of selfish routing when strategic players act independently of one another. A directed graph consists of two nodes S and T and thereare two disjoint edges A and B connecting S to T (see Figure 4.1). A certain amountof traffic has to move from S to T . Each edge is associated with a cost functionc(·) which describes the cost (for example travel time) from S to T , incurred by theusers of that edge, as a function of the fraction of total traffic that is routed on thatedge. Suppose x ∈ [0, 1] denotes the fraction of traffic routed. On the edge A, thecost function is c(x) = x ∀x ∈ [0, 1]. On the edge B, the cost function is constantand equal to unity, that is, c(x) = 1 ∀x ∈ [0, 1]. A routing network of the abovetype is called a Pigou network [3].nA (s)n\nAS\nTB1Fig. 4.1: A Pigou network\nWe shall consider a simple, stylized, discrete version of the above network withjust two users, that is, N = {1, 2}. Each user has two strategies A and B corresponding to the two routes she may select. Thus we have S1 = S2 = {A, B}. Eachuser selects a route to be followed simultaneously and independent of the other user.A natural way of defining the payoff of a user for a strategy profile here would benegative of the cost of travel of the user. For example, suppose the strategy profileis (A, B) (player 1 selecting route A and player 2 selecting route B). The cost of\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nStrategic Form Games\nbook\n53\ntravel for player 1 would be 12 since the fraction of traffic routed through edge A is112 . The payoff for player 1 becomes − 2 . The cost of travel for player 2 is 1 becausethe edge B is selected and the payoff becomes −1. The payoff matrix for this simplerouting game is therefore given by21AB\nA−1, −1−1, − 12\nB− 21 , −1−1, −1\nIf we have n users, we have N = {1, . . . , n} and S1 = . . . = Sn = {A, B}. Lets = (s1 , . . . , sn ) be a strategy profile chosen by all the users. To define the payofffunction, we shall first define nA (s) as the number of players who have chosen theroute A in the strategy profile s. Similarly, nB (s) denotes the number of users whohave chosen route B in the strategy profile s. Clearly, nA (s) + nB (s) = n for allstrategy profiles s. The payoff function is given bynA (s)n= −1\nui (s) = −\nif si = Aif si = B\nWe will analyze the above game in Chapter 6.4.14\nBraess Paradox Game\nThis game is developed on the lines of the game presented in the book by Easley andKleinberg [4]. This game illustrates the Braess paradox which is named after theGerman mathematician Dietrich Braess. This paradox is usually associated withtransportation networks and brings out the counter-intuitive fact that a transportation network with extra capacity added may actually perform worse (in terms oftime delays) than when the extra capacity did not exist. Figure 4.2 shows a network that consists of a source S and a destination T , and two intermediate hubs Aand B. It is required to travel from S to T . One route is via the hub A and theother route proceeds via the hub B.Regardless of the number of vehicles on the route, it takes 25 minutes to travelfrom S to B or from A to T . On the other hand, the travel time from S to Amtakes time 50minutes where m is the number of vehicles on that link. Similarly, themminutes where m is the number of vehiclestravel time from B to T takes time 50on that link. Assume that there are n = 1000 vehicles that wish to move from Sto T . This means N = {1, 2, . . . , 1000}. The strategy sets are S1 = . . . = Sn ={A, B}. Given a strategy profile (s1 , . . . , sn ), let nA (s1 , . . . , sn ) (nB (s1 , . . . , sn ))denote the number of vehicles taking the route via A (B). It is easy to note that\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n54\nGame Theory and Mechanism Design\nAm50\n25\nS\nT\nSource\nDestination\n25\nm50\nB\nFig. 4.2: A transportation network with four nodesnA (s1 , . . . , sn ) + nB (s1 , . . . , sn ) = n. Since we wish to minimize travel time from Sto T , it is convenient to define the utility of a player (in this case vehicle) as thenegative of the travel time for that player from S to T . It is easy to see thatnA (s1 , . . . , sn )ui (s1 , . . . , sn ) = −25 −if si = A50nB (s1 , . . . , sn )= −25 −if si = B50This defines a strategic form game. Note thatui (A, A, . . . , A) = ui (B, B, . . . , B) = −45ui (s1 , s2 , . . . , sn ) = −35 whenever nA (s1 , . . . , sn ) = nB (s1 , . . . , sn ) = 500Let us say we now introduce a fast link from A to B to ease the congestion inthe network (as a degenerate case, we will assume the travel time from A to Bto be zero). Figure 4.3 depicts this new network with extra capacity added fromA to B. Now the strategies available to each vehicle are to go from S to A toT (call this strategy A); S to B to T (call this strategy B); and S to A to B toT (call this strategy AB). So we have S1 = . . . = Sn = {A, B, AB}. DefiningnA (s1 , . . . , sn ), nB (s1 , . . . , sn ), nAB (s1 , . . . , sn ) on the same lines as before, we getnA (s1 , . . . , sn ) + nAB (s1 , . . . , sn )ui (s1 , . . . , sn ) = −25 −if si = A50nB (s1 , . . . , sn ) + nAB (s1 , . . . , sn )= −25 −if si = B50nA (s1 , . . . , sn ) + nAB (s1 , . . . , sn )=−50nB (s1 , . . . , sn ) + nAB (s1 , . . . , sn )−if si = AB50We will analyze the above two games in Chapters 5 and 6 and illustrate the Braessparadox.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nStrategic Form Games\nbook\n55\nA25\nm50\n0\nS\nT\nSource\nDestination\n25\nm50\nB\nFig. 4.3: Transportation network with an extra link from A to B\n4.15\nSummary and References\nIn this chapter, we presented many examples of strategic form games (also callednormal form games) to gain an appreciation of how real world strategic situationscould be abstracted as games. The examples we presented include:• Matching Pennies, a two person zero-sum game and Rock-Paper-Scissors game,another two person zero-sum game. The games are called zero-sum becausethe sum of the utilities of the two players is zero in every outcome of the game.These are also called strictly competitive games.• BOS (Bach or Stravinsky) game, also called the battle of the sexes game,captures a two player situation where the two players wish to coordinate witheach other but they have different preferences for outcomes.• Coordination game or the student’s coordination game where two players derivea positive payoff only when they are together, however the payoff they derivewhen they are together depends on which actions they select.• Prisoner’s Dilemma, a classic two player game which illustrates many nuancesof strategic conflict and cooperation. This is a game where rational and intelligent behavior does not lead to a socially optimal outcome.• Company’s Dilemma which shows how the prisoner’s dilemma can be used tomodel a strategic situation facing two competing companies trying to outwiteach other.• Non-Symmetric Company’s Dilemma which captures the strategic situationfacing two companies which do not have a symmetric payoff structure.• Duopoly Pricing Game which models the strategic situation facing two competing companies in deciding the price at which to sell a particular product.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n56\nGame Theory and Mechanism Design\n• Tragedy of the Commons, a well studied problem that illustrates a commonsocial paradox involving a conflict over resource sharing. This is a multi-persongame.• Bandwidth Sharing game, a multi-person game with infinite strategy sets whichillustrates the conflict that arises due to sharing of a common resource.• Sealed Bid Auction, which introduces the strategic form games underlying thewell known first price auction and second price auction.• Pigou’s Network game which illustrates the notion of selfish routing by strategic agents acting independently of one another• Braess Paradox game which faithfully captures the strategic conflict leadingto the famous paradox in routing games.The above examples are fairly representative of typical situations discussed in thisbook. We state cautiously that there are numerous other interesting and popularexamples that we have left out in our discussion – in fact, we have covered only aminuscule subset of popular examples here. The following books also contain manyillustrative examples of strategic form games: Osborne [1], Straffin [5], and Binmore[6], and Maschler, Solan, and Zamir [7].The material discussed in this chapter draws upon mainly from three sources,namely the books by Myerson [8], Mascolell, Whinston, and Green [9], and Osborneand Rubinstein [1]. The paper by Tardos and Vazirani [2] is a fine introduction toconcepts in game theory; we have taken many examples from their paper.\nReferences[1][2]\n[3][4][5][6][7][8][9][10][11]\nMartin J. Osborne and Ariel Rubinstein. A Course in Game Theory. Oxford University Press,1994.E. Tardos and V. Vazirani. “Introduction to game theory: Basic solution concepts and computational issues”. In: Algorithmic Game Theory. Ed. by Noam Nisan, Tim Roughgarden,Eva Tardos, and Vijay Vazirani. Cambridge University Press, 2007, pp. 3–28.T. Roughgarden and E. Tardos. “How bad is selfish routing?” In: Journal of ACM 49(2)(2002), pp. 236–259.David Easley and Jon Kleinberg. Networks, Crowds, and Markets: Reasoning About a HighlyConnected World. Cambridge University Press, 2010.Philip D. Straffin Jr. Game Theory and Strategy. The Mathematical Association of America,1993.Ken Binmore. Fun and Games : A Text On Game Theory. D. C. Heath & Company, 1992.Michael Maschler, Eilon Solan, and Shmuel Zamir. Game Theory. Cambridge UniversityPress, 2013.Roger B. Myerson. Game Theory: Analysis of Conflict. Harvard University Press, Cambridge,Massachusetts, USA, 1997.Andreu Mas-Colell, Michael D. Whinston, and Jerry R. Green. Microeconomic Theory. Oxford University Press, 1995.Noam Nisan, Tim Roughgarden, Eva Tardos, and Vijay Vazirani (Editors). Algorithmic GameTheory. Cambridge University Press, 2007.Martin J. Osborne. An Introduction to Game Theory. The MIT Press, 2003.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nStrategic Form Games\n4.16\nbook\n57\nExercises\n(1) There are many interesting games that we have not discussed in this chapter.Explore other examples such as hawk and dove (also called chicken), cold war,pollution control, Cournot pricing game, ISP routing game, available from theliterature, for example, the following books [10, 11, 5, 6, 7].(2) There are n players. Each player announces a number in the set {1, ..., K},where K is a fixed positive integer. A prize of $1 is split equally between allthe people whose number is closest to 23 of the average number. Formulate thisas a strategic form game.(3) Develop the strategic form game for the Pigou network game for n = 3 andn = 4.(4) Consider the following strategic form game (network formation game). Thenodes of the network are the players: N = {1, 2, . . . , n}. The strategy setSi of player i is the set of all subsets of N \\ {i}. A strategy of a node is todecide on with which other nodes it would like to have links. A strategy profilecorresponds to a particular network or graph. Assume that δ where 0 < δ < 1is the benefit that accrues to each node of a link while c > 0 is the cost toeach node of maintaining the link. Further, assume that δ k is the benefit thataccrues from a k-hop relationship, where, k is the length of a shortest pathbetween the two involved nodes. A link is formed under mutual consent whileit can be broken unilaterally. Given a graph g formed out of a strategy profile,let the utility ui (g) of node i be given byXui (g) =δ lij (g) − c.di (g)j6=i\nwhere lij (g) is the number of links in a shortest path between i and j anddi (g) is the degree of node i. Write down the strategy profiles correspondingto following structures of graphs assuming n nodes and compute the utilitiesof all individual nodes.• Complete graph• Straight line graph• Star graph\nJanuary 3, 2014\n11:48\nWorld Scientific Book - 10.25in x 7.5in\nThis page intentionally left blank\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nChapter 5\nDominant Strategy Equilibria\nIn the previous chapter, we presented several examples of strategic form gamesbut we stopped short of analyzing the games. Commencing from this chapter,we start analyzing strategic form games. We define the notions of dominatedstrategies, dominating strategies, dominant strategies, and dominant strategyequilibria. We explore three categories of dominance: strong, weak, and veryweak. We illustrate these notions through the examples of prisoner’s dilemma,Braess paradox, and second price sealed bid auction.\nWe start the chapter with the notion of strong dominance. Subsequently, we introduce the notions of weak dominance and very weak dominance.5.1\nStrong Dominance\nDefinition 5.1 (Strongly Dominated Strategy). Given a strategic form gameΓ = hN, (Si ), (ui )i, a strategy si ∈ Si of player i is said to be strongly dominated byanother strategy s0i ∈ Si ifui (s0i , s−i ) > ui (si , s−i ) ∀s−i ∈ S−iWe also say strategy s0i strongly dominates strategy si .It is easy to note that player i will always prefer to play strategy s0i over strategy si .Definition 5.2 (Strongly Dominant Strategy). A strategy s∗i ∈ Si is said to bea strongly dominant strategy for player i if it strongly dominates every other strategysi ∈ Si . That is, ∀si 6= s∗i ,ui (s∗i , s−i ) > ui (si , s−i ) ∀s−i ∈ S−iDefinition 5.3 (Strongly Dominant Strategy Equilibrium). A strategy profile (s∗1 , . . . , s∗n ) is called a strongly dominant strategy equilibrium of the gameΓ = hN, (Si ), (ui )i if, ∀i = 1, 2, . . . , n, the strategy s∗i is a strongly dominant strategyfor player i.Example 5.1. Recall the prisoner’s dilemma problem where N = {1, 2} and S1 = S2 ={C, N C} and the payoff matrix is given by:59\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n60\nGame Theory and Mechanism Design\n21NCC\nNC−2, −2−1, −10\nC−10, −1−5, −5\nNote that the strategy N C is strongly dominated by strategy C for player 1 sinceu1 (C, N C) > u1 (N C, N C)u1 (C, C) > u1 (N C, C)Similarly, the strategy N C is strongly dominated by strategy C for player 2 sinceu2 (N C, C) > u2 (N C, N C)u2 (C, C) > u2 (C, N C)Thus C is a strongly dominant strategy for player 1 and also for player 2. Therefore (C, C)is a strongly dominant strategy equilibrium for this game.\u0003\nNote that if a (rational) player has a strongly dominant strategy, then we shouldexpect the player to choose that strategy. On the other hand, if a player has astrongly domin i (1 −\nX\nxj ) ∀i ∈ N.\nj∈N\nConsider player i and define:ti =\nX\nxj .\nj6=i\nThe payoff for player i is equal toxi (1 − ti − xi ).In order to maximize the above payoff, we have to choose1 − tix∗i = arg max xi (1 − ti − xi ) ==2xi ∈[0,1]\n1−\n∗j6=i xj\nP\n2\n.\nIf this has to be satisfied for all i ∈ N , then we end up with n simultaneous equationsP1 − j6=i x∗j∗i = 1, . . . , n.xi =2We know that the profile (x∗1 , . . . , x∗n ) is a Nash equilibrium if and only ifui (x∗i , x∗−i ) = max ui (xi , x∗−i ) ∀i = 1, . . . , n.xi ∈Si\nIt can be shown that the above set of simultaneous equations has the unique solution:x∗i =\n1i = 1, . . . , n.1+n\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nPure Strategy Nash Equilibria\nbook\n73\n11, . . . , 1+n) is thus a Nash equilibrium. The payoff for player i in the aboveThe profile ( 1+nNash equilibrium is equal to\u0013\u0012\u0013\u001211.n+1n+1\nTherefore the total payoff to all players combined is equal ton.(n + 1)2As shown below, the above is not a happy situation. Consider the following profile\u0012\u00131 11, ,...,.2n 2n2nIt is easy to show that the above is a non-equilibrium profile and that the profile gives eachplayer a payoff1 \u0010n\u00111.1−=2n2n4nTherefore the total payoff to all the playersn1>.4(n + 1)2\u0001111provides higher payoff than a Nash equilib, 2n, . . . , 2nThus a non-equilibrium profile 2nrium payoff. In general, like in the prisoner’s dilemma problem, the equilibrium payoffs maynot be the best possible outcome for the players individually or collectively or both. Thisis a limitation that Nash equilibrium payoffs often suffer from.\u0003=\nExample 6.6 (Pigou’s Network Game). Let us recall from Chapter 4, Pigou’s network routing game (Figure 4.1). First, we consider the two player version where the payoffmatrix is given by21AB\nA−1, −1−1, − 21\nB− 21 , −1−1, −1\nIt is easy to see that the profiles (A, A), (A, B), and (B, A) are all pure strategy Nashequilibria. The remaining profile (B, B) is not a pure strategy Nash equilibrium becauseeach player stands to gain by deviating unilaterally by playing strategy A instead of strategyB. The Nash equilibrium (A, A) leads to a total utility of −2 for the two agents while theother two equilibria lead to a total utility of − 32 .Now let us consider the case when we have n > 2 players. In this case, the profile(A, A, . . . , A) is a pure strategy Nash equilibrium and it yields a total utility of −n. If nis even, then the profile that produces the highest total utility is any profile in which halfof the players play strategy A and the rest of the players play strategy B. The value ofthis total utility is −(( n2 )( 12 ) − n2 ), which is equal to − 3n4 . Notice that a non-equilibriumprofile where half of the players play strategy A and the rest of the players play strategy B\nDecember 27, 2013\n11:21\n74\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nproduces a total utility that is greater than the total utility produced by a Nash equilibriumprofile. Such a degradation in performance due to rationality of agents is discussed using thenotion of price of anarchy in algorithmic game theory. The book by Nisan, Roughgarden,Tardos, and Vazirani [2] is an excellent source to probe further on this topic.\u0003\nExample 6.7 (Braess Paradox Game). Here we consider the Braess paradox gamewhich we discussed in Chapters 4 and 5. First consider that there is no link from A to B(Figure 4.2). Suppose (s1 , . . . , sn ) is any strategy profile such thatnA (s1 , . . . , sn ) = nB (s1 , . . . , sn ) = 500That is, of the 1000 vehicles, exactly 500 take the route via A while the rest of the 500vehicles take the route via B. Clearly, for such a strategy profile, ui (s1 , s2 , . . . , sn ) is equalto −35 for all vehicles i ∈ N . Suppose vehicle i deviates from si with the rest of the vehiclesretaining their strategies. The utility of vehicle i now becomes (−25 − 50150 ) which is lessthan −35. In fact, because of the unilateral deviation by vehicle i, the utility of all the499 vehicles which were following the same route as vehicle i will now be better off whereasvehicle i and the rest of the 500 vehicles will be worse off. Thus all strategy profiles satisfyingthe above condition will be pure strategy Nash equilibria.Now consider that an additional link is introduced from A to B (Figure 4.3). We haveshown in Chapter 5 that the profile (AB, AB, . . . , AB) is a strongly dominant strategy equilibrium. Hence it is also a pure strategy Nash equilibrium. Note that the above equilibriumprofile results in a total delay of 40 minutes.On the other hand, consider a profile such that 500 vehicles use strategy A while theother 500 vehicles use strategy B. This profile is not a dominant strategy equilibrium or aNash equilibrium but causes a total delay of only 35 minutes for each vehicle. As seen inChapter 5, the paradox here is that the additional link introduced forces strategy AB onevery vehicle (AB being a strongly dominant strategy for each vehicle) thereby causing adelay that is higher than what it would be for a non-equilibrium profile.\u0003\n6.3\nGames without a Pure Strategy Nash Equilibrium\nGiven a strategic form game, there is no guarantee that a pure strategy Nash equilibrium will exist. We provide several examples below.Example 6.8 (Matching Pennies Game). Recall the matching pennies game discussed in Chapter 3 and the payoff matrix for this game:21AB\nA1, −1−1, 1\nB−1, 11, −1\nIt is easy to see that this game does not have a pure strategy Nash equilibrium. This showsthat there is no guarantee that a pure strategy Nash equilibrium will exist. In Chapter 10,we will state sufficient conditions under which a given strategic form game is guaranteed\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nPure Strategy Nash Equilibria\nbook\n75\nto have a pure strategy Nash equilibrium. In the next chapter (Chapter 7), we define thenotion of a mixed strategy Nash equilibrium and show that this game has a mixed strategyNash equilibrium.\u0003\nExample 6.9. The rock-paper-scissors game, whose payoff matrix is shown below, doesnot have a pure strategy Nash equilibrium.\n1RockPaperScissors\nRock0, 01, −1−1, 1\n2Paper−1, 10, 01, −1\nScissors1, −1−1, 10, 0\nThe non-symmetric company’s dilemma game with the following payoff matrix also doesnot have a pure strategy Nash equilibrium.21AB\nA4, 11, 5\nB0, 41, 1\nWe now provide an example of an infinite game that does not have a pure strategy Nashequilibrium.\u0003\nExample 6.10 (Procurement Exchange Game). This game is adapted from anexample presented by Tardos and Vazirani [1]. Imagine a procurement exchange wherebuyers and sellers meet to match supply and demand for a particular product. Supposethat there are two sellers, 1 and 2, and three buyers A, B, and C. Because of certainconstraints such as logistics, assume that• A can only buy from seller 1.• C can only buy from seller 2.• B can buy from either seller 1 or seller 2.• Each buyer has a maximum willingness to pay of 1 and wishes to buy one item.• The sellers have enough items to sell.• Each seller announces a price in the range [0, 1].Let s1 and s2 be the prices announced. It is easy to see that buyer A will buy an item fromseller 1 at price s1 and buyer C will buy an item from seller 2 at price s2 . If s1 < s2 , thenbuyer B will buy an item from seller 1; if s1 > s2 , buyer B will buy from seller 2. Assumethat buyer B will buy from seller 1 if s1 = s2 . The game can now be defined as follows:N = {1, 2}S1 = S2 = [0, 1]u1 (s1 , s2 ) = 2s1 if s1 ≤ s2= s1 if s1 > s2u2 (s1 , s2 ) = 2s2 if s1 > s2= s2 if s1 ≤ s2 .\nDecember 27, 2013\n11:21\n76\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nIt is easy to observe that u2 (1, s2 ) has a value 2s2 for 0 ≤ s2 < 1. Therefore u2 (1, s2 )increases when s2 increases from 0, until s2 reaches 1 when it suddenly drops to 1. Thus itis clear that a profile of the form (1, s2 ) cannot be a Nash equilibrium for any s2 ∈ [0, 1].Similarly, no profile of the form (s1 , 1) can be a Nash equilibrium for any s1 ∈ [0, 1].We now explore if there exists any Nash equilibrium (s∗1 , s∗2 ), with s∗1 , s∗2 ∈ [0, 1). Thereare two cases here.Case 1: If s∗1 ≤ 12 , then the best response for player 2 would be to bid s2 = 1 since thatwould fetch him the maximum payoff. However bidding s2 = 1 is not an option here sincethe range of values for s2 is [0, 1).Case 2: If s∗1 > 12 , then there are two cases: (1) s∗1 ≤ s∗2 (2) s∗1 > s∗2 . Suppose s∗1 ≤ s∗2 .Thenu1 (s∗1 , s∗2 ) = 2s∗1u2 (s∗1 , s∗2 ) = s∗2 .Choose s2 such that 21 < s2 < s∗1 . Thenu2 (s∗1 , s2 ) = 2s2> s∗2 since 2s2 > 1 and s∗2 < 1= u2 (s∗1 , s∗2 ).Thus the players can improve upon (s∗1 , s∗2 ) and hence (s∗1 , s∗2 ) is not a Nash equilibrium.Now, suppose, s∗1 > s∗2 . Thenu1 (s∗1 , s∗2 ) = s∗1u2 (s∗1 , s∗2 ) = 2s∗2 .Now let us choose s1 such that 1 > s1 > s∗1 . Thenu1 (s1 , s∗2 ) = s1 > s∗1 = u1 (s∗1 , s∗2 ).Thus the players can always improve upon (s∗1 , s∗2 ). Therefore this game does not have apure strategy Nash equilibrium.\u0003\n6.4\nInterpretations of Nash Equilibrium\nNash equilibrium is an extensively discussed and debated topic in game theory.Many possible interpretations have been provided. Note that a Nash equilibrium is aprofile of strategies of the n players, such that each player’s choice is the player’s bestresponse given that the rest of the players play their Nash equilibrium strategies. Bydeviating from a Nash equilibrium strategy, a player will not be better off given thatthe other players do not deviate from their Nash equilibrium strategies. Followingare several interpretations put forward by game theorists.A common interpretation views a Nash equilibrium as a prescription. An adviser or a consultant to the n players would logically prescribe a Nash equilibriumstrategy profile to the players. If the adviser recommends strategies that do not\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nPure Strategy Nash Equilibria\nbook\n77\nconstitute a Nash equilibrium, then at least one player would find she is better offdoing differently than advised. If the adviser prescribes strategies that do constitutea Nash equilibrium, then the players are happy because playing the prescribed strategy is best under the assumption that the other players will play their prescribedstrategies. Thus a logical, rational, adviser would recommend a Nash equilibriumprofile to the players. We have to be cautious however: A Nash equilibrium is aninsurance against only unilateral deviations (that is, only one player at a time deviating from the equilibrium strategy). Two or more players deviating might result inplayers improving their payoffs compared to their equilibrium payoffs. For example,in the prisoner’s dilemma problem, (C, C) is a Nash equilibrium. If both the playersdecide to deviate, then the resulting profile is (N C, N C), which is better for boththe players. Note that (N C, N C) is not a Nash equilibrium.Another common interpretation of Nash equilibrium is that of prediction. Ifthe players are rational and intelligent, then a Nash equilibrium provides one possible, scientific prediction for the game. For example, a systematic elimination ofstrongly dominated strategies will lead to a reduced form that will include a Nashequilibrium (this will be illustrated in Chapter 7). Often, iterated elimination ofstrongly dominated strategies leads to a unique prediction which would be a Nashequilibrium.An appealing interpretation of Nash equilibrium is that of a self-enforcing agreement. A Nash equilibrium can be viewed as an implicit or explicit agreement between the players. Once this agreement is reached, it does not need any external means of enforcement because it is in the self-interest of each player to followthis agreement if the others do. In a non-cooperative game, agreements cannot beenforced, hence, Nash equilibrium agreements are desirable in the sense of beingsustainable under the assumption that only unilateral deviations are possible.A natural, easily understood interpretation for Nash equilibrium has to do withevolution and steady-state. A Nash equilibrium is a potential convergence point of adynamic adjustment process in which players adjust their behavior to that of otherplayers in the game, constantly searching for strategy choices that will yield themthe best results. This interpretation has been used to explain biological evolution.In this interpretation, Nash equilibrium is the outcome that results over time whena game is played repeatedly. A Nash equilibrium is like a long standing socialconvention that people are happy to maintain forever.The above interpretations provide the most accepted points of view about Nashequilibrium in game theory. Holt and Roth [3] have published an insightful perspective on the notion of Nash equilibrium.Note. Common knowledge of the game is a standard assumption in identifyinga Nash equilibrium. It has been shown that the common knowledge assumptionis quite strong and may not be required in its full strength. Suppose that eachplayer is rational, knows his own payoff function, and knows the strategy choices of\nDecember 27, 2013\n11:21\n78\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nthe others. This condition is weaker than common knowledge and is called mutualknowledge. Assuming mutual knowledge is adequate to identify a Nash equilibriumprofile. For a detailed discussion of these concepts, the reader is referred to thepaper by Aumann [4]. The book by Maschler, Solan, and Zamir [5] discusses thesenotions extensively with several illustrative examples.\nThomas Schelling received, jointly with Robert Aumann, the2005 Nobel Prize in Economic Sciences for pioneering contributions that led to a clear understanding of conflict and cooperation through game theory analysis. Schelling’s stellar contributions are best captured, among others, by several books that hehas authored. The book The Strategy of Conflict that he wrotein 1960 is a classic work that initiated the study of bargainingand strategic behavior. It has been voted as one of the 100 mostinfluential books since 1945. The notion of focal point, whichis now called the Schelling point is introduced in this work toexplain strategic behavior in the presence of multiple equilibria.Another book entitled Arms and Influence is also a popularly cited work. A highlightof Schelling’s work has been to use simple game theoretic models in an imaginativeway to obtain deep insights into global problems such as the cold war, nuclear armsrace, war and peace, etc.Schelling was born on April 14, 1921. He received his Doctorate in Economicsfrom Harvard University in 1951. During 1950-53, Schelling was in the team of foreignpolicy advisers to the US President, and ever since, he has held many policy makingpositions in public service. He has played an influential role in the global warmingdebate also. He was at Harvard University from 1958 to 1990. Since 1990, he has beena Distinguished University Professor at the University of Maryland, in the Departmentof Economics and the School of Public policy.\n6.5\nExistence of Multiple Nash Equilibria\nWe have seen several examples of strategic form games where multiple Nash equilibria exist. If a game has multiple Nash equilibria, then a fundamental question toask is, which of these would get implemented? This question has been addressedby numerous game theorists, in particular, Thomas Schelling, who proposed thefocal point effect. According to Schelling, anything that tends to focus the players’attention on one equilibrium may make them all expect it and hence fulfill it, likea self-fulfilling prophecy. Such a Nash equilibrium, which has some property thatdistinguishes it from all other equilibria is called a focal equilibrium or a SchellingPoint.Example 6.11. Consider the BOS game with the payoff matrix:\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nPure Strategy Nash Equilibria\nbook\n79\n21AB\nA2, 10, 0\nB0, 01, 2\nHere (A, A) and (B, B) are both Nash equilibria. If there is a special interest created aboutproduct A, then (A, A) may become the focal equilibrium. On the other hand, if there is amarketing blitz on product B, then (B, B) may become the focal equilibrium.\u0003\n6.6\nMaxmin Values and Minmax Values\nGiven a Nash equilibrium, we have seen that the equilibrium strategy of a playerprovides a best response strategy assuming optimistically that the other players donot deviate from their equilibrium strategies. If a player wants to play so as toprotect her payoff against any possible irrationality of the other players, then shehas to plan for a worst case situation. Such situations lead to maxmin strategies.Maxmin Value and Maxmin StrategyThe notion of a maxmin strategy of a player looks at the best possible payoff theplayer can guarantee herself even in the worst case when the other players are freeto choose any strategies. We illustrate this notion using an example.Example 6.12 (Maxmin Value). Consider the non-symmetric company’s dilemmagame (Section 4.8).21AB\nA4, 11, 5\nB0, 41, 1\nThe above game does not have a pure strategy Nash equilibrium. If player 1 chooses strategyA, the minimum payoff he could get is 0 (when player 2 chooses strategy B). On the otherhand, if player 1 chooses B, then the minimum he could get is 1 (when player 2 chooses A orB). Thus player 1 could decide to play strategy B and he is guaranteed to get a minimumpayoff of 1, regardless of the strategy played by player 2. This payoff is called the maxminvalue or security value of player 1 and the strategy B which assures him this payoff is calleda maxmin strategy or a security strategy.Similarly, if player 2 chooses strategy A, the minimum payoff she could get is 1 (whenplayer 1 chooses strategy A). On the other hand, if player 2 chooses B, then the minimumshe could get is again 1 (when player 1 chooses B). Thus whether player 2 plays strategyA or strategy B, she is guaranteed to get a minimum payoff of 1, regardless of player 1’sstrategy. Here, the payoff 1 is called the maxmin value or security value of player 2 andeither of the strategies A, B, is called a maxmin strategy or security strategy of player 2. \u0003\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n80\nGame Theory and Mechanism Design\nSuppose Γ = hN, (Si ), (ui )i is any strategic form game. If player i chooses astrategy si , then the minimum payoff for this player would bemin ui (si , s−i ).\ns−i ∈S−i\nPlayer i can choose a strategy in Si that would maximize the above to obtain apayoff that he is guaranteed to obtain, irrespective of the strategies adopted by therest of the players. This motivates the following definition.Definition 6.3 (Maxmin Value and Maxmin Strategy). Given a strategicform game, Γ = hN, (Si ), (ui )i, the maxmin value or security value of a player i(i = 1, . . . , n) is given by:vi = max min ui (si , s−i ).si ∈Si s−i ∈S−i\nAny strategy s∗i ∈ Si that guarantees this payoff to player i is called a maxminstrategy or security strategy of player i.Example 6.13. For the non-symmetric company’s dilemma game, the maxmin value ofplayer 1 is 1 and that of player 2 is also 1. Strategy B is a maxmin strategy of player 1while strategy A is not a maxmin strategy for him. Strategies A and B are both maxminstrategies for player 2. This shows that a player may have multiple maxmin strategies. \u0003\nNote. If a player i plays a maxmin strategy and the other players play arbitrarily,then player i is always guaranteed to receive a payoff that is no less than vi . Forthis reason, a maxmin strategy is also called a no-regret strategy. In contrast, aNash equilibrium strategy is not necessarily a no-regret strategy for a given player;other players deviating from their equilibrium strategies can cause the payoff of theplayer to become less than his payoff in the equilibrium.The following proposition shows that the payoff of a player in a Nash equilibriumprofile (if one exists) is at least the maxmin value of the player.Proposition 6.1. Suppose a strategic form game Γ = hN, (Si ), (ui )i has a purestrategy Nash equilibrium (s∗1 , . . . , s∗n ). Thenui (s∗1 , . . . , s∗n ) ≥ vi ∀i ∈ N.Proof: First, we note that, ∀i ∈ N ,ui (s∗1 , . . . , s∗n ) = max ui (si , s∗−i ).si ∈Si\nNext we note that ∀i ∈ N ,ui (si , s∗−i ) ≥ min ui (si , s−i ).s−i ∈S−i\nCombining the above two inequalities, it is clear that ∀i ∈ N , ui (s∗1 , . . . , s∗n ) ≥ vi . \u0004\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nPure Strategy Nash Equilibria\nbook\n81\nNote. Given a strategic form game, a profile of maxmin strategies of the playerscan be regarded as another solution concept for the game. There could exist severalsuch profiles. Clearly, these profiles are in general different from Nash equilibriumprofiles. We will see, in Chapter 9, in the specific context of two player zero-sumgames, that, every pure strategy Nash equilibrium profile (when one exists) will infact also be a profile of maxmin strategies of the players.Minmax ValueInformally, the minmax value of a player i is the lowest payoff that can be forced onthe player i when the other players choose strategies that hurt player i the most. Itis defined as follows.Definition 6.4 (Minmax Value and Minmax Strategy). Given a strategicform game, Γ = hN, (Si ), (ui )i, the minmax value of a player i (i = 1, . . . , n) isgiven by:vi = min max ui (si , s−i ).s−i ∈S−i si ∈Si\nAny strategy profile s∗−i ∈ S−i of the other players that forces the payoff vi on playeri is called a minmax strategy profile (of the rest of the players) against player i.Example 6.14. In the non-symmetric company’s dilemma game, suppose we want tocompute the minmax value of player 1. If player 2 plays strategy A, the maximum thatplayer 1 could get is 4 (by playing strategy A). If player 2 plays strategy B, the maximumthat player 1 could get is 1 (by playing strategy A or strategy B). Thus if player 2 playsstrategy B, player 1 is forced to get a maximum payoff of 1, so the minmax value of player1 is 1. The minmax strategy of player 2 against player 1 is clearly the strategy B. Similarly,the minmax value of player 2 is 4 and the minmax strategy of player 1 against player 2 isstrategy A.\u0003\nNote that the minmax value of a player i is such that other players can guaranteethat player i cannot receive more than the minmax value. Alternatively, it is indicative of the maximum resistance that player i can offer when the other players choosetheir strategies to hurt him most. On the other hand, the maxmin value of playeri is the minimum payoff the player can guarantee himself of receiving. Intuitively,it is clear that the minmax value of a player must be greater than or equal to themaxmin value of that player. The following proposition formalizes this fact.Proposition 6.2. Consider a strategic form game Γ = hN, (Si ), (ui )i. Thenvi ≥ vi ∀i ∈ N.Proof: Suppose s∗−i is a minmax strategy against player i. This meansvi = max ui (si , s∗−i ) ∀i ∈ N.si ∈Si\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n82\nbook\nGame Theory and Mechanism Design\nNote ∀i ∈ N thatui (si , s∗−i ) ≥ min ui (si , s−i ) ∀si ∈ Si .s−i ∈S−i\nUsing the above two inequalities, we getvi = max ui (si , s∗−i ) ≥ max min ui (si , s−i ) = vi ∀i ∈ N.si ∈Si\nsi ∈Si s−i ∈S−i\nThus the minmax value of a player is no less than his maxmin value.\u0004The following proposition shows that the payoff of a player in a Nash equilibriumprofile (if one exists) is at least the minmax value of the player.Proposition 6.3. Suppose a strategic form game Γ = hN, (Si ), (ui )i has a purestrategy Nash equilibrium (s∗1 , . . . , s∗n ). Thenui (s∗1 , . . . , s∗n ) ≥ vi ∀i ∈ N.Proof: First, we note that ∀i ∈ N ,ui (s∗1 , . . . , s∗n ) = max ui (si , s∗−i ).si ∈Si\nNote thatmax ui (si , s∗−i ) ≥ min max ui (si , s−i ) ∀i ∈ N.s−i ∈S−i si ∈Si\nsi ∈Si\nFrom the above, it is clear thatui (s∗1 , . . . , s∗n ) ≥ vi ∀i ∈ N.\u0004Note. The above discussion shows that the payoff of a player in a pure strategyNash equilibrium (if one exists) is greater than or equal to the minmax value of theplayer which in turn is greater than or equal to the maxmin value of the player.6.7\nEquilibria in Extensive Form Games\nWe have studied extensive form games briefly in Chapter 3. We now revisit this important class of games and introduce a key solution concept called subgame perfectequilibrium. We discuss only extensive form games with perfect information.Definition 6.5 (Subgame). Given an extensive form game Γ and a non-terminalhistory h, the subgame following h is the part of the game that remains after thehistory h has occurred.Example 6.15. Consider the entry game shown in Figure 6.1(a). Figure 6.1(b) shows theonly proper subgame of the entry game. Figure 6.2(a) shows another extensive form game.Figures 6.2(b) and 6.2(c) show the two proper subgames of this game.\u0003\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nbook\nPure Strategy Nash Equilibria\n83\n1challenger\n2incumbent\nin\naccept\nincumbent\nout\nfight\n2, 1\naccept\n1, 2\n0, 0\n(a)\nfight\n2, 1\n0, 0\n(b)\nFig. 6.1: Entry game and its subgame corresponding to history (in)1\n2\nC\nD2\n1\nG\nE\nF\nH\n(1, 2)\n(3,1)\n(0, 0)(a)\n(2,0)\n1\nG\n(1, 2)\nE\nF1\nH\n(b)\nG\n(0, 0)\n(1, 2)\nH\n(c)\n(0, 0)\nFig. 6.2: Another game and its two subgames with history (C) and history (C, E)Pure Strategy Nash Equilibria in Extensive Form GamesThe notion of Nash equilibrium for extensive form games follows immediatelythrough strategic form game representation of extensive form games. We can formally define a pure strategy Nash equilibrium as follows.Definition 6.6. Given an extensive form game Γ = hN, (Ai ), H, P, (Ii ), (ui )i, astrategy profile s∗ = (s∗1 , . . . , s∗n ) is called a pure strategy Nash equilibrium if ∀i ∈ N ,ui (O(s∗i , s∗−i )) ≥ ui (O(si , s∗−i )) ∀si ∈ Siwhere Si is the set of all strategies of player i (i = 1, 2, . . . , n) and O(.) denotes theoutcome corresponding to a strategy profile.Example 6.16. As an immediate example, consider the entry game (Figure 6.1(a)). Thepayoff matrix of strategic form game that is equivalent to the above game is given by\nDecember 27, 2013\n11:21\n84\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\n1inout\n2accept fight2, 10, 01, 21, 2\nIt is clear that both (in, accept) and (out, fight) are pure strategy Nash equilibria. Note thatplayer 1 would prefer the equilibrium (in, accept) since his utility is higher in this equilibriumwhile player 2 would prefer the equilibrium (out, fight) since her utility is higher in this latterequilibrium.Also, note that the Nash equilibrium (in, accept) is intuitive since the strategy acceptis a valid and best response choice for player 2 in his decision node. The equilibrium (out,fight) is somewhat counter-intuitive because the strategy out played by player 1 will takeplayer 1 to a leaf state, so player 2 is not called upon to play any strategy. However, theequilibrium (out, fight) can be explained through the following threat by player 2 s−i )\nj∈N\n(s1 ,...,sn )∈S\n=\nX X\n···\ns1 ∈S1 s2 ∈S2\n=\nX\nY\nsn ∈Sn\nσj (sj ) ui (si , s−i )\nj∈N\nXY σj (sj ) σi (si ) ui (si , s−i )\nX\nsi ∈Si s−i ∈S−i\nj6=i\n XXY σj (sj ) ui (si , s−i ) .=σi (si )si ∈Si\ns−i ∈S−i\nj6=i\nFrom the above, we immediately get:Xui (σi , σ−i ) =σi (si )ui (si , σ−i ).\n\u0004\nsi ∈Si\nThe implication of this result is that the payoff for any player under a mixed strategycan be computed as a convex combination of the payoffs obtained when the playerplays pure strategies with the rest of the players playing σ−i .We now bring out a few important observations about convex combinations inthe context of mixed strategies with a simple example.Example 7.3. Suppose N = {1, 2}, S1 = {x1 , x2 , x3 , x4 , x5 }, andu1 (σ1 , σ2 ) =\nX\nσ1 (s1 )u1 (s1 , σ2 )\ns1 ∈S1\n= σ1 (x1 )u1 (x1 , σ2 )+ σ1 (x2 )u1 (x2 , σ2 ) + σ1 (x3 )u1 (x3 , σ2 )+ σ1 (x4 )u1 (x4 , σ2 ) + σ1 (x5 )u1 (x5 , σ2 )Suppose S2 is some finite set. Let u1 (x1 , σ2 ) = 5; u1 (x2 , σ2 ) = u1 (x3 , σ2 ) = 10; andu1 (x4 , σ2 ) = u1 (x5 , σ2 ) = 20. First note that the maximum value of the convex combinationis 20 and this maximum value is attained when σ1 (x4 ) = 1 or σ1 (x5 ) = 1 or in general whenσ1 (x4 ) + σ1 (x5 ) = 1. That is, when σ1 (x1 ) + σ1 (x2 ) + σ1 (x3 ) = 0, or equivalently, whenσ1 (x1 ) = σ1 (x2 ) = σ1 (x3 ) = 0. Also, note thatmax\nσ1 ∈∆(S1 )\nu1 (σ1 , σ2 ) = 20;\nmax\nσ1 ∈∆(S1 )\nu1 (σ1 , σ2 ) = max u1 (s1 , σ2 )s1 ∈S1\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n98\nbook\nGame Theory and Mechanism Design\nLet ρ ∈ {σ1 ∈ ∆(S1 ) : u1 (σ1 , σ2 ) ≥ u1 (σ1 0 , σ2 ) ∀σ1 0 ∈ ∆(S1 )}.⇐⇒ ρ(x4 ) + ρ(x5 ) = 1⇐⇒ ρ(x1 ) + ρ(x2 ) + ρ(x3 ) = 0⇐⇒ ρ(x1 ) = ρ(x2 ) = ρ(x3 ) = 0⇐⇒ ρ(y) = 0 ∀ y ∈/ arg max u1 (s1 , σ2 ).s1 ∈S1\nThis example motivates the following important result.\n\u0003\nProposition 7.2. Given a strategic form game hN, (Si ), (ui )i, then, for any σ ∈×i∈N ∆(Si ) and for any player i ∈ N ,max ui (σi , σ−i ) = max ui (si , σ−i )si ∈Si\nσi ∈∆(Si )\nFurthermoreρi ∈ arg max ui (σi , σ−i )σi ∈∆(Si )\niffρi (x) = 0 ∀x ∈/ arg max ui (si , σ−i )si ∈Si\nProof: The first step is to express ui (σi , σ−i ) as a convex combination:Xui (σi , σ−i ) =σi (si )ui (si , σ−i )si ∈Si\nThe maximum value of a convex combination of values is simply the maximum ofthe values. Hencemax ui (σi , σ−i ) = max ui (si , σ−i )\nσi ∈∆(Si )\nsi ∈Si\nA mixed strategy ρi ∈ ∆(Si ) will attain this maximum value iffXρi (x) = 1 where X = arg max ui (si , σ−i )si ∈Si\nx∈X\nThe above is equivalent to: ρi (x) = 0 ∀ x ∈/\narg max ui (si , σ−i ).si ∈Si\n7.4\n\u0004\nNecessary and Sufficient Conditions for a Profile to be a MixedStrategy Nash Equilibrium\nWe now prove an extremely useful characterization for a mixed strategy Nash equilibrium profile. First we define the notion of support of a mixed strategy.Definition 7.4 (Support of a Mixed Strategy). Let σi be any mixed strategyof a player i. The support of σi , denoted by δ(σi ), is the set of all pure strategieswhich have non-zero probabilities under σi , that is:δ(σi ) = {si ∈ Si : σi (si ) > 0}\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nMixed Strategies and Mixed Strategy Nash Equilibrium\nbook\n99\nDefinition 7.5 (Support of a Mixed Strategy Profile). Let σ = (σ1 , . . . , σn )be a mixed strategy profile with δ(σi ) as the support of σi for i = 1, . . . , n. Then thesupport δ(σ) of the profile σ is the Cartesian product of the individual supports, thatis δ(σ1 ) × . . . × δ(σn ).Theorem 7.1. The mixed strategy profile (σ1∗ , . . . , σn∗ ) is a mixed strategy Nashequilibrium iff ∀i ∈ N ,∗ ) is the same ∀s ∈ δ(σ ∗ ) and(1) ui (si , σ−iii∗ ) ≥ u (s0 , σ ∗ ) ∀s ∈ δ(σ ∗ ); ∀s0 ∈∗(2) ui (si , σ−ii i −iiii / δ(σi ).\nWe refer to (1) and (2) above as condition (1) and condition (2), respectively, in therest of this chapter. The theorem implies that the payoff for player i corresponding to any pure strategy having positive probability is the same and moreover isno less than the payoff corresponding to any pure strategy having zero probability(whenever all other players are playing their Nash equilibrium mixed strategies).The theorem is extremely useful in many contexts, including computation of Nashequilibria. We now prove this theorem.Proof of Necessity: We are given that (σ1∗ , . . . , σn∗ ) is a Nash equilibrium. Wehave to show that the profile will satisfy conditions (1) and (2). It is clear from thedefinition of Nash equilibrium that ∀i ∈ N ,∗∗ui (σi∗ , σ−i) ≥ ui (σi , σ−i) ∀σi ∈ ∆(Si )\nThis implies that∗∗ui (σi∗ , σ−i) = max ui (σi , σ−i)σi ∈∆(Si )\nUsing Proposition (7.2) above, we can now write∗∗ui (σi∗ , σ−i) = max ui (si , σ−i)si ∈Si\nThis immediately implies by Proposition (7.1) thatX∗∗σi∗ (si )ui (si , σ−i) = max ui (si , σ−i) ∀i ∈ Nsi ∈Si\nsi ∈Si\nSince σi∗ (si ) = 0 ∀si ∈/ δ(σi ), the above becomesX∗∗σi∗ (si )ui (si , σ−i) = max ui (si , σ−i) ∀i ∈ N.si ∈Si\nsi ∈δ(σi∗ )\nSuppose we have a convex combination π1 x1 + . . . + πk xk of numbers x1 , . . . , xkwith πi 6= 0 ∀i = 1, . . . , k, such that π1 + . . . + πk = 1 and π1 x1 + . . . + πk xk =max(x1 , . . . , xk ), then, it is easy to see thatx1 = x2 = . . . = xk = max(x1 , . . . , xk ).Using the above property, we obtain∗∗ui (si , σ−i) = max ui (si , σ−i) ∀si ∈ δ(σi∗ ); ∀i ∈ N.si ∈Si\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n100\nbook\nGame Theory and Mechanism Design\nThis immediately implies that∗∗ui (si , σ−i) = ui (σi∗ , σ−i) ∀si ∈ δ(σi∗ ); ∀i ∈ N.\nIt is clear from the above that∗∗ui (si , σ−i) ≥ ui (s0i , σ−i) ∀si ∈ δ(σi∗ ); ∀s0i ∈/ δ(σi∗ ); ∀i ∈ N.\nThis proves the necessity.Proof of Sufficiency: We are given that∗ ) has the same value, say, w , for all s ∈ δ(σ ∗ ); ∀i ∈ N(1) ui (si , σ−iiii∗∗ ), ∀s ∈ δ(σ ∗ ); ∀s0 ∈∗ ); ∀i ∈ N .(2) ui (si , σ−i ) ≥ ui (s0i , σ−i/δ(σiiii\nTo prove sufficiency, we have to show that u(σ1∗ , . . . , σn∗ ) is a mixed strategy Nashequilibrium. Consider for any i ∈ N ,X∗∗ui (σi∗ , σ−i)=σi∗ (si )ui (si , σ−i) (Proposition 7.1)si ∈Si\n=\nX\n∗σi∗ (si )ui (si , σ−i)\n(since σi∗ (si ) = 0 ∀si ∈/ δ(σi∗ ))\nsi ∈δ(σi∗ )\n=\nX\nσi∗ (si ).wi (Condition 1)\nsi ∈δ(σi∗ )\n= wiX=σi (si )wi ∀σi ∈ ∆(Si )si ∈Si\n≥\nX\n∗σi (si )ui (si , σ−i) (Condition 2)\nsi ∈Si∗= ui (σi , σ−i).\nThus the above inequality can be written as:∗∗ui (σi∗ , σ−i) ≥ ui (σi , σ−i) ∀σi ∈ ∆(Si ); ∀i ∈ N.\nTherefore, (σ1∗ , . . . , σn∗ ) is a mixed strategy Nash equilibrium.\n\u0004\nImplications of the Necessary and Sufficient ConditionsThe necessary and sufficient conditions above have the following implications.• Given a mixed strategy Nash equilibrium, each player gets the same payoff (asin the equilibrium) by playing any pure strategy having positive probability inher equilibrium mixed strategy.• The above implies that the player can be indifferent about which of the purestrategies (having positive probability in her equilibrium mixed strategy) shewill play. Of course, when this player plays only one of these pure strategies,then it may not be a best response for the other players to play their Nashequilibrium strategies.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nMixed Strategies and Mixed Strategy Nash Equilibrium\nbook\n101\n• To verify whether or not a mixed strategy profile is a Nash equilibrium, it isenough to consider the effects of only pure strategy deviations (with the rest ofthe players playing their equilibrium strategies).Another important implication is described in the following result.Proposition 7.3. Given si ∈ Si , let e(si ) denote the degenerate mixed strategy thatassigns probability 1 to si and probability 0 to all other strategies in Si . The strategyprofile (s∗i , . . . , s∗n ) is a pure strategy Nash equilibrium of the game hN, (Si ), (ui )i iffthe mixed strategy profile (e(s∗1 ), . . . , e(s∗n )) is a mixed strategy Nash equilibrium ofthe game hN, (Si ), (ui )i.Proof: First we prove the sufficiency. Let (e(s∗1 ), . . . , e(s∗n )) be a mixed strategyNash equilibrium. This=⇒ ui (e(s∗i ), e(s∗−i )) ≥ ui (σi , e(s∗−i )) ∀σi ∈ ∆(Si ); ∀i ∈ N=⇒ ui (s∗i , s∗−i ) ≥ ui (σi , s∗−i ) ∀σi ∈ ∆(Si ); ∀i ∈ N=⇒ ui (s∗i , s∗−i ) ≥ ui (e(si ), s∗−i ) ∀si ∈ Si ; ∀i ∈ N=⇒ ui (s∗i , s∗−i ) ≥ ui (si , s∗−i ) ∀si ∈ Si ; ∀i ∈ N=⇒ (s∗1 , . . . , s∗n ) is a pure strategy Nash equilibriumThe above proves sufficiency. To prove the necessity, we proceed as follows. Giventhat (s∗1 , . . . , s∗n ) is a pure strategy Nash equilibrium=⇒ ui (s∗i , s∗−i ) ≥ ui (si , s∗−i ) ∀si ∈ Si ∀i ∈ N=⇒ ui (e(s∗i ), e(s∗−i )) ≥ ui (si , e(s∗−i )) ∀si ∈ Si ∀i ∈ N=⇒ ui (e(s∗i ), e(s∗−i )) = max ui (si , e(s∗−i )) ∀i ∈ Nsi ∈Si\n=⇒ ui (e(s∗i ), e(s∗−i )) =\nmax ui (σi , e(s∗−i )) ∀i ∈ N (By Prop. 7.2)\nσi ∈∆(Si )\n=⇒ ui (e(s∗i ), e(s∗−i )) ≥ ui (σi , e(s∗−i )) ∀σi ∈ ∆(Si ); ∀i ∈ N=⇒ (e(s∗1 ), . . . , e(s∗n )) is a mixed strategy Nash equilibrium.The implication of the above is that to identify pure strategy equilibria of the gamehN, (∆(Si )), (ui )i, it is enough to look at the pure strategy game hN, (Si ), (ui )i. \u0004Mixed Strategy Nash Equilibria of the BOS GameWe consider again the BOS game with the payoff matrix:21A\nA2, 1\nB0, 0\nB\n0, 0\n1, 2\nDecember 27, 2013\n11:21\n102\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nFirst we verify that (A, A) is a Nash equilibrium. For this profile, we denoteσ1∗ (A) = 1; σ1∗ (B) = 0; σ2∗ (A) = 1;\nσ2∗ (B) = 0\nu1 (A, σ2∗ ) = 2; u1 (B, σ2∗ ) = 0Condition (1) of Theorem (7.1) is trivially true and condition (2) of that theorem istrue becauseu1 (A, σ2∗ ) > u1 (B, σ2∗ )These conditions are similarly satisfied for player 2 also. Hence (A, A) is a Nashequilibrium. Similarly, (B, B) is also a NE. Now, let us look at the candidate Nashequilibrium: (( 32 , 13 ), ( 13 , 32 )). We denote:12σ1∗ (B) =3312σ2∗ (A) =σ2∗ (B) =33First we examine the situation with player 1. Let us check condition (1).221u1 (A, σ2∗ ) = (2) + (0) =333122∗u1 (B, σ2 ) = (0) + (1) =333Thus condition (1) is satisfied. Now, condition (2) is trivially satisfied sinceδ(σ1∗ ) = {A, B}, the entire set.σ1∗ (A) =\nLet us examine the case of player 2. First we check condition (1).22u2 (σ1∗ , A) = ; u2 (σ1∗ , B) = .33Thus condition (1) is satisfied. As before, condition (2) is trivially satisfied.Let us investigate if there are any other Nash equilibria. The equilibrium (A, A)corresponds to the support {A} × {A}. The equilibrium (B, B) corresponds to thesupport {B} × {B}. The equilibrium (( 32 , 13 ), ( 13 , 32 )) corresponds to the support{A, B} × {A, B}. We notice the following facts.• There is no Nash equilibrium with support {A} × {A, B}. If player 1 playsA, then player 2 has to play only A, which leads to the pure strategy Nashequilibrium (A, A). There is no way player will play B with non-zero probability.• Similarly, there is no Nash equilibrium with any of the following supports:{B} × {A, B}{A, B} × {A}{A, B} × {B}{B} × {A}{A} × {B}\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nMixed Strategies and Mixed Strategy Nash Equilibrium\nbook\n103\n• Let us see if there is any other Nash equilibrium with support {A, B} × {A, B}.To see this, let (σ1∗ , σ2∗ ) defined byσ1∗ (A) = x\nσ1∗ (B) = 1 − x\nσ2∗ (A) = y\nσ2∗ (B) = 1 − y\nbe a Nash equilibrium such that neither x 6= 0, x 6= 1, y 6= 0 and y 6= 1 (0 < x <1; 0 < y < 1). Then by condition (1) of the theorem, we have:u1 (A, σ2∗ ) = u1 (B, σ2∗ )u2 (σ1∗ , A) = u2 (σ1∗ , B)This implies 2y = 1 − y and x = 2(1 − x). This in turn implies y = 31 ; x = 32 .This leads to the NE\u0012\u0013\u0012\u00132 11 2∗σ1∗ =,,; σ2 =3 33 3The above equilibrium is the same as what we have discussed earlier. Thus the gamedoes not have any other equilibria.Mixed Strategy Nash Equilibria of the Coordination GameLet us consider the coordination game with the payoff matrix:21\nA\nB\nAB\n10, 100, 0\n0, 01, 1\nIn one interpretation of this game, the two players are students studying in a collegeand option A corresponds to staying in college and option B corresponds to goingto a movie. We have already seen that (A, A) and (B, B) are pure strategy Nashequilibria. These correspond to the supports {A}×{A} and {B}×{B}, respectively.It can be shown that the supports {A}×{B}; {B}×{A}; {A}×{A, B}; {B}×{A, B};{A, B}×{A}; {A, B}×{B} do not lead to any Nash equilibrium. We now investigateif there exists a Nash equilibrium with the support {A, B} × {A, B}. Let σ1∗ =(x, 1 − x); σ2∗ = (y, 1 − y) with x 6= 0, x 6= 1, y 6= 0, y 6= 1 be a Nash equilibrium.Then condition (2) is trivially satisfied (since the support in each case is the entirestrategy set). Let us check condition (1) which leads to:u1 (A, σ2∗ ) = u1 (B, σ2∗ )u2 (σ1∗ , A) = u2 (σ1∗ , B)The above equations are equivalent to10y = 1 − y10x = 1 − x\nDecember 27, 2013\n11:21\n104\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\n11 101 101; x = 11. This means (σ1∗ = ( 11, 11 )), σ2∗ = ( 11, 11 )) is alsoThis leads to: y = 11a Nash equilibrium. This equilibrium looks somewhat counter-intuitive, however,a careful examination of conditions (1) and (2) of Theorem 7.1 explains why thismust be a Nash equilibrium. Note that the players have no real preference over theprobabilities with which they play their strategies. What actually determines theseprobabilities is the Nash equilibrium requirement to make the other player indifferentover her pure strategies in the support. Well, is it not common that students gooff to a movie with a high probability rather than studying in the college? It isinteresting that though staying in college gives higher payoff, the friends are morelikely to meet in a movie if that is the (focal) equilibrium selected.\n7.5\nMaxmin Values and Minmax Values in Mixed Strategies\nWe have discussed in Section 6.6, the notions of maxmin values and minmax valuesin pure strategies. We now discuss these notions in the context of mixed strategies.For the sake of convenience, we use the same symbols vi and vi (that we have used inthe context of pure strategies) to denote maxmin value and minmax value in mixedstrategies. We hasten to add that the maxmin value of a player in mixed strategiesis not necessarily equal to the maxmin value in pure strategies. Similar is the casewith minmax values.Maxmin Value in Mixed StrategiesGiven a strategic form game, the maxmin value of a player is the highest payoff theplayer can guarantee himself even in the worst case when the other players are freeto play any mixed strategies. This notion is formalized in the following definition.Definition 7.6 (Maxmin Value in Mixed Strategies). Given a strategic formgame, Γ = hN, (Si ), (ui )i, the maxmin value or security value, in mixed strategies,of a player i (i = 1, . . . , n) is given by:vi = max\nσi ∈∆(Si )\nmin\nσ−i ∈×j6=i ∆(Sj )\nui (σi , σ−i ).\nAny mixed strategy σi ∈ ∆(Si ) that guarantees this payoff to player i is called amaxmin mixed strategy or security strategy of player i.Note. A player may have multiple maxmin mixed strategies.The following proposition shows that the payoff of a player in a mixed strategyNash equilibrium is at least the maxmin value in mixed strategies of the player. The\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nMixed Strategies and Mixed Strategy Nash Equilibrium\nbook\n105\nproof is similar to that of Proposition 6.1 which appears in Section 6.6.Proposition 7.4. Suppose a strategic form game Γ = hN, (Si ), (ui )i has a mixedstrategy Nash equilibrium (σ1∗ , . . . , σn∗ ). Thenui (σ1∗ , . . . , σn∗ ) ≥ vi ∀i ∈ Nwhere vi is the maxmin value in mixed strategies of player i.\nMinmax Value in Mixed StrategiesIntuitively, the minmax value in mixed strategies of a player i is the lowest payoffthat the other players will be able to force on the player i when they choose mixedstrategies that hurt player i the most. It is defined as follows.Definition 7.7 (Minmax Value in Mixed Strategies). Given a strategic formgame, Γ = hN, (Si ), (ui )i, the minmax value, in mixed strategies, of a player i(i = 1, . . . , n) is given by:vi =minmax ui (σi , σ−i ).σ−i ∈×j6=i ∆(Sj ) σi ∈∆(Si )\nAny mixed strategy profile σ−i that forces this payoff on player i is called a minmaxmixed strategy profile (of the rest of the players) against player i.Intuitively, much like in the case of pure strategies, it is clear that the maxminvalue in mixed strategies of a player must be less than or equal to the minmax valuein mixed strategies of that player. The following proposition formalizes this fact.The proof proceeds on lines similar to that of Proposition 6.2 in Section 6.6.Proposition 7.5. Consider a strategic form game Γ = hN, (Si ), (ui )i. Thenvi ≥ vi ∀i ∈ Nwhere vi is the maxmin value in mixed strategies of player i and vi is the minmaxvalue in mixed strategies of player i.Note. It turns out that in two player strategic form games, the maxmin valuein mixed strategies is in fact equal to the minmax value in mixed strategies. Weemphasize that this need not be true in pure strategies.The following proposition states that the payoff of a player in a mixed strategyNash equilibrium profile (if one exists) is at least the minmax value of the player.The proof again proceeds on lines similar to the analogous proposition in Section6.5 (Proposition 6.3).Proposition 7.6. Suppose a strategic form game Γ = hN, (Si ), (ui )i has a mixedstrategy Nash equilibrium (σ1∗ , . . . , σn∗ ). Thenui (σ1∗ , . . . , σn∗ ) ≥ vi ∀i ∈ Nwhere vi is the minmax value in mixed strategies of player i.\nDecember 27, 2013\n11:21\n106\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nNote. The above discussion shows that the payoff of a player in a mixed strategyNash equilibrium (if one exists) is greater than or equal to the minmax value inmixed strategies of the player which in turn is greater than or equal to the maxminvalue in mixed strategies of the player.\n7.6\nDomination in Mixed Strategies\nIn this section, we define the notion of dominance in the context of mixed strategiesand describe how elimination of dominated strategies simplifies equilibrium analysis.Dominating Strategies and Dominated StrategiesSuppose hN, (Si ), (ui )i is a strategic form game. In Chapter 5, we have discussed thenotion of domination in the context of pure strategies. We now extend this notionto mixed strategies.Definition 7.8 (Domination in Mixed Strategies). Given two mixed strategies σi , σi0 ∈ ∆(Si ) of player i, we say σi strictly dominates σi0 ifui (σi , σ−i ) > ui (σi0 , σ−i ) ∀σ−i ∈ ×j6=i ∆(Sj ).We say σi weakly dominates σi0 ifui (σi , σ−i ) ≥ ui (σi0 , σ−i ) ∀σ−i ∈ ×j6=i ∆(Sj ) andui (σi , σ−i ) > ui (σi0 , σ−i ) for some σ−i ∈ ×j6=i ∆(Sj )We say σi very weakly dominates σi0 ifui (σi , σ−i ) ≥ ui (σi0 , σ−i ) ∀σ−i ∈ ×j6=i ∆(Sj )In the cases above, we say the strategy σi0 is strongly (weakly) (very weakly)dominated by σi .Definition 7.9 (Dominant Mixed Strategy Equilibrium). If the mixed strategy σi∗ strongly (weakly) (very weakly) dominates all other strategies σi0 ∈ ∆(Si ), wesay σi∗ is a strongly (weakly) (very weakly) dominant strategy of player i. A strategyprofile (σ1∗ , · · · , σn∗ ) such that σi∗ is a strictly (weakly) (very weakly) dominant strategy for player i, ∀i ∈ N , is called a strictly (weakly) (very weakly) dominant mixedstrategy equilibrium.Note. Clearly, any dominant mixed strategy equilibrium is also a mixed strategyNash equilibrium.Note. A strictly dominant mixed strategy for any player, if one exists, is unique.Therefore a strictly dominant mixed strategy equilibrium, if one exists, is unique.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nbook\nMixed Strategies and Mixed Strategy Nash Equilibrium\n(a)\n(b)2\n1NC\nNC−2, −2\nC−10, −1\n1NC\n2C−10, −1\nC\n−1, −10\n−5, −5\nC\n−5, −5\n107\n(c)\n1C\n2C−5, −5\nFig. 7.1: Prisoner’s dilemma problem and elimination of strictly dominated strategiesExample 7.4. Consider the Prisoner’s Dilemma game whose payoff matrix is reproducedin Figure 7.1(a) for ready reference.Since the strategy N C is strictly dominated by strategy C for player 2, the player willnever play N C. So, strategy N C of player 2 can be eliminated leading to the reducedpayoff matrix as in Figure 7.1(b). Now the strategy N C of player 1 which is dominated bystrategy C can also be eliminated, leading to the degenerate payoff matrix with a single entrycorresponding to the profile (C, C), which in this case happens to be a strongly dominantstrategy equilibrium.\u0003\nExample 7.5. Consider a two player game shown in Figure 7.2 (this game is a modifiedversion of an example that appears in Shoham and Leyton-Brown [1]).\n1\nX\n2Y\nABC\n3,10,11,1\n0,14,11,1\nZ0,00,05,0\nFig. 7.2: A two player game to illustrate elimination of strictly dominated strategiesNote that the strategy Z of player 2 is strictly dominated by the strategy X and alsothe strategy Y . Therefore player 2 will never play strategy Z (whatever the strategy chosenby player 1). Thus strategy Z can be eliminated, leading to the reduced game as shown inFigure 7.3.\n21AB\nX3,10,1\nY0,14,1\nC\n1,1\n1,1\nFig. 7.3: Game obtained after eliminating 0.8• Option 2: A laptop with probability 0.3 or a motorcycle with probability 0.7If the player prefers motorcycle to a laptop, then monotonicity implies that he would preferoption 1 which corresponds to the lottery [0.2 : laptop; 0.8 : motorcycle] over option 2 whichcorresponds to the lottery [0.3 : laptop; 0.7 : motorcycle].\u0003\nAxiom 6 (Continuity)This axiom states that ∀x1 , x2 , x3 ∈ X,x1 \u001f x2 and x2 \u001f x3 =⇒ ∃ p ∈ [0, 1] such that x2 ∼ [p : x1 ; 1 − p : x3 ]The implication of the above axiom is that any outcome x2 such that outcome x1 isstrictly preferred to x2 but outcome x2 is strictly preferred to another outcome x3will be indifferent to a player with [p : x1 ; 1 − p : x3 ] for some probability p.Example 8.6. Suppose a player who has won a competition can get a motorcycle (x1 ) ora laptop (x2 ) or a cellphone (x3 ). Assume that the player strictly prefers a motorcycle over alaptop and strictly prefers a laptop over a cellphone. Then the continuity axiom asserts thatthere exists a probability p ∈ [0, 1] such that the player is indifferent between the secondpreferred outcome laptop and the lottery which gives her a motorcycle with probability por a cellphone with probability (1 − p).\u0003\nWe now state (without proof) a lemma and then state and prove an importanttheorem.Lemma 8.1. Suppose a relation \u0017 satisfies completeness, transitivity, decomposability, and monotonicity. Then if x1 \u001f x2 and x2 \u001f x3 , there would exist a probabilityp such thatx2 \u001f [q : x1 ; 1 − q : x3 ] ∀ 0 ≤ q < p[r : x1 ; 1 − r : x3 ] \u001f x2 ∀ 1 ≥ r > pThe proof is left as an exercise (see exercises at the end of the chapter). Usingaxioms (1) to (6) and the above lemma, we are now in a position to state and provethe key result due to von Neumann and Morgenstern [1].\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nUtility Theory\n8.3\nbook\n121\nThe von Neumann - Morgenstern Theorem\nTheorem 8.1. Given a set of outcomes X = {x1 , . . . , xm } and a preference relation\u0017 on X that satisfies completeness, transitivity, substitutability, decomposability,monotonicity and continuity, there exists a utility function u : X → [0, 1] with thefollowing two properties:(1) u(x1 ) ≥ u(x2 ) iff x1 \u0017 x2 , ∀x1 , x2 ∈ XP(2) u([p1 : x1 ; p2 : x2 ; ... ; pm : xm ]) = mj=1 pj u(xj )Note. Condition (2) in the above theorem clearly specifies how to define the utilityfunction over lotteries. Note that the right hand side is linear in the probabilitiesp1 , . . . , pm . This is a noteworthy feature of the von Neumann - Morgenstern utilityfunction. A utility function that satisfies conditions (1) and (2) above is aptly calleda von Neumann – Morgenstern utility function.Proof : First we look at the degenerate case when xi ∼ xj ∀ xi , xj ∈ X. That is,the player is indifferent among all xi ∈ X. Consider the function u(xi ) = 0 ∀xi ∈ X.Part 1 of the theorem follows immediately. Part 2 follows from decomposability andsubstitutability and is left as an exercise.If this degenerate case is not satisfied, then by completeness, there must exist atleast one most preferred outcome and at least one least preferred outcome with theformer different from the latter. Suppose x̄ ∈ X is a most preferred outcome andx ∈ X is a least preferred outcome. Clearly, x̄ \u001f x. Now, given any xi ∈ X, bycontinuity, there exists a probability pi uniquely such thatxi ∼ [pi : x̄; 1 − pi : x].Define u : X → [0, 1] as u(xi ) = pi ∀xi ∈ X. For this choice of u, we will now provePart 1 and Part 2.Proof of Part 1 : Suppose x1 , x2 ∈ X. Let us define two lotteries σ1 and σ2 in thefollowing way, corresponding to x1 and x2 , respectively:x1 ∼ σ1 = [ u(x1 ) : x̄; 1 − u(x1 ) : x ].x2 ∼ σ2 = [ u(x2 ) : x̄; 1 − u(x2 ) : x ].We will show that u(x1 ) ≥ u(x2 ) ⇐⇒ x1 \u0017 x2 . First we prove that u(x1 ) ≥u(x2 ) =⇒ x1 \u0017 x2 . Suppose u(x1 ) > u(x2 ). Since x̄ \u001f x, then by monotonicity wecan conclude thatx1 ∼ σ1 \u001f σ2 ∼ x2 .Using transitivity, substitutability, and decomposability, we get x1 \u001f x2 .Suppose u(x1 ) = u(x2 ). Then σ1 and σ2 are identical lotteries which meansx1 ∼ σ1 ≡ σ2 ∼ x2 .\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n122\nbook\nGame Theory and Mechanism Design\nTransitivity now yields x1 ∼ x2 . We have thus shown thatu(x1 ) ≥ u(x2 ) =⇒ x1 \u0017 x2 .It remains to show thatx1 \u0017 x2 =⇒ u(x1 ) ≥ u(x2 ).We show the above by proving the contrapositive:u(x1 ) < u(x2 ) =⇒ x2 \u001f x1 .Note that the contrapositive above can be written down by virtue of completeness.In fact, the above statement has already been proved when we showed above thatu(x1 ) > u(x2 ) =⇒ x1 \u001f x2 .All that we have to do is to swap x1 and x2 to get the implication for the currentcase.Proof of Part 2 : First we defineu∗ = u([p1 : x1 ; p2 : x2 ; . . . ; pm : xm ]).By the definition of u, for each xj ∈ X, we havexj ∼ [u(xj ) : x̄;\n1 − u(xj ) : x].\nUsing substitutability, we can replace each xj (in the definition of u∗ ) by the corresponding lottery. This yieldsu∗ = u([p1 : [u(x1 ) : x̄; 1 − u(x1 ) : x] ; . . . ; pm : [u(xm ) : x̄; 1 − u(xm ) : x]]).Note that the above nested or compound lottery only selects between the two outcomes x̄ and x. Using decomposability, we get mmXXpj u(xj ) : x .pj u(xj ) : x̄; 1 −u∗ = u j=1\nj=1\nWe can now use the definition of u to immediately obtainmXpj u(xj ).u∗ =j=1\nThis proves Part 2 of the theorem.\n\u0004\nExample 8.7. Suppose a player who has won a competition is given two options.• Option 1: A tablet with probability 0.3 or a motorcycle with probability 0.7• Option 2: A cellphone with probability 0.3 or a laptop with probability 0.2 or a motorcycle with probability 0.5Suppose the utility function of the player u(·) assigns real numbers 100, 200, 300, 400 to theoutcomes cellphone, tablet, laptop, and motorcycle, respectively. Then the von Neumann– Morgernstern utility function assigns the number (0.3)(200) + (0.7)(400) to option 1 andthe number (0.3)(100) + (0.2)(300) + (0.5)(400) to option 2. The expected utility of option 1is therefore 340 and the expected utility of option 2 is 290. A rational player would clearlyprefer option 1.\u0003\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nUtility Theory\n8.4\nbook\n123\nAffine Transformations\nIn the above theorem, the range of the utility function is [0, 1]. It would be usefulto have a utility function which is not confined to the range [0, 1]. The followingresult extends utility functions to a wider range of possibilities.Proposition 8.1. Every positive affine transformation U (x) of a utility functionu(x) that satisfies U (x) = au(x) + b, where a and b are constants and a > 0,yields another utility function (in this case U ) that satisfies properties (1) and (2)of Theorem 8.1.The proof of the result is left as an exercise. An interesting consequence of the aboveresult is that some two player games which do not appear to be zero-sum are in factzero-sum games, as seen by the following examples.Example 8.8 (A Constant Sum Game). Consider the constant sum game shownin Figure 8.1. The constant sum here is equal to 1. By subtracting this constant sum fromthe utilities of one of the players (say player 2), we end up with the zero-sum game in Figure8.2.\u0003\n21A\nA2, −1\nB5, −4\nB\n−6, 7\n−1, 2\nFig. 8.1: A constant sum game\n21\nA\nB\nAB\n2, −2−6, 6\n5, −5−1, 1\nFig. 8.2: An equivalent zero-sum game\nExample 8.9 (A Non-Zero Sum Game). Consider the two player non-zero, nonconstant sum game shown in Figure 8.3. Using affine transformation g(x) = 12 (x − 17) onthe utilities of player 1, we get a zero-sum game shown in Figure 8.4.\u0003\nDecember 27, 2013\n11:21\n124\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\n21\nA\nB\nAB\n27, −519, −1\n17, 023, −3\nFig. 8.3: A non-zero sum game\n21\nA\nB\nAB\n5, −51, −1\n0, 03, −3\nFig. 8.4: An equivalent zero-sum game\n8.5\nComputing von Neumann - Morgenstern Utilities\nGiven a set of outcomes X, the theory of von Neumann - Morgenstern utilitiesprovides a way of constructing utilities on those outcomes. The key observationis that the utilities can be constructed by asking the player concerned appropriatequestions about lotteries. We explain this with an example (a simplified version ofthe one appearing in chapter 9 of [2]).Suppose X = {x1 , x2 , x3 } and assume without loss of generality that the player inquestion has the following preference ordering: x1 \u001f x2 \u001f x3 . We start by assigningnumbers to the most preferred outcome x1 and least preferred outcome x3 in anarbitrary way, respecting only the fact that x1 is assigned a larger number than x3 .Suppose we choose the numbers 200 and 100 respectively (u(x1 ) = 200; u(x3 ) = 100).We now try to fix a number for x2 . For this, we ask questions such as the following:would you prefer x2 with probability 1 or a lottery that gives you x1 with probability112 and x3 with probability 2 . If the player prefers the certain event x2 to the lottery,the implication is that x2 ranks higher than the midpoint between x1 and x3 , whichmeans x2 must be assigned a number greater than 150. This situation is pictoriallydepicted in Figure 8.5.A possible next question to the player would be: Do you prefer x2 for certain orthe outcome x1 with probability 0.75 and the outcome x3 with probability 0.25 ? Ifthe player prefers the lottery, then the situation will be depicted in Figure 8.6.After a logical sequence of such questions, we would eventually find a lotterysuch that player 1 is indifferent between x2 and a lottery, say, [0.7 : x1 ; 0.3 : x3 ].This means we assign the number 170 to x2 as shown in Figure 8.7.The existence of a unique such solution is guaranteed by von Neumann - Morgenstern utility theory as long as our exploration is within the axiomatic framework.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nbook\nUtility Theory\n125\nx3\nx1\n100\n150\n200x2 here\nFig. 8.5: Scenario 1x3\nx1\n100\n150\n175\n200\nx 2 here\nFig. 8.6: Scenario 2x3\nx1\n100\n150\n170x2\n200\nFig. 8.7: Final assignment8.6\nRisk Attitudes of Players\nIn classic economics literature, three types of risk attitudes are considered: riskaverse, risk neutral, and risk loving (or risk seeking). These three attitudes can beelegantly characterized using utility theory. We first provide a motivating example.Example 8.10 (Risk Attitudes). Suppose a player who has won a competition iseligible to get a motorcycle (x1 ) or a laptop (x2 ) or a cellphone (x3 ). Suppose his utilitiesfor the individual outcomes areu(x1 ) = 1000; u(x2 ) = 200; u(x3 ) = 0We know by utility theory that there exists a probability p ∈ [0, 1] such that the playeris indifferent between a sure outcome x2 and the lottery [p : x1 ; (1 − p) : x3 ]. What thisprobability is will depend on the degree of risk the player is willing to take. If the player isrisk neutral, this probability will be 0.2 (note that 200 = (0.2)1000 + (0.8)(0). A risk averse\nDecember 27, 2013\n11:21\n126\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nplayer will play it safe by tilting towards a sure outcome, so, p will be less than or equal to0.2. A risk loving player is willing to gamble to obtain a higher payoff and p will be greaterthan or equal to 0.2. We formalize these notions below.\u0003\nSuppose the set of outcomes X = [−R, R] where R is a certain positive realnumber and assume that x ∈ X represents the monetary reward a designated playerreceives in the game. Let ui (·) be the von Neumann-Morgenstern utility functiondefined over lotteries on finite subsets of X for that player. As we have seen, ui (·)can be determined from the utilities of the player for individual outcomes, say,Ui : X → R. Note thatUi (x) = ui ([1 : x]) ∀x ∈ XSuppose σ = [p1 : x1 ; . . . , pm : xm ] is a lottery over the set of outcomes {x1 , . . . , xm }where xj ∈ X ∀j = 1, . . . , m. Since ui (·) is a von Neumann – Morgenstern utilityfunction, we havemXpj Ui (xj )ui (σ) =j=1\nDenote the expected monetary reward corresponding to σ by:mXpj xjµσ =j=1\nThen we say player i is risk neutral if for all lotteries σ defined over finite subsetsof X,ui (σ) = ui ([1 : µσ ]).We say player i is risk averse ifui (σ) ≤ ui ([1 : µσ ]).We say player i is risk loving ifui (σ) ≥ ui ([1 : µσ ]).In order to determine if a given utility function is risk neutral or risk averse or riskloving, the above setup entails that we exhaustively check the condition for eachand every σ which is not feasible at all. The following theorem provides a muchmore efficient way of determining the risk attitude of a player. We state this usefultheorem without proof.Theorem 8.2. Suppose x1 , x2 ∈ R represent any pair of monetary receipts by aplayer i. Then player i is risk neutral if ∀p ∈ [0, 1],ui ([p : x1 ; (1 − p) : x2 ]) = ui ([1 : px1 + (1 − p)x2 ]) ∀x1 , x2 ∈ RThe player is risk averse if ∀p ∈ [0, 1],ui ([p : x1 ; (1 − p) : x2 ]) ≤ ui ([1 : px1 + (1 − p)x2 ]) ∀x1 , x2 ∈ RThe player is risk loving if ∀p ∈ [0, 1],ui ([p : x1 ; (1 − p) : x2 ]) ≥ ui ([1 : px1 + (1 − p)x2 ]) ∀x1 , x2 ∈ R\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nbook\nUtility Theory\n127\nNote. The above theorem implies that the utility function of a risk averse playeris concave while the utility function of a risk loving player is convex. Clearly, theutility function of a risk neutral player will be linear. Figures 8.8 and 8.9 depictutility functions that are risk averse and risk loving respectively.\nui (x)ui (x2 )\nui (p(x1 ) + (1 − p)(x2 ))pui (x1 ) + (1 − p)ui (x2 )\nui (x1 )\nx1\npx1 + (1 − p)x2\nx2\nx\nFig. 8.8: Utility function of a risk averse player\nui (x)\nui (x2 )\npui (x1 ) + (1 − p)ui (x2 )\nui (p(x1 ) + (1 − p)(x2 ))\nui (x1 )\nx1\npx1 + (1 − p)x2\nx2\nFig. 8.9: Utility function of a risk loving player\nx\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n128\n8.7\nGame Theory and Mechanism Design\nSummary and References\nA utility function defined in games maps multi-dimensional profiles into real numbersand the question arises whether such a mapping can capture all the preferencescompletely. This question was answered by von Neumann and Morgenstern throughtheir utility theory. The key learnings of this chapter are provided below.• von Neumann and Morgenstern proposed six axioms to express the desirableproperties that we would expect a set of outcomes and preferences to satisfy.These are: completeness, transitivity, substitutability, decomposability, monotonicity, and continuity.• To describe the interaction of preferences with uncertainty about which outcomeis selected, the utility theory uses the notion of lotteries on the set of outcomes.• The utility theory developed by von Neumann and Morgenstern guarantees theexistence of a utility function that completely captures the preferences over lotteries on the outcome set when the above six axioms are satisfied. Interestingly,this utility function is linear in the probabilities in the lottery.• Any affine transformation of a von Neumann Morgenstern utility function is alsoa von Neumann Morgenstern utility function.• A systematic procedure can be used to compute von Neumann Morgensternutilities given a set of outcomes.• Based on the risk attitudes, players can be categorized as risk neutral, riskaverse, or risk loving. The utility functions of these players will be linear, concave, and convex respectively.• It is often tempting to interpret utilities in monetary terms. However, it is notalways appropriate to represent utilities by money. There are many reasonsfor this. First, the utility of an individual is not necessarily dependent onlyon the amount of money. Second, money may not always be involved in everytransaction that we are involved in. An example would be kidney exchange orbarter transaction. Even in those situations where money is involved, the utilitymay not depend linearly on money. The exact dependence will be decided bythe risk attitudes of the players.The material of this chapter has been put together based on the treatment thatappears in [4], [3], [2], and [5]. The reader must consult these references for moreinsights. The treatment [5] and [3] is rigorous and comprehensive. An exhaustiveaccount appears in the original classic work of von Neumann and Morgenstern [1].References[1][2]\nJohn von Neumann and Oskar Morgenstern. Theory of Games and Economic Behavior.Princeton University Press, 1944.Philip D. Straffin Jr. Game Theory and Strategy. The Mathematical Association of America,1993.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nUtility Theory[3][4][5]\n8.8\nbook\n129\nMichael Maschler, Eilon Solan, and Shmuel Zamir. Game Theory. Cambridge UniversityPress, 2013.Yoam Shoham and Kevin Leyton-Brown. Multiagent Systems: Algorithmic, Game-Theoretic,and Logical Foundations. Cambridge University Press, New York, USA, 2009, 2009.Roger B. Myerson. Game Theory: Analysis of Conflict. Harvard University Press, Cambridge,Massachusetts, USA, 1997.\nExercises\n(1) Complete the proof of Lemma 8.1. (Proof is available in [4])(2) Complete the proof of the result that affine transformations of a utility functiondo not affect properties (1) and (2) of the von Neumann – Morgenstern utilities(see Theorem 8.1).(3) Straffin [2] describes a simple graphical way of investigating whether or not agiven two player non-zero sum game is equivalent to a zero-sum game. Thisinvolves plotting of the utilities of player 1 and player 2 on the X-Y plane. Thiswould be an instructive reading exercise.(4) Prove Theorem 8.2 which provides a convenient characterization for risk neutral,risk averse, and risk loving players.\nJanuary 3, 2014\n11:48\nWorld Scientific Book - 10.25in x 7.5in\nThis page intentionally left blank\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nChapter 9\nMatrix Games\nTwo player zero-sum games describe strictly competitive situations involving twoplayers. Matrix games are two player zero-sum games with finite strategy sets.Matrix games are interesting in many ways and their analysis is tractable due totheir simplicity and special structure. It was shown by von Neumann and Morgenstern that linear programming can be used to solve these games. In this chapter,we first provide several examples of matrix games. Next we analyze matrix gamesin the context of pure strategies through key notions such as security level, securitystrategies, and saddle points. We show that pure strategy Nash equilibria, if theyexist, are precisely the saddle points. Following this, we analyze matrix games inthe context of mixed strategies. We show that the optimal strategies for the twoplayers can be described by linear programs which are duals of each other. Thisleads to the main result in this chapter, the minimax theorem, which shows thatevery matrix game is guaranteed to have a mixed strategy Nash equilibrium.\nA two person zero-sum game is a strategic form game h{1, 2}, (S1 , S2 ), (u1 , u2 )i suchthat u1 (s1 , s2 ) + u2 (s1 , s2 ) = 0 ∀s1 ∈ S1 ; ∀s2 ∈ S2 . We also use the notationh{1, 2}, S1 , S2 , u1 , −u1 i. A critical point to note is that a player maximizing herpayoff is equivalent to minimizing the payoff of the other player. For this reason,these games are also called strictly competitive games. By convention, player 1 iscalled the row player and player 2 is called the column player .In this chapter, we only discuss two player zero-sum games with finite strategy sets. Suppose S1 = {s11 , s12 , . . . , s1m } and S2 = {s21 , s22 , . . . , s2n }. Without any confusion, we will assume from now on, that, S1 = {1, 2, . . . , m} andS2 = {1, 2, . . . , n} (the symbol n here is not to be confused with its usual meaning elsewhere in the book, namely the number of players in the game). Sincethe payoffs of one player are just the negative of the payoffs of the other player,these games can be represented by a matrix A with m rows and n columns withaij = u1 (i, j) ∀i ∈ S1 and ∀j ∈ S2 . The number aij is the payoff to player 1 (rowplayer) and −aij is the payoff to player 2 (column player) when player 1 choosesstrategy i and player 2 chooses strategy j. For this reason, these games are alsoaptly called matrix games. For brevity, we will just say A is a matrix game.131\nbook\nDecember 27, 2013\n11:21\n132\n9.1\nWorld Scientific Book - 10.25in x 7.5in\nbook\nGame Theory and Mechanism Design\nExamples of Matrix Games\nExample 9.1 (Matching Pennies). Consider the standard matching pennies game,whose payoff matrix is given by the following table, assuming that strategy 1 correspondsto heads and strategy 2 corresponds to tails:2112\n11, −1−1, 1\n2−1, 11, −1\nThe above matrix can be specified by a matrix A that includes only the payoffs of player 1:\"#1 −1A=−11\n\u0003Example 9.2 (Rock-Paper-Scissors). We have already seen in Section 4.3 the rockpaper-scissors game where there are two players and each player has three possible strategies:1 (rock); 2 (paper); and 3 (scissors). This is a matrix game with the following matrix:0 −11A= 10 −1 −110\n\u0003Example 9.3 (Product Prediction Game). Assume that there are two competingcompanies 1 and 2 that can produce one of three products X, Y , and Z, at a time. Acompany can only produce one product at a time and the payoff to the company dependson the products being produced by both companies. Suppose that when one companygets profit, the other company makes an equal amount of loss. Assuming X, Y , and Z asstrategies 1, 2, and 3, respectively, we have S1 = S2 = {1, 2, 3}. An example payoff matrixis given by100200100A=0 −100200 −1000 −200Each company has to decide simultaneously upon a product to produce. It would be ofinterest to predict which products the two companies will produce in equilibrium.\u0003\nExample 9.4 (A Constant Sum Game). An immediate generalization of a zerosum game is a constant sum game: h{1, 2}, S1 , S2 , u1 , u2 i such that u1 (s1 , s2 ) + u2 (s1 , s2 ) =C, ∀s1 ∈ S1 ; s2 ∈ S2 where C is a known constant. Any constant sum game can be transformed into a zero-sum game using a simple transformation (for example, by subtractingthe constant from each payoff of one player) and can be analyzed as a zero-sum game. \u0003\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nMatrix Games\n9.2\nbook\n133\nPure Strategies in Matrix Games\nIn this section, we analyze matrix games when only pure strategies are allowed.First note that maximizing the payoff of any player is the same as minimizing thepayoff of the other player. When the row player plays strategy i, the column playerplays a strategy that will minimize the row player’s payoff:min aij\nj∈S2\nThe above payoff is the minimum guaranteed payoff to the row player when sheplays i. The row player will therefore look for a pure strategy i that maximizes theabove. That is, a strategy i such thatmax min aiji∈S1 j∈S2\nIn other words, an optimal strategy for the row player is maxminimization. Notethat the row player chooses a pure strategy that is best for her on the assumptionthat whatever she does, the column player will choose a strategy that will hurt her(row player) as much as possible. Such a strategy of the row player is called themaxmin strategy or security strategy of the row player.Similarly, when the column player plays pure strategy j, he assures himself of apayoff equal tomin (−aij ) = − max aij .i∈S1\ni∈S1\nThat is, he assures himself of losing no more thanmax aiji∈S1\nThe column player’s optimal strategy will be to minimize this loss:min max aij\nj∈S2 i∈S1\nThis is called minmaximization. Such a strategy of the column player is called asecurity strategy of the column player.Thus, the maxmin value and minmax value play a natural role in describing theoptimal strategies of players in a matrix game. We have already defined the notionsof maxmin value and minmax value in Chapter 6 and we recall these below.Definition 9.1 (Maxmin Value). Given a matrix game A, the maxmin value isdefined as:v = max min aiji∈S1 j∈S2\nNote. The maxmin value v is the minimum guaranteed payoff to the row playerwhen the column player is free to play any strategy. A strategy of the row playerthat yields her the payoff v is called a maxmin strategy of the player.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n134\nGame Theory and Mechanism Design\nNote. The maxmin value v is also called the security level of the row player orlower value. A maxmin strategy is also called a security strategy or optimal strategyof the row player.Definition 9.2 (Minmax Value). Given a matrix game A, the minmax value isdefined as:v = min max aijj∈S2 i∈S1\nNote. The value v is the maximum loss that the column player may suffer whenthe row player is free to play any strategy. The minmax value v is also called theupper value. A strategy of the column player that results in his getting the payoff−v is called a security strategy or optimal strategy of the column player.Note. We have already shown in Section 6.5 that v ≤ v. If v = v, then we havethe following definition.Definition 9.3 (Value in Pure Strategies). Given a matrix game A, if v = v,the number v = v = v is called the value of the matrix game in pure strategies.Example 9.5 (Maxmin Value and Minmax Value). Consider\nthe matchingpennies game. If the row player plays strategy 1, then the possible payoffs are 1 (if thecolumn player plays strategy 1) or −1 (if the column player plays strategy 2) and hence theminimum payoff is −1. Similarly, if the row player plays strategy 2, the minimum payoffpossible is −1. Thus the maxmin value is given byv = max min aij = max{−1, −1} = −1i\nj\nBoth strategy 1 and strategy 2 are security strategies for the row player. The minmax valueis given byv = min max aij = min{1, 1} = 1j\ni\nHere again, both strategy 1 and strategy 2 are security strategies for the column player.The game does not have a value since v 6= v.Next we consider the rock-paper-scissors game. We have:v = max min aij = max{−1, −1, −1} = −1i\nj\nv = min max aij = min{1, 1, 1} = 1j\ni\nThis game, like the previous one, does not have a value since v 6= v.Finally we consider the product prediction game. We havev = max min aij = max{100, −100, −200} = 100i\nj\nv = min max aij = min{100, 200, 200} = 100j\ni\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nMatrix Games\nbook\n135\nNote that v = v and the payoff v = 100, corresponding to the strategy profile (1, 1) is thevalue. Strategy 1 is row player’s security strategy and strategy 1 is column player’s securitystrategy.\u0003\n9.3\nSaddle Points and Pure Strategy Nash Equilibria\nAs observed in the examples above, given a matrix game A, the maxmin value vand the minmax value v always exist but they may not be equal. If they are equal,then the matrix is guaranteed to have one or more saddle points. We now definethe notion of saddle point of a matrix.Definition 9.4 (Saddle Point of a Matrix). Given a matrix A = [aij ], the element aij is called a saddle point of A (or matrix game A) ifaij ≥ akj\n∀k = 1, . . . , m; and\naij ≤ ail\n∀l = 1, . . . , n.\nThat is, the element aij is simultaneously a maximum in its column and a minimumin its row. Given a matrix game A, the strategies i and j are called the saddle pointstrategies of row player and column player, respectively.We now make several key observations on saddle points. First we present twoexamples.Example 9.6 (Saddle Points). Consider the product prediction game. We have seenthat the value is v = 100 and this corresponds to the strategy profile (1, 1). Note that a11is simultaneously a column maximum and a row minimum and therefore is a saddle point.We also make the following important additional observations.• Saddle point strategy 1 is a best response strategy of the row player when the columnplayer chooses saddle point strategy 1, and vice-versa. Hence the profile (1, 1) is apure strategy Nash equilibrium. The strategy profile (1, 1) obviously satisfies the Nashequilibrium property namely the row player (the column player) will not be better offplaying any other strategy when the column player (row player) sticks to the equilibriumstrategy.• The saddle point strategy profile (1, 1) remarkably satisfies the following property aswell: The row player (column player) is not worse off by sticking to her saddle pointstrategy when the column player (row player) deviates from his saddle point strategy.• By playing the saddle point strategy 1, the row player can assure herself a payoff of atleast 100. By playing the saddle point strategy 1, the column player can assure himselfthat the row player will get a payoff of at most 100.• If the row player gets a payoff of less than 100, then the row player can always do betterby playing the saddle point strategy 1. If the row player gets a payoff of greater than100, then the column player can always do better by playing saddle point strategy 1and limiting the row player to a payoff of 100.The above observations capture many properties satisfied by saddle point strategies.\n\u0003\nDecember 27, 2013\n11:21\n136\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nExample 9.7. Let us look at a matrix game with the following matrix:\n5A = 24\n313\n5−15\n3−2 3\nv = max min aij = max{3, −2, 3} = 3i\nj\nv = min max aij = min{5, 3, 5, 3} = 3j\ni\nFor the above game, note that v = v = 3. This game has four saddle points, namelya12 , a14 , a32 , and a34 , and they all yield the same payoff 3. Furthermore, all the fourstrategy profiles (1, 2), (1, 4), (3, 2), (3, 4) also turn out to be pure strategy Nash equilibria.In fact, these are the only pure strategy Nash equilibria.\u0003\nThe above two examples motivate and lead to the following results. First, thefollowing theorem gives a necessary and sufficient condition for existence of a saddlepoint.Theorem 9.1. A matrix A has a saddle point if and only if v = v.The proof of the above is left as an exercise. The following proposition asserts thatpure strategy Nash equilibria in matrix games are in fact the same as saddle points.Proposition 9.1. For a matrix game with payoff matrix A, aij is a saddle point ifand only if the strategy profile (i, j) is a pure strategy Nash equilibrium.Proof: Suppose aij is a saddle point of A. We show that the outcome (i, j) isa PSNE. Since aij is a saddle point, aij is a maximum in column j and aij is aminimum in row i (which means −aij is a maximum in row i). Together, theseimply that the column player is playing a best response strategy against strategy iof the row player and the row player is playing a best response strategy with respectto strategy j of the column player. This in turn implies that (i, j) is a pure strategyNash equilibrium. Thus if aij is a saddle point, then the profile (i, j) is a purestrategy Nash equilibrium.If we assume that the profile (i, j) is a pure strategy Nash equilibrium, we canexactly reverse the above arguments and show that aij is a saddle point of A.\u0004Note. The implication of the above proposition is that pure strategy Nash equilibriaare endowed with substantial additional power in matrix games. Specifically, a purestrategy equilibrium strategy of a player also happens to be a security strategy ormaxmin strategy of the player. This, of course, does not necessarily happen ingames other than two player zero-sum games.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nMatrix Games\nbook\n137\nThe following proposition brings out the interchangeability of saddle points inmatrix games.Proposition 9.2. If in a matrix game with payoff matrix A, the elements aij andahk are both saddle points, then aik and ahj are also saddle points. Also, all saddlepoints in the game yield the same respective payoffs to the players.Another way of stating this proposition would be to state that if (i, j) and (h, k)are pure strategy Nash equilibria, then (i, k) and (h, j) are also pure strategy Nashequilibria. The proof of this is left as an exercise. The proposition implies thatif multiple saddle points exist, they are interchangeable in the sense that a playerusing any of her saddle point strategies against any of the other player’s saddlepoint strategies will also result in a saddle point. Moreover the saddle points areequivalent in the sense that they all yield the same respective payoff value to theplayers.9.4\nMixed Strategies in Matrix Games\nWe have seen that saddle points or pure strategy Nash equilibria may not exist inmatrix games. However, when mixed strategies are allowed, equilibria are guaranteed to exist. Let x = (x1 , . . . , xm ) and y = (y1 , . . . , yn ) be the mixed strategies ofthe row player and the column player respectively. Note that aij is the payoff of therow player when the row player chooses row i and column player chooses columnj with probability 1. The corresponding payoff for the column player is −aij . Theexpected payoff to the row player with the above mixed strategies x and y can becomputed as:= u1 (x, y)m XnXxi yj aij=i=1 j=1\n= xAy\nwhere x = (x1 , . . . , xm ); y = (y1 , . . . , yn ); A = [aij ]\nWe have slightly abused the notation in the above by using the vector y instead ofits transpose (we do this throughout this chapter for the sake of convenience sincethe context is always clear). The expected payoff to column player = −xAy. Whenthe row player plays x, she assures herself of an expected payoffmin xAy\ny∈∆(S2 )\nThe row player should therefore look for a mixed strategy x that maximizes theabove. That is, an x such thatmax\nmin\nx∈∆(S1 ) y∈∆(S2 )\nxAy\nDecember 27, 2013\n11:21\n138\nWorld Scientific Book - 10.25in x 7.5in\nbook\nGame Theory and Mechanism Design\nIn other words, an optimal strategy for the row player is to do maxminimization.Note that the row player chooses a mixed strategy that is best for her on theassumption that whatever she does, the column player will choose a strategy thatwill hurt her (row player) as much as possible. Such a strategy of the row player isalso aptly called a security strategy of the row player.Similarly, when the column player plays y, she assures herself of a payoff= min −xAyx∈∆(S1 )\n= − max xAyx∈∆(S1 )\nThat is, she assures herself of losing no more thanmax xAy\nx∈∆(S1 )\nThe column player’s optimal strategy should be to minimize this loss:min\nmax xAy\ny∈∆(S2 ) x∈∆(S1 )\nThis is called minmaximization. Such a strategy of the column player is also aptlycalled a security strategy of the column player.We now state and prove an important lemma which asserts that when the rowplayer plays x, among the best response strategies y of the column player, there isalways at least one pure strategy.Lemma 9.1. Given a matrix game A and mixed strategies x = (x1 , x2 , . . . , xm ) andy = (y1 , . . . , yn ),min xAy = minj\ny∈∆(S2 )\nmX\naij xi\ni=1\nProof: For a given j, the summationmX\naij xi\ni=1\ngives the payoff to the row player when she adopts x = (x1 , . . . , xm ) and the columnplayer adopts the pure strategy j. Thereforeminj\nmX\naij xi\ni=1\ngives the minimum payoff that the row player gets when she plays x and when thecolumn player is free to play any pure strategy. Since a pure strategy is a specialcase of mixed strategies, we haveminj\nmXi=1\naij xi ≥ min xAyy∈∆(S2 )\n(9.1)\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nMatrix Games\nbook\n139\nOn the other hand,xAy =\nnX\nyj\n≥\n!aij xi\ni=1\nj=1nX\nmX\nyj\nminj\nj=1\n= minj\nmX\nmX\n!aij xi\ni=1\naij xi\nnX\nsince\nyj = 1\nj=1\ni=1\nTherefore, we have:xAy ≥ minj\nmX\naij xi ∀ x ∈ ∆(S1 ); ∀ y ∈ ∆(S2 )\ni=1\nThis implies thatmX\nmin xAy ≥ minj\ny∈∆(S2 )\naij xi\n(9.2)\ni=1\nFrom equations (9.1) and (9.2), we have,min xAy = min\nmX\nj\ny∈∆(S2 )\naij xi\ni=1\nThis completes the proof of the lemma.As an immediate corollary of the above lemma, it can be shown thatnXaij yjmax xAy = maxi\nx∈∆(S1 )\n\u0004\nj=1\nUsing the above results, we can describe the optimization problems of the row playerand the column player as follows.Row Player’s Optimization Problem (Maxminimization)The optimization problem facing the row player can be expressed asmXmaximize minaij xij\ni=1\nsubject tomXxi = 1i=1\nxi ≥ 0 i = 1, . . . , mCall the above problem P1 . Note that this problem can be succinctly expressed asmax\nmin xAy\nx∈∆(S1 ) y∈∆(S2 )\nDecember 27, 2013\n11:21\n140\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nColumn Player’s Optimization Problem (Minmaximization)The optimization problem facing the column player can be expressed asnXminimize maxaij yji\nj=1\nsubject tonXyj = 1j=1\nyj ≥ 0 j = 1, . . . , nCall the above problem P2 . Note that this problem can be succinctly expressed asmin\nmax xAy\ny∈∆(S2 ) x∈∆(S1 )\nThe following proposition shows that the problems P1 and P2 are equivalent toappropriate linear programs.Proposition 9.3. The problem P1 is equivalent to the following linear program (weshall call this linear program LP1 ):Maximizesubject tomXaij xiz−\nz\n≤\n0\nj = 1, . . . , n\ni=1mX\nxi = 1\ni=1\nxi ≥ 0\ni = 1, . . . , m\nProof: Note that P1 is a maximization problem and therefore by looking at theconstraintsmXaij xi ≤ 0 j = 1, 2, . . . , n,z−i=1\nany optimal solution (z ∗ , x∗ ) will satisfy one of the n inequalities in the aboveconstraint. That is,mX∗aij x∗i for some j ∈ {1, . . . , n}z =i=1∗Let j be one such value of j. Then\nz∗ =\nmXi=1\naij ∗ x∗i\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nMatrix Games\nbook\n141\nBecause z ∗ is a feasible solution of LP1 , we havemX\naij ∗ x∗i ≤\nmX\naij x∗i\n∀j = 1, . . . , n\ni=1\ni=1\nThis meansmX\naij ∗ x∗i = min\ni=1\nj\nmX\naij x∗i\ni=1\nIf not, we have∗\nz <\nmX\naij xi ∀j = 1, 2, . . . , n.\n\u0004\ni=1\nThus the following two linear programs describe the optimization problems facingthe row player and the column player.Row Player’s Linear Program (LP1 )maximize zsubject tomXaij xi ≤ 0 j = 1, . . . , nz−mX\ni=1\nxi = 1\ni=1\nxi ≥ 0 ∀i = 1, . . . , mColumn Player’s Linear Program (LP2 )minimize wsubject tonXaij yj ≥ 0 i = 1, . . . , mw−j=1nX\nyj = 1\nj=1\nyj ≥ 0 ∀j = 1, . . . , nExample 9.8 (Rock-Paper-Scissors Game). For the rock-paper-scissors game, recall the matrix of payoffs of row player:\n0A= 1−1\n−101\n1−1 0\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n142\nbook\nGame Theory and Mechanism Design\nThe problem P1 would be:maximize min{x2 − x3 , −x1 + x3 , x1 − x2 }\nsubject to\nx1 + x2 + x3 = 1x1 ≥ 0; x2 ≥ 0; x3 ≥ 0The above problem is equivalent to the linear program (LP 1 ):maximize z\nsubject to\nz ≤ x2 − x3 ; z ≤ −x1 + x3 ; z ≤ x1 − x2 .x1 + x2 + x3 = 1 x1 ≥ 0; x2 ≥ 0; x3 ≥ 0.In respect of the column player, the problem P2 would be:minimize max{−y2 + y3 , y1 − y3 , −y1 + y2 }\nsubject to\ny1 + y2 + y3 = 1y1 ≥ 0; y2 ≥ 0; y3 ≥ 0The above problem is equivalent to the linear program (LP 2 ):minimize w\nsubject to\nw ≥ −y2 + y3 ; w ≥ y1 − y3 ; w ≥ −y1 + y2 .y1 + y2 + y3 = 1; y1 ≥ 0; y2 ≥ 0; y3 ≥ 0.The above linear programs enable us to compute the mixed strategy equilibria.\n9.5\n\u0003\nMinimax Theorem\nThis result is one of the important landmarks in the initial decades of game theory.This result was proved by von Neumann in 1928 using the Brouwer’s fixed pointtheorem. Later, he and Morgenstern provided an elegant proof of this theorem using linear programming duality. The key implication of the minimax theorem is theexistence of a mixed strategy Nash equilibrium in any matrix game.\nTheorem 9.2 (Minimax Theorem). For every matrix game with a (m × n) matrix A, there is a mixed strategy of the row player x∗ = (x∗1 , . . . , x∗m ) and a mixedstrategy of the column player y ∗ = (y1∗ , . . . , yn∗ ) such thatmax xAy ∗ = min x∗ Ay\nx∈∆(S1 )\ny∈∆(S2 )\nMoreover, the profile (x∗ , y ∗ ) is a mixed strategy Nash equilibrium.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nMatrix Games\nbook\n143\nProof: Given a matrix A, we have defined linear programs LP 1 and LP 2 in thepreceding section. The linear program LP 1 describes the optimal strategy of the rowplayer while the linear program LP 2 describes the optimal strategy of the columnplayer. First we make the observation that the linear program LP 2 is the dual of thelinear program LP 1 . We now invoke the strong duality theorem which states: If anLP has an optimal solution, then its dual also has an optimal solution; moreover theoptimal value of the dual is the same as the optimal value of the original (primal)LP . See the mathematical appendix (Chapter 33) for a quick primer on LP duality.To apply the strong duality theorem in the current scenario, we first observe thatthe problem P1 has an optimal solution by the very nature of the problem. SinceLP 1 is equivalent to the problem P1 , the immediate implication is that LP 1 has anoptimal solution. Thus we have two linear programs LP 1 and LP 2 which are dualsof each other and LP 1 has an optimal solution. Then by the strong duality theorem,LP 2 also has an optimal solution and the optimal value of LP 2 is the same as theoptimal value of LP 1 .Let z ∗ , x∗1 , . . . , x∗m be an optimal solution of LP 1 . Then, we havemXaij ∗ x∗i for some j ∗ ∈ {1, . . . , n}z∗ =i=1\nBy the feasibility of an optimal solution in LP 1 , we havemmXXaij x∗i for j = 1, . . . , naij ∗ x∗i ≤i=1\ni=1\nThis implies thatmX\naij ∗ x∗i = minj\ni=1\nmX\naij x∗i\ni=1\n= min x∗ Ayy∈∆(S2 )\n(by Lemma 9.1)\nThusz ∗ = min x∗ Ayy∈∆(S2 )\nSimilarly, let w∗ , y1∗ , . . . , yn∗ be an optimal solution of LP 2 . ThennXai∗ j yj∗ for some i∗ ∈ {1, . . . , m}w∗ =j=1\nBy the feasibility of an optimal solution in LP 2 , we havenmXXaij yj∗ for i = 1, 2, . . . , mai∗ j yj∗ ≥j=1\nj=1\nThis implies thatnXj=1\nai∗ j yj∗ = maxi\nnXj=1\naij yj∗\nDecember 27, 2013\n11:21\n144\nWorld Scientific Book - 10.25in x 7.5in\nbook\nGame Theory and Mechanism Design\n= max xAy ∗x∈∆(S1 )\n(by Lemma 9.1)\nThereforew∗ = max xAy ∗ .x∈∆(S1 )\nBy the strong duality theorem, the optimal values of the primal and the dual arethe same and therefore z ∗ = w∗ . This means thatmin x∗ Ay = max xAy ∗\ny∈∆(S2 )\nx∈∆(S1 )\n(9.3)\nThis proves the main part of the minimax theorem.We now show that the mixed strategy profile (x∗ , y ∗ ) is a mixed strategy Nashequilibrium of the matrix game with matrix A. For this, considerx∗ Ay ∗ ≥ min x∗ Ayy∈∆(S2 )\n= max xAy ∗x∈∆(S1 )\n≥ xAy ∗\n∀x ∈ ∆(S1 )\n(by equation (9.3))\nThat is, x∗ Ay ∗ ≥ xAy ∗ ∀x ∈ ∆(S1 ). This impliesu1 (x∗ , y ∗ ) ≥ u1 (x, y ∗ ) ∀x ∈ ∆(S1 )\n(9.4)\nFurtherx∗ Ay ∗ ≤ max xAy ∗x∈∆(S1 )\n= min x∗ Ayy∈∆(S2 )\n≤ x∗ Ay\n∀y ∈ ∆(S2 )\n(by (equation (9.3))\nThat is, x∗ Ay ∗ ≤ x∗ Ay ∀y ∈ ∆(S2 ). This impliesu2 (x∗ , y ∗ ) ≥ u2 (x∗ , y) ∀y ∈ ∆(S2 )\n(9.5)\nEquations (9.4) and (9.5) immediately imply that (x∗ , y ∗ ) is a mixed strategy Nashequilibrium. This means the minimax theorem guarantees the existence of a mixedstrategy Nash equilibrium for any matrix game.\u0004Example 9.9. For the rock-paper-scissors game, it is easy to see that the linear programsLP 1 and LP 2 are duals of each other. Moreover, the optimal solution of LP 1 can be seento be111x∗1 = ; x∗2 = ; x∗3 = ; z ∗ = 0333The optimal solution of LP 2 can be seen to bey1∗ =\n1 ∗11; y = ; y3∗ = ; w∗ = 03 233\nThus (( 13 , 13 , 13 ), ( 31 , 13 , 13 )) is a mixed strategy Nash equilibrium of the game.\n\u0003\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nMatrix Games\nbook\n145\nA Necessary and Sufficient Condition for Existence of EquilibriumWe now state a key theorem that provides necessary and sufficient conditions for amixed strategy profile to be a Nash equilibrium in matrix games. We leave the proofof this as an exercise. The minimax theorem is used in a crucial way in proving thistheorem.Theorem 9.3. Given a matrix game h{1, 2}, S1 , S2 , u1 , −u1 i, a mixed strategy profile (x∗ , y ∗ ) is a Nash equilibrium if and only ifx∗ ∈ arg max\nmin xAy\ny ∗ ∈ arg min\nmax xAy\nx∈∆(S1 ) y∈∆(S2 )\nandy∈∆(S2 ) x∈∆(S1 )\nFurthermoreu1 (x∗ , y ∗ ) = −u2 (x∗ , y ∗ )= x∗ Ay ∗= max min xAyx∈∆(S1 ) y∈∆(S2 )\n= min\nmax xAy\ny∈∆(S2 ) x∈∆(S1 )\nNote. A key point that must be noted in the context of matrix games, is that thetwo notions Nash equilibrium and maxmin strategy profile, which are in generaldifferent, turn out to be the same. Also, Nash equilibrium provides an insurance toeach player not only against his own unilateral deviations but also against deviationsby the other player.9.6\nSummary and References\nTwo player zero-sum games represent a well studied, well understood special class ofstrategic form games. If the strategy sets are finite, such a game can be convenientlyrepresented by a matrix A where the element aij is the utility of the row player and−aij is the utility of the column player when the row player plays pure strategy iand the column player plays pure strategy j. The following are the key results thatwe have covered in this chapter.• When only pure strategies are allowed, an optimal strategy for the row player isto choose a strategy that maximizes the minimum payoff that she can get in eachof her pure strategies. An optimal strategy for the column player is to choosea strategy that minimizes the maximum payoff that the row player gets in eachof her (column player’s) pure strategies (this is equivalent to minimizing themaximum loss that the column player may suffer in each of her pure strategies).These optimal strategies are also called security strategies of the players.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n146\nGame Theory and Mechanism Design\n• The maxmin value or lower value is denoted by v and the minmax value or uppervalue is denoted by v. It turns out that v ≤ v. If v = v = v, then v is called thevalue. A value may or may not exist if only pure strategies are allowed.• A saddle point of a matrix A is any element aij such that it is a row minimumand a column maximum at the same time. Given a matrix A, a saddle pointexists if and only if v = v. A matrix may have zero or more saddle points.Furthermore, saddle points, if they exist, are precisely the pure strategy Nashequilibria of the game.• If multiple saddle points exist, they all correspond to the same value (which isthe value of the game). Also, saddle point strategies are interchangeable; thatis, given a matrix game A, if aij and ahk are both saddle points, then aik andahj are also saddle points.• The saddle point strategies (also called optimal strategies) in matrix gamesare such that a saddle point strategy of a player not only offers a best responseagainst unilateral deviations in his strategy but also against unilateral deviationsin the other player’s strategy.• In a matrix game, we have seen that pure strategy Nash equilibria (or equivalently saddle points) may or may not exist. However, mixed strategy Nashequilibria always exist and this is a consequence of the minimax theorem of vonNeumann and Morgenstern.• The minimax theorem can be proved using LP duality. An optimal strategy ofthe row player can be computed using a linear program and the dual of thisLP gives an optimal strategy for the column player. Using the strong dualitytheorem, the minimax theorem can be established.• Mixed strategy Nash equilibria of matrix games can be computed by solving alinear program and therefore the worst case computational complexity of thisproblem is polynomial time (which is a rarity in Nash equilibrium computation).The classic book by von Neumann and Morgenstern [1] contains a detailed exposition of matrix games, including the LP duality based approach to the minimaxtheorem. Another excellent reference is the book by Luce and Raiffa [2].The book by Myerson [3] and the book on linear programming by Chvatal [4]have inspired the exposition in this chapter. Other books which can be consultedare the ones by Maschler, Solan, and Zamir [5], Osborne [6], by Rapoport [7], andby Straffin [8].References[1][2][3]\nJohn von Neumann and Oskar Morgenstern. Theory of Games and Economic Behavior.Princeton University Press, 1944.R.D. Luce and H. Raiffa. Games and Decisions. Wiley, New York, 1957.Roger B. Myerson. Game Theory: Analysis of Conflict. Harvard University Press, Cambridge,Massachusetts, USA, 1997.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nMatrix Games[4][5][6][7][8]\n9.7\nbook\n147\nVasek Chvatal. Linear Programming. W.H. Freeman & Company, 1983.Michael Maschler, Eilon Solan, and Shmuel Zamir. Game Theory. Cambridge UniversityPress, 2013.Martin J. Osborne. An Introduction to Game Theory. The MIT Press, 2003.Anatol Rapoport. Two Person Game Theory. Dover Publications, Inc., New York, USA,1966.Philip D. Straffin Jr. Game Theory and Strategy. The Mathematical Association of America,1993.\nExercises\n(1) Given a matrix A = [aij ], recall the definitions:v = max min aiji\nj\nv = min max aijj\ni\n(a) Show that v ≤ v. (b) Show that A has a saddle point if and only if v = v.(2) In a matrix A = [aij ], if two elements aij and ahk are saddle points, thenshow that aik and ahj are also saddle points. An equivalent way of stating thisproposition would be: if (i, j) and (h, k) are pure strategy Nash equilibria, then(i, k) and (h, j) are also pure strategy Nash equilibria.(3) An m × m matrix is called a latin square if each row and each column is apermutation of (1, . . . , m). Compute pure strategy Nash equilibria, if they exist,of a matrix game for which a latin square is the payoff matrix.(4) Consider a matrix game with |S1 | = |S2 | such that the matrix A is antisymmetric. Show that the value in mixed strategies is equal to zero.(5) Consider the following game.\"#a bA=c dDerive the conditions on the values of a, b, c, d for which the game is guaranteedto have a saddle point. Also, compute all mixed strategy Nash equilibria for thegame.(6) Suppose you are given a matrix game with 3 pure strategies for each player.Which numbers among {0, 1, . . . , 9} cannot be the total number of pure strategyNash equilibria for the game? Justify your answer.(7 this chapter, we have outlined that the problem of computing a mixed strategyNash equilibrium in a finite strategic form game is PPAD-complete where the classPPAD consists of all search problems for which every instance has a solution andthe proof of existence of solution is based on the PPAD argument. PPAD stands forpolynomial parity argument for directed graphs and the PPAD argument says that ifa directed graph has an unbalanced node (that is in-degree not equal to out-degree),then there must exist at least one other unbalanced node.As already stated, much of the content in this chapter owes to the survey paperby Daskalakis, Goldberg, and Papadimitriou [1]. The detailed proofs of results areavailable in [7, 1, 4]. There are many other survey articles on both complexityand algorithmic issues in the volume on Algorithmic Game Theory edited by Nisan,Roughgarden, Tardos, and Vazirani [8], The papers by Conitzer and Sandholm [9]and Roughgarden [3] are also expository. There is a good discussion in the book byShoham and Leyton-Brown [10]. Other useful references include [5, 11].References[1][2]\n[3][4][5]\n[6]\n[7][8][9]\n[10][11]\nC. Daskalakis, P. W. Goldberg, and C. H. Papadimitriou. “The complexity of computing aNash equilibrium”. In: Communications of the ACM 52(2) (2009), pp. 89–97.C.H. Papadimitriou. “The complexity of finding Nash equilibria”. In: Algorithmic GameTheory. Ed. by Noam Nisan, Tim Roughgarden, Eva Tardos, and Vijay Vazirani. CambridgeUniversity Press, 2007, pp. 29–52.T. Roughgarden. “Algorithmic game theory”. In: Communications of the ACM 53(7) (2010),pp. 78–86.Xi Chen, Xiaotie Deng, and Shang-Hua Teng. “Settling the complexity of two-player Nashequilibrium”. In: Journal of ACM 56(3) (2009).R. J. Lipton, E. Markakis, and A. Mehta. “Playing large games using simple strategies”.In: Proceedings of the 4th ACM Conference on Electronic Commerce, EC-2003. ACM. 2003,pp. 36–41.R. D. McKelvey and A. McLennan. “Computation of equilibria in finite games”. In: Handbookof Computational Economics. Ed. by J. Rust, H. Amman, and D. Kendrick. Elsevier, 1996,pp. 87–142.C. Daskalakis. “The complexity of computing a Nash equilibrium”. In: Proceedings of the 38thAnnual ACM Symposium on Theory of Computing, STOC-2006. ACM. 2006, pp. 71–78.Noam Nisan, Tim Roughgarden, Eva Tardos, and Vijay Vazirani (Editors). Algorithmic GameTheory. Cambridge University Press, 2007.Vincent Conitzer and Tuomas Sandholm. “Complexity Results about Nash Equilibria”.In: Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence,IJCAI-2003, Acapulco, Mexico. 2003, pp. 765–771.Yoam Shoham and Kevin Leyton-Brown. Multiagent Systems: Algorithmic, Game-Theoretic,and Logical Foundations. Cambridge University Press, New York, USA, 2009, 2009.K. Etessami and M. Yannakakis. “On the complexity of Nash equilibria and other fixedpoints”. In: 48th Annual IEEE Symposium on Foundations of Computer Science, FOCS2007. IEEE. 2007, pp. 113–123.\nJanuary 3, 2014\n11:48\nWorld Scientific Book - 10.25in x 7.5in\nThis page intentionally left blank\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nChapter 13\nBayesian Games\nWe have so far studied strategic form games with complete information, where thethe entire game is common knowledge to the players. We will now study games withincomplete information, where at least one player has private information about thegame which the other players may not know. While complete information gamesprovide a convenient and useful abstraction for strategic situations, incompleteinformation games are more realistic. Incomplete information games are centralto the theory of mechanism design. In this chapter, we study a particular form ofthese games called Bayesian games and introduce the important notion of BayesianNash equilibrium.\n13.1\nGames with Incomplete Information\nA game with incomplete information is one in which, when the players are ready tomake a move, at least one player has private information about the game which theother players may not know. The initial private information that a player has, justbefore making a move in the game, is called the type of the player. For example,in an auction involving a single indivisible item, each player has a valuation for theitem, and typically this player would know this valuation deterministically while theother players may only have probabilistic information about how much this playervalues the item.Definition 13.1 (Strategic Form Game with Incomplete Information).A strategic form game with incomplete information is defined as a tuple Γ =hN, (Θi ), (Si ), (pi ), (ui )i where• N = {1, 2, . . . , n} is the set of players.• Θi is the set of types of player i where i = 1, 2, . . . , n.• Si is the set of actions or pure strategies of player i where i = 1, 2, . . . , n.• The belief function pi is a mapping from Θi into ∆(Θ−i ), the set of probabilitydistributions over Θ−i . That is, for any possible type θi ∈ Θi , pi specifies aprobability distribution pi (.|θi ) over the set Θ−i representing player i’s beliefsabout the types of the other players if his own type were θi ;189\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n190\nGame Theory and Mechanism Design\n• The payoff function ui : Θ1 × . . . × Θn × S1 × . . . × Sn → R assigns to each profileof types and each profile of actions, a payoff that player i would get.When we study such a game, we assume that(1) Each player i knows the entire structure of the game as defined above.(2) Each player i knows his own type θi ∈ Θi . The player learns his type throughsome signals and each element in his type set is a summary of the informationgleaned from the signals.(3) The above facts are common knowledge among all the players in N .(4) The exact type of a player is not known deterministically to the other playerswho however have a probabilistic guess of what this type is. The belief functionspi describe these conditional probabilities. Note that the belief functions pi arealso common knowledge among the players.\nBayesian GamesJohn Harsanyi (joint winner of the Nobel Prize in Economic Sciences in 1994 withJohn Nash and Reinhard Selten) proposed in 1968, Bayesian games to representgames with incomplete information. We first define the notion of consistency whichis a natural and reasonable assumption to make in games with incomplete information.Definition 13.2 (Consistency of Beliefs). We say beliefs (pi )i∈N are consistentif there is some common prior distribution over the set of type profiles Θ such thateach player’s beliefs given his type are just the conditional probability distributionsthat can be computed from the prior distribution.If the game is finite, beliefs are consistent if there exists some probability distributionP ∈ ∆(Θ) such thatpi (θ−i |θi ) =\nP(θ , θ )P i −i∀θi ∈ Θi ; ∀θ−i ∈ Θ−i ; ∀i ∈ N.P(θi , t−i )t−i ∈Θ−i\nIn a consistent model, differences in beliefs among players can be logically explainedby differences in information. If the model is not consistent, differences in beliefsamong players can only be explained by differences of opinion that cannot be derivedfrom any differences in information and must be simply assumed a priori [1]. Whenconsistency of beliefs is satisfied, we refer to the games as Bayesian games.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nBayesian Games\nbook\n191\nIn 1994, John Charles Harsanyi was awarded the Nobel Prizein Economic Sciences, jointly with Professor John Nash andProfessor Reinhard Selten, for their pioneering analysis of equilibria in non-cooperative games. Harsanyi is best known for hiswork on games with incomplete information and in particularBayesian games, which he published as a series of three celebrated papers titled Games with incomplete information playedby Bayesian players in the Management Science journal in 1967and 1968.His work on analysis of Bayesian games is of foundational value to mechanismdesign since mechanisms crucially use the framework of games with incomplete information. Harsanyi is also acclaimed for his intriguing work on utilitarian ethics, wherehe applied game theory and economic reasoning in political and moral philosophy.Harsanyi’s collaboration with Reinhard Selten on the topic of equilibrium analysisresulted in a celebrated book entitled A General Theory of Equilibrium Selection inGames (MIT Press, 1988).John Harsanyi was born in Budapest, Hungary, on May 29, 1920. He got twodoctoral degrees – the first one in philosophy from the University of Budapest in1947 and the second one in economics from Stanford University in 1959. His adviserat Stanford University was Professor Kenneth Arrow, who got the Economics NobelPrize in 1972. Harsanyi worked at the University of California, Berkeley, from 1964to 1990 when he retired. He died on August 9, 2000, in Berkeley, California.\nReinhard Selten, a joint winner of the Nobel prize in economic sciences along with John Nash and John Harsanyi, is akey contributor to the theory of incomplete information gamesbesides John Harsanyi. In fact Harsanyi refers to the type agentrepresentation of Bayesian games as the Selten game. Selten isbest known for his fundamental work on extensive form gamesand their transformation to strategic form through a representation called the agent normal form. Selten is also widely knownfor his deep work on bounded rationality.Selten is also widely regarded as a pioneer of experimental economics. Harsanyi andSelten, in their remarkable book A General Theory of Equilibrium Selection in Games(MIT Press, 1988), develop a general framework to identify a unique equilibrium asthe solution of a given finite strategic form game. Their solution can be thought ofas the limit of an evolutionary process.Selten was born in Breslau (currently in Poland but formerly in Germany) onOctober 5, 1930. He earned a doctorate in Mathematics from Frankfurt University,working with Professor Ewald Burger and Professor Wolfgang Franz. He is currentlya Professor Emeritus at the University of Bonn, Germany.\nThe phrases actions and strategies are used differently in the Bayesian gamecontext. A strategy for a player i in Bayesian games is defined as a mapping from\nDecember 27, 2013\n11:21\n192\nWorld Scientific Book - 10.25in x 7.5in\nbook\nGame Theory and Mechanism Design\nΘi to Si . A strategy si of a player i, therefore, specifies a pure action for each type ofplayer i; si (θi ) for a given θi ∈ Θi would specify the pure action that player i wouldplay if his type were θi . The notation si (.) is used to refer to the pure action ofplayer i corresponding to an arbitrary type from his type set. When it is convenient,we use ai ∈ Si to represent a typical action of player i.13.2\nExamples of Bayesian Games\nExample 13.1 (A Two Player Bargaining Game). This example is taken fromthe book by Myerson [1]. There are two players, player 1 (seller) and player 2 (buyer).Player 1 wishes to sell an indivisible item and player 2 is interested in buying this item.Each player knows what the object is worth to himself but thinks that its value to the other1player may be any integer from 1 to 100 with probability 100. The type of the seller hasthe natural interpretation of being the willingness to sell (minimum price at which the selleris prepared to sell the item), and the type of the buyer has the natural interpretation ofbeing the willingness to pay (maximum price the buyer is prepared to pay for the item).Assume that each player will simultaneously announce a bid between 0 and 100 for tradingthe object. If the buyer’s bid is greater than or equal to the seller’s bid they will tradethe object at a price equal to the average of their bids; otherwise no trade occurs. For thisgame:N = {1, 2}Θ1 = Θ2 = {1, 2, . . . , 100}S1 = S2 = {0, 1, 2, . . . , 100}1∀θ1 ∈ Θ1 ; ∀θ2 ∈ Θ2p1 (θ2 |θ1 ) =1001p2 (θ1 |θ2 ) =∀θ1 ∈ Θ1 ; ∀θ2 ∈ Θ2100s1 + s2u1 (θ1 , θ2 , s1 , s2 ) =− θ1 if s2 ≥ s12=0if s2 < s1s1 + s2u2 (θ1 , θ2 , s1 , s2 ) = θ2 −if s2 ≥ s12=0if s2 < s1 .Note that the beliefs p1 and p2 are consistent with the prior:P(θ1 , θ2 ) =\n1∀θ1 ∈ Θ1 ∀θ2 ∈ Θ210000\nwhereΘ1 × Θ2 = {1, . . . , 100} × {1, . . . , 100}.\n\u0003Example 13.2 (A Sealed Bid Auction). Consider a seller who wishes to sell an indivisible item through an auction. Let there be two prospective buyers who bid for this\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nBayesian Games\nbook\n193\nitem. The buyers have their individual valuations for this item. These valuations could beconsidered as the types of the buyers. Here the game consists of the two bidders, namelythe buyers, so N = {1, 2}. The two bidders submit bids, say b1 and b2 for the item. Let ussay that the one who bids higher is awarded the item with a tie resolved in favor of bidder1. The winner determination function therefore is:f1 (b1 , b2 )\n==\n1 if b1 ≥ b20 if b1 < b2\nf2 (b1 , b2 )\n==\n1 if b1 < b20 if b1 ≥ b2 .\nAssume that the valuation set for each buyer is the real interval [0, 1] and also that thestrategy set for each buyer is again [0, 1]. This means Θ1 = Θ2 = [0, 1] and S1 = S2 = [0, 1].If we assume that each player believes that the other player’s valuation is chosen accordingto an independent uniform distribution, then note thatp1 ([x, y]|θ1 ) = y − x ∀ 0 ≤ x ≤ y ≤ 1; ∀θ1 ∈ Θ1 .p2 ([x, y]|θ2 ) = y − x ∀ 0 ≤ x ≤ y ≤ 1; ∀θ2 ∈ Θ2 .In a first price auction, the winner will pay what is bid by her, and therefore the utilityfunction of the players is given byui (θ1 , θ2 , b1 , b2 ) = fi (b1 , b2 )(θi − bi ); i = 1, 2.This completes the definition of the Bayesian game underlying a first price auction involvingtwo bidders. One can similarly develop the Bayesian game for the second price sealed bidauction. Note that only u1 and u2 would be different in the case of second price auction. \u0003\n13.3\nType Agent Representation and the Selten Game\nThis is a representation of Bayesian games that enables a Bayesian game to betransformed to a strategic form game (with complete information). Given a BayesiangameΓ = hN, (Θi ), (Si ), (pi ), (ui )ithe Selten game is an equivalent strategic form gameΓs = hN s , (Sθi ) θi ∈Θi , (Uθi ) θi ∈Θi i.i∈N\ni∈N\nThe idea used in formulating a Selten game is to have type agents. Each player inthe original Bayesian game is now replaced with a number of type agents; in fact,a player is replaced by exactly as many type agents as the number of types in the\nDecember 27, 2013\n11:21\n194\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\ntype set of that player. We can safely assume that the type sets of the players aremutually disjoint. The set of players in the Selten game is given by:[Ns =Θi .i∈N\nNote that each type agent of a particular player can play precisely the same actionsas the player himself. This means that for every θi ∈ Θi ,Sθi = Si .The payoff function Uθi for each θi ∈ Θi is the conditional expected utility to playeri in the Bayesian game given that θi is his actual type. It is a mapping with thefollowing domain and co-domain:\u0013\u0012××Si → R.Uθi :i ∈ N θi ∈ ΘiWe will explain the way Uθi is derived using an example. This example is developed,based on the illustration in the book by Myerson [1].Example 13.3 (Selten Game for a Bayesian Pricing Game). Consider\ntwofirms, company 1 and company 2. Company 1 produces a product x1 whereas company2 produces either product x2 or product y2 . The product x2 is somewhat similar to productx1 while the product y2 is a different line of product. The product to be produced by company 2 is a closely guarded secret, so it can be taken as private information of company 2.We thus have N = {1, 2}, Θ1 = {x1 }, and Θ2 = {x2 , y2 }. Each firm has to choose a pricefor the product it produces, and this is the strategic decision to be taken by the company.Company 1 has the choice of choosing a low price a1 or a high price b1 whereas company 2has the choice of choosing a low price a2 or a high price b2 . We therefore have S1 = {a1 , b1 }and S2 = {a2 , b2 }. The type of company 1 is common knowledge since Θ1 is a singleton.Therefore, the belief probabilities of company 2 about company 1 are given by p2 (x1 |x2 ) = 1and p2 (x1 |y2 ) = 1. Let us assume the belief probabilities of company 1 about company 2 tobe p1 (x2 |x1 ) = 0.6 and p1 (y2 |x1 ) = 0.4. Let the utility functions for the two possible typeprofiles (θ1 = x1 , θ2 = x2 ) and (θ1 = x1 , θ2 = y2 ) be given as in Tables 13.1 and 13.2.\n21a1\na21, 2\nb20, 1\nb1\n0, 4\n1, 3\nTable 13.1: u1 and u2 for θ1 = x1 ; θ2 = x2This completes the description of the Bayesian game. We now derive the equivalentSelten game. We haveN s = Θ1 ∪ Θ2 = {x1 , x2 , y2 }Sx1 = S1 = {a1 , b1 }Sx2 = Sy2 = S2 = {a2 , b2 }.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nBayesian Games\nbook\n195\n21\na2\nb2\na1b1\n1, 30, 1\n0, 41, 2\nTable 13.2: u1 and u2 for θ1 = x1 ; θ2 = y2\nNote thatUθi : S1 × S2 × S2 → R ∀θi ∈ Θi , ∀i ∈ NS1 × S2 × S2 = {(a1 , a2 , a2 ), (a1 , a2 , b2 ), (a1 , b2 , a2 ), (a1 , b2 , b2 ),(b1 , a2 , a2 ), (b1 , a2 , b2 ), (b1 , b2 , a2 ), (b1 , b2 , b2 )}.The above gives the set of all strategy profiles of all the type agents. A typical strategyprofile can be represented as (sx1 , sx2 , sy2 ). This could also be represented as (s1 (.), s2 (.))where the strategy s1 is a mapping from Θ1 to S1 , and the strategy s2 is a mapping fromΘ2 to S2 . In general, for an n player Bayesian game, a pure strategy profile is of the form((sθ1 )θ1 ∈Θ1 , (sθ2 )θ2 ∈Θ2 , . . . , (sθn )θn ∈Θn ).An equivalent way to write this would be (s1 (.), s2 (.), . . . , sn (.)), where si is a mapping fromΘi to Si for i = 1, 2, . . . , n. The payoffs for type agents (in the Selten game) are obtainedas conditional expectations over the type profiles of the rest of the agents. For example, letus compute the payoff Ux1 (a1 , a2 , b2 ), which is the expected payoff obtained by type agentx1 (belonging to player 1 ) when this type agent plays action a1 and the type agents x2and y2 of player 2 play the actions a2 and b2 respectively. In this case, the type of player1 is known, but the type of player could be x2 or y2 with probabilities given by the belieffunction p1 (.|x1 ). The following conditional expectation gives the required payoff.Ux1 (a1 , a2 , b2 ) = p1 (x2 |x1 ) u1 (x1 , x2 , a1 , a2 )+p1 (y2 |x1 ) u1 (x1 , y2 , a1 , b2 )= (0.6)(1) + (0.4)(0)= 0.6.It can be similarly shown thatUx1 (b1 , a2 , b2 ) = 0.4Ux2 (a1 , a2 , b2 ) = 2Ux2 (a1 , b2 , b2 ) = 1Uy2 (a1 , a2 , b2 ) = 4Uy2 (a1 , a2 , a2 ) = 3.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n196\nGame Theory and Mechanism Design\nFrom the above, we see thatUx1 (a1 , a2 , b2 ) > Ux1 (b1 , a2 , b2 )Ux2 (a1 , a2 , b2 ) > Ux2 (a1 , b2 , b2 )Uy2 (a1 , a2 , b2 ) > Uy2 (a1 , a2 , a2 ).We can immediately conclude that the action profile (a1 , a2 , b2 ) is a Nash equilibrium of theSelten game. Another way of representing this profile would be (s∗1 , s∗2 ) where s∗1 (x1 ) = a1and s∗2 (x2 ) = a2 ; s∗2 (y2 ) = b2 .\u0003\nPayoff Computation in Selten GameFrom now on, when there is no confusion, we will use u instead of U . In general, givena Bayesian game Γ = hN, (Θi ), (Si ), (pi ), (ui )i, suppose (s1 , . . . , sn ) is a strategyprofile where for i = 1, . . . , n, si is a mapping from Θi to Si . Assume the currenttype of player i to be θi . Then the expected utility to player i is given byui ((si , s−i )|θi ) = Eθ−i [(ui (θi , θ−i , si (θi ), s−i (θ−i ))]For a finite Bayesian game, the above immediately translates toui ((si , s−i )|θi ) =\nX\npi (t−i |θi )(ui (θi , t−i , si (θi ), s−i (t−i ))\nt−i ∈Θ−i\nWith this setup, we now define the notion of Bayesian Nash equilibrium.13.4\nBayesian Nash Equilibrium\nDefinition 13.3 (Pure Strategy Bayesian Nash Equilibrium). A pure strategy Bayesian Nash equilibrium in a Bayesian gameΓ = hN, (Θi ), (Si ), (pi ), (ui )ican be defined in a natural way as a pure strategy Nash equilibrium of the equivalentSelten game. That is, a profile of strategies (s∗1 , . . . , s∗n ) is a pure strategy BayesianNash equilibrium if ∀i ∈ N ; ∀si : Θi → Si ; ∀θi ∈ Θi ,ui ((s∗i , s∗−i ) | θi ) ≥ ui ((si , s∗−i ) | θi )That is, ∀i ∈ N ; ∀ai ∈ Si ; ∀θi ∈ Θi ,\u0002\u0003\u0002\u0003Eθ−i ui (θi , θ−i , s∗i (θi ), s∗−i (θ−i )) ≥ Eθ−i ui (θi , θ−i , ai , s∗−i (θ−i ))Example 13.4 (Bayesian Pricing Game). Consider the Bayesian pricing game being discussed. We make the following observations.• When θ2 = x2 , the strategy b2 is strongly dominated by a2 . Thus player 2 chooses a2when θ2 = x2 .\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nBayesian Games\nbook\n197\n• When θ2 = y2 , the strategy a2 is strongly dominated by b2 and therefore player 2chooses b2 when θ2 = y2 .• When the action profiles are (a1 , a2 ) or (b1 , b2 ), player 1 has payoff 1 regardless of thetype of player 2. In all other profiles, payoff of player 1 is zero.• Since p1 (x2 |x1 ) = 0.6 and p1 (y2 |x1 ) = 0.4, player 1 thinks that the type x2 of player 2is more likely than type y2 .The above arguments imply that a pure strategy Bayesian Nash equilibrium in the aboveexample is given by:(s∗x1 = a1 , s∗x2 = a2 , s∗y2 = b2 )thus validating what we have already shown. In the above equilibrium, the strategy ofcompany 1 is to price the product low whereas the strategy of company 2 is to price theproduct low if it produces x2 and to price the product high if it produces y2 . It can be seenthat the above is the unique pure strategy Bayesian Nash equilibrium for this game.The above example clearly illustrates the ramification of analyzing each matrix separately. If it is common knowledge that player 2’s type is x2 , then the unique Nash equilibrium is (a1 , a2 ). If it is common knowledge that player 2 has type y2 , then we get (b1 , b2 ) asthe unique Nash equilibrium. However, in a Bayesian game, the type of player 2 is not common knowledge, and hence the above prediction based on analyzing the matrices separatelywould be wrong.\u0003\nExample 13.5 (First Price Sealed Bid Auction). Consider again the example offirst price sealed bid auction with two prospective buyers. Here the two buyers are theplayers. Each buyer submits a sealed bid, bi ≥ 0 (i = 1, 2). The sealed bids are lookedat, and the buyer with the higher bid is declared the winner. If there is a tie, buyer 1 isdeclared the winner. The winning buyer pays to the seller an amount equal to his bid. Thelosing bidder does not pay anything.Let us make the following assumptions:(1) θ1 , θ2 are independently drawn from the uniform distribution on [0, 1].(2) The sealed bid of buyer i takes the form bi (θi ) = αi θi , where αi ∈ (0, 1]. This assumptionimplies that player i bids a fraction αi of his value; this is a reasonable assumption thatimplies a linear relationship between the bid and the value. Each buyer knows that thebids are of the above form. Buyer 1 (buyer 2) seeks to compute an appropriate valuefor α1 (α2 ).Buyer 1’s problem is now to bid in order to maximize his expected payoff:max(θ1 − b1 )P {b2 (θ2 ) ≤ b1 }.b1 ≥0\nSince the bid of player 2 is b2 (θ2 ) = α2 θ2 and θ2 ∈ [0, 1], the maximum bid of buyer 2 is α2 .Buyer 1 knows this and therefore b1 ∈ [0, α2 ]. Also,P {b2 (θ2 ) ≤ b1 } = P {α2 θ2 ≤ b1 }b1}= P {θ2 ≤α2b1=(since θ2 is uniform over [0, 1]).α2\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n198\nGame Theory and Mechanism Design\nThus buyer 1’s problem is:max (θ1 − b1 )\nb1 ∈[0,α2 ]\nb1.α2\nThe solution to this problem is(\nif θ21 ≤ α2α2 if θ21 > α2 .\n(\nθ22\nb1 (θ1 ) =\nθ12\nWe can show on similar lines thatb2 (θ2 ) =\nif θ22 ≤ α1α1 if θ22 > α1 .\nLet α1 = α2 = 12 . Then we getθ1∀ θ1 ∈ Θ1 = [0, 1]2θ2∀ θ2 ∈ Θ2 = [0, 1].b2 (θ2 ) =2b1 (θ1 ) =\nIf b2 (θ2 ) = θ22 , the best response of buyer 1 is b1 (θ1 ) = θ21 since α1 = 12 . Similarly, ifb1 (θ1 ) = θ21 , the best response of buyer 2 is b2 (θ2 ) = θ22 since α2 = 12 . This implies that the\u0001profile θ21 , θ22 ∀θ1 ∈ Θ1 , ∀θ2 ∈ Θ2 is a Bayesian Nash equilibrium of the Bayesian gameunderlying the first price auction (under the setting that we have considered).\u0003\n13.5\nDominant Strategy Equilibria\nDominant strategy equilibria of Bayesian games can again be defined using the Seltengame representation. We only define the notion of very weakly dominant strategyequilibrium and leave the definitions of weakly dominant strategy equilibrium andstrongly dominant strategy equilibrium to the reader.Definition 13.4 (Very Weakly Dominant Strategy Equilibrium). Given aBayesian gameΓ = hN, (Θi ), (Si ), (pi ), (ui )ia profile of strategies (s∗1 , . . . , s∗n ) is called a very weakly dominant strategy equilibrium if ∀i ∈ N ; ∀si : Θi → Si ; ∀s−i : Θ−i → S−i ; ∀θi ∈ Θiui ((s∗i , s−i ) | θi ) ≥ ui ((si , s−i ) | θi )That is, ∀i ∈ N ; ∀ai ∈ Si ; ∀θi ∈ Θi ; ∀s−i : Θ−i → S−i ;,Eθ−i [ui (θi , θ−i , s∗i (θi ), s−i (θ−i ))] ≥ Eθ−i [ui (θi , θ−i , ai , s−i (θ−i ))]\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nBayesian Games\nbook\n199\nA close examination of the above definition (note the presence of s−i on the lefthand side as well as the right hand side) shows that the notion of dominant strategyequilibrium is independent of the belief functions, and this is what makes it a verypowerful notion and a very strong property. The notion of dominant strategy equilibrium is used extensively in mechanism design theory to define dominant strategyimplementation. Often very weakly dominant strategy equilibrium is used in thesesettings.Example 13.6 (Second Price Auction). We have shown above that the first pricesealed bid auction has a Bayesian Nash equilibrium. Now we consider the second price sealedbid auction with two bidders and show that it has a weakly dominant strategy equilibrium.Let us say buyer 2 announces his bid as b2 . There are two cases.(1) θ1 ≥ b2(2) θ1 < b2\nCase 1: θ1 ≥ b2Let b1 be the bid of buyer 1. Here there are two cases.• If b1 ≥ b2 , then the payoff for buyer 1 is θ1 − b2 ≥ 0.• If b1 < b2 , then the payoff for buyer 1 is 0.• Thus in this case, the maximum payoff possible is θ1 − b2 ≥ 0.If b1 = θ1 (that is, buyer 1 announces his true valuation), then payoff for buyer 1 is θ1 − b2 ,which happens to be the maximum possible payoff as shown above. Thus announcing θ1 isa best response to buyer 1 whatever the announcement of buyer 2.\nCase 2: θ1 < b2Here again there are two cases: b1 ≥ b2 and b1 < b2 .• If b1 ≥ b2 , then the payoff for buyer 1 is θ1 − b2 , which is negative.• If b1 < b2 , then buyer 1 does not win and payoff for him is zero.• Thus in this case, the maximum payoff possible is 0.If b1 = θ1 , payoff for buyer 1 is 0. By announcing b1 = θ1 , his true valuation, buyer 1 getszero payoff, which in this case is a best response.We can now make the following observations about this example.• Bidding his true valuation is optimal for buyer 1 regardless of the bid of buyer 2.• Similarly bidding his true valuation is optimal for buyer 2 whatever the bid of buyer 1.• This means truth revelation is a very weakly dominant strategy for each player, and(s∗1 (θ1 ) = θ1 , s∗2 (θ2 ) = θ2 ) is a very weakly dominant strategy equilibrium.We leave it to the reader to show that the equilibrium is in fact a weakly dominant strategyequilibrium as well.\u0003\n13.6\nSummary and References\nIn this chapter, we have introduced strategic form games with incomplete information. We summarize the main points of this chapter below.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n200\nGame Theory and Mechanism Design\n• In a game with incomplete information, every player, in addition to strategies(actions), also has private information which is called the type of the player.Each player has a type set. Also, each player has a probabilistic guess aboutthe types of the rest of the players. The utilities depend not only on the actionschosen by the players but also the types of the players. Bayesian games provide acommon way of representing strategic form games with incomplete information.• Harsanyi and Selten have developed a theory of Bayesian games. The central idea of their theory is to transform a Bayesian game into a strategic formgame with complete information using the so called type agent representation.The resulting strategic form games with complete information are called Seltengames.• A strategy of a player in a Bayesian game is a mapping from the player’s typeset to his action set. Using these mappings, different notions of equilibrium canbe defined. Bayesian Nash equilibrium is a natural extension of pure strategyNash equilibrium to the case of Bayesian games.• We have illustrated the computation of Bayesian Nash equilibrium and dominantstrategy equilibria using the familiar examples of first price auction and secondprice auction, respectively.The material discussed in this chapter is mainly drawn from the the book byMyerson [1]. John Harsanyi wrote a series of three classic papers introducing, formalizing, and elaborating upon Bayesian games. These papers [2, 3, 4] appeared in1967 and 1968.References[1][2][3][4]\n13.7\nRoger B. Myerson. Game Theory: Analysis of Conflict. Harvard University Press, Cambridge,Massachusetts, USA, 1997.John C. Harsanyi. “Games with incomplete information played by Bayesian players. Part I:The basic model”. In: Management Science 14 (1967), pp. 159–182.John C. Harsanyi. “Games with incomplete information played by Bayesian players. Part II:Bayesian equilibrium points”. In: Management Science 14 (1968), pp. 320–334.John C. Harsanyi. “Games with incomplete information played by Bayesian players. Part III:The basic probability distribution of the game”. In: Management Science 14 (1968), pp. 486–502.\nExercises\n(1) Write down the definitions of weakly dominant strategy equilibrium and stronglydominant strategy equilibrium for Bayesian games.(2) Consider the example of first price sealed bid auction with two buyers which wediscussed in this chapter. What is the common prior with respect to which thebeliefs of the two players are consistent?(3) We have shown for the second price auction that bidding true valuations is a\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nBayesian Games\nbook\n201\nvery weakly dominant strategy equilibrium. Show that this equilibrium is weaklydominant as well. Also, show that this equilibrium is not strongly dominant.(4) Consider two agents 1 and 2 where agent 1 is the seller of an indivisible itemand agent 2 is a prospective buyer of the item. The type θ1 of agent 1 (seller)can be interpreted as the willingness to sell of the agent (minimum price atwhich agent 1 is willing to sell). The type θ2 of agent 2 (buyer) has the naturalinterpretation of willingness to pay (maximum price the buyer is willing to pay).Assume that Θ1 = Θ2 = [0, 1] and that each agent thinks that the type of theother agent is uniformly distributed over the real interval [0, 1]. Define thefollowing protocol. The seller and the buyer are asked to submit their bidsb1 and b2 respectively. Trade happens if b1 ≤ b2 and trade does not happenotherwise. If trade happens, the buyer gets the item and pays the seller an2). Compute a Bayesian Nash equilibrium of the Bayesian gameamount (b1 +b2here.(5) Programming Assignment. Given a finite Bayesian game, write a programto transform it into a Selten game and compute all Bayesian Nash equilibria (ifthey exist) and all dominant strategy equilibria (if they exist).\nJanuary 3, 2014\n11:48\nWorld Scientific Book - 10.25in x 7.5in\nThis page intentionally left blank\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nPART 2\nMECHANISM DESIGN\nMechanism design is the art of designing games so that they exhibit desirable equilibriumbehavior. In this part (Chapters 14-24), we study fundamental principles and key issues inmechanism design.• In Chapter 14, we introduce mechanisms with simple, illustrative examples and discussthe key notions of social choice functions, direct mechanisms, and indirect mechanisms.In Chapter 15, we bring out the principles underlying implementation of social choicefunctions by mechanisms. In Chapter 16, we define the important notion of incentivecompatibility and bring out the difference between dominant strategy incentive compatibility (DSIC) and Bayesian incentive compatibility (BIC). We prove the revelationtheorem, an important fundamental result. Chapter 17 is devoted to two key impossibility results: the Gibbard-Satterwaite theorem and the Arrow theorem.• Chapters 18-22 are devoted to different classes of quasilinear mechanisms which are either DSIC or BIC. In Chapter 18, we study VCG (Vickrey-Clarke-Groves) mechanisms,by far the most extensively investigated class of mechanisms. Chapter 19 contains anexploration of mechanism design space in quasilinear environment, including Bayesianmechanisms. In Chapter 20, we discuss auctions which are a popular example of mechanisms. In Chapter 21, we study optimal mechanisms, in particular the Myerson auction.In Chapter 22, we study the sponsored search auction problem in detail to illustrate acompelling application of mechanism design.• In Chapter 23, we discuss implementation in Nash equilibrium which assumes a complete information setting. Finally, Chapter 24 provides a brief description of importantadvanced topics in mechanism design.\n203\nbook\nJanuary 3, 2014\n11:48\nWorld Scientific Book - 10.25in x 7.5in\nThis page intentionally left blank\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nChapter 14\nIntroduction to Mechanism Design\nMechanism design can be viewed as the reverse engineering of games or equivalentlyas the art of designing the rules of a game to achieve a specific desired outcome.The main focus of mechanism design is to create institutions or protocols thatsatisfy certain desired objectives, assuming that the individual agents, interactingthrough the institution, will act strategically and may hold private information thatis relevant to the decision at hand. We commence our discussion of mechanismdesign with this chapter. We introduce mechanisms through simple examples andtrace the evolution of mechanism design theory from the 1960s. Mechanisms inducea game among strategic agents in order to realize a system-wide objective or socialchoice function, in an equilibrium of the game. Mechanisms could be direct orindirect. In this chapter, we define the key notions of social choice function, directmechanism, and indirect mechanism. We provide several illustrative examples ofsocial choice functions.\n14.1\nMechanism Design: Common Examples and History\nMechanism design is concerned with settings where a policy maker (or social planner)faces the problem of aggregating the announced preferences of multiple agents intoa collective (or social), system-wide decision when the actual preferences of theagents are not publicly known. Thus mechanism design requires the designer tosolve a decision or optimization problem with incomplete information or incompletespecification. The essential technique that mechanism design uses is to induce agame among the agents in such a way that in an equilibrium of the induced game,the desired system-wide solution is implemented. Informally, a mechanism makesthe players do what the social planner would like them to do.\nMechanisms: Two Common ExamplesMechanisms have been used and practiced from times immemorial. For example,auctions, which provide a popular instance of mechanisms, have been in vogue forseveral centuries.205\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n206\nbook\nGame Theory and Mechanism Design\nCake Cutting ProblemThe following popular stories capture the idea behind mechanisms quite strikingly(see Figure 14.1). The first story is that of a mother with two kids, who has todesign a mechanism to make her kids share a cake equally. The mother is thesocial planner in this case. If the mother slices the cake into two equal pieces anddistributes one piece to each of the kids, the solution is not necessarily acceptable tothe kids because each kid will be left with the perception that he/she got the smallerof the two pieces. On the other hand, consider the following mechanism: (1) One ofthe kids would slice the cake into two pieces and (2) the other kid gets the chance topick up any of the pieces, leaving the remaining piece to the kid who sliced the cakeinto two pieces. Child 1, who cuts the cake will slice it exactly into two equal halves(in his eyes), as any other division will leave him with the smaller piece (since child2 will pick the larger of the two slices). Child 2 is happy because she gets to chooseand also chooses what in her eyes is the larger of the two slices. This mechanismimplements the desirable outcome of the kids sharing the cake equally and furthereach kid has every reason to be happy about this mechanism.\nMotherSocial PlannerMechanism Designer\nMeAmUber Cool\nDaughterStrategic Agent\nSonStrategic Agent\nFig. 14.1: Mechanism design for cake cutting\nBaby’s Mother ProblemThe second story is from ancient wisdom. This is attributed to several wise people,notably King Solomon. In India, it is attributed independently to (a) Birbal who\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nIntroduction to Mechanism Design\nbook\n207\nwas an adviser to King Akbar in the late 1500s and to (b) Tenali Rama, whowas a popular poet and adviser in the court of King Sri Krishna Devaraya of theVijayanagara dynasty in the early 1500s. In this fable, two women come to the kingwith a baby, each claiming to be the baby’s mother, seeking justice (see Figure 14.2).The clueless king turns to his adviser to solve the problem. The adviser suggests thefollowing mechanism: slice the baby into two equal pieces and give one piece eachto the two mothers. Upon which, one of the women (the real mother) immediatelypleads with the king not to slice the baby. The adviser and the king, after watchingthe reactions and body languages of the two mothers immediately ordered that thebaby be handed over to the real mother. This is an example of a truth elicitationmechanism.\nKing/MinisterSocial PlannerMechanism Designer\nClaimant 1Woman 1Strategic Agent\nBaby\nClaimant 2Woman 2Strategic Agent\nFig. 14.2: Mechanism design for truth elicitationMechanisms such as above are ubiquitous in everyday life. We implicitly orexplicitly use mechanisms in many activities in day-to-day life, be it family related,profession related, or society related. The emergence of game theory during the1940s and 1950s helped develop a formal theory of mechanism design starting fromthe 1960s.Mechanism Design: A Brief HistoryLeonid Hurwicz (Nobel laureate in Economic Sciences in 2007) first introduced thenotion of mechanisms with his work in 1960 [1]. He defined a mechanism as a communication system in which participants send messages to each other and perhaps to\nDecember 27, 2013\n11:21\n208\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\na message center and a pre-specified rule assigns an outcome (such as allocation ofgoods and payments to be made) for every collection of received messages. WilliamVickrey (Nobel laureate in Economic Sciences in 1996) wrote a classic paper in 1961[2] which introduced the celebrated Vickrey auction (second price auction). To thisday, the Vickrey auction continues to enjoy a special place in the annals of mechanism design and can be described as one of the earliest landmarks in mechanismdesign. John Harsanyi (Nobel laureate in Economic Sciences in 1994 jointly withJohn Nash and Reinhard Selten) developed the theory of games with incompleteinformation, in particular Bayesian games, through a series of three seminal papersin 1967-68 [3, 4, 5]. Harsanyi’s work later proved to be of foundational value tomechanism design. Hurwicz [6] introduced the key notion of incentive compatibilityin 1972. This notion allowed mechanism design to incorporate the incentives of rational players and opened up mechanism design. Edward Clarke [7] and TheodoreGroves [8] came up with a generalization of Vickrey mechanisms and helped definea broad class of so called dominant strategy incentive compatible mechanisms in thequasi-linear environment.\nLeonid Hurwicz, Eric Maskin, and Roger Myerson werejointly awarded the Nobel prize in Economic Sciences in 2007 forhaving laid the foundations of mechanism design theory. Hurwicz, born in 1917, is the oldest winner of the Nobel prize. It wasHurwicz who first introduced the notion of mechanisms with hiswork in 1960 [1]. He defined a mechanism as a communicationsystem in which participants send messages to each other andperhaps to a message center and a pre-specified rule assigns anoutcome (such as allocation of goods and payments to be made)for every collection of received messages.Hurwicz introduced the key notion of incentive compatibility in 1972 [6]. Thisnotion allowed mechanism design to incorporate the incentives of rational players andopened up the area of mechanism design. The notion of incentive compatibility playsa central role in the revelation theorem, which is a fundamental result in mechanismdesign theory. Hurwicz is also credited with many important possibility and impossibility results in mechanism design. For example, he showed that, in a standardexchange economy, no incentive compatible mechanism that satisfies individual rationality can produce Pareto optimal outcomes. Hurwicz’s work in game theory andmechanism design demonstrated, beyond doubt, the value of using analytical methodsin modeling economic institutions.Hurwicz was, until his demise on June 24, 2008, Regents Professor Emeritus inthe Department of Economics at the University of Minnesota. He taught there inthe areas of welfare economics, public economics, mechanisms and institutions, andmathematical economics.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nIntroduction to Mechanism Design\nEric Maskin is credited with many pioneering contributions tomechanism design. One of his most creative contributions washis work on implementation theory, which addresses the following problem: Given a social goal, can we characterize when wecan design a mechanism whose equilibrium outcomes coincidewith the outcomes that are desirable according to that goal?Maskin [9] gave a general solution to this problem. He brilliantly showed that if social goals are to be implementable, thenthey must satisfy a certain kind of monotonicity (Maskin Monotonicity). He alsoshowed that monotonicity guarantees implementation under certain mild conditions(at least three players and no veto power). He has also made major contributionsto dynamic games. One of his early contributions was to formalize the RevelationTheorem to the setting of Bayesian incentive compatible mechanisms.Maskin was born on December 12, 1950, in New York City. He earned an A.B.in Mathematics and a Ph.D. in Applied Mathematics from Harvard University in1976. He taught at the Massachusetts Institute of Technology during 1977–1984and at Harvard University during 1985–2000. During 2000-2011, he was the AlbertO. Hirschman Professor of Social Science at the Institute for Advanced Study inPrinceton, NJ, USA. Since 2011, he is Adams University Professor in the Departmentof Economics at the Harvard University, Cambridge, Massachusetts, USA.\nRoger Bruce Myerson has contributed to several areas ingame theory and mechanism design, and his contributions haveleft a deep impact in the area. He was instrumental in conceptualizing and proving the revelation theorem in mechanism designfor Bayesian implementations in its greatest generality. His workon optimal auctions in 1981 is a landmark result and has led toan extensive body of further work in the area of optimal auctions. He has also made major contributions in bargaining withincomplete information and cooperative games with incompleteinformation. His textbook Game Theory: Analysis of Conflict is a scholarly andcomprehensive reference text that embodies all important results in game theory in arigorous, yet insightful way. Myerson has also worked on economic analysis of politicalinstitutions and written several influential papers in this area including recently ondemocratization and the Iraq war.Myerson was born on March 29, 1951. He received his A.B., S.M., and Ph.D., allin Applied Mathematics from Harvard University. He completed his Ph.D. in 1976,working with the legendary Kenneth Arrow. He was a Professor of Economics at theKellogg School of Management in Northwestern University during 1976-2001. Since2001, he has been the Glen A. Lloyd Distinguished Service Professor of Economics atthe University of Chicago.\nbook\n209\nDecember 27, 2013\n11:21\n210\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nThere were two major advances in mechanism design in the 1970s. The first wasthe revelation principle which essentially showed that direct mechanisms are thesame as indirect mechanisms. This meant that mechanism theorists needed to worryonly about direct mechanisms, leaving the development of real-world mechanisms(which are mostly indirect mechanisms) to mechanism designers and practitioners. Alan Gibbard [10] formulated the revelation principle for dominant strategyincentive compatible mechanisms. This was later extended to Bayesian incentivecompatible mechanisms through several independent efforts [11] – Eric Maskin andRoger Myerson (both Nobel laureates in Economic Sciences in 2007) had a leadingrole to play in this. In fact, Myerson developed the revelation principle in its greatest generality [11]. The second major advance in mechanism design in the 1970s wason implementation theory which addresses the following problem: can a mechanismbe designed so that all its equilibria are optimal? Maskin [9] gave the first generalsolution to this problem.Mechanism design has made phenomenal advances during 1980s, 1990s, 2000s,and during the past few years. It has found widespread applicability in a variety ofdisciplines. These include: design of auctions, markets, and trading institutions [11,12, 13, 14], regulation and auditing [11], social choice theory [11], computer science[15], resource allocation to strategic agents, electronic commerce and web-basedapplications [16], etc. This list is by no means exhaustive.\n14.2\nMechanism Design Environment\nThe following provides a general setting for formulating, analyzing, and solvingmechanism design problems.• There are n agents, 1, 2, . . . , n, with N = {1, 2, . . . , n}. The agents are rationaland intelligent, and interact strategically among themselves towards making acollective decision.• X is a set of alternatives or outcomes. The agents are required to make acollective choice from the set X.• Prior to making the collective choice, each agent privately observes his preferences over the alternatives in X. This is modeled by supposing that agent iprivately observes a parameter or signal θi that determines his preferences. Thevalue of θi is known to agent i and may not be known to the other agents. θi iscalled a private value or type of agent i.• We denote by Θi the set of private values of agent i, i = 1, 2, . . . , n. The setof all type profiles is given by Θ = Θ1 × . . . × Θn . A typical type profile isrepresented as θ = (θ1 , . . . , θn ).• We assume that there is a common prior P ∈ ∆(Θ). To ensure consistency ofbeliefs, individual belief functions pi : Θi → ∆(Θ−i ) (where Θ−i is the set oftype profiles of agents other than i) can all be derived from the common prior.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nIntroduction to Mechanism Design\nbook\n211\n• Individual agents have preferences over outcomes that are represented by a utility function ui : X × Θi → R. Given x ∈ X and θi ∈ Θi , the value ui (x, θi )denotes the payoff that agent i, having type θi ∈ Θi , receives from an outcomex ∈ X. In the more general case, ui depends not only on the outcome and thetype of player i, but could depend on the types of the other players as well, andso ui : X × Θ → R. We restrict our attention to the former case in this booksince most situations discussed in this book fall into the former category.• The set of outcomes X, the set of players N , the type sets Θi (i = 1, . . . , n), thecommon prior distribution P ∈ ∆(Θ), and the payoff functions ui (i = 1, . . . , n)are assumed to be common knowledge among all the players. The specific typeθi observed by agent i is private information of agent i.\nSocial Choice FunctionsSince the preferences of the agents depend on the realization of their types θ =(θ1 , . . . , θn ), it is logical and natural to make the collective decision depend on θ.This leads to the definition of a social choice function.Definition 14.1 (Social Choice Function). Suppose N = {1, 2, . . . , n} is a setof agents with the type sets Θ1 , Θ2 , . . . , Θn respectively. Given a set of outcomesX, a social choice function is a mapping f : Θ1 × . . . × Θn → X that assigns toeach possible type profile (θ1 , θ2 , . . . , θn ), an outcome from the set X. The outcomecorresponding to a type profile is called a social choice or collective choice for thattype profile.We will be presenting several examples of social choice functions subsequently inthis chapter. We provide an immediate example here in an informal way.Example 14.1 (Shortest Path Problem with Incomplete Information).Consider a connected directed graph with a source vertex and a destination vertex identified. Let the graph have n edges, each owned by a rational and intelligent agent. Let theset of agents be denoted by N = {1, 2, . . . , n}. Assume that the cost of the edge is privateinformation of the agent owning the edge and let θi be this private information for agent i(i = 1, 2, . . . , n). Let us say that a social planner is interested in finding a shortest path fromthe source vertex to the destination vertex. The social choice function here maps each typeprofile (θ1 , . . . , θn ) (which is in fact a profile of edge costs) to a shortest path correspondingto those edge costs. The social planner knows everything about the graph except the costsof the edges. So, the social planner first needs to extract this information from each agentand then find a shortest path from the source vertex to the destination vertex. Thus thereare two problems facing the social planner, which are described below.\u0003\nDecember 27, 2013\n11:21\n212\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nPreference Elicitation ProblemConsider a social choice function f : Θ1 × . . . × Θn → X. The types θ1 , . . . , θn of theindividual agents are private information of the agents. Hence for the social choicef (θ1 , . . . , θn ) to be chosen when the individual types are θ1 , . . . , θn , each agent mustdisclose its true type to the social planner. However, given a social choice functionf , a given agent may not find it in its best interest to reveal this information truthfully. This is called the preference elicitation problem or the information revelationproblem.Preference Aggregation ProblemOnce all the agents report their types, the profile of reported types has to be transformed to an outcome, based on the social choice function. Let θi be the truetype and θˆi the reported type of agent i (i = 1, . . . , n). The process of computingf (θˆ1 , . . . , θˆn ) is called the preference aggregation problem.Example 14.2. In the current example of shortest path problem with incomplete information, the preference elicitation problem is to elicit the true values of the costs of theedges from the respective edge owners. The preference aggregation problem is to computea shortest path from the source vertex to the destination vertex, given the structure of thegraph and the (reported) costs of the edges. The preference aggregation problem is oftenan optimization problem like for instance in the current example.\u0003\nFigure 14.3 provides a pictorial representation of all the elements in a mechanismdesign environment.\n14.3\nDirect and Indirect Mechanisms\nOne can view mechanism design as the process of solving an incompletely specifiedoptimization problem where the specification is first elicited and then the underlying optimization problem or decision problem is solved. Specification elicitation isbasically the preference elicitation or type elicitation problem. To elicit the typeinformation from the agents in a truthful way, there are broadly two kinds of approaches, which are aptly called direct mechanisms and indirect mechanisms. Wedefine these below. In these definitions, we assume that the set of agents N , the setof outcomes X, the sets of types Θ1 , . . . , Θn , the common prior P ∈ ∆(Θ), and theutility functions ui : X × Θi → R are given and are common knowledge.Definition 14.2 (Direct Mechanism). Suppose f : Θ1 ×. . .×Θn → X is a socialchoice function. A direct mechanism (also called a direct revelation mechanism)corresponding to f consists of the tuple (Θ1 , Θ2 , . . . , Θn , f (.)).\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nIntroduction to Mechanism Design\nΘ1\nΘ2\nθ1\nθ2\nbook\n213\nΘn\nIndividual Type Sets\nθn\nIndividual Types\n···\nθ̂1\nθ̂2\nθ̂n\nf : Θ1 × · · · × Θn → X\nReported Types\nSocial Choice Function\nx = f (θ̂1, · · · , θ̂n)\nOutcome\nu1 : X × Θ1 → R\nu2 : X × Θ2 → R\nun : X × Θn → R\nu1 (x, θ1)\nu2(x, θ2)\nun (x, θn)\nUtility Functions\nUtility Values\nFig. 14.3: Mechanism design environment\nThe idea of a direct mechanism is to directly seek the type information from theagents by asking them to reveal their true types.Definition 14.3 (Indirect Mechanism). An indirect mechanism (also called anindirect revelation mechanism) consists of a tuple (S1 , S2 , . . . , Sn , g(.)) where Si isa set of possible actions for agent i (i = 1, 2, . . . , n) and g : S1 × S2 × . . . × Sn → Xis a function that maps each action profile to 2 ≤ θ̂1 }θ̂1\nSince θ2 is uniformly distributed on [0,1],P {θ2 ≤ θ̂1 } = θ̂1Thus buyer 1 tries to solve the problem:max(θ1 − θ̂1 )θ̂1θ̂1\nThis problem has the solutionθ̂1 =\nθ12\nThus if buyer 2 is truthful, the best response for buyer 1 is to announce θ21 .Similarly if buyer 1 always announces his true valuation θ1 , then the best response ofbuyer 2 is to announce θ22 when his true type is θ2 . Thus there is no incentive for the buyersto announce their true valuations. A social planner who wishes to realize the above socialchoice function finds that rational players will not reveal their true private values. ThusSCF1 cannot be implemented.\u0003\nExample 15.3 (Implementability of SCF2). We now show that the functionSCF2 can be implemented. Suppose θi is the true valuation of buyer i (i = 1, 2). Letus say buyer 2 announces his valuation as θ̂2 . There are two cases: (1) θ1 ≥ θ̂2 and (2)θ1 < θ̂2 .Case 1: θ1 ≥ θ̂2Let θ̂1 be the announcement of buyer 1. Here there are two cases.• If θ̂1 ≥ θ̂2 , then buyer 1 wins and his payoff is θ1 − θ̂2 ≥ 0.• If θ̂1 < θ̂2 , then buyer 1 does not win and his payoff is 0.• Thus in this case, the maximum payoff possible is θ1 − θ̂2 ≥ 0.If θ̂1 = θ1 (that is, buyer 1 announces his true valuation), then payoff for buyer 1 equalsθ1 − θ̂2 , which happens to be the maximum possible payoff as shown above. Thus announcingθ1 is a best response for buyer 1 whenever θ1 ≥ θ̂2 .\nCase 2: θ1 < θ̂2Here again there are two cases: θ̂1 ≥ θ̂2 and θ̂1 < θ̂2 .• If θ̂1 ≥ θ̂2 , then buyer 1 wins and his payoff is θ1 − θ̂2 which is negative.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nImplementation of Social Choice Functions by Mechanisms\nbook\n227\n• If θ̂1 < θ̂2 , then buyer 1 does not win and payoff for him is zero.• Thus in this case, the maximum payoff possible is 0.If θ̂1 = θ1 , payoff for buyer 1 is 0. By announcing θ̂1 = θ1 , his true valuation, buyer 1 getszero payoff, which in this case is a best response.We can now make the following observations about this example. Reporting his truevaluation is optimal for buyer 1 regardless of what buyer 2 reports. Similarly announcinghis true valuation is optimal for buyer 2 whatever the announcement of buyer 1 may be.More formally, reporting true type is a weakly dominant strategy for each player. Thus thissocial choice function can be implemented even though the valuations (types) are privateinformation.\u0003\nExample 15.4 (Implementability of SCF3). Again, suppose θ1 and θ2 are thetrue valuations of buyers 1 and 2, respectively. Assume that buyer 2 reports his true typeθ2 . Suppose buyer 1 has type θ1 , then his optimal report θ̂1 is obtained by solvingθ̂1max θ1 −2θ̂1\n!P {θ2 ≤ θ̂1 }\nThis is the same asθ̂1max θ1 −2θ̂1\n!θ̂1\nThis yields θ̂1 = θ1 . Thus it is optimal in expectation for buyer 1 to reveal his true privatevalue if buyer 2 reveals his true value. The same situation applies to buyer 2. Thus, a bestresponse for each agent, given that the other agent truthfully reports his true type, is toreport his true type. This implies that SCF3 can be implemented.\u0003\nNote. It is important to see the difference in the implementability of SCF2 andSCF3. In the case of SCF2, reporting truth is a best response whatever the otheragent reports. In the case of SCF3, reporting truth is a best response in expectationover the type reports of the other agent if the other agent also reports truthfully.We say SCF2 is implementable in dominant strategy equilibrium and SCF3 is implementable in Bayesian Nash equilibrium. We wish to emphasize again that SCF1is not implementable.\n15.2\nImplementation by Indirect Mechanisms\nThe examples above have shown us a possible way in which one can try to implementa social choice function. The protocol we followed for implementing the social choicefunctions was:• Announce the social choice function f : Θ1 × . . . × Θn → X.• Ask each agent i = 1, . . . , n to announce his type θi .\nDecember 27, 2013\n11:21\n228\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\n• Given announcements (θ̂1 , . . . , θ̂n ) by the agents, choose the outcome x =f (θ̂1 , . . . , θ̂n ) ∈ X.It is natural to call such a method of trying to implement an SCF as a direct revelation mechanism or simply a direct mechanism. Another approach to implementinga social choice function is through an indirect way. Here the mechanism makes theagents interact through an institutional framework in which there are rules governing the actions the agents would be allowed to play and in which there is a way oftransforming these actions into an outcome. The design of the mechanism is suchthat the actions the agents choose will invariably depend on their private valuesand become the strategies of the players. Auctions provide a common example ofindirect mechanisms and we illustrate below two commonly used auctions, first priceauction (FPA) and second price auction (SPA).Example 15.5 (First Price Sealed Bid Auction for Selling). Consider\ntheseller (agent 0) and two potential buyers (agents 1, 2) as before. The seller plays the role ofan auctioneer and the buyers play the role of bidders in the auction. Each buyer is askedto submit a sealed bid, bi ≥ 0 (i = 1, 2). The sealed bids are examined and the buyer withthe higher bid is declared the winner. If there is a tie, assume that buyer 1 is declared thewinner. The winning buyer pays to the seller an amount equal to his bid. The losing bidderdoes not pay anything.We emphasize the subtle difference between the situations in Example 15.2 and thecurrent example. In Example 15.2 (direct mechanism), each buyer is asked to announce(directly) his type (valuation for the object), whereas in the current example 15.5 (indirectmechanism), each buyer is asked to submit a bid for the object. The intent is that thebid submitted will depend on the type. Based on the type, the buyer has a strategy forbidding. So it becomes a game and in an equilibrium of the game, the strategies, hopefully,will indirectly reveal the types of the players.Let us make the following assumptions:(1) θ1 , θ2 are independently drawn from the uniform distribution on [0, 1].(2) The sealed bid of buyer i takes the form bi (θi ) = αi θi , where αi ∈ (0, 1]. That the bidwill be of the above form is known to both the bidders. The values of α1 , α2 are notknown however and the bidders have to compute these in order to determine their bestresponse bids.Buyer 1’s problem is now to bid in a way so as to maximize his payoff:max (θ1 − b1 ) P {b2 (θ2 ) ≤ b1 }b1 ≥0\nSince the bid of player 2 is b2 (θ2 ) = α2 θ2 and θ2 ∈ [0, 1], the maximum bid of buyer 2 is α2 .Buyer 1 knows this and therefore b1 ∈ [0, α2 ]. Also,P {b2 (θ2 ) ≤ b1 } = P {α2 θ2 ≤ b1 }\u001b\u001ab1= P θ2 ≤α2b1=since θ2 is uniform over [0, 1]α2\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nImplementation of Social Choice Functions by Mechanisms\nbook\n229\nThus buyer 1’s problem is:max (θ1 − b1 )\nb1 ∈[0,α2 ]\nb1α2\nThe solution to this problem is(\nif θ21 ≤ α2α2 if θ21 > α2\n(\nif θ22 ≤ α1α1 if θ22 > α1\nb1 (θ1 ) =\nθ12\nWe can show on similar lines thatb2 (θ2 ) =\nθ22\nLet α1 = α2 = 12 . Then we getθ1∀θ1 ∈ Θ1 = [0, 1]2θ2b2 (θ2 ) =∀θ2 ∈ Θ2 = [0, 1]2\nb1 (θ1 ) =\nNote that if b2 (θ2 ) = θ22 , we have α2 = 21 and θ21 ≤ α2 and therefore the best response ofbuyer 1 is b1 (θ1 ) = θ21 . Similarly if b1 (θ1 ) = θ21 , we have α1 = 12 and θ22 ≤ α1 and therefore\u0001the best response of buyer 2 is b2 (θ2 ) = θ22 . Hence the profile θ21 , θ22 is a Bayesian Nashequilibrium of an underlying Bayesian game. This equilibrium can be computed by therational and intelligent bidders.This means there is a Bayesian Nash equilibrium of an underlying Bayesian game (induced by the indirect mechanism namely the first price sealed bid auction) that yields theoutcome f (θ) = (y0 (θ), y1 (θ), y2 (θ), t0 (θ), t1 (θ), t2 (θ)) such that ∀θ = (θ0 , θ1 , θ2 ) ∈ Θ,y0 (θ) = 0y1 (θ) = 1=0y2 (θ) = 1\nif θ1 ≥ θ2θ1 < θ2if θ1 < θ2\n=0\nθ1 ≥ θ2θ1t1 (θ) = −y1 (θ)2θ2t2 (θ) = −y2 (θ)2t0 (θ) = −(t1 (θ) + t2 (θ))Note that the social choice function that is realized above is SCF3. We emphasize that it isneither SCF1 nor SCF2.\u0003\nExample 15.6 (Second Price Sealed Bid Auction). In this indirect mechanism,each buyer is asked to submit a sealed bid bi ≥ 0. The bids are examined and the buyerwith higher bid is declared the winner. In case there is a tie, buyer 1 is declared the winner.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n230\nGame Theory and Mechanism Design\nThe winning buyer will pay to the seller an amount equal to the second highest bid. Thelosing bidder does not pay anything.In this case, we can show that bi (θi ) = θi for i = 1, 2 constitutes a weakly dominantstrategy for each player. The arguments are identical to those in Example 15.3.Thus the game induced by the indirect mechanism second price sealed bid auction hasa weakly dominant strategy in which the social choice function SCF2 is implemented. \u0003\nSummary of ExamplesWe can summarize the main points of the current chapter so far as follows.• The social choice function SCF1 cannot be implemented by a direct mechanism.We still have not investigated if SCF1 can perhaps be implemented by an indirectmechanism.• The function SCF2 can be implemented in dominant strategies by a direct mechanism. Also, the indirect mechanism, namely second price auction implementsSCF2 in dominant strategies.• The function SCF3 is implemented in Bayesian Nash equilibrium by a directmechanism. Also the indirect mechanism, namely first price auction, implementsit in Bayesian Nash equilibrium.\n15.3\nBayesian Game Induced by a Mechanism\nRecall that a mechanism is an institution or a framework with a set of rules thatprescribe the actions available to players and specify how these action profiles aretransformed into outcomes. A mechanism specifies an action set for each player.The outcome function gives the rule for obtaining outcomes from action profiles.Given:(1) a set of agents N = {1, 2, . . . , n},(2) type sets Θ1 , . . . , Θn ,(3) a common prior P ∈ ∆(Θ) and belief functions pi : Θi → ∆(Θ−i ) (i = 1, . . . , n)that can be derived from P,(4) a set of outcomes X,(5) utility functions u1 , . . . , un , with ui : X × Θi → R,a mechanism M = (S1 , . . . , Sn , g(·)) induces among the players, a Bayesian gamehN, (Θi ), (Si ), (pi ), (Ui )i whereUi (θ1 , . . . , θn , s1 , . . . , sn ) = ui (g(s1 , . . . , sn ), θi ).We will use the symbol ui instead of Ui whenever there is no confusion.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nImplementation of Social Choice Functions by Mechanisms\nbook\n231\nStrategies in the Induced Bayesian GameFor i = 1, 2, . . . , n, a strategy si for agent i in the induced Bayesian game is amapping si : Θi → Si . Thus, given a type θi ∈ Θi , si (θi ) will give the action ofplayer i corresponding to θi . The strategy si (.) will specify actions correspondingto types. In the auction scenario, the bid bi of player i is a function of the valuationθi . For example, bi (θi ) = αi θi is a particular strategy for player i.Example 15.7 (Bayesian Game Induced by First Price Auction).First, note that N = {0, 1, 2}. The type sets are Θ0 , Θ1 , Θ2 , and the common prior issome known distribution P ∈ ∆(Θ). The set of outcomes isX = {(y0 , y1 , y2 , t0 , t1 , t2 ) : yi ∈ {0, 1}, y0 + y1 + y2 = 1, ti ∈ R ∀i ∈ N }The utility functions for the buyers 1 and 2 are given byui ((y0 , y1 , y2 , t0 , t1 , t2 ), θi ) = yi θi + ti ;\ni = 1, 2\nThe strategy sets are given byS0 = {θ0 }; S1 = R+ ; S2 = R+Note that θ0 is some known valuation the seller has for the object. Since S0 is a singleton,the bid of the seller is common knowledge. We include it in the following only for the sakeof completeness. The outcome rule g(·) for bid profiles b = (b0 , b1 , b2 ) ∈ S0 × S1 × S2 isgiven byg(b) = (y0 (b), y1 (b), y2 (b), t0 (b), t1 (b), t2 (b))such that ∀(b0 , b1 , b2 ) ∈ S0 × S1 × S2 ,y0 (b0 , b1 , b2 ) = 0y1 (b0 , b1 , b2 ) = 1if b1 ≥ b2=0if b1 < b2y2 (b0 , b1 , b2 ) = 1if b1 < b2=0if b1 ≥ b2t1 (b0 , b1 , b2 ) = −y1 (b0 , b1 , b2 ) b1t2 (b0 , b1 , b2 ) = −y2 (b0 , b1 , b2 ) b2t0 (b0 , b1 , b2 ) = −(t1 (b0 , b1 , b2 ) + t2 (b0 , b1 , b2 )).If we specify the common prior P and the belief functions, it would complete the specificationof the Bayesian game induced by the first price auction.\u0003\n15.4\nImplementation of a Social Choice Function by a Mechanism\nWe now formalize the notion of implementation of a social choice function by amechanism.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n232\nbook\nGame Theory and Mechanism Design\nDefinition 15.1 (Implementation of an SCF). We say a mechanism M =((Si )i∈N , g(·)), where g : S1 × . . . × Sn → X, implements the social choicefunction f (·) if there is a pure strategy equilibrium s∗ (·) = (s∗1 (·), . . . , s∗n (·))of the Bayesian game Γ induced by M such that g (s∗1 (θ1 ), . . . , s∗n (θn )) =f (θ1 , . . . , θn ) , ∀ (θ1 , . . . , θn ) ∈ Θ.Figure 15.2 depicts all the building blocks involved in the implementation of a socialchoice function by an indirect mechanism.\ns∗i (θi )\nθiSocial Choice Function\nf : Θ1 × · · · × Θn → X\nOutcome Rule of the Indirect Mechanism\nΘi\nSi\nType Set\nStrategy Set\ng : S1 × · · · × Sn → X\nAgent i\nui (x, θi)i=1:n\nf (θ1, · · · , θn)\n=\nx\n=\ng(s∗1(θ1), · · · , s∗n(θn))\nFig. 15.2: The idea behind implementation by an indirect mechanismNote that a direct mechanism corresponding to a social choice function f (·) is aspecial case of an indirect mechanism with the strategy sets same as the type setsand the outcome rule g(·) same as the social choice function f (·). It goes withoutsaying that a Bayesian game is induced by a direct mechanism as well.Depending on the nature of the underlying equilibrium, two ways of implementingan SCF f (·) are standard in the literature.Definition 15.2 (Implementation in Dominant Strategies). We say a mechanism M = ((Si )i∈N , g(·)) implements the social choice function f (·) in dominant strategy equilibrium if there is a weakly dominant strategy equilibrium s∗ (·) =(s∗1 (·), . . . , s∗n (·)) of the Bayesian game Γ induced by M such thatg (s∗1 (θ1 ), . . . , s∗n (θn )) = f (θ1 , . . . , θn ) ∀ (θ1 , . . . , θn ) ∈ Θ.Since a strongly dominant strategy equilibrium is automatically a weakly dominantstrategy equilibrium, the above definition applies to the strongly dominant case also.In the latter case, we could say the implementation is in strongly dominant strategy\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nImplementation of Social Choice Functions by Mechanisms\nbook\n233\nequilibrium. The definition also applies to very weakly dominant strategy equilibriaand often times this is the implementation that is considered.Note that the second price auction implements SCF2 in weakly dominant strategyequilibrium. We have also shown that SCF2 can be implemented through a directmechanism in (weakly) dominant strategies. The latter statement is technicallystated by saying that SCF2 is dominant strategy incentive compatible (more aboutthis in the next chapter).Definition 15.3 (Implementation in Bayesian Nash Equilibrium). We saythat a mechanism M = ((Si )i∈N , g(·)) implements the social choice function f (·)in Bayesian Nash equilibrium if there is a pure strategy Bayesian Nash equilibriums∗ (·) = (s∗1 (·), . . . , s∗n (·)) of the game Γ induced by M such thatg (s∗1 (θ1 ), . . . , s∗n (θn )) = f (θ1 , . . . , θn ) ∀ (θ1 , . . . , θn ) ∈ Θ.Note that the first price auction implements SCF3 in Bayesian Nash equilibrium.We have also shown that SCF3 can be implemented through a direct mechanismin Bayesian Nash equilibrium. The latter statement is technically stated by sayingthat SCF3 is Bayesian incentive compatible (more about this in the next chapter).Finally, note that SCF1 cannot be implemented using a direct mechanism. Infact, as shown in the next chapter, there is no indirect mechanism that can implement SCF1.Key Facts about ImplementationNote the requirement on existence of a pure strategy Bayesian Nash equilibrium forthe game Γ induced by M . Naturally we must be wary of the possibility that suchan equilibrium may not exist.On the other hand, the game Γ may have more than one equilibrium, but theabove definition requires only that one of them induces outcomes in accordancewith the SCF f (·). Implicitly, then, the above definition assumes that, if multipleequilibria exist, the agents will play the equilibrium that the mechanism designer(social planner) wants.Another implicit assumption of the above definition is that the game induced bythe mechanism is a simultaneous move game, that is all the agents, after learningtheir types, choose their actions simultaneously.We have talked about two broad categories of implementations: dominant strategy implementation (DSI) and Bayesian Nash implementation (BNI). It is easyto see that DSI implies BNI but BNI need not imply DSI. Apart from these twobroad categories, we can consider other solution concepts for games and define implementability in those equilibria. Examples include: Nash equilibrium (completeinformation), subgame perfect equilibrium, etc. Chapter 24 treats implementationin Nash equilibrium in detail. At this point, we only state that implementation in\nDecember 27, 2013\n11:21\n234\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nNash equilibrium is stronger than BNI but weaker than DSI.The revelation theorem which is a fundamental result in mechanism design showsthat direct mechanisms and indirect mechanisms are equivalent. Indirect mechanisms (for example, auctions) are appealing and useful because they provide uswith practical ways of implementing social choice functions. Direct mechanismsprovide an abstraction which is valuable in developing the theory of mechanismdesign. The revelation theorem is covered in detail in the next chapter.\n15.5\nSummary and References\nIn this chapter, we have investigated the process of implementing a social choicefunction through a direct mechanism or an indirect mechanism. The following arethe salient points to be noted.• A direct mechanism for a social choice function works by trying to extract theprivate information (types) from the agents truthfully. An indirect mechanism(such as an auction where agents bid) tries to extract truthful information byinducing the agents to play certain strategies that indirectly capture the privateinformation.• Not all social choice functions can be implemented by direct mechanisms, asshown by the social choice function SCF1.• Social choice functions such as SCF2 can be implemented by a direct mechanismin dominant strategies.• Social choice functions such as SCF3 cannot be implemented by a direct mechanism in dominant strategies but may be implemented by a direct mechanismin Bayesian Nash equilibrium.• A direct mechanism (corresponding to an SCF) induces a Bayesian game amongthe agents and the induced Bayesian game may have a dominant strategy equilibrium or a Bayesian Nash equilibrium or none. If reporting true types is anequilibrium, then we say the direct mechanism implements the SCF and we saythe SCF is incentive compatible.• Given an SCF, an indirect mechanism is said to implement the SCF if the mechanism induces a Bayesian game having an equilibrium that produces preciselythe outcomes of the SCF through the mechanism’s outcome rule.In the next chapter, we show that direct mechanisms and indirect mechanisms arein fact equivalent. This is the central idea of the revelation theorem. The nextchapter also defines the key notion of incentive compatibility.Chapter 24 introduces the notion of implementation in Nash equilibrium in thecomplete information setting. The chapter also talks about the notion of strongimplementation which means that the outcomes of the social choice function arereproduced in every equilibrium of the induced Bayesian game.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nImplementation of Social Choice Functions by Mechanisms\nbook\n235\nThe contents of this chapter, especially SCF1, SCF2, and SCF3, are based onthe examples discussed in the book by Mas-Colell, Whinston, and Green [1]. Theprocurement versions (buying scenarios) of SCF1, SCF2, and SCF3 are discussed indetail in the monograph by Narahari, Garg, Narayanam, and Prakash [2].References[1]\nAndreu Mas-Colell, Michael D. Whinston, and Jerry R. Green. Microeconomic Theory. Oxford University Press, 1995.Y. Narahari, Dinesh Garg, Ramasuri Narayanam, and Hastagiri Prakash. Game TheoreticProblems in Network Economics and Mechanism Design Solutions. Springer, London, 2009.\n[2]\n15.6\nExercises\n(1) Investigate the implementability of the eight social choice functions (supplierselection problem) presented in Table 15.1.(2) Think about what would be an indirect mechanism for implementing socialchoice functions of the type presented for the supplier selection problem.(3) Consider a buying scenario with one buying agent (agent 0) and two sellingagents (agents 1, 2). Modify the social choice functions SCF1, SCF2, SCF3 torepresent the buying scenario and call the new social choice functions BUY1,BUY2, and BUY3 respectively. Write down these three new social choice functions in the usual notation.(4) Show that the social choice function BUY1 cannot be implemented by a directmechanism.(5) Show that BUY2 and BUY3 can be implemented by appropriate direct mechanisms.(6) Show that the mechanism lowest price procurement auction implements BUY3in Bayesian Nash equilibrium (Hint: see [2]).(7) Show that BUY2 is implementable in dominant strategy equilibrium by themechanism second lowest price procurement auction.(8) In some of the examples discussed in this chapter, it is assumed that a tiebetween agent 1 and agent 2 will be resolved in favor of agent1. Investigatewhat would happen in these examples if the tie is resolved in favor of agent 1or agent 2 using a Bernoulli random variable.(9) Consider two agents 1 and 2 where agent 1 is the seller of an indivisible itemand agent 2 is a prospective buyer of the item. An outcome here is of theform x = (y1 , y2 , t1 , t2 ) where yi = 1 if agent i gets the item and ti denotes thepayment received by agent i (i = 1, 2). A natural set of outcomes here isX = {(y1 , y2 , t1 , t2 ) : y1 + y2 = 1; y1 , y2 ∈ {0, 1}} .Define the utilities of the agents i (i = 1, 2) appropriately. The type θ1 of agent\nDecember 27, 2013\n11:21\n236\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\n1 (seller) can be interpreted as the willingness to sell of the agent (minimumprice at which agent 1 is willing to sell). The type θ2 of agent 2 (buyer) has thenatural interpretation of willingness to pay (maximum price the buyer is willingto pay). Assume that Θ1 = Θ2 = [0, 1] and that each agent thinks that the typeof the other agent is uniformly distributed over the real interval [0, 1]. Definethe social choice function f (θ) = (y1 (θ), y2 (θ), t1 (θ), t2 (θ)) byy1 (θ1 , θ2 ) = 1 θ1 > θ2= 0 θ1 ≤ θ2y2 (θ1 , θ2 ) = 1 θ1 ≤ θ2= 0 θ1 > θ2\u0013\u0012θ1 + θ2t1 (θ1 , θ2 ) = y2 (θ1 , θ2 )2\u0012\u0013θ1 + θ2t2 (θ1 , θ2 ) = −y2 (θ1 , θ2 ).2Now define the following indirect mechanism. The seller and the buyer are askedto submit their bids b1 and b2 respectively. Trade happens if b1 ≤ b2 and tradedoes not happen otherwise. If trade happens, the buyer gets the item and pays2). Will this indirect mechanism implement the abovethe seller an amount (b1 +b2social choice function?\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nChapter 16\nIncentive Compatibility and RevelationTheorem\nIn mechanism design, the notion of incentive compatibility is of fundamental importance and the revelation theorem is a key result. This chapter first presents thenotions of dominant strategy incentive compatibility (DSIC) and Bayesian incentive compatibility (BIC) in a formal way. Next, it develops the revelation theoremfor dominant strategy equilibrium followed by the revelation theorem for BayesianNash equilibrium. Finally the chapter describes two important properties of socialchoice functions in which a social planner would be interested: ex-post efficiencyand non-dictatorship.\n16.1\nIncentive Compatibility\nWe have already seen that mechanism design involves the preference elicitationproblem and the preference aggregation problem. The preference elicitation problemseeks to collect truthful information from the agents about their types. In order toelicit truthful information, the idea is to make truth revelation a best response for theagents, consistent with rationality and intelligence assumptions. Offering incentivesis a way of achieving this; incentive compatibility essentially refers to offering theright incentives that make agents reveal their types truthfully. There are broadlytwo types of incentive compatibility: (1) Truth revelation is a best response foreach agent irrespective of what is reported by the other agents; (2) truth revelationis a best response for each agent in expectation of the types of the rest of theagents. The first one is called dominant strategy incentive compatibility (DSIC),and the second one is called Bayesian Nash incentive compatibility (BIC). Sincetruth revelation is always with respect to types, only direct revelation mechanismsare relevant when formalizing the notion of incentive compatibility. The notion ofincentive compatibility was first introduced by Leonid Hurwicz [1].Definition 16.1 (Incentive Compatibility (IC)). A social choice function f :Θ1 × . . . × Θn → X is said to be incentive compatible (or truthfully implementable) ifthe Bayesian game induced by the direct revelation mechanism D = ((Θi )i∈N , f (·))has a pure strategy equilibrium s∗ (·) = (s∗1 (·), . . . , s∗n (·)) in which s∗i (θi ) = θi , ∀θi ∈Θi , ∀i ∈ N .237\nbook\nDecember 27, 2013\n11:21\n238\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nThat is, truth revelation by each agent constitutes an equilibrium of the game induced by D. It is easy to infer that if an SCF f (·) is incentive compatible then thedirect revelation mechanism D = ((Θi )i∈N , f (·)) can implement it. This means thesocial choice function f (·) can be realized by directly asking the agents to reporttheir types and using this type information in f ( ·) to determine the social outcome.We emphasize again the point that the induced Bayesian game may have no equilibrium, exactly one equilibrium, or two or more equilibria. The above definitionrequires at least one of them to induce outcomes that are identical to those of thesocial choice function. Thus the above definition assumes that, if multiple equilibria exist, the agents will play the truth revealing equilibrium that the mechanismdesigner (social planner) wants.Based on the type of equilibrium concept used, two types of incentive compatibility are defined: dominant strategy incentive compatibility and Bayesian incentivecompatibility.Dominant Strategy Incentive CompatibilityDefinition 16.2 (Dominant Strategy Incentive Compatibility (DSIC)).A social choice function f : Θ1 × . . . × Θn → X is said to be dominant strategy incentive compatible (or truthfully implementable in dominant strategies) if thedirect revelation mechanism D = ((Θi )i∈N , f (·)) has a weakly dominant strategyequilibrium s∗ (·) = (s∗1 (·), . . . , s∗n (·)) in which s∗i (θi ) = θi , ∀θi ∈ Θi , ∀i ∈ N .That is, truth revelation by each agent constitutes a weakly dominant strategy equilibrium of the game induced by D. Other phrases which are often used for DSIC arestrategy-proof , cheat-proof , straightforward , and truthful . In a few cases, the weaklydominant strategy equilibrium could turn out to be a strongly dominant strategyequilibrium as well. Also, often times, we find it convenient to relax the weaklydominant strategy equilibrium to be a very weakly dominant strategy equilibrium.Example 16.1 (Dominant Strategy Incentive Compatibility of SCF2).We have seen in the previous chapter that the social choice function SCF2 can be realized by a direct revelation mechanism in dominant strategies. As a consequence, for eachθ = (θ1 , . . . , θn ) ∈ Θ, the profile (θ1 , . . . , θn ) can be shown to be a (weakly) dominant strategy equilibrium of the induced Bayesian game. This means SCF2 is DSIC. Also, SCF2 isimplemented by the second price auction (which is an indirect mechanism) in dominantstrategy equilibrium.\u0003\nNecessary and Sufficient Condition for DSICUsing the definition of a weakly dominant strategy equilibrium in Bayesian games(Chapter 13), the following necessary and sufficient condition for an SCF f (·) to be\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nIncentive Compatibility and Revelation Theorem\nbook\n239\ndominant strategy incentive compatible can be derived:ui (f (θi , θ−i ) , θi ) ≥ ui (f (θi0 , θ−i ), θi )∀θi0 ∈ Θi , ∀θi ∈ Θi , ∀θ−i ∈ Θ−i , ∀i ∈ N.\n(16.1)\nThe above condition says that the SCF f (.) is DSIC if and only if for each agent i(i = 1, 2, . . . , n), it is always a best response for agent i to report his true type θi ,irrespective of what is reported by the rest of the agents.Bayesian Incentive CompatibilityDefinition 16.3 (Bayesian Incentive Compatibility (BIC)). A social choicefunction f : Θ1 × . . . × Θn → X is said to be Bayesian incentive compatible (ortruthfully implementable in Bayesian Nash equilibrium) if the direct revelation mechanism D = ((Θi )i∈N , f (·)) has a Bayesian Nash equilibrium s∗ (·) = (s∗1 (·), . . . , s∗n (·))in which s∗i (θi ) = θi , ∀θi ∈ Θi , ∀i ∈ N .That is, truth revelation by each agent constitutes a Bayesian Nash equilibrium ofthe game induced by D.Example 16.2 (Bayesian Incentive Compatibility of SCF3). We have seen inthe previous chapter that the social choice function SCF3 can be realized by a direct revelation mechanism in Bayesian Nash sense. As a consequence, for each θ = (θ1 , . . . , θn ) ∈ Θ,the profile (θ1 , . . . , θn ) can be shown to be a Bayesian Nash equilibrium of the inducedBayesian game. This means that SCF3 is BIC. Also, SCF3 is implemented by the first priceauction (which is an indirect mechanism) in Bayesian Nash equilibrium.\u0003\nNecessary and Sufficient Condition for BICUsing the definition of a Bayesian Nash equilibrium in Bayesian games (Chapter14), the following necessary and sufficient condition for an SCF f (·) to be Bayesianincentive compatible can be derived:Eθ−i [ui (f (θi , θ−i ) , θi ) |θi ] ≥ Eθ−i [ui (f (θi0 , θ−i ), θi )|θi ]∀θi0 ∈ Θi , ∀θi ∈ Θi , ∀i ∈ N.\n(16.2)\nwhere the expectation is taken over the distribution of type profiles of agents otherthan agent i. Recall from Chapter 14 that we have used pi : Θi → ∆(Θ−i ) to denotethe belief probability distributions of player i about the type profiles of the restof the agents, for different types of player i. That is, pi (θi ) represents the beliefdistribution of player i when his type is θi about the type profiles of the rest of theagents. Also, recall that pi (·) is derived from a common prior P ∈ ∆(Θ).The above condition says that the SCF f (.) is BIC if and only if for each agent i(i = 1, 2, . . . , n), whenever the other agents report their types truthfully, it is a bestresponse in expectation for agent i to report his true type θi .\nDecember 27, 2013\n11:21\n240\nWorld Scientific Book - 10.25in x 7.5in\nbook\nGame Theory and Mechanism Design\nNote. If a social choice function f (·) is dominant strategy incentive compatiblethen it is also Bayesian incentive compatible. The proof of this follows triviallyfrom the fact that a weakly dominant strategy equilibrium is clearly also a BayesianNash equilibrium.\n16.2\nThe Revelation Principle for Dominant Strategy Equilibrium\nThe revelation principle basically illustrates the relationship between an indirectrevelation mechanism M and a direct revelation mechanism D with respect toa given SCF f (·). This result enables us to restrict our inquiry about truthfulimplementation of an SCF to the class of direct revelation mechanisms only.Theorem 16.1. Suppose that there exists a mechanism M = (S1 , . . . , Sn , g(·)) thatimplements the social choice function f (·) in dominant strategy equilibrium. Thenf (·) is dominant strategy incentive compatible.Proof: It is given that M = (S1 , . . . , Sn , g(·)) implements f (·) in dominant strategies. This implies there exists a weakly dominant strategy equilibrium s∗ (·) =(s∗1 (·), . . . , s∗n (·)) of the underlying Bayesian game such thatg (s∗1 (θ1 ), . . . , s∗n (θn )) = f (θ1 , . . . , θn ) ∀ (θ1 , . . . , θn ) ∈ Θ\n(16.3)\nThe above equilibrium condition implies thatui (g(s∗i (θi ), s−i (θ−i )), θi ) ≥ ui (g(ai , s−i (θ−i )), θi ); ∀ai ∈ Si ; ∀θi ∈ Θi ;∀θ−i ∈ Θ−i ; ∀s−i (·) ∈ S−i ; ∀i ∈ N.\n(16.4)\nCondition (16.4) implies, in particular, thatui (g(s∗i (θi ), s∗−i (θ−i )), θi ) ≥ ui (g(s∗i (θi0 ), s∗−i (θ−i )), θi )∀θi0 ∈ Θi , ∀θi ∈ Θi , ∀θ−i ∈ Θ−i ∀i ∈ N.\n(16.5)\nConditions (16.3) and (16.5) together imply thatui (f (θi , θ−i ) , θi ) ≥ ui (f (θi0 , θ−i ), θi ), ∀θi0 ∈ Θi , ∀θi ∈ Θi , ∀θ−i ∈ Θ−i , ∀i ∈ N.But this is precisely condition (16.1), the necessary and sufficient condition for f (·)to be truthfully implementable in dominant strategies.\u0004The idea behind the revelation principle can be understood with the help ofFigure 16.1. In this picture, DSI represents the set of all social choice functions thatare implementable in dominant strategies and DSIC is the set of all social choicefunctions that are dominant strategy incentive compatible. The picture depicts theobvious fact that DSIC is a subset of DSI and illustrates the revelation theoremby showing that the set difference between these two sets is the empty set, thusimplying that DSIC is precisely the same as DSI.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nIncentive Compatibility and Revelation Theorem\nbook\n241\nFig. 16.1: Revelation principle for dominant strategy equilibrium16.3\nThe Revelation Principle for Bayesian Nash Equilibrium\nTheorem 16.2. Suppose that there exists a mechanism M = (S1 , . . . , Sn , g(·)) thatimplements the social choice function f (·) in Bayesian Nash equilibrium. Then f (·)is Bayesian incentive compatible.Proof: It is known that M = (S1 , . . . , Sn , g(·)) implements f (·) in BayesianNash equilibrium. This means there exists a Bayesian Nash equilibrium s∗ (·) =(s∗1 (·), . . . , s∗n (·)) of the underlying Bayesian game such thatg (s∗1 (θ1 ), . . . , s∗n (θn )) = f (θ1 , . . . , θn ) ∀ (θ1 , . . . , θn ) ∈ Θ\n(16.6)\nBayesian Nash equilibrium condition implies that\u0002\u0002\u0003\u0003Eθ−i ui (g(s∗i (θi ), s∗−i (θ−i )), θi )|θi ≥ Eθ−i ui (g(ai , s∗−i (θ−i )), θi )|θi∀ai ∈ Si , ∀θi ∈ Θi , ∀i ∈ N.\n(16.7)\nCondition (16.7) implies, in particular, that\u0002\u0002\u0003\u0003Eθ−i ui (g(s∗i (θi ), s∗−i (θ−i )), θi )|θi ≥ Eθ−i ui (g(s∗i (θi0 ), s∗−i (θ−i )), θi )|θi∀θi0 ∈ Θi , ∀θi ∈ Θi , ∀i ∈ N.\n(16.8)\nConditions (16.6) and (16.8) together imply that\u0002\u0003Eθ−i [ui (f (θi , θ−i ) , θi ) |θi ] ≥ Eθ−i ui (f (θi0 , θ−i ), θi )|θi , ∀θi0 ∈ Θi , ∀θi ∈ Θi , ∀i ∈ N.But this is precisely condition (16.2), the necessary and sufficient condition for f (·)to be Bayesian incentive compatible.\u0004\nDecember 27, 2013\n11:21\n242\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nIn a way similar to the revelation principle for dominant strategy equilibrium,the revelation principle for Bayesian Nash equilibrium can be explained with thehelp of Figure 16.2. In this picture, BNI represents the set of all social choicefunctions which are implementable in Bayesian Nash equilibrium and BIC is the setof all social choice functions which are Bayesian incentive compatible. The picturedepicts the fact that BIC is a subset of BNI and illustrates the revelation theoremby showing that the set difference between these two sets is the empty set, thusimplying that BIC is precisely the same as BNI.\nFig. 16.2: Revelation principle for Bayesian Nash equilibriumFigure 16.3 provides a high level view of both the revelation theorems that wehave seen in this chapter. The revelation theorems essentially imply that indirectmechanisms are the same as direct mechanisms in terms of the collection of socialchoice functions that can be implemented. The theorems have enabled mechanismdesign theorists to focus only on direct mechanisms for developing theoretical results.Indirect mechanisms are required by practitioners to design practical, imaginativeways of realizing the outcomes of the social choice functions.16.4\nProperties of Social Choice Functions\nWe have seen that a mechanism facilitates a solution to both the preference elicitation problem and preference aggregation problem, if the mechanism can implementthe desired social choice function f (·). It is obvious that some SCFs are implementable and the others are not. Before we look into the question of characterizing\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nIncentive Compatibility and Revelation Theorem\nbook\n243\nFig. 16.3: Combined view of revelation theorems for dominant strategy equilibrium andBayesian Nash equilibrium\nthe space of implementable social choice functions, it is important to know whichproperties a social planner would like the social choice function to possess. In thissection, we highlight two desirable properties of an SCF: ex-post efficiency andnon-dictatorship. Other key properties will be introduced appropriately in futurechapters.Ex-Post EfficiencyDefinition 16.4 (Ex-Post Efficiency). A social choice function f : Θ → X issaid to be ex-post efficient (or Paretian) if for every profile of agents’ types, θ ∈ Θ,the outcome f (θ) is a Pareto optimal outcome. The outcome f (θ) is Pareto optimalif there does not exist any x ∈ X such that:ui (x, θi ) ≥ ui (f (θ), θi ) ∀ i ∈ N and ui (x, θi ) > ui (f (θ), θi ) for some i ∈ N.Example 16.3 (Supplier Selection Problem). Consider the supplier selection\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n244\nbook\nGame Theory and Mechanism Design\nproblem (Example 14.3). Let the social choice function f be given byf (a1 , a2 ) = xf (a1 , b2 ) = x.The reader is cautioned not to confuse the outcome x above with the symbol x used inDefinition 16.4. The outcome f (a1 , a2 ) = x is Pareto optimal since the other outcomes yand z are such thatu1 (y, a1 ) < u1 (x, a1 )u1 (z, a1 ) < u1 (x, a1 ).The outcome f (a1 , b2 ) = x is Pareto optimal since the other outcomes y and z are such thatu1 (y, a1 ) < u1 (x, a1 )u1 (z, a1 ) < u1 (x, a1 ).Thus the above defined SCF is ex-post efficient.\n\u0003\nExample 16.4 (Selling a Single Indivisible Object). We have looked at threesocial choice functions, SCF1, SCF2, SCF3, in the previous chapter. The reader can verifythat all these SCFs are ex-post efficient.\u0003\nWe state below a useful proposition which can be proved easily by contradiction.The proof is left as an exercise.Proposition 16.1. Suppose f : Θ → X is a social choice function such that ∀θ ∈Θ,nnXXui (x, θi ) ∀x ∈ Xui (f (θ), θi ) ≥i=1\ni=1\nThat is, the outcome chosen in every type profile maximizes the sum of utilities ofthe agents. Then the SCF f (·) is ex-post efficient.\nNon-DictatorshipWe define this through a dictatorial social choice function.Definition 16.5 (Dictatorship). A social choice function f : Θ → X is said tobe dictatorial if there exists an agent d ∈ N such that ∀ θ ∈ Θ,ud (f (θ), θd ) ≥ ud (x, θd ) ∀ x ∈ X.Such an agent is called a dictator. A social choice function that does not contain adictator is said to be non-dictatorial.Intuitively, a dictator is an agent for whom all outcomes of the social choice functionturn out to be most favored outcomes. Note that multiple dictators could exist fora given social choice function.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nIncentive Compatibility and Revelation Theorem\nbook\n245\nExample 16.5 (Supplier Selection Problem). Let the social choice function f inExample 14.3 be given byf (a1 , a2 ) = x; f (a1 , b2 ) = x.It is easy to see that agent 1 is a dictator and hence this is a dictatorial SCF. On the otherhand, consider the following SCF:f (a1 , a2 ) = x; f (a1 , b2 ) = y.One can verify that this is not a dictatorial SCF.\n16.5\n\u0003\nSummary and References\nThis chapter was devoted to the revelation theorem which is a central result inmechanism design theory. Intuitively, the revelation theorem says that direct mechanisms and indirect mechanisms are equivalent. The following are the salient pointsof this chapter.• A social choice function is said to be incentive compatible if reporting truetypes constitutes an equilibrium of the Bayesian game induced by the directmechanism corresponding to the SCF. If the equilibrium is a dominant strategyequilibrium, we say the SCF is DSIC. If the equilibrium is only a Bayesian Nashequilibrium, we say the SCF is BIC.• Intuitively, DSIC means that reporting true types is a best response strategyfor each agent irrespective of what is reported by the other agents. BIC meansthat reporting true types is a best response strategy in expectation for eachagent whenever all other agents also report their types truthfully. Clearly, DSICimplies BIC but not vice-versa.• The revelation theorem for dominant strategy equilibrium states that if thereexists an indirect mechanism that implements an SCF in dominant strategies,there will also exist a direct mechanism that implements the SCF in dominantstrategies (that is the SCF is DSIC). The revelation theorem for Bayesian Nashequilibrium states that if there exists an indirect mechanism that implements anSCF in Bayesian Nash equilibrium, there will also exist a direct mechanism thatimplements the SCF in Bayesian Nash equilibrium (that is the SCF is BIC).• We defined two important properties of a SCF namely ex-post efficiency andnon-dictatorship. Ex-post efficiency implies that all outcomes of the SCF arePareto optimal, which is desirable. A dictator in a SCF is an agent such thatevery outcome of the SCF is a most favored outcome for the dictator. AnSCF that does not contain a dictator is said to be non-dictatorial. These twoproperties will be crucially used in the next chapter.The proofs for the revelation theorems presented in this chapter are based on theones presented in the book by Mas-Colell, Whinston, and Green [2]. The monographby Narahari, Garg, Narayanam, and Prakash [3] is another useful reference.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n246\nGame Theory and Mechanism Design\nReferences[1]\nL. Hurwicz. “On informationally decentralized systems”. In: Decision and Organization. Ed.by C.B. McGuire and R. Radner. North-Holland, Amsterdam, 1972.Andreu Mas-Colell, Michael D. Whinston, and Jerry R. Green. Microeconomic Theory. Oxford University Press, 1995.Y. Narahari, Dinesh Garg, Ramasuri Narayanam, and Hastagiri Prakash. Game TheoreticProblems in Network Economics and Mechanism Design Solutions. Springer, London, 2009.\n[2][3]\n16.6\nExercises\n(1) Recall the cake-cutting problem in Chapter 14. A mother wants to distribute acake equally between two of her children. She designs the following mechanism:one of the children will cut the cake and the other child will get the first chanceto pick up the cake. The mechanism ensures that the social choice function(namely the cake is distributed equally between the two children) is implementedin dominant strategies. Now consider the case where there are 3 children insteadof 2. For this problem, suggest (i) a mechanism which will implement the SCFin dominant strategies and (ii) a mechanism which will implement the SCF inBayesian Nash equilibrium but not in dominant strategies. Prove your resultswith simple, brief, logical arguments.(2) Show that the social choice functions SCF1 and SCF2 we defined in Chapter 15are ex-post efficient. How about SCF3?(3) Consider a seller who is faced with a single buyer. The type set of the buyer isΘ = {0, 1, 2}. The set of outcomes is X = {a, b, c}. The valuation function ofthe buyer is v(a, θ) = 0 ∀ θ ∈ Θ; v(b, θ) = θ2 ∀ θ ∈ Θ; v(c, θ) = θ ∀ θ ∈ Θ.Write down all incentive compatible social choice functions for this setting. Notethat there is only one agent here.(4) Let N = {1, 2}; Θ1 = {a1 , b1 }; Θ2 = {a2 , b2 }; X = {x, y, z}; andu1 (x, a1 ) = 100; u1 (y, a1 ) = 50; u1 (z, a1 ) = 0u1 (x, b1 ) = 50; u1 (y, b1 ) = 100; u1 (z, b1 ) = 40u2 (x, a2 ) = 0; u2 (y, a2 ) = 50; u2 (z, a2 ) = 100u2 (x, b2 ) = 50; u2 (y, b2 ) = 30; u2 (z, b2 ) = 100For the above environment, suggest a social choice function in each case listedbelow (EPE - ex-post efficient; BIC - Bayesian Incentive Compatible; DSIC dominant strategy incentive compatible; D- Dictatorial; ND - Non-dictatorial).• An SCF which is EPE, DSIC, D• An SCF which is EPE, DSIC, ND• An SCF which is not EPE but is DSIC, ND• An SCF which is EPE, BIC (under a suitable prior), but not DSIC• An SCF which is EPE, not BIC (under some prior), not DSIC\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nIncentive Compatibility and Revelation Theorem\nbook\n247\n(5) Show that the social choice function representing the following situation is expost efficient. There are n agents and an indivisible good is to be allocated toone of them. The good is allocated to an agent having highest valuation andthe total amount received by all the agents together is zero.(6) Derive the following necessary and sufficient condition for a social choice functionf (·) to be DSIC:ui (f (θi , θ−i ) , θi ) ≥ ui (f (θi0 , θ−i ), θi ), ∀θi0 ∈ Θi , ∀θi ∈ Θi , ∀θ−i ∈ Θ−i , ∀i ∈ N.\n(7) Derive the following necessary and sufficient condition for a social choice functionf (·) to be BIC:Eθ−i [ui (f (θi , θ−i ) , θi ) |θi ] ≥ Eθ−i [ui (f (θi0 , θ−i ), θi )|θi ], ∀θi0 ∈ Θi , ∀θi ∈ Θi , ∀i ∈ N.\n(8) Can a given social choice function have more than one dictator? Prove yourresult.(9) Suppose f : Θ → X is a social choice function such that ∀θ ∈ Θ,nnXXui (x, θi ) ∀x ∈ Xui (f (θ), θi ) ≥i=1\ni=1\nThat is, the outcome chosen in every type profile maximizes the sum of utilitiesof the agents. Then show that the SCF f (·) is ex-post efficient.(10) Consider two agents 1 and 2 where agent 1 is the seller of an indivisible itemand agent 2 is a prospective buyer of the item. An outcome here is of theform x = (y1 , y2 , t1 , t2 ) where yi = 1 if agent i gets the item and ti denotes thepayment received by agent i (i = 1, 2). A natural set of outcomes here isX = {(y1 , y2 , t1 , t2 ) : y1 + y2 = 1; y1 , y2 ∈ {0, 1}.Define the utilities of the agents i (i = 1, 2) appropriately. The type θ1 of agent1 (seller) can be interpreted as the willingness to sell of the agent (minimumprice at which agent 1 is willing to sell). The type θ2 of agent 2 (buyer) has thenatural interpretation of willingness to pay (maximum price the buyer is willingto pay). Assume that Θ1 = Θ2 = [0, 1] and that each agent thinks that the typeof the other agent is uniformly distributed over the real interval [0, 1]. Definethe social choice function f (θ) = (y1 (θ), y2 (θ), t1 (θ), t2 (θ)) byy1 (θ1 , θ2 ) = 1 θ1 > θ2= 0 θ1 ≤ θ2y2 (θ1 , θ2 ) = 1 θ1 ≤ θ2= 0 θ 1 > θ2θ1 + θ2t1 (θ1 , θ2 ) = y2 (θ1 , θ2 )2θ1 + θ2.t2 (θ1 , θ2 ) = −y2 (θ1 , θ2 )2Is this social choice function DSIC? Is it BIC?\nDecember 27, 2013\n11:21\n248\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\n(11) Programming Assignment. Given a set of players, their finite type sets, afinite set of outcomes, utility values, and a social choice function, design andimplement a software tool to determine if a given SCF is ex-post efficient, DSIC,and dictatorial. Also, given belief probability distributions, investigate if a givenSCF is BIC.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nChapter 17\nThe Gibbard-Satterthwaite ImpossibilityTheorem\nIn this chapter, we discuss two impossibility theorems which have shaped the research and advances in mechanism design theory. The first one is the GibbardSatterthwaite theorem which essentially shows under some technical conditions thatdominant strategy incentive compatibility can only be achieved by dictatorial socialchoice functions. Remarkably, the theorem also opens up attractive opportunitiesfor implementing interesting, useful mechanisms under practical settings such asthe quasilinear environment. We provide a proof of this theorem. The chapter alsointroduces the celebrated Arrow’s impossibility theorem which is a related, important, and much earlier result in social choice theory. In this chapter, we also presentall the preliminary paraphernalia required for understanding the two theorems.\n17.1\nPreliminaries\nWe have seen in the last section that dominant strategy incentive compatibility is anextremely desirable property of social choice functions. However the DSIC property,being a strong one, precludes certain other desirable properties to be satisfied. In thissection, we discuss the Gibbard-Satterthwaite impossibility theorem (GS theorem,for short), which shows that the DSIC property will force a social choice functionto be dictatorial in an unrestricted utility environment. In fact, in the process, evenex-post efficiency will have to be sacrificed. One can say that the GS theorem hasshaped the course of research in mechanism design during the 1970s and beyond,and is therefore a landmark result in mechanism design theory. The GS theoremis credited independently to Gibbard [1] and Satterthwaite [2]. The GS theorem ispartly based on the famous Arrow’s impossibility theorem which also we discuss inthis chapter. We commence our discussion of the GS theorem with a motivatingexample.Example 17.1 (Supplier Selection Problem). We recall Example 14.3. We haveN = {1, 2}, X = {x, y, z}, Θ1 = {a1 }, and Θ2 = {a2 , b2 }. Consider the following utilityfunctions (note that the utility functions u1 (·, a1 ) and u2 (·, a2 ) are the same as in Example14.3 while the utility function u2 (·, b2 ) is different).\n249\nbook\nDecember 27, 2013\n11:21\n250\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nAllan Gibbard is currently Richard B. Brandt DistinguishedUniversity Professor of Philosophy at the University of Michigan. His classic paper Manipulation of Voting Schemes: A General Result published in Econometrica (Volume 41, Number 4)in 1973 presents the famous impossibility theorem which is thesubject of this chapter. The result was also independently developed by Mark Satterthwaite. Professor Gibbard’s currentresearch interests are in ethical theory. He is the author of twowidely popular books: Thinking How to Live (2003 - HarvardUniversity Press) and Wise Choices, Apt Feelings (1990 - Harvard University Press and Oxford University Press).\nMark Satterthwaite is currently A.C. Buehler Professor inHospital and Health Services Management and Professor ofStrategic Management and Managerial Economics at the KelloggSchool of Management, Northwestern University. He is a microeconomic theorist with keen interest in how healthcare marketswork. His paper Strategy-proofness and Arrow’s Conditions: Existence and Correspondence Theorems for Voting Procedures andSocial Welfare Functions published in the Journal of EconomicTheory (Volume 10, April 1975) presented a brilliant reinterpretation of Arrow’s impossibility theorem, which is now known asthe Gibbard-Satterthwaite Theorem. He has authored a largenumber of scholarly papers in the areas of dynamic matching inmarkets, organizational dynamics, and mechanism design.\nu1 (x, a1 ) = 100; u1 (y, a1 ) = 50; u1 (z, a1 ) = 0u2 (x, a2 ) = 0; u2 (y, a2 ) = 50; u2 (z, a2 ) = 100u2 (x, b 2 ) = 30; u2 (y, b2 ) = 60; u2 (z, b2 ) = 20.We observe for this example that the DSIC and BIC notions are identical since thetype of player 1 is common knowledge and hence player 1 always reports the truetype (since the type set is a singleton). Consider the social choice function f givenby f (a1 , a2 ) = x; f (a1 , b2 ) = x. It can be seen that this SCF is ex-post efficient.To investigate DSIC, suppose the type of player 2 is a2 . If player 2 reports histrue type, then the outcome is x. If he misreports his type as b2 , then also theoutcome is x. Hence there is no incentive for player 2 to misreport. A similarsituation presents itself when the type of player 2 is b2 . Thus f is DSIC.In both the type profiles, the outcome happens to be the most favorable one forplayer 1, that is, x. Therefore, player 1 is a dictator and f is dictatorial. Thus theabove function is ex-post efficient and DSIC, but dictatorial.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nbook\nThe Gibbard-Satterthwaite Impossibility Theorem\n251\nNow, let us consider a different SCF h defined by h(a1 , a2 ) = y; h(a1 , b2 ) = x.Following similar arguments as above, h can be shown to be ex-post efficient andnondictatorial but not DSIC. Table 17.1 lists all the nine possible social choicefunctions in this scenario and the combination of properties each function satisfies.i1\nfi (a1 , a2 )x\nfi (a1 , b2 )x\n23\nxx\nyz\n456\nyyy\nxyz\n789\nzzz\nxyz\nEPE√√\nDSIC√××\nNON-DICT×√\n×√√\n×√\n√√√\n×√\n×√\n√√\n√\n√√\n×√\n×\nTable 17.1: Social choice functions and properties satisfied by them\nNote that the situation is quite desirable with the following SCFs.f5 (a1 , a2 ) = y; f5 (a1 , b2 ) = yf7 (a1 , a2 ) = z; f7 (a1 , b2 ) = x.The reason is that the above functions are ex-post efficient, DSIC, and also nondictatorial. Unfortunately however, such desirable situations do not occur in general.In the present case, the desirable situation does occur due to certain reasons thatwill be clear soon.\u0003In a general setting, ex-post efficiency, DSIC, and nondictatorial properties can neverbe satisfied simultaneously. In fact, even DSIC and nondictatorial properties cannotcoexist. This is the implication of the powerful Gibbard-Satterthwaite theorem.17.2\nThe Gibbard-Satterthwaite Theorem\nWe will build up some notation before presenting the theorem.Rational Preference RelationsWe have already seen that the preference of an agent i, over the outcome set X,when its type is θi , can be described by means of a utility function ui (·, θi ) : X → R,which assigns a real number to each element in X. A utility function ui (·, θi ) always\nDecember 27, 2013\n11:21\n252\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\ninduces a unique preference relation % on X which can be described in the followingmanner:x % y ⇔ ui (x, θi ) ≥ ui (y, θi ).The above preference relation is often called a rational preference relation and it isformally defined as follows.Definition 17.1 (Rational Preference Relation). We say that a relation % onthe set X is a rational preference relation if it possesses the following three properties:(1) Reflexivity: ∀ x ∈ X, we have x % x.(2) Completeness: ∀ x, y ∈ X, we have that x % y or y % x (or both).(3) Transitivity: ∀ x, y, z ∈ X, if x % y and y % z, then x % z.The following proposition establishes the relationship between rational preferencerelations and utility functions.Proposition 17.1.(1) If a preference relation % on X is induced by some utility function ui (·, θi ), thenit will be a rational preference relation.(2) For any given rational preference relation % on X, there may not exist a utilityfunction that induces it. However, when the set X is finite, given any rationalpreference relation, there will certainly exist a utility function that induces it.(3) For a given rational preference relation % on X, there might be several utilityfunctions that induce it. Indeed, if the utility function ui (·, θi ) induces % , thenu0i (x, θi ) = f (ui (x, θi )) is another utility function that will also induce % , wheref : R → R is a strictly increasing function.Strict-Total Preference RelationsWe now define a special class of rational preference relations that satisfy the antisymmetry property also.Definition 17.2 (Strict-Total Preference Relation). We say that a rationalpreference relation % is strict-total if it possesses the antisymmetry property, inaddition to reflexivity, completeness, and transitivity. Antisymmetry means that,for any x, y ∈ X such that x % y as well as y % x, the outcomes x and y are thesame.The strict-total preference relation is also known as a linear order relation becauseit satisfies the properties of the usual greater than or equal to relationship on thereal line. Let us denote the set of all rational preference relations and strict-totalpreference relations on the set X by R and P, respectively. It is easy to see thatP ⊂ R.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nThe Gibbard-Satterthwaite Impossibility Theorem\nbook\n253\nOrdinal Preference RelationsIn a mechanism design problem, for agent i, the preferences over the set X aredescribed in the form of a utility function ui : X × Θi → R. That is, for everypossible type θi ∈ Θi of agent i, we can define a utility function ui (·, θi ) over the setX. Let this utility function induce a rational preference relation % i (θi ) over X.The set Ri = { % i (θi ) : θi ∈ Θi } is known as the set of ordinal preference relationsfor agent i. It is easy to see that Ri ⊂ R ∀ i ∈ N .With all the above notions in place, we are now in a position to state the GStheorem.Theorem 17.1 (Gibbard-Satterthwaite Impossibility Theorem). Considera social choice function f : Θ → X. Suppose that(1) The outcome set X is finite and |X| ≥ 3,(2) Ri = P ∀ i ∈ N ,(3) f is an onto mapping, that is, the image of SCF f (·) is the set X.Then the social choice function f is dominant strategy incentive compatible iff it isdictatorial.The implication of condition (2) above is that each agent will exhibit all possiblestrict-total preferences over outcomes through its different types. Thus the preference structure is as rich as it could possibly be. The implication of condition (3) isthat every outcome in X is possible under the social choice mapping f (.). Figure17.1 shows a pictorial representation of the GS theorem. The figure depicts twoclasses F1 and F2 of social choice functions. The class F1 is the set of all SCFs thatsatisfy conditions (1) and (2) of the theorem while the class F2 is the set of all SCFsthat satisfy condition (3) of the theorem. The class GS is the set of all SCFs in theintersection of F1 and F2 which are DSIC. The functions in the class GS have to benecessarily dictatorial.Implications of the GS TheoremOne way to get around the impossible situation described by the GS Theorem is tohope that at least one of the conditions (1), (2), and (3) of the theorem does nothold. We discuss each of the possibilities below.• Condition (1) asserts that |X| ≥ 3. This condition is violated only if |X| = 1or |X| = 2. The case |X| = 1 corresponds to a trivial situation and is not ofinterest. The case |X| = 2 is more interesting but is of only limited interest. Apublic project problem where only a go or no-go decision is involved and thereare no payments involved corresponds to this situation.• Condition (2) asserts that Ri = P ∀i ∈ N . This means that the preferencesof each agent cover the entire space of strict total preference relations on X.That is, each agent has an extremely rich set of preferences. If we are able to\nDecember 27, 2013\n11:21\n254\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nFig. 17.1: An illustration of the Gibbard-Satterthwaite theorem\nsomehow restrict the preferences, we can hope to violate this condition. Onecan immediately note that this condition was violated in the motivating example(Example 17.1, the supplier selection problem). The celebrated class of VCGmechanisms has been derived by restricting the preferences to the quasilineardomain. This will be discussed in detail in Chapter 18.• Condition (3) asserts that f is an onto function. Note that this condition alsowas violated in Example 17.1. This provides one more route for getting aroundthe GS Theorem.Another way of escaping from the undesirable implications of the GS Theorem is tosettle for a weaker form of incentive compatibility than DSIC. We have already discussed Bayesian incentive compatibility (BIC) which only guarantees that reportingtrue types is a best response in expectation for each agent whenever all other agentsalso report their true types. Following this route leads us to Bayesian incentivecompatible mechanisms. These are discussed in detail in Chapter 19.The GS Theorem is a significant result that influenced the course of mechanismdesign research in the 1970s and 1980s.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nThe Gibbard-Satterthwaite Impossibility Theorem\n17.3\nbook\n255\nProof of Gibbard Satterthwaite Theorem\nWe start with a few definitions and concepts: lower contour sets, weak preferencereversal property, and monotonicity.Definition 17.3 (Lower Contour Set). Given an outcome x ∈ X, and agenti ∈ N and a type of agent i, θi ∈ Θi , the lower contour set Li (x, θi ) is defined asLi (x, θi ) = {y ∈ X : ui (x, θi ) ≥ ui (y, θi )}The lower contour set of agent i corresponding to a type θi and an outcome x consistsof all outcomes which produce equal or less utility than ui (x, θi ).Weak Preference Reversal PropertyRecall the necessary and sufficient condition for DSIC of a social choice functionf (.):ui (f (θi , θ−i ), θi ) ≥ ui (f (θˆi , θ−i ), θi ) ∀ θi ∈ Θi ; ∀ θˆi ∈ Θi ; ∀ θ−i ∈ Θ−i ; ∀i ∈ N000Consider an agent i ∈ N and let θi , θi ∈ Θi be any two possible types. If thefunction f (.) is DSIC, then the above necessary and sufficient condition yields thefollowing two inequalities:00000ui (f (θi , θ−i ), θi ) ≥ ui (f (θi , θ−i ), θi ) ∀θ−i ∈ Θ−i0\n00\n00\n00\nui (f (θi , θ−i ), θi ) ≥ ui (f (θi , θ−i ), θi ) ∀θ−i ∈ Θ−i000Clearly, the preference ranking of the outcomes f (θi , θ−i ) and f (θi , θ−i ) weakly re000verses when the type changes from θi to θi . This motivates the following definition.Definition 17.4 (Weak Preference Reversal Property). Consider an agent000i ∈ N and let θi , θi ∈ Θi be any two possible types. Given θ−i ∈ Θ−i , we saythe SCF f (.) satisfies the weak preference reversal property for agent i and for types000θi , θi if the following inequalities are satisfied.00000ui (f (θi , θ−i ), θi ) ≥ ui (f (θi , θ−i ), θi )00\n00\n0\n00\nui (f (θi , θ−i ), θi ) ≥ ui (f (θi , θ−i ), θi )It can be shown that, if a social choice function f (.) is such that the above weak000preference reversal property holds for all possible pairs θi , θi ∈ Θi and for all θ−i ∈Θ−i (∀i ∈ N ), then f (.) is DSIC [3]. Thus DSIC can also be characterized as beingequivalent to the weak preference reversal property being satisfied for all agents000i ∈ N and for all θi , θi ∈ Θi and for all θ−i ∈ Θ−i . In terms of lower contour sets,the above observations can be summarized as the following proposition.Proposition 17.2. A social choice function f : θ → X is DSIC iff ∀i ∈ N, ∀θ−i ∈000Θ−i and all pairs θi , θi ∈ Θi , the following inequalities are satisfied.000000000f (θi , θ−i ) ∈ Li (f (θi , θ−i ), θi ) and f (θi , θ−i ) ∈ Li (f (θi , θ−i ), θi )\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n256\nbook\nGame Theory and Mechanism Design\nMonotonicityMonotonicity is an important property of a social choice function and plays a crucialrole in mechanism design theory. Suppose θ ∈ Θ and f (θ) = x ∈ X. Let the type00profile θ change to θ ∈ Θ and assume that in the new type profile θ , no agent findsthat some alternative which was weakly worse than x under type θ, becomes strictlypreferred to x. That is, there does not exist an agent i such that an outcome y ∈ X0that was (weakly) worse than x under θ will become strictly better than x under θ .0Then monotonicity of f (.) means that x must continue to be the social choice in θ ,0that is f (θ ) = x. This is formalized in the following definition.Definition 17.5 (Monotonicity). A social choice function f : Θ → X is mono00tonic if ∀θ ∈ Θ, ∀θ ∈ Θ (θ 6= θ),0\n0\nLi (f (θ), θi ) ⊂ Li (f (θ), θi ) ∀ i ∈ N =⇒ f (θ ) = f (θ)The above means that, for each agent i, outcomes which were weakly worse thanf (θ) under θi , will continue to be weakly worse than f (θ) under θi0 .Proof of Gibbard-Satterthwaite TheoremThe proof is simple in one direction: Suppose all the conditions (1)−(3) are satisfiedand f (.) is dictatorial, it can be shown easily that f (.) is DSIC. This is left as anexercise.In the other direction, we are given that conditions (1) − (3) are satisfied andf (.) is DSIC. We have to show that f (.) is dictatorial. The proof of this proceeds inthree steps. We have followed here closely the proof approach given by Mas-Colell,Whinston, and Green [3].Step 1 : Showing that f (.) is Monotonic0\nWe are given that f (.) is DSIC. Consider two profiles θ = (θ1 , θ2 , . . . , θn ) and θ =000(θ1 , θ2 , . . . , θn ) such that0\nLi (f (θ), θi ) ⊂ Li (f (θ), θi ) ∀i ∈ N0\nConsider the outcome f (θ1 , θ2 , . . . , θn ). Then by the weak preference reversal property, we have0\nf (θ1 , θ2 , . . . , θn ) ∈ L1 (f (θ1 , θ2 , . . . , θn ), θ1 )The above two equations imply that0\n0\nf (θ1 , θ2 , . . . , θn ) ∈ L1 (f (θ1 , θ2 , . . . , θn ), θ1 )From the above inclusion, it follows that0\n0\nf (θ1 , θ2 , . . . , θn ) % 1 (θ1 )f (θ1 , θ2 , . . . , θn )\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nbook\nThe Gibbard-Satterthwaite Impossibility Theorem\n257\nBy the weak preference reversal property, we again have0\n0\nf (θ1 , θ2 , . . . , θn ) ∈ L1 (f (θ1 , θ2 , . . . , θn ), θ1 )which implies0\n0\nf (θ1 , θ2 , . . . , θn ) % 1 (θ1 )f (θ1 , θ2 , . . . , θn )Since Ri = P ∀i ∈ N , no two alternatives can be indifferent in the preference0relation %1 (θ1 ). Therefore it must be that0\nf (θ1 , θ2 , . . . , θn ) = f (θ1 , θ2 , . . . , θn )On similar lines, it can be shown that0\n0\nf (θ1 , θ2 , θ3 , . . . , θn ) = f (θ1 , θ2 , . . . , θn )Extending the above argument iteratively we get what we need for monotonicity off (.):0\n0\n0\nf (θ1 , θ2 , . . . , θn ) = f (θ1 , θ2 , . . . , θn )Step 2 : Showing that f (.) is Ex-Post EfficientHere we show that f (.) is ex-post efficient if |X| ≥ 3; Ri = P ∀ i ∈ N ; f (Θ) = X,and f (.) is monotonic. We prove this by contradiction. Suppose f (.) is not ex-postefficient. Then, there exists a type profile θ ∈ Θ and an outcome y ∈ X, y 6= f (θ),such thatui (y, θi ) > ui (f (θ), θi ) ∀ i ∈ NThe above involves only strict inequality because no two alternatives can be indifferent for any agent as Ri = P ∀ i ∈ N . Since f is onto, there exists a type profile00θ ∈ Θ such that f (θ ) = y. Therefore, we have0\nui (f (θ ), θi ) > ui (f (θ), θi ) ∀i ∈ N00\nChoose θ ∈ Θ such that ∀ i ∈ N ,0\n0\n00\n00\n00\nui (f (θ ), θi ) > ui (f (θ), θi ) > ui (z, θi ) ∀ z 6= f (θ), f (θ )The above choice is certainly possible since all preferences in P are allowed and|X| ≥ 3. We now invoke monotonicity by first showing that0\n0\n0\n00\nLi (f (θ ), θi ) ⊂ Li (f (θ ), θi ) ∀ i ∈ NTo show the above, we show that0\n0\n0\n00\nx ∈ Li (f (θ ), θi ) =⇒ x ∈ Li (f (θ ), θi ) ∀x ∈ X0\n0\n00\nFirst note that if x = f (θ) or x = f (θ ), then clearly, x ∈ Li (f (θ ), θi ), so there is0nothing to show. If x 6= f (θ), f (θ ), then0\n0\n0\n0\n0\nx ∈ Li (f (θ ), θi ) =⇒ ui (x, θi ) ≤ ui (f (θ ), θi )\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n258\nGame Theory and Mechanism Design0\n00\n00\nWe know that ui (x, θi ) ≤ ui (f (θ ), θi ) which immediately implies that x ∈000Li (f (θ ), θi ).Now invoking monotonicity, we get00\n0\nf (θ ) = f (θ )00\nWe can also show that Li (f (θ), θi ) ⊂ Li (f (θ), θi ) ∀i ∈ N . Monotonicity againimplies that00\nf (θ ) = f (θ)0\nThe above is a contradiction, since f (θ ) 6= f (θ). This in turn implies that f mustbe ex-post efficient.Step 3 : Showing that f (.) is DictatorialWe are given that f (·) is DSIC and EPE and we have to show that f (·) is dictatorial.This result can be obtained as a corollary of the Arrow’s impossibility result (seethe next section).\u0004Some Notes and ObservationsWe make the following important observations about the GS theorem.Note. It may be noted that the finiteness of X is not required for GS Theorem.However, if X is not finite, the assumption about agents being expected utilitymaximizers may not be compatible with the condition Ri = P ∀ i ∈ N [3]. If Xis not finite, the GS Theorem will still hold if Ri for each i ∈ N is the set of allcontinuous preferences on X [3].Note. If |X| = 2, the GS theorem is not true. We have already seen this earlier inthis section while discussing Example 17.1.Note. When Ri = P ∀i ∈ N , it may be noted that any ex-post efficient socialchoice function must have f (Θ) = X.Note. The GS theorem holds even if the assumption (2) is relaxed to P ⊂ Ri ∀ i ∈N.Note. We have already seen (Definition 16.5) that f : Θ → X is dictatorial onY ⊂ X if there exists an agent d ∈ N such that ∀ θ ∈ Θ,ud (f (θ), θd ) ≥ ud (y, θd ) ∀y ∈ YThe GS theorem holds good under the following special setting also: suppose X isfinite, |f (Θ)| ≥ 3, and P ⊂ Ri ∀ i ∈ N . Then f (.) is DSIC iff f (.) is dictatorial onf (Θ).\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nThe Gibbard-Satterthwaite Impossibility Theorem\nbook\n259\nKenneth Joseph Arrow received the Nobel Prize in EconomicSciences in 1972, jointly with John R. Hicks, for their pioneering contributions to general economic equilibrium theory andwelfare theory. Arrow is regarded as one of the most influentialeconomists of all time. With his path-breaking contributions insocial choice theory, general equilibrium analysis, endogenousgrowth theory, and economics of information, Kenneth Arrowis truly a legend of economics. Three of his doctoral students,John Harsanyi, Michael Spencer, and Roger Myerson are alsoEconomics Nobel laureates.The famous Arrow impossibility theorem was one of the outstanding results includedin his classic book in 1951 Social Choice and Individual Values, which itself wasinspired by his doctoral work. The theorem was first published in the Journal ofPolitical Economy in 1950. This theorem is perhaps the most important result inwelfare economics and also has far-reaching ramifications for mechanism design theory.Kenneth Arrow was born in the New York City on August 23, 1921. He earned hisdoctorate from Columbia University in 1951, working with Professor Harold Hotelling.He is a recipient of the von Neumann Theory Prize in 1986, and he was awarded in2004 the National Medal of Science, the highest scientific honor in the United States.His joint work with Gerard Debreu on general equilibrium theory is also a majorlandmark that was prominently noted in the Nobel Prize awarded to Gerard Debreuin 1983. Arrow is currently the Joan Kenney Professor of Economics and Professorof Operations Research, Emeritus, at Stanford University.\n17.4\nArrow’s Impossibility Theorem\nThe need to aggregate preference orderings of individual players into a single socialpreference ordering arises in many contexts. The Arrow’s theorem is a landmark result that shows that when there are at least three outcomes, there is no method thatcan aggregate the individual preference orderings into a social preference orderingwhile meeting certain desirable criteria. Following are these criteria:• Unanimity: If every player prefers alternative x to alternative y, then the socialordering also prefers x to y.• Pairwise Independence: If every player’s preference between x and y remainsunchanged, then in the social ordering also, the preference between x and yremains unchanged (even if the preferences of the players between other pairssuch as x and z; y and z; and z and w change).• No Dictator Property: No single player possesses the power to completely dictatethe social ordering.Arrow’s impossibility theorem has shaped the discipline of social choice theory inmany significant ways. It has been used extensively in proving many importantresults in microeconomics including the Gibbard-Satterthwaite theorem.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n260\nGame Theory and Mechanism Design\nBefore discussing this result, we first set up some relevant notation. Consider a setof agents N = {1, 2, . . . , n} and a set of outcomes X. Let %i be a rational preferencerelation of agent i (i ∈ N ). For example, %i could be induced by ui (., θi ) whereθi is a certain type of agent i. Each agent is thus naturally associated with a setRi of rational preference relations derived from the utility functions ui (., θi ) whereθi ∈ Θi .Given a rational preference relation %i , denote by \u001fi the relation defined by(x, y) ∈ \u001fi iff (x, y) ∈ %i and (y, x) ∈/ %i .The relation \u001fi is said to be the strict total preference relation derived from %i .Note that \u001fi = %i if %i itself is a strict total preference relation. Given anoutcome set X, a strict total preference relation can be simply represented as anordered tuple of elements of X.As usual R and P denote, respectively, the set of all rational preference relationsand strict total preference relations on the set X. Let A be any nonempty subsetof R n . We define a social welfare functional as a mapping from A to R.Definition 17.6 (Social Welfare Functional). Given N = {1, 2, . . . , n}, anoutcome set X, and a set of profiles A of rational preference relations of the agents,A ⊂ R n , a social welfare functional is a mapping W : A −→ R.Note that a social welfare functional W aggregates a given profile of rational preference relations ( %1 , . . . , %n ) ∈ A , into a single rational preference relation %.Example 17.2 (Social Welfare Functional). Consider the example of the supplierselection problem discussed earlier, where N = {1, 2}, X = {x, y, z}, Θ1 = {a1 }, andΘ2 = {a2 , b2 }. Recall the utility functions:u1 (x, a1 ) = 100; u1 (y, a1 ) = 50; u1 (z, a1 ) = 0u2 (x, a2 ) = 0; u2 (y, a2 ) = 50; u2 (z, a2 ) = 100u2 (x, b2 ) = 30; u2 (y, b2 ) = 60; u2 (z, b2 ) = 20.The utility function u1 leads to the following strict preference relation:%a1 = (x, y, z).The utility function u2 leads to the strict total preference relations:%a2 = (z, y, x); %b2 = (y, x, z).Let the set A be defined asA = {(%a1 , %a2 ), (%a1 , %b2 )}.An example of a social welfare functional here would be the mapping W1 given byW1 (%a1 , %a2 ) = (x, y, z); W1 (%a1 , %b2 ) = (y, x, z).\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nThe Gibbard-Satterthwaite Impossibility Theorem\nbook\n261\nAnother example would be the mapping W2 given byW2 (%a1 , %a2 ) = (x, y, z);\nW2 (%a1 , %b2 ) = (z, y, x).\nSeveral such social welfare functionals can be defined here.\n\u0003\nNote the difference between a social choice function and a social welfare functional. In the case of a social choice function, the preferences are summarized interms of types and each type profile is mapped to a social outcome. On the otherhand, a social welfare functional maps a profile of individual preferences to a socialpreference relation. Recall that the type of an agent determines a preference relationon the set X through the utility function.We now define three properties of a social welfare functional: unanimity (alsocalled Paretian property); pairwise independence (also called independence of irrelevant alternatives (IIA)), and dictatorship.Definition 17.7 (Unanimity). A social welfare functional W : A −→ R is saidto be unanimous if ∀ (%1 , . . . , %n ) ∈ A and ∀x, y ∈ X,(x, y) ∈ %i ∀i ∈ N =⇒ (x, y) ∈ Wp (%1 , . . . , %n )where Wp (%1 , . . . , %n ) is the strict preference relation derived from W (%1 , . . . , %n ).The above definition means that, for all pairs x, y ∈ X, whenever x is preferred toy for every agent, then x is also socially preferred to y (in a strict way).Example 17.3 (Unanimity). For the setting in Example 17.2, recallW1 (%a1 , %a2 ) = W1 ((x, y, z), (z, y, x)) = (x, y, z)W1 (%a1 , %b2 ) = W1 ((x, y, z), (y, x, z)) = (y, x, z).In order to check unanimity, we need to check only the following pairs for which both thetwo players have the same preference order:• (y, z) ∈ %a1 , (y, z) ∈ %b2 , and (y, z) ∈ W1 (%a1 , %b2 ); and• (x , z) ∈ %a1 , (x, z) ∈ %b2 , and (x, z) ∈ W1 (%a1 , %b2 ).Thus W1 is unanimous. On the other hand, considerW2 ((x, y, z), (z, y, x)) = (x, y, z); W2 ((x, y, z), (y, x, z)) = (z, y, x)Here (y, z) ∈ %a1 and (y, z) ∈ %b2 but (y, z) ∈/ W2 ( %a1 , %b2 ). So W2 is not unanimous. \u0003\nWe now introduce pairwise independence or independence of irrelevant alternatives (IIA). This property implies that the social preference between x and y willdepend only on the individual preferences between x and y. More specifically, given00two profiles ( %1 , . . . , %n ) and ( %1 , . . . , %n ) such that for all players i ∈ N , the0outcomes x and y have the same order in %1 and %1 , then the outcomes x and y will00have the same order in W ( %1 , . . . , %n ) and W ( %1 , . . . , %n ). Note that preferencesbetween other pairs such as x and z; y and z; and z and w do not matter here (this\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n262\nbook\nGame Theory and Mechanism Design\nexplains why this property is called independence of irrelevant alternatives). Theformal definition of this key notion is given below.Definition 17.8 (Pairwise Independence). The social welfare functional W :A −→ R is said to satisfy pairwise independence if:0\n0\n∀x, y ∈ X, ∀( %1 , . . . , %n ), (%1 , . . . , %n ) ∈ A satisfying0\n0\n(x, y) ∈ %i ⇔ (x, y) ∈ %i and (y, x) ∈ %i ⇔ (y, x) ∈ %i ∀i ∈ N ,we have that0\n0\n(x, y) ∈ W ( %1 , . . . , %n ) ⇔ (x, y) ∈ W ( %1 , . . . , %n ); and0\n0\n(y, x) ∈ W ( %1 , . . . , %n ) ⇔ (y, x) ∈ W ( %1 , . . . , %n ).Example 17.4 (Pairwise Independence). Consider the example as before and letW3 (%a1 , %a2 ) = W3 ((x, y, z), (z, y, x)) = (x, y, z)W3 (%a1 , %b2 ) = W3 ((x, y, z), (y, x, z)) = (y, z, x).Here agent 1 prefers x to y in both the profiles while agent 2 prefers y to x in both theprofiles. However in the first case, x is socially preferred to y while in the second case yis socially preferred to x. Thus the social preference between x and y is not dependentsolely on the individual preferences between x and y. This shows that W3 is not pairwiseindependent. On the other hand, consider W4 given byW4 ((x, y, z), (z, y, x)) = (x, y, z)W4 ((x, y, z), (y, x, z)) = (z, x, y).Now this social welfare functional satisfies pairwise independence.\n\u0003\nThe pairwise independence property is a very appealing property since it ensuresthat the social ranking between any pair of alternatives x and y does not in anyway depend on alternatives other than x and y or the relative positions of theseother alternatives in the individual preferences. Secondly, the pairwise independence property has a connection to the weak preference reversal property, which wehave studied earlier in this chapter. Recall that weak preference reversal property isquite crucial in ensuring dominant strategy incentive compatibility of social choicefunctions. Finally, the pairwise independence property leads to a natural decomposition of the problem of social ranking. For instance, if we wish to determine asocial ranking on the outcomes of a subset Y of X, we do not need to worry aboutindividual preferences on the set X\\Y .We next introduce the dictatorship property which means that there exists aplayer (called a dictator) who calls all the shots: the social preference ordering isalways the same as the preference ordering of the dictator. In other words, thereexists a player whose preferences always prevail. Ideally we would like the socialwelfare functional to be non-dictatorial.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nThe Gibbard-Satterthwaite Impossibility Theorem\nbook\n263\nDefinition 17.9 (Dictatorship). A social welfare functional W : A −→ R iscalled a dictatorship if there exists an agent, d ∈ N , called the dictator such that∀x, y ∈ X and ∀ ( %1 , . . . , %n ) ∈ A , we have(x, y) ∈ %d =⇒ (x, y) ∈ Wp (%1 , . . . , %n ).This means that whenever the dictator prefers x to y, then x is also socially preferredto y, irrespective of the preferences of the other agents. A social welfare functionalthat does not have a dictator is said to be nondictatorial.Example 17.5 (Dictatorship). Consider the social welfare functionalW5 ((x, y, z), (z, y, x)) = (x, y, z)W5 ((x, y, z), (y, x, z)) = (x, y, z).It is clear that agent 1 is a dictator here. On the other hand, the social welfare functionalW3 ((x, y, z), (z, y, x)) = (x, y, z)W3 ((x, y, z), (y, x, z)) = (y, z, x)is not dictatorial.\n\u0003\nThe dream of a social planner would be to implement a social welfare functionalthat is unanimous, satisfies the pairwise independence property, and is nondictatorial. Unfortunately, this belongs to the realm of impossible situations when thepreference profiles of the agents are rich. This is the essence of the Arrow’s Impossibility Theorem, which is stated next.Theorem 17.2 (Arrow’s Impossibility Theorem). Suppose(1) |X| ≥ 3,(2) A = R n or A = P n .Then every social welfare functional W : A −→ R that is unanimous and satisfiespairwise independence is dictatorial.The theorem was first enunciated in [4] and elaborated later in [5]. For a proof ofthis theorem, we refer the reader to Proposition 21.C.1 of Mas-Colell, Whinston,and Green [3]. Arrow’s Impossibility Theorem is pictorially depicted in Figure 17.2.The set P denotes the set of all Paretian or unanimous social welfare functionals.The set IIA denotes the set of all social welfare functionals that satisfy independenceof irrelevant alternatives (or pairwise independence). The diagram shows that theintersection of P and IIA is necessarily a subset of D, the class of all dictatorialsocial welfare functionals.The Gibbard-Satterthwaite theorem has close connections to Arrow’s Impossibility Theorem. The property of unanimity of social welfare functionals is related\nDecember 27, 2013\n11:21\n264\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nWW : Set of all social welfare functionals with A = R n or P nP : Set of all paretian or unanimous functionalsIIA : Set of all functionals satisfying independence of irrelevant alternativesor pairwise independenceD : Dictatorial social welfare functionals\nFig. 17.2: An illustration of Arrow’s impossibility theoremto ex-post efficiency of social choice functions. The notions of dictatorship of social welfare functionals and social choice functions are closely related. The pairwiseindependence property of social welfare functionals has intimate connections withthe DSIC property of social choice functions through the weak preference reversalproperty and monotonicity. We do not delve deep into this here; interested readersare referred to the book of Mas-Colell, Whinston, and Green [3] (Chapters 21 and23).To conclude this section, we state a corollary of the Arrow’s impossibility theoremwhich is critically used in the proof of the Gibbard-Satterthwaite theorem. This isProposition 21.E.1 in the book by Mas-Colell, Whinston, and Green [3].Proposition 17.3. Suppose |X| ≥ 3 and the domain of admissible preferences iseither A = R n or A = P n . Then every weakly Paretian and monotonic socialchoice function f : A −→ X is dictatorial.17.5\nSummary and References\nThe GS theorem essentially states that DSIC can only be achieved by dictatorialsocial choice functions when (a) the outcome set is finite and there are at least threeelements (b) all possible strict preferences over outcomes are possible for every\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nThe Gibbard-Satterthwaite Impossibility Theorem\nbook\n265\nagent (c) the SCF produces every possible outcome. On the face of it, the GStheorem clearly gives disappointing news to mechanism designers. However, bycarefully looking at the conditions under which the theorem holds, mechanism designresearchers have unearthed many interesting possibilities as follows.• Restriction of the preferences to the quasilinear setting has led to the popular VCG (Vickrey-Clarke-Groves) mechanisms which achieve dominant strategyincentive compatibility and allocative efficiency in general practical situations• Relaxation of DSIC to BIC has led to a variety of Bayesian mechanisms such asthe dAGVA mechanism which satisfy BIC, AE, and also strict budget balance.The famous Arrow’s impossibility result predates the GS theorem by almost twodecades and provides technical support to prove the GS theorem. Arrow’s theoremis in the broader area of social choice theory and states under similar technicalconditions that unanimity and independence of irrelevant alternatives cannot coexistwith non-dictatorship.There are many alternate proofs for the Gibbard-Satterthwaite theorem and theArrow’s impossibility theorem. The proof provided here for the GS theorem is basedon the treatment available in the book by Mas-Colell, Whinston, and Green [3]. Senhas provided an elegant direct proof of the Gibbard-Satterthwaite theorem in [6].References[1][2]\n[3][4][5][6]\nA. Gibbard. “Manipulation of voting schemes”. In: Econometrica 41 (1973), pp. 587–601.M.A. Satterthwaite. “Strategy-proofness and Arrow’s conditions: Existence and correspondence theorem for voting procedure and social welfare functions”. In: Journal of EconomicTheory 10 (1975), pp. 187–217.Andreu Mas-Colell, Michael D. Whinston, and Jerry R. Green. Microeconomic Theory. Oxford University Press, 1995.Kenneth J. Arrow. “A difficulty in the concept of social welfare”. In: Journal of PoliticalEconomy 58(4) (1950), pp. 328–346.Kenneth J. Arrow. Social Choice and Individual Values. Yale University Press, 1951.Arunava Sen. “Another direct proof of the Gibbarad-Satterthwaite theorem”. In: EconomicsLetters 70 (2001), pp. 381–385.\nJanuary 3, 2014\n11:48\nWorld Scientific Book - 10.25in x 7.5in\nThis page intentionally left blank\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nChapter 18\nVickrey-Clarke-Groves (VCG) Mechanisms\nVCG mechanisms constitute an extensively studied special class of mechanisms withmoney. They are derived using the idea of violating one of the necessary conditions of the Gibbard-Satterthwaite theorem. VCG mechanisms assume a restrictedenvironment called the quasilinear environment in which no social choice functioncan be dictatorial and moreover the mechanism can be elegantly decomposed intoan allocation rule and a payment rule. Further the ex-post efficiency property canbe separated into two properties, allocative efficiency (a property of the allocationrule) and strict budget balance (a property of the payment rule). VCG mechanismsare appealing because they satisfy allocative efficiency as well as dominant strategyincentive compatibility. We discuss the quasilinear environment first followed byGroves mechanisms (which are the most general among VCG mechanisms). Thenwe discuss the Clarke mechanism (also called pivotal mechanism) of which the Vickrey mechanism is a special case. We provide several examples to illustrate VCGmechanisms.\n18.1\nThe Quasilinear Environment\nIn the quasilinear environment, an outcome x ∈ X is a vector of the form x =(k, t1 , . . . , tn ), where k is an element of a set K, which is called the set of projectchoices or allocations. The set K is usually assumed to be finite. The term ti ∈ Rrepresents the monetary transfer to agent i. If ti > 0, then, by convention, agent ireceives an amount of money equal to ti and if ti < 0, agent i pays an amount ofmoney equal to ti . It is important to note that an outcome is decomposed into anallocation part and a payment part. The set of alternatives X is thereforeX = {(k, t1 , . . . , tn ) : k ∈ K; ti ∈ R; ∀i ∈ N } .Often, we deal with a system in which the n agents have no external source offunding and we make the implicit assumption:X\nti ≤ 0.\ni∈N\n267\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n268\nGame Theory and Mechanism Design\nThis condition is known as the weak budget balance condition. When this conditionis assumed, the set( of alternatives will become:)XX = (k, t1 , . . . , tn ) : k ∈ K; ti ∈ R ∀ i ∈ N ;ti ≤ 0 .i∈N\nAn outcome of a social choice function f : Θ → X in quasilinear environment takesthe form f (θ) = (k(θ), t1 (θ), . . . , tn (θ)) where, for every θ ∈ Θ, we have k(θ) ∈ K.PIf weak budget balance is satisfied, we have in addition, i ti (θ) ≤ 0 ∀θ ∈ Θ.Note. We clarify the use of symbols k and k(θ) and the symbols ti and ti (θ). If thetype profile θ is implicit and clear, we simply use k and ti . Whenever θ is requiredto be explicitly mentioned, we use k(θ) and ti (θ). Note that k(·) is a mapping fromΘ to K while ti (·) for i = 1, . . . , n is a mapping from Θ to R.For a direct revelation mechanism D = ((Θi )i∈N , f (·)) in this environment, theagent i’s utility function takes the quasilinear formui (x, θi ) = ui ((k, t1 , . . . , tn ), θi ) = vi (k, θi ) + mi + tiwhere mi is agent i’s initial endowment of the money and the function vi (·, ·) isknown as agent i’s valuation function.Recall from our discussion of mechanism design environment (Chapter 16) thatthe utility functions ui (·) are assumed to be common knowledge. In the context ofa quasilinear environment, this implies that for any given type θi of any agent i, thesocial planner and every other agent j have a way of knowing the function vi (., θi ),ti (θ), and mi .Immediate examples of quasilinear environment include many of the previouslydiscussed examples, such as the first price and second price auctions (Example 14.4),bilateral trade (Example 14.6), the public project problem (Example 14.7), etc. Inthe quasilinear environment, we can define two important properties of a socialchoice function, namely, allocative efficiency and budget balance.Allocative EfficiencyAllocative efficiency is a property of the allocation function k(·) in quasilinear environment.Definition 18.1 (Allocative Efficiency (AE)). We say that a social choicefunction f (·) = (k(·), t1 (·), . . . , tn (·)) is allocatively efficient if for each θ ∈ Θ, k(θ)satisfies the following conditionnXvi (k, θi ).k(θ) ∈ arg maxk∈K\ni=1\nEquivalently,nXi=1\nvi (k(θ), θi ) = maxk∈K\nnXi=1\nvi (k, θi ).\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nbook\nVickrey-Clarke-Groves (VCG) Mechanisms\n269\nThe above definition implies that for every θ ∈ Θ, the allocation k(θ) will maximizethe sum of the values of the players. In other words, every allocation is a valuemaximizing allocation, or the objects are allocated to the players who value theobjects most. This is an extremely desirable property to have for any social choicefunction. Often, we will be using the symbol k ∗ (·) for a function k(·) that satisfiesEquation (18.1), to indicate that it maximizes the total value in all allocations.Note. The above definition implicitly assumes that for any given θ, the functionPni=1 vi (., θi ) : K → R attains a maximum over the set K.Example 18.1 (Public Project Problem). Consider the public project problemwith two agents N = {1, 2}. Let the cost of the public project be 50 units of money.Let the type sets of the two players be given by Θ1 = Θ2 = {20, 60}. Each agent eitherhas a low willingness to pay, 20, or a high willingness to pay, 60. Let the set of projectchoices be K = {0, 1}, with 1 indicating that the project is taken up and 0 indicating thatthe project is dropped.Assume that if k = 1, then the two agents will equally share the cost of the projectby paying 25 each. If k = 0, the project is not taken up and agents do not pay anything.Consider the valuation function:vi (k, θi ) = k(θi − 25).This means, if k = 0, the agents derive zero value while if k = 1, the value derived is thewillingness to pay minus 25. Define the following allocation function:k(θ1 , θ2 ) = 0 if θ1 = θ2 = 20= 1 otherwise.This means, the project is taken up only when at least one of the agents has a high willingnessto pay. We can see that this function is allocatively efficient.\n(θ1 , θ2 )\nk\nv1 (k, θ1 )when k = 0\nv2 (k, θ2 )when k = 0\nv1 (k, θ1 )when k = 1\nv2 (k, θ2 )when k = 1\n(20, 20)(20, 60)(60, 20)\n011\n000\n000\n-5-535\n-535-5\n(60, 60)\n1\n0\n0\n35\n35\nTable 18.1: Values for different type profiles when vi (k, θi ) = k(θi − 25)\nThis may be easily inferred from Table 18.1, which shows the values derived by theagents for different type profiles. The second column gives the actual value of k.\u0003\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n270\nbook\nGame Theory and Mechanism Design\nExample 18.2 (A Non-Allocatively Efficient SCF). Let the v function be defined as under:vi (k, θi ) = kθi\ni = 1, 2.\nWith respect to the above function, the allocation function k defined in Example 18.1 isnot allocatively efficient. The values for different type profiles are shown in Table 18.2. If\n(θ1 , θ2 )\nk\nv1 (k, θ1 )when k = 0\nv2 (k, θ2 )when k = 0\nv1 (k, θ1 )when k = 1\nv2 (k, θ2 )when k = 1\n(20, 20)(20, 60)(60, 20)\n011\n000\n000\n202060\n206020\n(60, 60)\n1\n0\n0\n60\n60\nTable 18.2: Values for different type profiles when vi (k, θi ) = kθi\nthe type profile is (20, 20), the allocation is k = 0 and the total value of allocation is 0.However, the total value is 40 when the allocation is k = 1. This immediately shows that kis not allocatively efficient.\u0003\nBudget BalanceBudget balance is a property of the payment functions t1 (·), . . . , tn (·) in quasilinearenvironment.Definition 18.2 (Budget Balance (BB)). We say that a social choice functionf (·) = (k(·), t1 (·), . . . , tn (·)) is budget balanced if for each θ ∈ Θ, t1 (θ), . . . , tn (θ)satisfy the following condition:Xti (θ) = 0.(18.1)i∈N\nConventionally, this property is called strong budget balance (SBB), and the propertyof havingXti (θ) ≤ 0i∈N\nis called weak budget balance (WBB). In this book, we will use the term budgetbalance (BB) to refer to strong budget balance.Budget balance ensures that the total receipts are equal to total payments. Thismeans that the system is a closed one, with no surplus and no deficit. The weakbudget balance property means that the total payments are greater than or equalto total receipts. Suppose we have a bilateral trading system where there is a setof sellers and a set of buyers who are exchanging objects with monetary transfers.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nVickrey-Clarke-Groves (VCG) Mechanisms\nbook\n271\nSuppose ti (θ) is the payment received by agent i (i = 1, 2, . . . , n) when the typeprofile is θ. There are three possibilities here.Strictly Budget BalancedThis corresponds to the case when the sum of all monetary transfers of all agentsin all type profiles is equal to zero. This means the sum total of payments madeby the agents is equal to the sum total of payments received by the agents. Thisis a happy situation because monetary transfers happen in such a way that thereis no surplus or deficit. Such a trading institution can run by itself (in fact in acompletely decentralized way).Weakly Budget BalancedThis corresponds to the case when the sum of all monetary transfers of all agentsin all type profiles is less than or equal to zero. This means that the sum totalof payments made by the agents is at least as high as the sum total of paymentsreceived and there is a surplus. This surplus could be consumed by the marketmaker or the broker who runs the trading institution.Not Budget BalancedHere it will happen that in at least one type profile, the sum total of payments madeby the agents is strictly less than the sum total of payments received by the agents,so there is a deficit of money. In this situation, in order to maintain budget balance,there must be an outside agency supplying the deficit. This is a situation that wewould like to avoid. In general, the budget balance property has to be carefullyinterpreted in the context of the specific institutional framework being studied.Note. In this chapter, we assume that the set of feasible outcomes is given by()XX = (k, t1 , . . . , tn ) : k ∈ K; ti ∈ R; ∀i ∈ N ;ti ≤ 0 .i∈N\nAs a consequence of this, all social choice functions discussed in this chapter areWBB by design. In the next chapter, we will be discussing a broader class of socialchoice functions that may or may not be WBB.\nImportant Consequences of QuasilinearityWe now prove the following two consequences of quasilinearity:• No social choice function in quasilinear environment is dictatorial.• In quasilinear environment, ex-post efficiency is equivalent to allocative efficiencytogether with budget balance.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n272\nGame Theory and Mechanism Design\nThe first lemma summarizes an important fact about social choice functions inquasilinear environment. This fact enables us to get around the impossible situationcreated by condition (2) of the Gibbard-Satterthwaite theorem (Theorem 17.1).Lemma 18.1. No social choice function with at least two agents in quasilinearenvironment is dictatorial.Proof: Suppose that a social choice function, f (·), is dictatorial in the quasilinearenvironment. This means that there exists a dictator, say d ∈ N , such that for eachθ ∈ Θ, we haveud (f (θ), θd ) ≥ ud (x, θd ) ∀x ∈ X.Since the environment is quasilinear, we haveud (f (θ), θd ) = vd (k(θ), θd ) + td (θ).Since we are currently assuming that a social choice function is WBB (see noteabove), there are only two possibilities given a θ ∈ Θ: Either the sum of paymentsis equal to zero or less than to zero. Consider the following alternative x ∈ X :(PnPti (θ) < 0(k(θ), (ti = ti (θ))i6=d , td = td (θ) − ni=1 ti (θ)) :x=Pi=1n(k(θ), (ti = ti (θ))i6=d,j , td = td (θ) + \u000f, tj = tj (θ) − \u000f) :i=1 ti (θ) = 0where \u000f > 0 is any arbitrary real number, and j is any agent other than d. It iseasy to verify, for the above outcome x, that we have ud (x, θd ) > ud (f (θ), θd ), whichcontradicts the assumption that d is a dictator.\u0004We emphasize that allocative efficiency is a property of the allocation functionwhile budget balance is a property of the payment function. If the environment isquasilinear, these two properties together are equivalent to ex-post efficiency. Thefollowing lemma states this result.Lemma 18.2. A social choice function f (·) = (k(·), t1 (·), . . . , tn (·)) is ex-post efficient in quasilinear environment if and only if it is allocatively efficient and budgetbalanced.Proof: Let us assume that f (·) = (k(·), t1 (·), . . . , tn (·)) is allocatively efficient andbudget balanced. This implies that for any θ ∈ Θ, we havennnXXXti (θ)vi (k(θ), θi ) +ui (f (θ), θi ) =i=1\ni=1\ni=1\n=≥=\nnXi=1nXi=1nXi=1\nvi (k(θ), θi ) + 0vi (k, θi ) +\nnX\nti ; ∀ x = (k, t1 , . . . , tn ) ∈ X\ni=1\nui (x, θi ); ∀ x = (k, t1 , . . . , tn ) ∈ X.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nVickrey-Clarke-Groves (VCG) Mechanisms\nbook\n273\nThat is, if the SCF is allocatively efficient and budget balanced, then for any typeprofile θ of the agent, the outcome chosen by the social choice function will be suchthat it maximizes the total utility derived by all the agents under any allocation.This will automatically imply that the SCF is ex-post efficient (see Proposition16.1).To prove the other direction of the lemma, we proceed in two parts. In the firstpart, we show that if f (·) is not allocatively efficient, then, it cannot be ex-postefficient and in the second part, we will show that if f (·) is not budget balancedthen it cannot be ex-post efficient. These two facts together will imply that if f (·)is ex-post efficient, then it will have to be allocatively efficient and budget balanced,thus completing the proof of the lemma.To prove the first part, let us assume that f (·) is not allocatively efficient. Thismeans that there exists a θ ∈ Θ and a k 0 ∈ K such thatnnXX0vi (k(θ), θi ).vi (k , θi ) >i=1\ni=1\nThis implies that there exists at least one agent j such that vj (k 0 , θi ) > vj (k(θ), θi ).Now consider the following alternative x given by\u0010\nk 0 , (ti = ti (θ) + vi (k(θ), θi ) − vi (k 0 , θi ))i6=j , tj = tj (θ) + vj (k(θ), θj ) − vj (k 0 , θj ) + ε\n\u0011\nwhere ε > 0. It is easy to verify that ui (x, θi ) = ui (f (θ), θi ) ∀ i 6= j and uj (x, θj ) >uj (f (θ), θj ), implying that f (·) is not ex-post efficient.To prove the second part, we assume that f (·) is not budget balanced. Thismeans that there exists at least one agent j such that tj (θ) < 0. Let us consider thefollowing alternative x:\u0010\u0011x = k 0 , (ti = ti (θ))i6=j , tj = tj (θ) + ε .It is easy to verify that for the above alternative x, we haveui (x, θi ) = ui (f (θ), θi ) ∀ i 6= j and uj (x, θj ) > uj (f (θ), θj ),implying that f (·) is not ex-post efficient.\u0004In view of Lemma 18.1, the social planner need not worry about the existence ofa dictator in any social choice function in a quasilinear environment and the plannercan explore whether there exists any SCF that is both EPE and DSIC. Furthermore,in the light of Lemma 18.2, we can say that the social planner can look for an SCFthat is AE, SBB, and DSIC. Once again the question arises whether there couldexist social choice functions which satisfy all these three properties – AE, SBB, andDSIC. We explore this and other questions in the forthcoming sections.\n18.2\nGroves Mechanisms\nThe main result in this section is that in the quasilinear environment, there existsocial choice functions that are both allocatively efficient and dominant strategy\nDecember 27, 2013\n11:21\n27 4\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nincentive compatible. These are in general called the VCG (Vickrey–Clarke–Groves)mechanisms.The VCG mechanisms are named after their famous inventors William Vickrey, Edward Clarke, and Theodore Groves. It was Vickrey who introduced thefamous Vickrey auction (second price sealed bid auction) in 1961 [1]. To this day,the Vickrey auction continues to enjoy a special place in the annals of mechanismdesign. Clarke [2] and Groves [3] came up with a generalization of the Vickreymechanisms and helped define a broad class of dominant strategy incentive compatible mechanisms in the quasilinear environment. VCG mechanisms are by far themost extensively used among quasilinear mechanisms. They derive their popularityfrom their mathematical elegance and the strong properties they satisfy for manypractical settings.The Groves TheoremThe following celebrated result provides a sufficient condition for an allocativelyefficient social choice function in quasilinear environment to be dominant strategyincentive compatible. We will refer to this theorem in the sequel as Groves theorem,rather than Groves’ theorem. The Groves theorem is one of the landmark results inmechanism design theory.\nWilliam Vickrey is the inventor of the famous Vickrey Auction, which is considered a major breakthrough in the designof auctions. He showed that the second price sealed bid auction enjoys the strong property of dominant strategy incentivecompatibility, in his classic paper Counterspeculation, Auctions,and Competitive Sealed Tenders which appeared in the Journalof Finance in 1961. This work demonstrated for the first timethe value of game theory in designing auctions. Apart from thisfamous auction, Vickrey is known for an early version of revenueequivalence theorem, a key result in auction theory.Vickrey is also known for pioneering work in congestion pricing, where he introduced the idea of pricing roads and services as a natural means of regulating heavydemand. His ideas were subsequently put into practice in London city transportation.The Nobel prize in economic sciences in 1996 was jointly won by James A. Mirrleesand William Vickrey for their fundamental contributions to the economic theory ofincentives under asymmetric information. However, just three days before the prizeannouncement, Vickrey passed away on October 11, 1996.Vickrey was born on June 21, 1914 in Victoria, British Columbia. He earned aPh.D. from Columbia University in 1948. His doctoral dissertation titled Agenda forProgressive Taxation is considered a pioneering piece of work. He taught at Columbiafrom 1946 until his retirement in 1982.\nbook\nDecember 27, 2013\n16:19\nWorld Scientific Book - 10.25in x 7.5in\nVickrey-Clarke-Groves (VCG) Mechanisms\nbook\n275\nEdward Clarke distinguished himself as a senior economistwith the Office of Management and Budget (Office of Information and Regulatory Affairs) involved in transportation regulatory affairs. He is a graduate of Princeton University and theUniversity of Chicago, where he received an MBA and a Ph.D.(1978). He has worked in public policy at the city/regional(Chicago), state, federal, and international levels.In public economics, he developed the demand revealing mechanism for publicproject selection, which was noted in the Nobel Committee’s award of the 1996 NobelPrize in Economics to William Vickrey. Clarke’s paper Multi-part Pricing of PublicGoods in the journal Public Choice in 1971 is a classic in mechanism design. AmongVCG mechanisms, Clarke’s mechanism is a natural and popular approach used inmechanism design problems.\nTheodore Groves is credited with the most general among thecelebrated class of VCG mechanisms. In a classic paper entitledIncentives in Teams published in Econometrica in 1973, Grovesproposed a general class of allocatively efficient, dominant strategy incentive compatible mechanisms.The Groves mechanism generalizes the Clarke mechanism (proposed in 1971),which in turn generalizes the Vickrey auction proposed in 1961. Groves earned adoctorate in economics at the University of California, Berkeley, and he is currentlya Professor of Economics at the University of California, San Diego.\nTheorem 18.1 (Groves Theorem). Let the SCF f (·) = (k ∗ (·), t1 (·), . . . , tn (·))be allocatively efficient. Then f (·) is dominant strategy incentive compatible if itsatisfies the following payment structure (the Groves payment (incentive) scheme):Xti (θi , θ−i ) = vj (k ∗ (θ), θj ) + hi (θ−i ) ∀ i = 1, . . . , n(18.2)j6=i\nwhere hi : Θ−i → R is any arbitrary function.Proof: The proof is by contradiction. Suppose f (·) satisfies both allocative efficiency and the Groves payment structure but is not DSIC. This implies that f (·)does not satisfy the following necessary and sufficient condition for DSIC:0\n0\nui (f (θi , θ−i ), θi ) ≥ ui (f (θi , θ−i ), θi ) ∀θi ∈ Θi ∀θ ∈ Θ ∀θ−i ∈ Θ−i ∀i ∈ N.This implies that there exists at least one agent i for which the above is false. Leti be one such agent. That is, for agent i,0\nui (f (θi , θ−i ), θi ) > ui (f (θi , θ−i ), θi )\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n276\nbook\nGame Theory and Mechanism Design0\nfor some θi ∈ Θi , for some θ−i ∈ Θ−i , and for some θi ∈ Θi . Expanding the0expression for ui above, we obtain that, for agent i, there would exist θi ∈ Θi , θi ∈Θi , θ−i ∈ Θ−i such that0\n0\nvi (k ∗ (θi , θ−i ), θi ) + ti (θi , θ−i ) + mi > vi (k ∗ (θi , θ−i ), θi ) + ti (θi , θ−i ) + mi .Recall the Groves payment structure:Xti (θi , θ−i ) = vj (k ∗ (θi , θ−i ), θj ) + hi (θ−i )j6=i\nX0ti (θi , θ−i ) = vj (k ∗ (θi , θ−i ), θj ) + hi (θ−i )0\nj6=i\nSubstituting these, we getXX00vi (k ∗ (θi , θ−i ), θi ) +vj (k ∗ (θi , θ−i ), θj ) > vi (k ∗ (θi , θ−i ), θi ) +vj (k ∗ (θi , θ−i ), θj ),j6=i\nj6=i\nwhich impliesnX\n∗\n0\nvi (k (θi , θ−i ), θi ) >\nnX\nvi (k ∗ (θi , θ−i ), θi ).\ni=1\ni=1\nThe above contradicts the fact that f (·) is allocatively efficient. This completes theproof.\u0004The following are a few immediate and interesting implications of the above theorem.Note. Given the announcements θ−i of agents j 6= i, the monetary transfer to agenti depends on his announced type only through the project choice k ∗ (θi , θ−i ).Note. The change in the monetary transfer of agent i when his type changes fromθi to θi0 is equal to the effect that the corresponding change in project choice has ontotal value of the rest of the agents. That is,X\u0002\u0003ti (θi , θ−i ) − ti (θi0 , θ−i ) =vj (k ∗ (θi , θ−i ), θj ) − vj (k ∗ (θi0 , θ−i ), θj ) .j6=i\nAnother way of describing this is to say that the change in monetary transfer toagent i reflects exactly the externality he is imposing on the other agents.After the famous result of Groves, a direct revelation mechanism in which theimplemented SCF is allocatively efficient and satisfies the Groves payment schemeis called a Groves Mechanism.Definition 18.3 (Groves Mechanisms). A direct revelation mechanism, D =((Θi )i∈N , f (·)) in which f (·) = (k(·), t1 (·), . . . , tn (·)) satisfies allocative efficiency(18.1) and Groves payment rule (18.2) is known as a Groves mechanism.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nVickrey-Clarke-Groves (VCG) Mechanisms\nbook\n277\nIn mechanism design parlance, Groves mechanisms are often referred to as Vickrey–Clarke–Groves (VCG) mechanisms because the Clarke mechanism is a special caseof the Groves mechanism, and the Vickrey mechanism is a special case of the Clarkemechanism. We will discuss this relationship later in this chapter.The Groves theorem provides a sufficiency condition under which an allocativelyefficient SCF will be DSIC. The following theorem due to Green and Laffont [4]provides a set of conditions under which the condition of Groves Theorem alsobecomes a necessary condition for an allocatively efficient SCF to be DSIC. In thistheorem, we let F denote the set of all possible functions f : K → R.Theorem 18.2 (First Characterization Theorem of Green–Laffont).Suppose for each agent i ∈ N that {vi (., θi ) : θi ∈ Θi } = F , that is, every possible valuation function from K to R arises for some θi ∈ Θi . Then any allocativelyefficient social choice function f (·) will be dominant strategy incentive compatible ifand only if it satisfies the Groves payment scheme given by Equation (18.2).Note that in the above theorem, every possible valuation function from K to R arisesfor each θi ∈ Θi . In the following characterization theorem, again due to Green andLaffont [4], F is replaced with Fc where Fc denotes the set of all possible continuousfunctions f : K → R.Theorem 18.3 (Second Characterization Theorem of Green–Laffont).Suppose for each agent i ∈ N that {vi (., θi ) : θi ∈ Θi } = Fc , that is, every possible continuous valuation function from K to R arises for some θi ∈ Θi . Then anyallocatively efficient social choice function f (·) will be dominant strategy incentivecompatible if and only if it satisfies the Groves payment scheme given by Equation(18.2).\n18.3\nClarke (Pivotal) Mechanisms\nGroves mechanisms were reported in 1973 [3]. A special class of Groves mechanismswas developed earlier by Clarke in 1971 [2] and these are known as the Clarkemechanisms, or the pivotal mechanisms. The Clarke mechanism is a special case ofthe Groves mechanism in the sense of using a natural special form for the functionhi (·). In the Clarke mechanism, the function hi (·) is given by the following relation:X∗hi (θ−i ) = −vj (k−i(θ−i ), θj ) ∀ θ−i ∈ Θ−i , ∀ i = 1, . . . , n(18.3)j6=i∗ (θ ) ∈ Kwhere k−i−i−i is a project choice that is allocatively efficient if the system consisted of all agents other than agent i. The set K−i above is the set of∗ (θ ) must satisfy theproject choices available when agent i is absent. Formally, k−i−i\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n278\nbook\nGame Theory and Mechanism Design\nfollowing condition.X\n∗vj (k−i(θ−i ), θj ) ≥\nj6=i\nX\nvj (k, θj ) ∀k ∈ K−i\n(18.4)\nj6=i\nSubstituting the value of hi (·) from Equation (18.3) in Equation (18.2), we get thefollowing expression for agent i’s monetary transfer in the Clarke mechanism: XX∗ti (θ) = vj (k ∗ (θ), θj ) − vj (k−i(θ−i ), θj ) ∀i = 1, . . . , n.(18.5)j6=i\nj6=i\nThe above payment rule has an appealing interpretation: Given a type profile θ =(θ1 , . . . , θn ), the monetary transfer to agent i is given by the total value of all agentsother than i under an efficient allocation when agent i is present in the system minusthe total value of all agents other than i under an efficient allocation when agent iis absent in the system. Another appealing interpretation of Clarke’s payment rulecan be derived as follows. We can writeXX∗ti (θi , θ−i ) =vj (k ∗ (θ), θj ) − vi (k ∗ (θ), θi ) −vj (k−i(θ−i ), θj )j6=i\nj∈N\n=\nXj∈N\n∗\nvj (k (θ), θj ) −\nX\n∗vj (k−i(θ−i ), θj ) − vi (k ∗ (θ), θi ).\nj6=i\nThe difference in the first two terms represents the marginal contribution of agenti to the system. Thus the Clarke mechanism gives an additional incentive to everyallocated agent, namely that agent’s marginal contribution to the mechanism. Thisadditional incentive is key to inducing truth from the agents (in a dominant strategysense).The Clarke mechanism is also known as the pivotal mechanism since each allocated agent plays a pivotal role in deciding the value received by the other agentsdue to his presence in the society of players.18.4\nExamples of VCG Mechanisms\nVCG mechanisms derive their popularity on account of the elegant mathematicaland economic properties that they have and the rich first level insights they provide during the process of designing mechanisms for a mechanism design problem.For this reason, invariably, the first choice of mechanisms for mechanism designresearchers are always VCG mechanisms. However, VCG mechanisms do havemany limitations. The virtues and limitations of VCG mechanisms are capturedby Ausubel and Milgrom [5], whereas a recent paper by Rothkopf [6] summarizesthe practical limitations of applying VCG mechanisms. In this section, we providea number of examples to illustrate some interesting nuances of VCG mechanisms.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nVickrey-Clarke-Groves (VCG) Mechanisms\nbook\n279\nExample 18.3 (Vickrey Auction for a Single Indivisible Item). Consider 5bidders {1, 2, 3, 4, 5}, with valuations v1 = 20; v2 = 15; v3 = 12; v4 = 10; v5 = 6, participating in a sealed bid auction for a single indivisible item. If Vickrey auction is themechanism used, then a dominant strategy for the agents is to bid their valuations. Agent1 with valuation 20 will be the winner, and the monetary transfer to agent 1XX∗=vj (k ∗ (θ), θj ) −vj (k−1(θ−1 ), θj )j6=1\nj6=1\n= 0 − 15 = −15.This means agent 1 would pay an amount equal to 15, which happens to be the secondhighest bid (in this case the second highest valuation). Note that 15 is the change in thetotal value of agents other than agent 1 when agent 1 drops out of the system. This is theexternality that agent 1 imposes on the rest of the agents. This externality becomes thepayment of agent 1 when he wins the auction.Another way of determining the payment by agent 1 is to compute his marginal contribution to the system (refer to the discussion in the previous section). The total value inthe presence of agent 1 is 20, while the total value in the absence of agent 1 is 15. Thusthe marginal contribution of agent 1 is 5. The above marginal contribution is given as adiscount to agent 1 by the Vickrey payment mechanism, and agent 1 pays 20 − 5 = 15. Sucha discount is known as the Vickrey discount.\u0003\nExample 18.4 (Vickrey Auction for Multiple Identical Items). Considerthe same set of bidders as above but with the difference that there are 3 identical itemsavailable for auction. Each bidder wants only one item. If we apply the Clarke mechanismfor this situation, bidders 1, 2, and 3 become the winners. The payment by bidder 1XX∗=vj (k ∗ (θ), θj ) −vj (k−1(θ−1 ), θj )j6=1\nj6=1\n= (15 + 12) − (15 + 12 + 10)= −10.Thus bidder 1 pays an amount equal to the highest non-winning bid. Similarly, one canverify that the payment to be made by the other two winners (namely agent 2 and agent 3)is also equal to 10. This payment is consistent with their respective marginal contributions.Marginal contribution of agent 1 = (20 + 15 + 12) − (15 + 12 + 10) = 10Marginal contribution of agent 2 = (20 + 15 + 12) − (20 + 12 + 10) = 5Marginal contribution of agent 3 = (20 + 15 + 12) − (20 + 15 + 10) = 2.In the above example, let the demand by agent 1 be 2 units with the rest of agents continuingto have unit demand. Now the allocation will allocate 2 units to agent 1 and 1 unit to agent2.Payment by agent 1 = 15 − (15 + 12 + 10) = −22Payment by agent 2 = 40 − (40 + 12) = −12.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n280\nbook\nGame Theory and Mechanism Design\nThis is because the marginal contribution of agent 1 and agent 2 are given by: agent 1:55 − 37 = 18; agent 2: 55 − 52 = 3.\u0003\nExample 18.5 (A VCG Mechanism for the Public Project Problem).Consider the public project problem discussed in Example 18.1. We shall compute theClarke payments by each agent for each type of profile. We will also compute the utilities.First consider the type profile (20, 20). Since k(20, 20) = 0, the values derived by eitheragent is zero. Hence the Clarke payment by each agent is zero, and the utilities are alsozero.Next consider the type profile (60, 20). Note that k(60, 20) = 1. Agent 1 derives a value35 and agent 2 derives a value −5. If agent 1 is not present, then agent 2 is left alone andthe allocation will be 0 since its willingness to pay is 20. Thus the value to agent 2 whenagent 1 is not present is 0. This meanst1 (60, 20) = −5 − 0 = −5.This implies agent 1 would pay an amount 5 in addition to 25, which is its contribution tothe cost of the project. The above payment is consistent with the marginal contribution ofagent 1, which is equal to (60 − 25) + (20 − 25) − 0 = 35 − 5 = 30.We can now determine the utility of agent 1, which will beu1 (60, 20) = v1 (60, 20) + t1 (60, 20) = 35 − 5 = 30.To compute t2 (60, 20), we first note that the value to the agent 1 when agent 2 is not presentis (60 − 50). Thereforet2 (60, 20) = 35 − 10 = 25.This means agent 2 receives 25; of course, this is besides the amount of 25 it pays towardsthe cost of the project. Nowu2 (60, 20) = v2 (60, 20) + t2 (60, 20) = −5 + 25 = 20.\n(θ1 , θ2 )(20, 20)\nt1 (θ1 , θ2 )0\nt2 (θ1 , θ2 )0\nu1 (θ1 , θ2 )0\nu2 (θ1 , θ2 )0\n(60, 20)(20, 60)(60, 60)\n-52525\n25-525\n302060\n203060\nTable 18.3: Payments and utilities for different type profiles\nLikewise, we can compute the payments and utilities of the agents for all the type profiles.Table 18.3 provides these values.\u0003\nExample 18.6 (Strategy Proof Network Formation). Consider the problem offorming a supply chain as depicted in Figure 18.1. The node S represents a starting state\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nbook\nVickrey-Clarke-Groves (VCG) Mechanisms\n281\nand T represents a target state; A and B are two intermediate states. SP1 , SP2 , SP3 , SP4are four different service providers. In the figure, the service providers are represented asASP210\nSP110S\nTSP4\nSP3\n20\n5B\nFig. 18.1: A network formation problem - case 1owners of the respective edges. The cost of providing service (willingness to sell) is indicatedon each edge. The problem is to procure a path from S to T having minimum cost. Let(y1 , y2 , y3 , y4 ) represent the allocation vector. The feasible allocation vectors areK = {(1, 1, 0, 0), (0, 0, 1, 1)}.Among these, the allocation (1, 1, 0, 0) is allocatively efficient since it minimizes the cost ofallocation. We shall define the value as follows:vi ((y1 , y2 , y3 , y4 ); θi ) = −yi θi .The above manner of defining the values reflects the fact that cost minimization is the sameas value maximization. Applying Clarke’s payment rule, we obtaint1 (θ) = −10 − (−25) = 15t2 (θ) = −10 − (−25) = 15.If we compute the marginal contributions, we find that each of the agents makes a marginalcontribution of 5 which is added to the value in deciding the payment. The utilities forthese two agents areu1 (θ) = −10 + 15 = 5u2 (θ) = −10 + 15 = 5.The payments and utilities for SP3 and SP4 are zero. Let us study the effect of changingthe willingness to sell of SP4 . Let us make it as 15. Then, we find that both the allocations(1, 1, 0, 0) and (0, 0, 1, 1) are allocatively efficient. If we choose the allocation (1, 1, 0, 0), weget the payments ast1 (θ) = 10; t2 (θ) = 10; u1 (θ) = 0; u2 (θ) = 0.This means that the payments to the service providers are equal to the costs. There is nosurplus payment to the winning agents. In this case, the mechanism is friendly to the buyerand unfriendly to the sellers.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n282\nbook\nGame Theory and Mechanism Design\nIf we make the willingness to sell of SP4 as 95, the allocation (1, 1, 0, 0) is efficient andwe get the payments ast1 (θ) = 90; t2 (θ) = 90; u1 (θ) = 80; u2 (θ) = 80.In this case, the mechanism is extremely unfriendly to the buyer but is very attractive tothe sellers.Let us introduce one more edge from B to A corresponding to a new service providerSP5 and see the effect. See Figure 18.2.ASP210\nSP110SP52\nS\nTSP4\nSP3\n15\n5B\nFig. 18.2: A network formation problem - case 2The efficient allocation here is (0, 1, 1, 0, 1). The payments aret2 (θ) = 13; t3 (θ) = 8; t5 (θ) = 5; u2 (θ) = 3; u3 (θ) = 3; u5 (θ) = 3.This shows that the total payments to be made by the buyer is 26 whereas the total paymentif the service provider SP5 were absent is 20. Thus in spite of an additional agent beingavailable, the payment to the buyer is higher. This shows a kind of non-monotonicityexhibited by the Clarke payment rule.\u0003\nThe above examples have illustrated many characteristic features of VCG mechanisms when applied to practical problems of interest.18.5\nSummary and References\nVickrey-Clarke-Groves mechanisms represent a prominent class of mechanisms inthe quasilinear environment satisfying DSIC and AE. The salient points discussedin this chapter include the following.• In the quasilinear setting, each outcome of a given social choice function can bedecomposed into an allocation part and a payment part. The utilities dependlinearly on the values and the payments where the values are (possibly nonlinear) functions of the allocation and the private types.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nVickrey-Clarke-Groves (VCG) Mechanisms\nbook\n283\n• A remarkable property satisfied SCFs in quasilinear environment is that theyare non-dictatorial. Another elegant property is that ex-post efficiency is thesame as allocative efficiency plus strict budget balance. Allocative efficiencymeans that in every outcome, the sum of the values of the allocation (socialwelfare of the allocation) is maximized. Strict budget balance means that inevery outcome, the sum total of payments by the agents is equal to the sumtotal of receipts by the agents.• The Vickrey auction mechanism is a special case of the Clarke mechanism whichin turn is a special case of the Groves mechanism. The Groves theorem statesthat an allocatively efficient SCF with Groves payment structure will satisfy theextremely desirable DSIC property. The Groves payment formula is based onthe principle that the monetary transfer to an agent could depend on the typesof the other agents in an arbitrary way but should depend on the type of theagent only through the effect of its type on the allocation.• The Clarke mechanism can be derived as a special case of the Groves mechanismby requiring that the payment is decided by the values of the rest of the agentswhen the agent is dropped from the game. The Clarke mechanism proves thatthe agents report truthfully when their respective marginal contributions areoffered to them as additional incentives.• The Vickrey auction is essentially the Clarke mechanism applied to auctioningmultiple units of a single type of item. When the Clarke mechanism is applied toa combinatorial auction (to be introduced in Chapter 20), we call the mechanisma generalized Vickrey auction (GVA).The Vickrey auction is the pioneering contribution of William Vickrey [1] while thecelebrated pivotal mechanism was developed by Clarke [2] and a generalization ofClarke’s mechanisms were developed by Groves [3]. The original papers written bythese celebrities are a must-read for mechanism design students.\nReferences[1][2][3][4][5]\n[6]\nWilliam Vickrey. “Counterspeculation, auctions, and competitive sealed tenders”. In: Journalof Finance 16(1) (1961), pp. 8–37.E. Clarke. “Multi-part pricing of public goods”. In: Public Choice 11 (1971), pp. 17–23.T. Groves. “Incentives in teams”. In: Econometrica 41 (1973), pp. 617–631.J.R. Green and J.J. Laffont. Incentives in Public Decision Making. North-Holland, Amsterdam, 1979.L.M. Ausubel and P. Milgrom. “The lovely but lonely Vickrey auction”. In: CombinatorialAuctions. Ed. by P. Cramton, Y. Shoham, and R. Steinberg. The MIT Press, Cambridge,Massachusetts, 2006, pp. 17–40.M. Rothkopf. “Thirteen reasons why the Vickrey-Clarke-Groves process is not practical”. In:Operations Research 55(2) (2007), pp. 191–197.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n284\nGame Theory and Mechanism Design\n18.6\nExercises\n(1) Consider five selling agents {1, 2, 3, 4, 5}, with valuations v1 = 20; v2 = 15; v3 =12; v4 = 10; v5 = 6, participating in a sealed bid procurement auction for asingle indivisible item. These valuations are to be viewed as the willingnessto sell values of the bidders. If Vickrey auction is the mechanism used, thencompute the allocation and payment. If the buyer wishes to procure threeobjects instead of one object, and each bidder can supply at most one object,then compute the allocation and payments. Finally, if the buyer wishes to buy6 objects and each bidder is willing to supply up to two objects, compute theallocation and payments.(2) Consider an exchange where a single unit of an item is traded. There are 4sellers S1, S2, S3, S4 and 3 buyers B1, B2, and B3. Here are the bids fromthe buyers and the asks from the sellers for the single item. The objective is tomaximize the surplus in the exchange.S1: 10B1: 8\nS2: 12B2: 12\nS3: 14B3: 18\nS4: 16\n(a) Define the surplus of the exchange as the total amount of money paid bythe buyers minus the total amount of money received by the sellers. Call anallocation surplus maximizing if it maximizes the surplus of the exchange. Finda surplus maximizing allocation for this exchange. (b) Assuming that Vickreypricing is used, what will be the payment? (c) Will the mechanism satisfy budgetbalance?(3) Consider a forward auction for sale of m identical objects. Let there be nbidders where n > m. The valuations of the bidders for the object are v1 , . . .,vn , respectively. Each bidder is interested in at most one unit. For this auctionscenario, write down an allocation rule that is allocatively efficient. What willbe the Clarke payment in this case? Do you see any difficulty? How can youovercome the difficulty, if any?(4) Consider an auction for selling a single indivisible item where the bidder withthe highest bid is declared as the winner and the winner pays an amount equalto twice the bid of the bidder with the lowest valuation among the rest of theagents. As an example consider 5 bidders with valuations 20, 15, 12, 10, 8. Thebidder with valuation 20 is declared the winner and will pay an amount = 16.On the other hand, if there are only three bidders with values 20, 15, 12, thefirst bidder wins but has to pay 24. Is this mechanism a Clarke mechanism? Isthe mechanism a Groves mechanism? Is the mechanism incentive compatible?(5) Programming Assignment. Implement the Clarke mechanism. Identify theinputs to this program carefully. The output must be an efficient allocation anda payment vector for any given type profile. The implementation can also begeneralized to Groves mechanisms.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nChapter 19\nMechanism Design Space in QuasilinearEnvironment\nWe have seen that mechanism design is concerned with design of institutions orprotocols which minimize the economic losses arising from private information andself-interest. The trade-offs involved in designing mechanisms with desirable properties such as incentive compatibility, allocative efficiency, and budget balance arequite complex and there is a sea of literature comprising possibility results andimpossibility theorems. In this chapter, we study some of these tradeoffs. Weintroduce an important mechanism called the dAGVA mechanism which achievesallocative efficiency as well as strict budget balance, by relaxing DSIC to BIC.We also introduce another important property, namely, individual rationality (alsoknown as voluntary participation ) and study additional tradeoffs that arise dueto this property. Our discussion assumes quasilinear preferences. Towards the endof this chapter, we discuss a special case of the quasilinear environment called thelinear environment. For this special environment, we present a characterizationdeveloped by Myerson for BIC social choice functions.\n19.1\nGroves Mechanisms and Strict Budget Balance\nIn Chapter 18, we implicitly assumed that weak budget balance property is satisfiedby all the mechanisms discussed in that chapter. In general, however, it is not true.Note that a Groves mechanism, which we discussed at length in the previous chapter,always satisfies the properties of AE and DSIC. Therefore, if a Groves mechanism isstrictly budget balanced, then it will solve the problem of the social planner becauseit will then be ex-post efficient and dominant strategy incentive compatible. Bylooking at the definition of the Groves mechanism, one can conclude that it is thefunctions hi (·) for i = 1, . . . , n that decide whether or not the Groves mechanism isbudget balanced. The natural question that arises now is whether there exists a wayof defining functions hi (·) for i = 1, . . . , n such that the Groves mechanism is budgetbalanced. In what follows, we first present the Green-Laffont theorem which assertsthat Groves mechanisms cannot be strictly budget balanced in a general setting.Next, we show that there is a practically relevant special setting in which Grovesmechanisms can be made strictly budget balanced.285\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n286\nbook\nGame Theory and Mechanism Design\nPossibility and Impossibility Results for Budget BalanceGreen and Laffont [1] showed that in a quasilinear environment, if the set of possibletypes for each agent is sufficiently rich then ex-post efficiency and DSIC cannot beachieved together. The precise statement is given in the form of the followingtheorem. Recall the notation F which denotes the set of of all functions from theset K of project choices to R.Theorem 19.1 (Green–Laffont Impossibility Theorem). Suppose for eachagent i ∈ N that F = {vi (., θi ) : θi ∈ Θi }, that is, every possible valuation function from K to R arises for some θi ∈ Θi . Then there is no social choice functionthat is ex-post efficient and DSIC.Thus, the above theorem says that if the set of possible types for each agent issufficiently rich, then there is no hope of finding a way to define the functions hi (·)Pin Groves payment scheme such that we have ni=1 ti (θ) = 0. However, one specialcase in which a positive result arises is summarized in the form of the followingpossibility result.Theorem 19.2 (Budget Balance of Groves Mechanisms). If there is at leastone agent whose preferences are known (that is, the type set is a singleton) then itPis possible to choose the functions hi (·) so that ni=1 ti (θ) = 0.Proof: Let agent i be such that his preferences are known, that is Θi = {θi }. Inview of this condition, it is easy to see that for an allocatively efficient social choicefunction f (·) = (k ∗ (·), t1 (·), . . . , tn (·)), the allocation k ∗ (·) depends only on the typesof the agents other than i. That is, the allocation k ∗ (·) is a mapping from Θ−i toK. Let us define the functions hj (·) in the following manner:(hj (θ−j ) =\n−\nP\nr6=i hr (θ−r ) − (n − 1)\nhj (θ−j )∗r=1 vr (k (θ), θr )\nPn\n: j 6= i: j = i.\nIt is easy to see that under the above definition of the functions hi (·), we will havePti (θ) = − j6=i tj (θ) and therefore strict budget balance is achieved.\u000419.2\nClarke Mechanisms and Weak Budget Balance\nRecall from the definition of Groves mechanisms that, for weak budget balance, weshould choose the functions hi (θ−i ) for i = 1, . . . , n in a way that the weak budgetPbalance condition ni=1 ti (θ) ≤ 0 is satisfied. In this sense, the Clarke mechanismis a useful special case because it achieves weak budget balance under fairly generalsettings. In order to understand these general sufficiency conditions, we define the\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nMechanism Design Space in Quasilinear Environment\nbook\n287\nfollowing quantities:nX∗B (θ) = k ∈ K : k ∈ arg maxvj (k, θj )k∈Kj=1XB ∗ (θ−i ) = k ∈ K−i : k ∈ arg maxvj (k, θj ) .k∈K−ij6=i\nIn the above, B ∗ (θ) is the set of project choices that are allocatively efficient whenall the agents are present in the system. Similarly, B ∗ (θ−i ) is the set of projectchoices that are allocatively efficient if all agents except agent i were present in thesystem.Using the above quantities, we define the following property of a direct revelationmechanism in quasilinear environment.Definition 19.1 (No Single Agent Effect). We say that mechanism M has nosingle agent effect if for each agent i, for each θ ∈ Θ, and for each k ∗ (θ) ∈ B ∗ (θ),we have a k ∈ K−i such thatXXvj (k, θj ) ≥vj (k ∗ (θ), θj ).j6=i\nj6=i\nThe above property means that there would not exist an agent i such that the sumof values of all agents other than i under an AE allocation in the presence of agenti is strictly greater than the sum of values of all agents other than i under an AEallocation in the absence of agent i. Such an agent, if one exists, essentially weakensthe other agents by its absence.We now state and prove the following proposition that gives a sufficiency condition for Clarke mechanism to be weakly budget balanced.Proposition 19.1. If the Clarke mechanism has no single agent effect, then themonetary transfer to each agent would be non-positive, that is, ti (θ) ≤ 0 ∀θ ∈Θ; ∀i = 1, . . . , n. In such a situation, the Clarke mechanism would satisfy the weakbudget balance property.Proof: Note that by virtue of no single agent effect, for each agent i, each θ ∈ Θ,and each k ∗ (θ) ∈ B ∗ (θ), there exists a k ∈ K−i such thatXXvj (k, θj ) ≥vj (k ∗ (θ), θj ).j6=ij6=i∗However, by definition of k−i (θ−i ), given by Equation (18.4), we have\nX\n∗vj (k−i(θ−i ), θj ) ≥\nj6=i\nX\nvj (k, θj ) ∀k ∈ K−i .\nj6=i\nCombining the above two facts, we getXX∗vj (k ∗ (θ), θj ) −vj (k−i(θ−i ), θj ) ≤ 0 ∀i ∈ Nj6=i\nj6=i\nDecember 27, 2013\n11:21\n288\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nThat is, ti (θ) ≤ 0 ∀i ∈ N . This immediately impliesnX\nti (θ) ≤ 0.\ni=1\nThis shows that the the Clarke mechanism is weakly budget balanced when thereis no single agent effect.\u0004Redistribution MechanismsThese are Groves mechanisms which are weakly budget balanced and in additionthey try to minimize the budget imbalance while preserving the AE and DSICproperties. Here the idea is to start with a Clarke mechanism which clearly includesan allocation that is AE and payments are determined using the Clarke paymentrule. The payments are then redistributed among the agents in such a way thatthe budget imbalance is reduced without sacrificing either AE or DSIC. This is animportant class of mechanisms called redistribution mechanisms. Examples of thesemechanisms may be found in [2, 3, 4, 5].19.3\nIndividual Rationality\nIndividual rationality is also often referred to as voluntary participation property.Individual rationality of a social choice function essentially means that each agentgains a utility that is no less than he would get without participating in a mechanism that implements the social choice function. There are three stages at whichindividual rationality constraints (also called participation constraints) may be relevant in a mechanism design situation. Suppose ui (θi ) denotes the utility that agenti receives by withdrawing from the mechanism when his type is θi .Ex-Post Individual RationalityThese constraints become relevant when any agent i is given a choice to withdrawfrom the mechanism at the ex-post stage, that is, after all the agents have announcedtheir types and an outcome in X has been chosen. Then, to ensure agent i’s participation, we must satisfy the following ex-post participation (or individual rationality)constraintsui (f (θi , θ−i ), θi ) ≥ ui (θi ) ∀ (θi , θ−i ) ∈ Θ.Interim Individual RationalityLet the agent i be allowed to withdraw from the mechanism at the interim stagethat arises after the agents have learned their type but before they have chosentheir actions in the mechanism. In such a situation, the agent i will participate\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nMechanism Design Space in Quasilinear Environment\nbook\n289\nin the mechanism only if his interim expected utility Eθ−i [ui (f (θi , θ−i ), θi )|θi ] fromsocial choice function f (·), when his type is θi , is at least ui (θi ). Thus, interimparticipation (or individual rationality) constraints for agent i require thatEθ−i [ui (f (θi , θ−i ), θi )|θi ] ≥ ui (θi ) ∀ θi ∈ Θi .Ex-Ante Individual RationalityLet agent i be allowed to withdraw from participation in a mechanism even at exante stage, that is, before the agents learn their type. In such a situation, the agenti will participate voluntarily in the mechanism only if his ex-ante expected utilityEθ [ui (f (θi , θ−i ), θi )] from social choice function f (·) is at least Eθi [ui (θi )]. Note thatEθ indicates that the expectation is taken by an agent not only over the types of theother agents but also over his own types. Thus, ex-ante participation (or individualrationality) constraints for agent i require thatEθ [ui (f (θi , θ−i ), θi )] ≥ Eθi [ui (θi )].The following proposition establishes a relationship among the three different participation constraints discussed above. The proof is straightforward and is left asan exercise.Proposition 19.2. For any social choice function f (·), we havef (·) is ex-post IR =⇒ f (·) is interim IR =⇒ f (·) is ex-ante IR.19.4\nVCG Mechanisms and Individual Rationality\nWe motivate the importance of the individual rationality property through an example.Example 19.1 (Public Project Problem). Consider the public project problemwithN = {1, 2}; K = {0, 1}; Θ1 = Θ2 = {20, 60}.Further assume that the cost of the project is 50, so that the set of feasible outcomes is:X = {(k, t1 , t2 ) : k ∈ {0, 1}; t1 , t2 ∈ R; −(t1 + t2 ) ≤ 50}Consider the following allocation function:k ∗ (θ1 , θ2 ) = 0 if θ1 = θ2 = 20= 1 otherwise.Define the valuation function as:vi (k ∗ (θ1 , θ2 ), θi ) = k ∗ (θ1 , θ2 )(θi − 25) ∀θ1 ∈ Θ1 ; ∀θ2 ∈ Θ2\nDecember 27, 2013\n11:21\n290\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nWe have already shown in Chapter 18 that the above allocation function is allocativelyefficient. Therefore we can use the Groves payment rule and make the following socialchoice function DSIC:f (θ) = (k ∗ (θ), t1 (θ), t2 (θ)),where t1 (θ) and t2 (θ) satisfy the Groves payment rule. Suppose the above mechanism isex-post individually rational with ui (θi ) = 0 ∀ θi ∈ Θi ; i = 1, 2. This meansui (f (θ1 , θ2 ), θi ) ≥ 0 ∀θ1 ∈ Θ1 ; θ2 ∈ Θ2In particular, we have u1 (f (20, 60), 20) ≥ 0 which is equivalent to:v1 (k ∗ (20, 60), 20) + t1 (20, 60) ≥ 0Since v1 (k ∗ (20, 60), 20) = −5, we get −t1 (20, 60) ≤ −5. Now consider t1 (60, 60). Since thesocial choice function is DSIC, we haveu1 (f (60, 60), 60) ≥ u1 (f (20, 60), 60)which impliesv1 (k ∗ (60, 60), 60) + t1 (60, 60) ≥ v1 (k ∗ (20, 60), 60) + t1 (20, 60)Since v1 (k ∗ (60, 60), 60) = 35 and v1 (k ∗ (20, 60), 60) = 35, the above implies that−t1 (60, 60) ≤ −5. Similarly by symmetry, we have −t2 (60, 60) ≤ −5, which means−t1 (60, 60) − t2 (60, 60) ≤ −10The above shows that the sum total of payments made by the agents is less than or equal to−10 and since the project cost is 50, the above leads to an infeasible outcome. We arrived atthis based on our assumption that the social choice function is ex-post individually rational.Therefore the above mechanism does not satisfy individual rationality. This clearly meansthat the agents, of their own accord, will not participate voluntarily in the mechanism. \u0003\nClarke Mechanisms and Individual RationalityThe following proposition investigates the individual rationality of the Clarke mechanism. First, we provide two definitions.Definition 19.2 (Choice Set Monotonicity). We say that a mechanism M ischoice set monotone if the set of feasible outcomes X (weakly) grows as additionalagents are introduced into the system. An implication of this property is K−i ⊆K ∀ i = 1, . . . , n.Intuitively, choice set monotonicity means that as more agents become available,the feasible outcomes progressively become richer.Definition 19.3 (No Negative Externality). Consider a choice set monotonemechanism M . We say that the mechanism M has no negative externality if for\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nMechanism Design Space in Quasilinear Environment\nbook\n291\n∗ (θ ) ∈ B ∗ (θ ), we haveeach agent i, each θ ∈ Θ, and each k−i−i−i∗vi (k−i(θ−i ), θi ) ≥ 0.\nIntuitively, the above property means that every agent has a non-negative value forany project choice that is allocatively efficient in the absence of that agent. That isin the absence of this agent, the rest of the agents will not hurt this agent.We now state and prove a proposition which provides a sufficient condition forthe ex-post individual rationality of the Clarke mechanism. Recall from Section 19.3the notation ui (θi ), which represents the utility that agent i receives by withdrawingfrom the mechanism.Proposition 19.3 (Ex-Post Individual Rationality of Clarke Mechanism).Consider a Clarke mechanism in which(1) ui (θi ) = 0 ∀θi ∈ Θi ; ∀ i = 1, . . . , n,(2) the mechanism satisfies choice set monotonicity property, and(3) the mechanism satisfies no negative externality property.Then the Clarke mechanism is ex-post individual rational.Proof: Recall that utility ui (f (θ), θi ) of an agent i in Clarke mechanism is given by XX∗ui (f (θ), θi ) = vi (k ∗ (θ), θi ) + vj (k ∗ (θ), θj ) − vj (k−i(θ−i ), θj )j6=i\nj6=i\n XX∗vj (k ∗ (θ), θj ) − =vj (k−i(θ−i ), θj ) .j6=i\nj\n∗ (θ ) ∈ K. Therefore, weBy virtue of choice set monotonicity, we know that k−i−ihave XX∗∗vj (k−i(θ−i ), θj ) − ui (f (θ), θi ) ≥ vj (k−i(θ−i ), θj )j\nj6=i\n∗= vi (k−i(θ−i ), θi )\n≥ 0 = ui (θi ).The last step follows since the mechanism has no negative externality.\n\u0004\nExample 19.2 (Individual Rationality in Sealed Bid Auctions). Let us consider the example of first-price sealed bid auction. If for each possible type θi , the utilityui (θi ) derived by the agents i from not participating in the auction is 0, then it is easy tosee that the SCF would be ex-post IR.Let us next consider the example of a second-price sealed bid auction. If for each possibletype θi , the utility ui (θi ) derived by the agents i from not participating in the auction is0, then it is easy to see that the SCF would be ex-post IR. Moreover, the ex-post IR ofthis auction also follows directly from Proposition 19.3 because this is a special case of theClarke mechanism satisfying all the required conditions in the proposition.\u0003\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n292\n19.5\nbook\nGame Theory and Mechanism Design\nThe dAGVA Mechanism\nThe quasilinear environment provided us with an escape route from the GibbardSatterthwaite theorem and we were able to construct mechanisms that are AE andDSIC. However, these mechanisms do not satisfy budget balance as we realized inTheorem 19.1. Our quest for mechanisms that satisfy both AE and BB (that isex-post efficiency) leads us to relaxing DSIC to BIC. This is what is achieved by thedAGVA (d’Aspremont, Gérard-Varet, and Arrow) mechanism. This mechanism isalso known as the AVG mechanism.The following theorem, due to d’Aspremont and Gérard-Varet [6] and Arrow [7]establishes that in quasilinear environments, there exist social choice functions thatare both ex-post efficient and Bayesian incentive compatible.Theorem 19.3 (The dAGVA Theorem). Let the social choice function f (·) =(k ∗ (·), t1 (·), . . . , tn (·)) be allocatively efficient and the types of the agents be statistically independent of each other (that is, the joint density of types is the product ofmarginal densities). This social choice function is Bayesian incentive compatible ifthe payments satisfy:ti (θi , θ−i ) = ξi (θi ) + hi (θ−i ) ∀θi ∈ θi ; ∀θ−i ∈ Θ−i ; ∀i ∈ NXwhere ξi (θi ) = Eτ−i vj (k ∗ (θi , τ−i ), τj )\n(19.1)\nj6=i\nAs in the Groves payment scheme, hi : Θ−i → R is any arbitrary function.Proof: We are given that the social choice function f (·) = (k ∗ (·), t1 (·), . . . , tn (·))is allocatively efficient, that is, it satisfies the condition (18.1); the types are statistically independent of each other; and the payments are determined according tothe dAGVA payment scheme (19.1). We will set out to prove the necessary andsufficient condition for an SCF f (·) to be BIC:Eθ−i [ui (f (θi , θ−i ) , θi ) |θi ] ≥ Eθ−i [ui (f (θi0 , θ−i ), θi )|θi ], ∀θi0 ∈ Θi , ∀θi ∈ Θi , ∀i ∈ N.We first note thatEθ−i [ui (f (θi , θ−i ), θi )|θi ] = Eθ−i [vi (k ∗ (θi , θ−i ), θi ) + ti (θi , θ−i )|θi ] .Since θi and θ−i are statistically independent, the expectation can be taken withoutconditioning on θi . Using equation (19.1), the term Eθ−i [ui (f (θi , θ−i ), θi )|θi ] can bewritten asXEθ−i vi (k ∗ (θi , θ−i ), θi ) + hi (θ−i ) + Eτ−i vj (k ∗ (θi , τ−i ), τj )j6=i\nThis simplifies tonXvj (k ∗ (θi , θ−i ), θj ) + Eθ−i [hi (θ−i )].Eθ−i j=1\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nbook\nMechanism Design Space in Quasilinear Environment\n293\nSince k ∗ (·) is efficient allocation, it satisfies (18.1) and we get,nX\n∗\nvj (k (θi , θ−i ), θj ) ≥\nnX\nvj (k ∗ (θi0 , θ−i ), θj ) ∀ θi0 ∈ Θi .\nj=1\nj=1\nThus we get, ∀ θi0 ∈ Θi , ∀θi ∈ Θi , and ∀i ∈ N ,nXvj (k ∗ (θi , θ−i ), θj ) + Eθ−i [hi (θ−i )]Eθ−i j=1\nnXvj (k ∗ (θi0 , θ−i ), θj ) + Eθ−i [hi (θ−i )].≥ Eθ−i j=1\nAgain by making use of statistical independence we can rewrite the above inequality in the following form\u0002\u0003Eθ−i [ui (f (θi , θ−i ), θi )|θi ] ≥ Eθ−i ui (f (θi0 , θ−i ), θi )|θi ; ∀ θi0 ∈ Θi ; ∀θi ∈ Θi ; ∀i ∈ N.This proves that f (·) is BIC.\n\u0004\nNote. Observe that when agents j 6= i announce their types truthfully, agent ifinds that truth revelation is a best response strategy, in expectation over the typeprofiles of the rest of the agents.After the results of d’Aspremont and Gérard-Varet [6] and Arrow [7], a direct revelation mechanism in which the SCF is allocatively efficient and satisfies the dAGVApayment scheme (19.1) is called as dAGVA mechanism/expected externality mechanism/expected Groves mechanism.Definition 19.4 (dAGVA Mechanism). A direct revelation mechanism, D =((Θi )i∈N , f (·)) in which f (·) = (k ∗ (·), t1 (·), . . . , tn (·)) satisfies allocative efficiencyand the dAGVA payment scheme is known as dAGVA or expected externality orexpected Groves mechanism.\nThe dAGVA Mechanism and Strict Budget BalanceWe now show that the functions hi (·) above can be chosen so thatConsiderXξj (θj ) = Eτ−j vl (k ∗ (θj , τ−j ), τl ) ∀ i = 1, . . . , nl6=j\nLet us choose\u0012\n1hi (θ−i ) = −n−1\n\u0013Xj6=i\nξj (θj ) ∀ i = 1, . . . , n.\nPn\ni=1 ti (θ) = 0.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n294\nGame Theory and Mechanism Design\nIn view of the above definitions, we note that\u0013X\u00121ξj (θj )ti (θ) = ξi (θi ) −n−1j6=i\nThis impliesnX\nti (θ) =\nnX\n\u0012ξi (θi ) −\ni=1\ni=1\n1n−1\n\u0013Xn X\nξj (θj )\ni=1 j6=i\nAfter simplification, we obtainnXi=1\nti (θ) =\nnX\n\u0012ξi (θi ) −\ni=1\n1n−1\n\u0013Xn\n(n − 1)ξi (θi )\ni=1\nExpanding all the terms on the right hand side and simplifying, we obtainnX\nti (θ) = 0.\ni=1\nThis shows that the dAGVA mechanism can be made strictly budget balanced witha judicious choice of hi (.) functions.Example 19.3. Consider the dAGVA mechanism for the three agents case, that is, N ={1, 2, 3}. The payments for the three agents would be:t1 (θ) = ξ1 (θ1 ) −\n1[ξ2 (θ2 ) + ξ3 (θ3 )]2\n1[ξ1 (θ1 ) + ξ3 (θ3 )]21t3 (θ) = ξ3 (θ3 ) − [ξ1 (θ1 ) + ξ2 (θ2 )]2Clearly, t1 (θ) + t2 (θ) + t3 (θ) = 0. This situation can be better understood with the help ofFigure 19.1, which depicts the above payments in the form of a graph.\u0003t2 (θ) = ξ2 (θ2 ) −\nAs shown in Figure 19.1, the budget balanced payment structure of the agentsin the above mechanism can be given an elegant graph theoretic interpretation.Imagine a directed graph G = (V, A) where V is the set of n + 1 vertices, numbered0, 1, . . . , n, and A is the set of [n + n(n − 1)] directed arcs. The vertices startingfrom 1 through n correspond to the n agents involved in the system and the vertexnumbered 0 corresponds to the social planner. The set A consists of two typesof the directed arcs: (1) Arcs 0 → i ∀i = 1, . . . , n and (2) Arcs i → j ∀i, j ∈{1, 2, . . . , n} ; i 6= j.Each of the arcs 0 → i carries a flow of ti (θ) and each of the arcs i → j carries ai (θi ). Thus the total outflow from a node i ∈ {1, 2, . . . , n} is ξi (θi ) and totalflow of ξn−1\u0010\u0011P1inflow to the node i from nodes j ∈ {1, 2, . . . , n} is −hi (θ−i ) = n−1j6=i ξj (θj ).Thus for node i, ti (θ) − hi (θ−i ) is the net inflow which it is receiving from node 0\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nMechanism Design Space in Quasilinear Environment\n book\n295\nFig. 19.1: Payment structure showing budget balance in the dAGVA mechanismin order to respect the flow conservation constraint. Thus, if ti (·) is positive thenthe agent i receives the money from the social planner and if it is negative, thenthe agent pays the money to the social planner. Looking at the flow conservationequation for node 0, it is clear the total payment received by the planner from theagents and total payment made by the planner to the agents will add up to zero. Theflow from node i to node j can be justified as follows. Each agent i first evaluatesthe expected total valuation that would be generated together by all other agentsin his absence, which turns out to be ξi (θi ). Now, agent i divides it equally amongthe other agents and pays to every other agent an amount equivalent to this. Notethat the allocation itself will explicitly take into account the presence of agent i.Example 19.4 (Bilateral Trading Market). There are two players, player 1(seller) and player 2 (buyer). Player 1 wishes to sell an indivisible item and player 2 isinterested in buying this item. Player 1’s type is the willingness to sell (minimum price atwhich the seller is prepared to sell the item), and has two possible values {10, 20}. Player2’s type is the willingness to buy (maximum price the buyer is prepared to pay for the item)and has two possible values {10, 20}. Each player can be in any of the two types with equalprobability of 0.5. If the buyer’s type is greater than or equal to the seller’s announced type,they will trade the object; otherwise no trade occurs. Thus the allocation function k(θ1 , θ2 )allocates the object to the buyer (player 2) if θ1 ≤ θ2 and the object will remain with theseller (player 1) if θ1 > θ2 . This allocation function can be shown to be allocatively efficient(see exercise). We shall now use k ∗ instead of k to emphasize that k is allocatively efficient.The values of the players in different type profiles can be derived as follows. Note thatwhenever trade happens, the seller’s value is the negative of his willingness to sell while thebuyer’s value is his willingness to buy. Whenever trade does not happen, the seller’s value is\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n296\nGame Theory and Mechanism Design\nhis willingness to pay while the buyer’s value is zero. First let us consider v1 (k ∗ (10, 10), 10).The type profile (10, 10) allows trade to happen as a result of which the seller (agent 1)loses the item and the buyer (agent 2) gains the item. The willingness to sell of agent 1 is10 and therefore the value in this allocation is −10. Similarly, consider v1 (k ∗ (20, 10), 20).In the type profile (20, 10), trade does not happen and therefore the object remains withthe seller. Since the willingness to sell here is 20, the value of agent 1 in this allocation is20. Likewise, we can compute all the values and the following provides all the values.v1 (k ∗ (10, 10), 10) = −10; v1 (k ∗ (20, 10), 20) = 20v1 (k ∗ (10, 20), 10) = −10; v1 (k ∗ (20, 20), 20) = −20v2 (k ∗ (10, 10), 10) = 10; v2 (k ∗ (20, 10), 10) = 0v2 (k ∗ (10, 20), 20) = 20; v2 (k ∗ (20, 20), 20) = 20.We now compute the ξ values as defined in the strictly budget balanced version ofdAGVA payment scheme. We get:ξ1 (10) =\n111v2 (k ∗ (10, 10), 10) + v2 (k ∗ (10, 20), 20) = (10 + 20) = 15222\n111v2 (k ∗ (20, 10), 10) + v2 (k ∗ (20, 20), 20) = (0 + 20) = 10222111ξ2 (10) = v1 (k ∗ (10, 10), 10) + v1 (k ∗ (20, 10), 20) = (−10 + 20) = −5222111ξ2 (20) = v1 (k ∗ (10, 20), 10) + v1 (k ∗ (20, 20), 20) = (−10 − 20) = −15222The payments will be:ξ1 (20) =\nt1 (10, 10) = ξ1 (10) − ξ2 (10) = 15 − (−5) = 20t1 (10, 20) = ξ1 (10) − ξ2 (20) = 15 − (−15) = 30t1 (20, 10) = ξ1 (20) − ξ2 (10) = 10 − (−5) = 15t1 (20, 20) = ξ1 (20) − ξ2 (20) = 10 − (−15) = 25The payments of the buyer will be exactly the reverse. It is easy to see that this is notindividually rational for the buyer.\u0003\nThe dAGVA Mechanism and Individual RationalityWe have seen that the dAGVA mechanism satisfies AE, SBB, and BIC. One wouldbe curious to know whether it satisfies individual rationality also. Unfortunately,the following theorem rules out that possibility at least for a bilateral trade setting.The Myerson–Satterthwaite TheoremThe Myerson–Satterthwaite Theorem is an impossibility result and it asserts that ina bilateral trade setting, there is no SCF that satisfies AE, SBB, BIC, and InterimIR all together. The precise statement of the theorem is as follows.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nMechanism Design Space in Quasilinear Environment\nbook\n297\nTheorem 19.4 (Myerson–Satterthwaite Impossibility Theorem).Consider a bilateral trade setting in which the buyer and seller are risk neutral,the valuations θ1 and θ2 are drawn independently from the intervals [θ1 , θ1 ] ⊂ R andT[θ2 , θ2 ] ⊂ R with strict positive densities, and (θ1 , θ1 ) (θ2 , θ2 ) 6= ∅. Then there isno Bayesian incentive compatible social choice function that is ex-post efficient andgives every buyer and every seller nonnegative expected utilities from participation.The term risk neutral has already been elaborated in Chapter 8 (see Section 8.6).For a proof of the above theorem, refer to Proposition 23.E.1 of the book by MasColell, Whinston, and Green [8].19.6\nMechanism Design Space in Quasilinear Environment\nFigure 19.2 shows the space of mechanisms taking into account all the results wehave studied so far. This figure summarizes all the results we have seen in theprevious chapter and the current one. A careful look at the diagram suggests whydesigning a mechanism that satisfies a specified combination of properties is a quiteintricate exercise.A designer of mechanisms (with money) in a quasilinear setting has to weighin the tradeoffs in a judicious way while selecting a particular mechanism for hiscurrent application. This is where the possibility and impossibility theorems become important. An intelligent social planner will first identify the key propertiesrequired for a given application and examines if all of these key properties are inthe realm of the possible. If not, the social planner will have to filter out one ormore properties from the list and come up finally with a mechanism that fits theapplication best. As new applications emerge in the Internet era and new propertiesbecome relevant, research in mechanism design these days is all about how to designthe most appropriate mechanisms satisfying the most desirable subset of properties.19.7\nLinear Environment\nThe linear environment is a special, often-studied, subclass of the quasilinear environment. This environment is a restricted version of the quasilinear environment inthe following sense.(1) Each agent i’s type lies in an interval Θi = [θi , θi ] ⊂ R with θi < θi .(2) Agents’ types are statistically independent, that is, the density φ(·) has the formφ1 (·) × . . . × φn (·).(3) φi (θi ) > 0 ∀ θi ∈ [θi, θi ] ∀ i = 1, . . . , n.(4) Each agent i’s utility function takes the following formui (x, θi ) = θi vi (k) + mi + ti .\nDecember 27, 2013\n11:21\n298\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nFig. 19.2: Mechanism design space in quasilinear environment\nThe linear environment has very interesting properties in terms of being able toobtain a characterization of the class of BIC social choice functions. Before wepresent Myerson’s Characterization Theorem for BIC social choice functions in alinear environment, we define the following quantities with respect to any socialchoice function f (·) = (k(·), t1 (·), . . . , tn (·)) in this environment.• Let ti (θ̂i ) = Eθ−i [ti (θ̂i , θ−i )] be agent i’s expected transfer given that he announces his type to be θ̂i and that all agents j 6= i truthfully reveal their types.• Let vi (θ̂i ) = Eθ−i [vi (θ̂i , θ−i )] be agent i’s expected “benefits” given that heannounces his type to be θ̂i and that all agents j 6= i truthfully reveal theirtypes.• Let Ui (θ̂i |θi ) = Eθ−i [ui (f (θ̂i , θ−i ), θi )|θi ] be agent i’s expected utility when histype is θi , he announces his type to be θ̂i , and all agents j 6= i truthfully reveal\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nMechanism Design Space in Quasilinear Environment\nbook\n299\ntheir types. It is easy to verify from the previous two definitions thatUi (θ̂i |θi ) = θi vi (θ̂i ) + ti (θ̂i ).• Let Ui (θi ) = Ui (θi |θi ) be the agent i’s expected utility conditional on his typebeing θi when he and all other agents report their true types. It is easy to verifythatUi (θi ) = θi vi (θi ) + ti (θi ).Myerson’s Characterization TheoremWith the above notation in place, we now present Myerson’s [9] theorem for characterizing the BIC social choice functions in this environment.Theorem 19.5 (Myerson’s Characterization Theorem). In linear environment, a social choice function f (·) = (k(·), t1 (·), . . . , tn (·)) is BIC if and only if,for all i = 1, . . . , n,(1) vi (·) is nondecreasing,Rθ(2) Ui (θi ) = Ui (θi ) + θii vi (s)ds ∀ θi ∈ Θi .For a proof of the above theorem, refer to Proposition 23.D.2 of the book by MasColell, Whinston, and Green [8]. The above theorem shows that to identify allBIC social choice functions in a linear environment, we can proceed as follows:First identify which functions k(·) lead every agent i’s expected benefit functionvi (·) to be nondecreasing. Then, for each such function identify transfer functionst1 (·), . . . , tn (·) that satisfy the second condition of the above proposition. Substituting for Ui (·) in the second condition above, we get that expected transfer functionsare precisely those that satisfy, for i = 1, . . . , n,Z θiti (θi ) = ti (θi ) + θi vi (θi ) − θi vi (θi ) +vi (s)dsθi\nfor some constant ti (θi ). Finally, choose any set of transfer functions t1 (·), . . . , tn (·)such that for all θi , Eθ−i [ti (θi , θ−i )] = ti (θi ). In general, there are many such functions, ti (·, ·); one, for example, is simply ti (θi , θ−i ) = ti (θi ).19.8\nSummary and References\nIn this chapter, we have looked into a variety of possibilities and impossibilities formechanisms under quasilinear preferences.• First we looked at Groves mechanisms (which satisfy AE and DSIC) and budgetbalance. The Green-Laffont theorem rules out strict budget balance of Grovesmechanisms. An escape route is the scenario in which the type set of one of theplayers is common knowledge.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n300\nGame Theory and Mechanism Design\n• Next we looked at Clarke mechanisms and weak budget balance. We showed thatunder a sufficient condition (called no single agent effect), Clarke mechanisms areweakly budget balanced. Redistribution mechanisms are those which minimizethe budget imbalance while preserving AE and DSIC.• Following this, we defined an important property called individual rationality(IR) which ensures that every agent would participate in the mechanism voluntarily. This property could be defined at three stages of the game: ex-ante,interim, and ex-post. We showed that VCG mechanism are not necessarily IRand proved that Clarke mechanisms are IR if two conditions (choice set monotonicity and no negative externality) are satisfied.• The next topic we discussed was the dAGVA mechanism which is also called theexpected Groves mechanism. The dAGVA mechanism satisfies BIC, AE, andSBB but is not IR. The mechanism is tailor made for two sided market settingssuch as bilateral trade.• We consolidated all the results that we have examined in mechanism designunder quasilinear preferences and Figure 19.3 captures the intricate possibilitiesand impossibilities.• To conclude the chapter, we discussed an important special case of quasilinearsetting called the linear environment and presented a key result by Myersonwhich gives a characterization of BIC mechanisms in linear environment. Thisresult ties up BIC with monotonicity and will be crucially used in subsequentchapters while proving the revenue equivalence theorem (for single item auctions) and in setting up the results for optimal auctions.References[1][2]\n[3][4][5][6][7]\n[8][9]\nJ.R. Green and J.J. Laffont. Incentives in Public Decision Making. North-Holland, Amsterdam, 1979.R. Cavallo. “Optimal decision making with minimal waste: strategy-proof redistribution ofVCG payments”. In: Proceedings of the Fifth International Joint Conference on AutonomousAgents and Multiagent Systems, AAMAS-2006. 2006, pp. 882–889.H. Moulin. “Almost budget balanced VCG mechanisms to assign multiple objects”. In: Journal of Economic Theory 144 (2009), pp. 96–119.M. Guo and V. Conitzer. “Worst-case optimal redistribution of VCG payments in multiunitauctions”. In: Games and Economic Behavior 67 (2010), pp. 69–98.Sujit Gujar and Y. Narahari. “Redistribution mechanisms for assignment of heterogeneousobjects”. In: Journal of Artificial Intelligence Research 41 (2011), pp. 131–154.C. d’Aspremont and L.A. Gérard-Varet. “Incentives and incomplete information”. In: Journalof Public Economics 11 (1979), pp. 25–45.K. Arrow. “The property rights doctrine and demand revelation under incomplete information”. In: Economics and Human Welfare. Ed. by M. Boskin. Academic Press, New York,1979.Andreu Mas-Colell, Michael D. Whinston, and Jerry R. Green. Microeconomic Theory. Oxford University Press, 1995.Roger B. Myerson. “Optimal auction design”. In: Mathematics of Operations Research 6(1)(1981), pp. 58–73.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nMechanism Design Space in Quasilinear Environment\n19.9\nbook\n301\nExercises\n(1) Consider that there are two agents, each of them holding a single indivisibleobject. Suppose Θ1 = {1, 2}; Θ2 = {2, 3}. Consider the following direct mechanism where the two agents report their types. Agent 1 wins if her report isgreater than or equal to the report of player 2; otherwise player 2 wins. Whoeverwins becomes the seller and whoever loses becomes the buyer and the objectheld by the winner is bought by the loser. Design a (strictly) budget balanceddAGVA mechanism for the above problem.(2) Consider two agents 1 and 2 with Θ1 = {1, 2, 3} and Θ2 = {2, 3}. Each of theseagents has a single indivisible item to sell to the other. A dAGVA mechanismdecides who will sell. Assume that agent 1 sells if his bid is less than or equalto that of agent 2, in which case agent 2 will buy the item from agent 1. If thebid of agent 1 is greater than that of agent 2, then agent 2 sells and agent 1buys it from agent 2. Payments are decided by the dAGVA mechanism. Designa strictly budget balanced dAGVA mechanism for this problem.(3) Consider a selling agent 0 and two buying agents 1, 2. The buying agents submitsealed bids to buy a single indivisible item. Let θ1 and θ2 be the willingness topay of the buyers. Let us define the usual allocation function:y1 (θ1 , θ2 ) = 1 if θ1 ≥ θ2= 0 elsey2 (θ1 , θ2 ) = 1 if θ1 < θ2= 0 else.Let Θ1 = Θ2 = [0, 1] and assume that the bids from the bidders are i.i.d. uniformdistributions on [0, 1]. Also assume that Θ0 = {0}. Assuming that the dAGVAmechanism is used, compute the payments.(4) Consider a sealed bid auction with one buyer and two selling agents. There is asingle indivisible item which the buyer wishes to buy. The bidders are symmetricwith independent private values distributed uniformly over [0, 1]. Whoever bidslower will be selected to sell the item. Suppose the dAGVA payment rule isused. Compute the payment that the winner will receive. How about the loser?(5) Consider a bilateral trade setting in which each θi (i = 1, 2) is independentlydrawn from a uniform distribution on [0, 1]. Compute the payments in thedAGVA mechanism. Verify that truth telling is a Bayesian Nash equilibrium.(6) Consider again a bilateral trade setting in which each θi (i = 1, 2) is independently drawn from a uniform distribution on [0,1]. Suppose now that by refusingto participate in the mechanism a seller with valuation θ1 receives expected utility θ1 (he simply consumes the good), whereas a buyer with valuation θ2 receivesexpected utility 0. Show that in the dAGVA mechanism there is a type of buyeror seller who will strictly prefer not to participate.(7) Show by means of an example that when the buyer and seller in a bilateral trade\nDecember 27, 2013\n11:21\n302\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nsetting both have a discrete set of possible valuations, social choice functions mayexist that are Bayesian incentive compatible, ex-post efficient, and individuallyrational. (Hint: It is enough to consider each agent to have two possible types.)(8) Programming Assignment. Implement the dAGVA mechanism. Identify theinputs to this program carefully. The output must be an efficient allocation anda payment vector for any given type profile.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nChapter 20\nAuctions\nAuctions are ubiquitous these days in real-world e-commerce and e-business transactions and numerous other applications on the web. Auctions provide a naturalexample of mechanisms with money. Mechanism design theory provides a principled way of designing auctions to ensure that desirable properties are satisfied.In this chapter, we discuss different types of auctions and key mechanism designissues. In particular, we discuss four basic types of auctions for selling or procuringa single indivisible item: English auction, Dutch auction, first price auction, andsecond price auction (Vickrey auction). We discuss a key result concerning theabove four auctions, namely the revenue equivalence theorem. We also introducecombinatorial auctions.\nAn auction is a mechanism to allocate a set of goods to a set of bidders on the basisof bids announced by the bidders. Auctions have been used for trading of objects forthousands of years. In the recent times, the use of auctions in web-based applicationshas grown dramatically. These applications include traditional ones such as saleof paintings and memorabilia to more current applications such as auctions forInternet advertising space, keyword auctions on search engine websites, industrialprocurement auctions, auctions for spectrum allocation, auctions for airport slotallocation, etc. There is therefore a great deal of interest in the theory and practicalapplications of auctions.There are excellent books [1, 2, 3] and survey articles [4, 5, 6] on auctions. Morerecently, several survey papers have focused on combinatorial auctions [7, 8, 9, 10].\n20.1\nAuction Types and Desirable Properties\nClassification of AuctionsKalagnanam and Parkes [9] have suggested a framework for classifying auctionsbased on six major criteria as outlined below.(1) Resources: Resources are entities over which negotiations in an auction areconducted. Resources could be a single item or multiple items, with a single ormultiple units of each item. Multiple item auctions are called combinatorial auctions.303\nbook\nDecember 27, 2013\n11:21\n304\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\n(2) Market Structure: There are three types of market structures in auctions. Ina forward auction, a single seller sells resources to multiple buyers. In a reverseauction, a single buyer attempts to source resources from multiple suppliers, as iscommon in procurement. Auctions with multiple buyers and sellers are called doubleauctions or exchanges.(3) Preference Structure: The preferences define an agent’s utility for different outcomes in the auction. For example, when multiple units of an item are involved,agents could indicate a decreasing marginal utility for additional units. If an objecthas multiple attributes such as cost, lead time, quality, reliability, etc., an agent’spreference structure could capture the importance the agent attaches to the attributes.(4) Bid Structure: The structure of the bids within the auction defines the flexibilitywith which agents can express their resource requirements. For a simple singleunit, single item commodity, the bids required are simply the willingness to buy orwillingness to sell. For a multiunit identical items setting, the bids need to specifyprice and quantity. This introduces the possibility for allowing volume discounts.With multiple items, bids may specify preferences on bundles.(5) Winner Determination: Other phrases which are used synonymously with winner determination are market clearing, bid evaluation, bid allocation, or simplyallocation. In the case of forward auctions, winner determination refers to choosingan optimal subset of buyers who would be awarded the items. In the case of reverseauctions, winner determination refers to choosing an optimal subset of sellers whowould be awarded the contracts for supplying the required items. In the case ofan exchange, winner determination refers to determining an optimal match betweenbuyers and sellers. The computational complexity of the winner determination problem is an important issue to be considered in designing auctions.(6) Information Feedback : An auction protocol may be with information feedbackor without information feedback. In a single round auction, agents submit bidswithout receiving feedback (such as price signals) from the auction. In multi-roundauctions, agents can adjust bids in response to information feedback from the auction. Feedback about the state of the auction is usually characterized by a pricesignal and a tentative allocation, and provides useful information about the bids ofwinning agents which helps an agent to revise its own bids.\nAuctions: Desirable PropertiesWe now provide an intuitive idea about desirable properties that an auction designerlooks for. Not all of these can be realized simultaneously as we have seen in theprevious chapter. Depending on the context, the auction designer has to carefullychoose a maximal subset of these properties that can be simultaneously achieved.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nAuctions\nbook\n305\nSolution EquilibriumThe solution of a mechanism is in equilibrium, if no agent wishes to change itsbid, given the information it has about other agents. Many types of equilibriacan be computed given the assumptions about the preferences of agents (buyersand sellers), rationality, and information availability. We are already familiar withdifferent types of equilibria: Bayesian Nash equilibrium, ex-post Nash equilibrium,and strongly/weakly/very-weakly dominant strategy equilibrium.\nIncentive CompatibilityAn auction is said to be incentive compatible if the agents optimize their expectedutilities by bidding their true valuations of the resources. Depending on the equilibrium achieved by truthful bidding, an incentive compatible auction is qualifiedas Bayesian incentive compatible or dominant strategy incentive compatible. If amechanism is DSIC, each agent’s decision depends only on its local information andthere is no need whatsoever for the agent to model or compute the strategies of theother agents. In the case of BIC, computation of equilibrium strategies will requireinformation about the prior. Ex-post incentive compatibility (EPIC) (which will bediscussed in Chapter 23) is another kind of incentive compatibility – stronger thanBIC but weaker than DSIC.\nAllocative EfficiencyAllocative efficiency is achieved when the social utility (sum of utilities) of all thewinners is maximized. Allocative efficiency ensures that the resources are allocatedto the agents who value them most.\nIndividual RationalityAn auction is said to be individually rational (or is said to have voluntary participation property) if its allocations do not make any agent worse off than if the agenthad not participated in the mechanism. That is, every agent gains a nonnegativeutility by participating in the mechanism.\nBudget BalanceAn auction is said to be weakly budget balanced if, in all feasible outcomes, thepayments by buyers exceed or equal to the receipts of sellers. An auction is said tobe strongly budget balanced if the net monetary transfer is zero. In other words,budget balance ensures that the auctioneer or mechanism designer does not makelosses.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n306\nGame Theory and Mechanism Design\nRevenue Maximization or Cost MinimizationIn an auction where a seller is auctioning a set of items, the seller would like tomaximize total revenue earned. On the other hand, in a procurement auction,the buyer would like to procure at minimum cost. Often, rather than revenuemaximization, the goal of the seller will be profit maximization, where profit isrevenue minus cost. In an exchange setting where there are multiple buyers andmultiple sellers, maximization of surplus where surplus is the total amount of receiptsminus total amount of payments could be the objective.FairnessWinner determination algorithms, especially those based on heuristics, could leadto different sets of winners at different times. Since there could be multiple optimalsolutions, different sets of winners could be produced by different algorithms. Thiscreates a perception of unfairness and can influence bidders’ willingness to participate in auctions. Bidders who lose even though they could have won with a differentalgorithm could end up feeling unfairly treated.CheatproofnessAn auction should be robust to false name attacks and innumerable other types ofmanipulations by the bidders.20.2\nCanonical Mechanisms for a Single Indivisible Item Auction\nThere are four basic types of auctions when a single indivisible item is to be soldor bought. We discuss the case of selling or forward auction here. When a singleindivisible item is to be bought or procured, the four types of auctions can be usedin a reverse way. These are then called reverse auctions or procurement auctions.English AuctionThis is also called an open cry auction or an ascending bid auction. Here, the goingprice starts at a low level and is successively raised until only one bidder remainsin the fray. This can be done in several ways: (a) an auctioneer announces prices,(b) bidders call the bids themselves, or (c) bids are submitted electronically. Atany point of time, each bidder knows the level of the current best bid. The winningbidder pays the latest going price.Dutch AuctionThis is also called a descending bid auction. Here, the auctioneer announces aninitial (high) price and then keeps lowering the price in successive rounds until oneof the bidders accepts the current price. The winner pays the current price.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nAuctions\nbook\n307\nFirst Price Sealed Bid AuctionHere, potential buyers submit sealed bids and the highest bidder is awarded theitem. If multiple highest bidders are available, a suitable tie-breaking rule is appliedto select the winner. The winning bidder pays the price that he has bid.Second Price Sealed Bid AuctionThis is the classic Vickrey auction. Recall that potential buyers submit sealed bidsand the allocation is as in the first price auction. The winning bidder pays a priceequal to the second highest bid (which is also the highest losing bid).Example 20.1 (Canonical Auctions). Consider the following scenario. There is aseller who wishes to auction a property. There are two prospective buyers for this property.The first buyer has a willingness to pay of Rs. 10 million for the property and the secondbidder has a willingness to pay of Rs. 15 million. Each bidder does not know the willingnessto pay of the other bidder.\nEnglish AuctionA typical English auction may progress like this. The first bidder bids Rs. 5 million andthen the second bidder places a bid of Rs. 6 million. The first bidder may now increase hisbid to Rs. 8 million. The second bidder may then increase her bid to Rs. 9 million. Thefirst bidder may again revise his bid to Rs. 9.5 Million. The second bidder now revises herbid to Rs. 10 million. Now, the first bidder will not increase his bid anymore. So the secondbidder will receive the property by paying Rs. 10 million.\nDutch AuctionA typical Dutch auction would proceed as follows. The seller declares a price Rs. 20 million.No agent is willing to purchase at that price. The seller drops the price to Rs. 18 million.Still no agent would be willing to buy. The seller continues to drop the price, say, to Rs. 16million, Rs. 14 million, Rs. 12 million, Rs. 11 million. At Rs. 11 million, the second biddermay decide to buy it, since she might (though she does not know the valuation of the firstbidder) apprehend that the first agent may express his intent to buy before her. Note thatRs. 11 million is lower than what the second bidder is willing to pay.\nFirst Price Sealed Bid AuctionSuppose the first bidder bids Rs. 9 million and the second one bids Rs. 11 million. Thesecond bidder will win and pay Rs. 11 million, which is his bid, to the seller.\nSecond Price Sealed Bid Auction (Vickrey Auction)Each bidder knows that if he wins, he has to pay the other’s bid. Truthful bidding is aweakly dominant strategy here. So the first bidder will bid Rs. 10 million and the secondbidder will bid Rs. 15 million. The second bidder will receive the property by paying Rs.10 million which is the second highest bid.\u0003\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n308\nGame Theory and Mechanism Design\n20.3\nRevenue Equivalence of First Price and Second Price Auctions\nIn this section, we prove under some conditions that the expected revenue to theseller is the same in the first price auction and second price auction. We in factprove a more general result on the revenue equivalence of two auctions which arenatural generalizations of first price auction and second price auction.Consider a seller who wishes to sell an indivisible object in which n buying agents{1, . . . , n} are interested. Suppose θi is the type of buying agent i (i = 1, . . . , n whereθi denotes the willingness to buy of agent i. Assume that yi (θ) is the probability ofagent i getting the object when the vector of announced types is θ = (θ1 , . . . , θn ).The expected payoff to the buyer i with a type profile θ = (θ1 , . . . , θn ) will beyi (θ)θi + ti (θ) where ti (θ) is the monetary transfer to player i when the type profileis θ (linear environment – see Section 19.7). The set of allocations is given by)(nXyi ≤ 1 .K = (y1 , . . . , yn ) : yi ∈ [0, 1] ∀i = 1, . . . , n;i=1\nAs earlier, let yi (θ̂i ) = Eθ−i [yi (θˆi , θ−i )] be the expected probability that agent igets the object conditional to announcing his type as θˆi , with the rest of the agentsannouncing their types truthfully. Similarly, ti (θˆi ) = Eθ−i [ti (θˆi , θ−i )] denotes theexpected payment received by agent i conditional to announcing his type as θˆi , withthe rest of the agents announcing their types truthfully. Then,Ui (θi ) = yi (θi )θi + ti (θi )denotes the expected payoff to agent i when all the buying agents announce theirtypes truthfully. We now state and prove an important proposition.Theorem 20.1. Consider an auction scenario with:(1) n risk-neutral bidders (buyers) 1, 2, . . . , n(2) The valuation of bidder i (i = 1, . . . , n) is a real interval [θi , θi ] ⊂ R with θi < θi .(3) The valuation of bidder i (i = 1, . . . , n) is drawn from [θi , θi ] with a strictlypositive density φi (.) > 0. Let Φi (.) be the cumulative distribution function.(4) The types of the bidders are statistically independent.Suppose that a given pair of Bayesian Nash equilibria of two different auction procedures are such that:• For every bidder i, for each possible realization of (θ1 , . . . , θn ), bidder i has anidentical probability of getting the object in the two auctions.• Every bidder i has the same expected payoff in the two auctions when his valuation for the object is at its lowest possible level.Then the two auctions generate the same expected revenue to the seller.Before proving the theorem, to appreciate on the first assumption above, namelyrisk neutrality, we point the reader to Section 8.6 where we discussed three different\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nbook\nAuctions\n309\ntypes of risk attitudes of players: risk averse, risk neutral, and risk loving. In brief,a bidder is risk neutral if his utility is a linear function of the money held by him.Proof: By the revelation principle, it is enough that we investigate two BIC socialchoice functions in this auction setting. It is sufficient to show that two separate BICsocial choice functions having (a) the same allocation functions (y1 (θ), . . . , yn (θ))∀θ ∈ Θ, and (b) the same values of U1 (θ1 ), . . . , Un (θn ) will generate the same expected revenue to the seller.We first derive an expression for the seller’s expected revenue given any BICmechanism.nXEθ [−ti (θ)].(20.1)Expected revenue to the seller =i=1\nNow, we have:Eθ [−ti (θ)] = Eθi [−Eθ−i [ti (θ)]]Z θi=[yi (θi )θi − Ui (θi )]φi (θi )dθiθiZ \"Zθi\n#\nθi\n[yi (θi )θi − Ui (θi )] −\n=θi\nyi (s)ds φi (θi )dθi .θi\nThe last step is an implication of Myerson’s characterization of Bayesian incentivecompatible functions in linear environment (see Section 19.7). The above expressionis now equal to!#\"ZZ θiθiyi (θi )θi −yi (s)ds φi (θi )dθi − Ui (θi ).θi\nθi\nWe first simplifyZ θi\nZ θi\nθi\nθi\n!yi (s)ds φi (θi )dθi\nby applying integration by parts with\nR θi\nZ θi\nθi yi (s)ds as the first function. This yields\nZ θiyi (θi )dθi −\nθi\nyi (θi )Φi (θi )dθiθi\nwhich is equal to:Z θiyi (θi )[1 − Φi (θi )]dθi .θi\nTherefore we get\"ZEθi [−ti (θi )] = −Ui (θi ) +\nθi\nθi\n#\u001a\u001b1 − Φi (θi )yi (θi ) θi −φi (θi )dθiφi (θi )\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n310\nbook\nGame Theory and Mechanism Design\n\"Z\nθ1\n= −Ui (θi ) +\nZ θn...\nyi (θ1 , . . . , θn )\u0012\u0013 Yn1 − Φi (θi ) × θi −φj (θj ) dθn . . . dθ1 φi (θi )θ1\nθn\nj=1\nsinceZ θ1yi (θi ) =\n...θ1\n\nZ θn\nyi (θ1 , . . . , θn ) θn\nnY\nj=1\nφj (θj )\ndθ . . . dθ .| n {z }1without dθi\nTherefore the expected revenue of the seller\u0014 Z θ1\u0013\u0015 Y\u0012Z θn Xnn1 − Φi (θi )=...φj (θj ) dθn . . . dθ1yi (θ1 , . . . , θn ) θi −φi (θi )θnθ1i=1\n−\nnX\nj=1\nUi (θi ).\ni=1\nBy looking at the above expression, we see that any two Bayesian incentive compatible social choice functions that generate the same functions (y1 (θ), . . . , yn (θ)) andthe same values of (U1 (θ1 ), . . . , Un (θn )) generate the same expected revenue to theseller.\u0004Note. The first price auction and the second price auction satisfy the conditions ofthe above theorem:• In both the auctions, the bidder with the highest valuation wins the auction.• Bidders’ valuations are drawn from some real interval [θi , θi ] and a bidder withvaluation at the lower limit of the interval has a payoff of zero in both theauctions.Thus the theorem can be applied to the equilibria of the two auctions: Note thatin the case of the first price auction, it is a Bayesian Nash equilibrium while in thecase of the second price auction, it is a weakly dominant strategy equilibrium. Thusthese two auctions generate the same expected revenue to the seller.We are now in a position to state and informally prove an important result, therevenue equivalence theorem, in the context of auctioning a single indivisible item.The article by McAfee and McMillan [4] and the book by Vijay Krishna [1] provideexcellent references for this topic and much of the discussion in this section is basedon the above references.20.4\nRevenue Equivalence Theorem\nThis important theorem states that the four canonical auctions for a single indivisibleitem produce the same expected revenue to the seller under a benchmark model.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nAuctions\nbook\n311\nThe Benchmark ModelThere are four assumptions that are key to the revenue equivalence theorem: (1)risk neutrality of bidders; (2) bidders have independent private values; (3) biddersare symmetric; (4) payments depend on bids alone. These are described below inmore detail.(1) Risk Neutrality of BiddersIt is assumed in the benchmark model that all the bidders are risk neutral. Thisimmediately implies that the utility function of each bidder is linear in the moneyheld by the bidder. See Section 8.6 for more details.(2) Independent Private Values ModelIn the independent private values model, each bidder knows precisely how much hevalues the item. However, each bidder may not know the valuation of the item forthe other bidders. Each bidder perceives any other bidder’s valuation as drawn fromsome known probability distribution. Also, each bidder knows that the other biddersand the seller regard his own valuation as being drawn from some known probabilitydistribution. More formally, let N = {1, 2, . . . , n}, as usual, be the set of bidders.The independent private values assumption presupposes a probability distributionΦi from which bidder i (i ∈ N ) draws his valuation vi . Only bidder i observes hisown valuation vi , but all other bidders and the seller only know the distribution Φi .The probability distributions of the bidders are mutually independent.An appropriate example of this assumption is provided by the auction of a rarepainting in which the bidders are consumers buying for their own use and not forresale.A popular model that is different from the above model is the common valuemodel . Here, if V is the unobserved true value of the item, then the bidders’ perceived values vi , i = 1, . . . , n are independent draws from some probability distribution H(vi |V ). All bidders know the distribution H. An example is provided by thesale of a rare painting that is being bid for by bidders who intend to resell it. Therare painting has one single objective value, namely its market price. However, noone knows its true market price. The bidders, if they gain access to useful but different bits of information, will have different guesses about how much the paintingis objectively worth.Suppose a bidder comes to know the valuation of another bidder for the painting.If the situation is described by the common value model, then the above providesuseful information about the likely true value of the item, and the bidder wouldperhaps change his own valuation in the light of this. If the situation is describedby the independent private values model, the bidder has definite valuation for thepainting, and learning about others’ valuations will not make him change his own\nDecember 27, 2013\n11:21\n312\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nvaluation. He might perhaps, for strategic reasons, change his bid.Real world auction situations are likely to contain aspects of both the independent private values model and the common value model. It is assumed in thebenchmark model that the independent private values assumption holds.(3) SymmetryThis assumption implies that all the bidders have the same set of possible valuations, and further they draw their valuations using the same probability distributionfunction Φ. That is, Φ1 = Φ2 = . . . = Φn = Φ.(4) Dependence of Payments on Bids AloneIt is assumed that the payment to be made by the winner to the seller is a functionof bids alone.Theorem 20.2 (Revenue Equivalence Theorem). Consider a seller or anauctioneer seeking to sell a single indivisible item in which n bidders are interested. For the benchmark model (bidders are risk neutral, bidders have independentprivate values, bidders are symmetric, and payments depend only on bids), all thefour basic auction types (English auction, Dutch auction, first price auction, andsecond price auction) yield the same expected revenue to the seller.Note. The result may seem somewhat counter intuitive. For example, it mightseem that receiving the highest bid in a first price sealed bid auction must be betterfor the seller than receiving the second highest bid, as in second price auction.However, it is to be noted that bidders act differently in different auction situations.In particular, they bid more aggressively in a second price auction than in a firstprice auction.Proof: The proof proceeds in three parts. In Part 1, we show that the first priceauction and the second price auction yield the same expected revenue in their respective equilibria. In Part 2, we show that the Dutch auction and the first priceauction produce the same outcome. In Part 3, we show that the English auction andthe second price auction yield the same outcome. We caution the readers that ourproof is intuition based but informal and we refer the readers to [1] for a rigorousproof of this result.Part 1: Revenue Equivalence of First Price and Second Price AuctionsWe have already shown that first price auction and the second price auction satisfythe conditions of Theorem 20.1. It is clear that the two auctions generate the sameexpected revenue to the seller. In fact, it can be shown in any symmetric auctionsetting (where the bidders’ valuations are independently drawn from identical distributions) that the conditions of Theorem 20.1 will be satisfied by any Bayesian Nash\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nAuctions\nbook\n313\nequilibrium of the first price auction and the weakly dominant strategy equilibriumof the second price sealed bid auction.\nPart 2: Revenue Equivalence of Dutch Auction and First Price AuctionTo see this, consider the situation facing a bidder in these two auctions. In eachcase, the bidder must choose how high to bid without knowing the other bidders’valuations. If he wins, the price he pays equals his own bid. This result is trueirrespective of which of the assumptions in the benchmark model apply. We pointout that the equilibrium in the underlying Bayesian game in the two cases here is aBayesian Nash equilibrium.\nPart 3: Revenue Equivalence of English Auction and Second Price AuctionThe outcomes of the English auction and the second price auction satisfy a weaklydominant strategy equilibrium. That is, each bidder has a well defined best responsebid regardless of how high he believes the other agents will bid. In the second priceauction, the weakly dominant strategy is to bid true valuation. In the Englishauction, the weakly dominant strategy is to remain in the bidding process until theprice reaches the bidder’s own valuation.First we analyze the English auction. Note that a bidder drops out as soon thegoing price exceeds his valuation. The second last bidder drops out as soon as theprice exceeds his own valuation. This leaves only one bidder in the fray and he winsthe auction. Note that the winning bidder’s valuation is the highest among all thebidders and he earns some payoff in spite of the monopoly power of the seller. Onlythe winning bidder knows how much payoff he receives because only he knows hisown valuation. Suppose the valuations of the n bidders are v(1) , v(2) , . . . , v(n) . Sincethe bidders are symmetric, these valuations are draws from the same distributionand without loss of generality, assume that these are in descending order. Thewinning bidder gets a payoff of v(1) − v(2) .Next we analyze the second price auction. In the second price auction, thebidder’s choice of bid determines only whether or not he wins; the amount he pays ifhe wins is beyond his control. We have already shown that each bidder’s equilibriumstrategy is to bid his valuation for the item. The payment here is equal to thetrue valuation of the bidder with the second highest valuation. Thus the expectedpayments and hence the expected revenue to the seller are the same in Englishauction and the second price auction.\u0004\nSome ObservationsWe now make a few important observations on the revenue equivalence theorem.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n314\nGame Theory and Mechanism Design\nEquivalence in ExpectationThe theorem does not imply that the outcomes of the four auction forms are alwaysexactly the same. They are only equal in expectation. Note that in the Englishauction or the second price auction, the price exactly equals the valuation of thebidder with the second highest valuation. In Dutch auction or the first price auction,the price is the expectation of the second highest valuation conditional on the winning bidder’s own valuation. The above two prices will be equal only by accident;however, they are equal in expectation.Variance of RevenueThe revenue equivalence theorem does not prescribe under what circumstances aparticular one among the four candidate auctions would serve the purpose best.When the assumptions of the benchmark model are relaxed, particular auction formsemerge as being superior.It has been shown in the literature that variance of revenue is lower in Englishauction or second price auction than in Dutch auction or first price auction. Henceif the seller were risk averse, he would choose English or second price rather thanDutch or first price.Bidding ComplexityThe bidding strategy is very simple in the English auction and the second priceauction. In the English auction, a bidder remains in bidding until the price reacheshis valuation. In the second price auction, he submits a sealed bid equal to hisown valuation. On the other hand, the bidding logic is quite complex in the Dutchauction and the first price auction. Here the bidder bids some amount less than histrue valuation. Exactly how much less depends upon the probability distributionof the other bidders’ valuations and the number of competing bidders. Finding theNash equilibrium bid is a non-trivial computational problem.20.5\nCombinatorial Auctions\nA combinatorial auction is one where the bids correspond to bundles or combinationsof different items. In a forward combinatorial auction, a bundle of different types ofobjects is available with the seller; the buyers are interested in purchasing certainsubsets of the items. In a reverse combinatorial auction, a bundle of different typesof objects is required by the buyer; several sellers are interested in selling subsetsof the objects to the buyer. There is a rich body of literature on combinatorialauctions, for example see the volume edited by Cramton, Shoham, and Steinberg[3].To illustrate a simple combinatorial auction, we provide an example below.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nAuctions\nbook\n315\nA\nB\nAB\nAgent 1\n*\n*\n10\nAgent 2Agent 3\n5*\n*5\n**\nTable 20.1: Valuations of agents for bundles in scenario 1\nGeneralized Vickrey AuctionGeneralized Vickrey auction (GVA) refers to an auction that results when the Clarkemechanism is applied to a combinatorial auction. Let a seller be interested in auctioning two items A and B. Let there be three buying agents {1, 2, 3}. With a slightabuse of notation, let us denote the subsets {A}, {B}, {A, B} by A, B, and AB,respectively. These are called combinations or bundles. Assume that the agentshave valuations for the bundles as shown in Table 20.1. In the above table, eachstarred entry indicates that the agent is not interested in that bundle. Note fromTable 20.1 that agent 1 values bundle AB at 10 and does not have any valuation forbundle A and bundle B. Agent 2 is only interested in bundle A and has a valuationof 5 for this bundle. Agent 3 is only interested in bundle B and has a valuation of5 for this bundle.If we apply the Clarke mechanism to this situation, the bids from the agents willbe identical to the valuations because of the DSIC property of the Clarke mechanism.There are two allocatively efficient allocations, namely: (1) allocate bundle AB toagent 1; (2) allocate bundle A to agent 2 and bundle B to agent 3. Each of theseallocations has a total value of 10. Suppose we choose allocation (2), which awardsbundle A to agent 2 and bundle B to agent 3. To compute the payments to be madeby agents 2 and 3, we have to use the Clarke payment rule. For this, we analyzewhat would happen in the absence of agent 2 and agent 3 separately. If agent 2is absent, the allocation will award the bundle AB to agent 1 resulting in a totalvalue of 10. Therefore, the Vickrey discount to agent 2 is 10 − 10 = 0, which meanspayment to be made by agent 2 is 5 + 0 = 5. Similarly the Vickrey discount toagent 3 is also 0 and the payment to be made by agent 3 is also equal to 5. Thetotal revenue to the seller is 5 + 5 = 10. Even if allocation (1) is chosen (that is,award bundle AB to agent 1), the total revenue to the seller remains as 10. This isa situation where the seller is able to capture the entire consumer surplus.A contrasting situation will result if the valuations are as shown in Table 20.2.In this case, the winning allocation is: award bundle A to agent 2 and bundle B toagent 3, resulting in a total value of 20. If agent 2 is not present, the allocation willbe to award bundle AB to agent 1, thus resulting in a total value of 10. Similarly, ifagent 3 were not present, the allocation would be to award bundle AB to agent 1,thus resulting in a total value of 10. This would mean a Vickrey discount of 10 each\nDecember 27, 2013\n11:21\n316\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nA\nB\nAB\nAgent 1\n*\n*\n10\nAgent 2Agent 3\n10*\n*10\n**\nTable 20.2: Valuations of agents for bundles in scenario 2\nA\nB\nAB\nAgent 1Agent 2\n*2\n**\n10*\nAgent 3\n*\n2\n*\nTable 20.3: Valuations of agents for bundles in scenario 3\nto agent 2 and agent 3, which in turn means that the payment to be made by agent2 and agent 3 is 0 each! This represents a situation where the seller will end upwith a zero revenue in the process of guaranteeing allocative efficiency and dominantstrategy incentive compatibility. Worse still, if agent 2 and agent 3 are both thefalse names of a single agent, then the auction itself is seriously manipulated!We now study a third scenario where the valuations are as described in Table20.3. Here, the allocation is to award bundle AB to agent 1, resulting in a totalvalue of 10. If agent 1 were absent, the allocation would be to award bundle A toagent 2 and bundle B to agent 3, which leads to a total value of 4. The Vickreydiscount to agent 1 is therefore 10−4 = 6, and the payment to be made by agent 1 is4. The revenue to the seller is also 4. Contrast this scenario with scenario 2, wherethe valuations of bidders 2 and 3 were higher, but they were able to win the bundlesby paying nothing. This shows that the GVA mechanism is not foolproof againstbidder collusion (in this case, bidders 2 and 3 can collude and deny the bundle toagent 1 and also seriously reduce the revenue to the seller).It has been shown that GVA has the desirable properties of DSIC, AE, WBB,and IR. However, in general, applying Clarke mechanism to combinatorial auctionsinvolves solving up to (n+1) winner determination problems, where n is the numberof agents. These problems are often NP-hardCombinatorial Auctions: To Probe FurtherCombinatorial auctions have found widespread applications in numerous networkeconomics situations. The edited volume by Cramton, Shoham, and Steinberg [3] isa comprehensive source of information on different aspects of combinatorial auctions.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nAuctions\nbook\n317\nThere are also many survey articles on combinatorial auctions. These include: deVries and Vohra [7], Pekec and Rothkopf [8], Narahari and Dayama [10], and Blumrosen and Nisan [11].20.6\nSummary and References\nIn this chapter, we have looked into various aspects of auctions and auction design.Specifically, we have covered the following topics.• Desirable properties of auctions, based on the context, include incentive compatibility, allocative efficiency or welfare maximization, budget balance, individualrationality, revenue maximization (or cost minimization), etc.• There are numerous types of auctions: single item - single unit; single item multiunit; multi-item - single unit; multi-item - multiunit; multi-attribute, etc.• For auctioning a single indivisible item, four canonical auctions are commonlyconsidered: English auction, Dutch auction, first price sealed bid auction, second price sealed bid auction (Vickrey auction). The revenue equivalence theorem states that these four auctions produce the same expected revenue to theauctioneer under a standard benchmark model. For more details on the revenue equivalence theorem, the reader is referred to the papers by Myerson [12],McAfee and McMillan [4], Klemperer [13], and the books by Milgrom [2] andKrishna [1].• Combinatorial auctions represent auctions for multiple item types. The generalized Vickrey auction (GVA) is essentially the Clarke mechanism applied tocombinatorial auctions.We must mention here that we have covered in this chapter only a few keyresults in auctions. In fact, we have only covered a limited variety of auctions inthis chapter. For more details on auctions, there are excellent survey articles [4,5, 6] and books [1, 2, 3] devoted to auctions. Recent survey papers have focusedon combinatorial auctions [7, 8, 9, 10]. Procurement auctions are very popular inindustrial settings. A survey as well as a case study appear in [14].In the next chapter, we discuss optimal auctions which maximize revenue orminimize cost to the auctioneer subject to incentive compatibility and individualrationality. In the chapter following that, we present the case study of sponsoredsearch auctions on the web and bring out the role of mechanism design in creatingthese auctions.References[1][2]\nVijay Krishna. Auction Theory. Academic Press, San Diego, California, USA, 2002.Paul Milgrom. Putting Auction Theory to Work. Cambridge University Press, Cambridge,UK, 2004.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n318\nGame Theory and Mechanism Design\n[3]\nP. Cramton, Y. Shoham, and R. Steinberg (Editors). Combinatorial Auctions. The MIT Press,Cambridge, Massachusetts, 2005.R. P. McAfee and J. McMillan. “Auctions and bidding”. In: Journal of Economic Literature25(2) (1987), pp. 699–738.P. Milgrom. “Auctions and bidding: A primer”. In: Journal of Economic Perspectives 3(3)(1989), pp. 3–22.E. Wolfstetter. “Auctions: An introduction”. In: Economic Surveys 10 (1996), pp. 367–421.S. de Vries and R.V. Vohra. “Combinatorial auctions: A survey”. In: INFORMS Journal ofComputing 15(1) (2003), pp. 284–309.A. Pekec and M.H. Rothkopf. “Combinatorial auction design”. In: Management Science 49(2003), pp. 1485–1503.J.R. Kalagnanam and D.C. Parkes. “Auctions, bidding, and exchange design”. In: Handbookof Quantitative Supply Chain Analysis: Modeling in the E-Business Era. Ed. by D. SimchiLevi, S.D. Wu, and Z.J. Shen. Kluwer Academic Publishers, New York, 2005.Y. Narahari and P. Dayama. “Combinatorial auctions for electronic business”. In: Sadhana- Indian Academy Proceedings in Engineering Sciences 30(3) (2003), pp. 179–212.L. Blumrosen and N. Nisan. “Combinatorial auctions”. In: Algorithmic Game Theory. Ed.by Noam Nisan, Tim Roughgarden, Eva Tardos, and Vijay Vazirani. Cambridge UniversityPress, 2007, pp. 267–300.Roger B. Myerson. “Optimal auction design”. In: Mathematics of Operations Research 6(1)(1981), pp. 58–73.P. Klemperer. “Why every economist should learn some auction theory”. In: Advances inEconomics and Econometrics: Invited Lectures to 8th World Congress of the EconometricSociety. Ed. by M. Dewatripont, L. Hansen, and S. Turn ovsky. Cambridge University Press,Cambridge, UK, 2003.Charles H. Rosa Devadatta Kulkarni Pankaj Dayama T.S. Chandrashekar Y. Narahari andJeffrey D. Tew. “Auction based mechanisms for electronic procurement”. In: IEEE Transactions on Automation Science and Engineering 4(3) (2006), pp. 297–321.\n[4][5][6][7][8][9]\n[10][11]\n[12][13]\n[14]\n20.7\nExercises\n(1) (Second price auction with budget). Consider a second price auction for a singleindivisible item. Suppose each bidder i has a value vi > 0 and a budget ci > 0.If a bidder wins the object and has to pay higher than the budget, the bidderwill simply drop out from the auction but is charged with a small penalty \u000f > 0.Compute a bid in the auction for each player i which will be a weakly dominantstrategy for the player.(2) Consider a single-item, multi-unit exchange with two selling agents and two buying agents. The selling agents specify marginally decreasing, piecewise constantasks and buying agents specify marginally decreasing, piecewise constant bids.It is required to maximize the total surplus (total receipts minus total paymentsby the exchange). The asks received from the sellers are:Ask-1: ((1-50, 10), (51-150, 8), (151-200, 6))(the above means unit price of Rs. 10 for the 50 items;unit price of Rs. 8 for the next 100 items;unit price of Rs. 6 for the next 50 items)\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nAuctions\nbook\n319\nAsk-2: ((1-50, 12), (51-100, 10), (101-200, 6))The bids received from the buying agents are:Bid-1: ((1-50, 12), (51-100, 11), (101-150, 10))Bid-2: ((1-75, 12), (76-150, 10))Assume that Clarke mechanism is used. For this problem:• Compute a surplus maximizing allocation for the given bids.• What is the payment required to be made by the two buyers?• What is the payment received by the two sellers?(3) The GVA mechanism is used by a buyer for procuring a bundle {A, B, C, D, E}.The following are the bids received from 5 sellers.• Seller 1: (A, 20), (B, 30), (AB, 45)• Seller 2: (B, 25), (C, 35), (BC, 50)• Seller 3: (C, 30), (D, 40), (CD, 60)• Seller 4: (D, 35), (E, 45), (DE, 70)• Seller 5: (E, 40), (A, 15), (EA, 50)Assume XOR bids (that is, at most one bid will be selected from any seller).Compute the allocation and the payments that the winning bidders will receive.Is this mechanism individually rational? Why?(4) Apply the GVA mechanism to the following combinatorial auction scenario.There are three bidders and two objects. The valuation matrix is as follows.\nBidder 1Bidder 2Bidder 3\n{1}\n{2}\n{1,2}\n688\n1050\n1089\n(5) Programming Project. It would be useful to set up a web-based auction houseto implement a variety of auctions. Such a platform will enable experimentingwith various auction mechanisms.\nJanuary 3, 2014\n11:48\nWorld Scientific Book - 10.25in x 7.5in\nThis page intentionally left blank\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nbook\nChapter 21\nOptimal Mechanisms and Myerson Auction\nIn this chapter, we introduce the notion of an optimal mechanism and discuss indetail a particular case of an optimal auction for selling a single indivisible object.The Myerson auction is a well known mechanism to solve this problem. Thisauction proposes an allocation policy and a payment protocol for maximizing theexpected revenue of the seller ensuring at the same time that incentive compatibilityand individual rationality properties are satisfied.\n21.1\nOptimal Mechanisms\nA key problem that a social planner is faced with is to decide which direct revelationmechanism (or equivalently, social choice function) is optimal for a given problem.We now attempt to formalize the notion of optimality of social choice functions andoptimal mechanisms.Social Utility FunctionWe first define the concept of a social utility function.Definition 21.1 (Social Utility Function). A social utility function is a mapping w : Rn → R that aggregates each profile (u1 , . . . , un ) ∈ Rn of individual utilityvalues of the agents into a social utility.Consider a mechanism design problem and a direct revelation mechanism D =((Θi )i∈N , f (·)) proposed for the problem. Let (θ1 , . . . , θn ) be the type profile of theagents and assume for a moment that they will all reveal their true types whenrequested by the planner. In such a case, the social utility that would be realizedby the social planner for a type profile θ of the agents is given by:w(u1 (f (θ), θ1 ), . . . , un (f (θ), θn )).\n(21.1)\nHowever, the agents, being strategic, may not reveal their true types unless it is abest response for them to do so. In general, rationality of the agents implies thatthe agents report their types according to a strategy suggested by an equilibriums∗ (·) = (s∗1 (·), . . . , s∗n (·)) of the Bayesian game induced by the mechanism. In such a321\nDecember 27, 2013\n11:21\n322\nWorld Scientific Book - 10.25in x 7.5in\nbook\nGame Theory and Mechanism Design\ncase, the social utility that would be realized by the social planner for a type profileθ of the agents is given byw(u1 (f (s∗ (θ)), θ1 ), . . . , un (f (s∗ (θ)), θn )).(21.2)In some instances, the above equilibrium, if one exists, may turn out to be a dominant strategy equilibrium. In general, it is a Bayesian Nash equilibrium. It will beperfect if any of these equilibria corresponds to truthful reporting of types by allthe players.Optimal Mechanism Design ProblemIn view of the above notion of a social utility function, it is clear that the objectiveof a social planner would be to look for a social choice function f (·) that wouldmaximize the expected social utility for a given social utility function w(·), subjectto certain natural and reasonable constraints. The desirable constraints may includeany combination of all the previously studied properties of a social choice function,such as ex-post efficiency, incentive compatibility, and individual rationality. Thisset of social choice functions is known as a set of feasible social choice functionsand is denoted by F . Thus, the problem of a social planner can now be cast as anoptimization problem where the objective is to maximize the expected social utility,and the constraint is that the social choice function must be chosen from the feasibleset F . This problem is known as the optimal mechanism design problem and thesolution of the problem would be a social choice function f ∗ (·) ∈ F , which is used todefine the optimal mechanism D ∗ = ((Θi )i∈N , f ∗ (·)) for the problem being studied.Depending on whether the agents are honest or rational entities, the optimalmechanism design problem will take one of two different forms.maximizeEθ [w(u1 (f (θ), θ1 ), . . . , un (f (θ), θn ))]f (·) ∈ F\n(21.3)\nmaximizeEθ [w(u1 (f (s∗ (θ)), θ1 ), . . . , un (f (s∗ (θ)), θn ))](21.4)f (·) ∈ FThe problem (21.3) is relevant when the agents are honest and always reveal theirtrue types whereas the problem (21.4) is relevant when the agents are strategic. Onemight ask how to define the set of feasible social choice functions F . There is nounique definition of this set and it is mostly based on a subjective judgment of thesocial planner and on the problem being modeled. The choice of the set F dependson the desirable properties the social planner would wish to have in the optimalsocial choice function f ∗ (·). The various choices include:FDSIC = {f : Θ → X|f (·) is dominant strategy incentive compatible}FBIC = {f : Θ → X|f (·) is Bayesian incentive compatible}FEPIR = {f : Θ → X|f (·) is ex-post individual rational}FIIR = {f : Θ → X|f (·) is interim individual rational}\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nOptimal Mechanisms and Myerson Auction\nbook\n323\nFEAIR = {f : Θ → X|f (·) is ex-ante individual rational}FEPE = {f : Θ → X|f (·) is ex-post efficient} .\nThe set of feasible social choice functions F may be either any one of the above setsor intersection of any combination of the above sets.21.2\nMyerson’s Optimal Auction\nMyerson’s optimal auction [1] is a landmark result in mechanism design theory.TMyerson chooses F = FBIC FIIR as the set of feasible social choice functions. Inthe literature, this particular feasible set is known as incentive feasible set due toMyerson [1]. Note that if the agents are honest, then the sets FDSIC and FBIC will beequal to the whole set of all the social choice functions. If the agents are strategic,Tthe set F = FBIC FIIR is an appropriate choice for a feasible set. BIC ensuresincentive compatibility that is not too strong to be satisfied and so is reasonable. IIRassumes that players know their types but do not know the types of the other players(which is quite realistic) and guarantees that every player participates voluntarily.In this section, we specifically consider the problem of a seller (also the auctioneerin this case) who would like to auction a single indivisible object and assume thatthere are n buying agents or bidders (N = {1, . . . , n}) interested in the object.Suppose there is no reserve price (minimum price below which the auctioneer is notprepared to sell the object). The objective here is to maximize the expected revenueof the auctioneer. We discuss an optimal mechanism developed by Myerson [1] forthis problem.We assume that each bidder i’s type (valuation for the object) lies in an intervalΘi = [θi , θi ]. We impose the following additional conditions.(1) The auctioneer and the bidders are risk neutral (see Section 8.6 for more details).(2) The types of the bidders are statistically independent, that is, the joint densityφ(·) has the form φ1 (·) × . . . × φn (·)(3) φi (·) > 0 ∀ i = 1, . . . , n(4) We consider a general form of the outcome set X by allowing a random assignment of the object. We consider yi (θ) to be buyer i’s probability of getting theobject when the vector of announced types is θ = (θ1 , . . . , θn ). Thus, the newoutcome set is given by(X=\n(y0 , . . . , yn , t0 , . . . , tn )|y0 ∈ [0, 1], t0 ≥ 0, yi ∈ [0, 1], ti ≤ 0 ∀ i = 1, . . . , n,nXi=1\nyi ≤ 1;\nnXi=0\n)ti = 0\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n324\nGame Theory and Mechanism Design\nPNote that the condition ni=1 yi < 1 will imply that there is no trade. The utilityfunctions of the agents i = 1, . . . , n are given byui (f (θ), θi ) = ui ((y0 (θ), . . . , yn (θ), t0 (θ), . . . , tn (θ)), θi ) = θi yi (θ) + ti (θ)Viewing yi (θ) = vi (k(θ)) (where k(θ) is the project choice corresponding to typeprofile θ) in conjunction with the second and third conditions above, we can claimthat the underlying environment here is linear (see Section 19.7 for definition oflinear environment).In the above example, the seller or the auctioneer is the social planner lookingfor an optimal direct revelation mechanism to sell the object. Myerson’s [1] idea wasthat the auctioneer must use a social choice function which is Bayesian incentivecompatible and interim individual rational and would fetch the maximum expectedrevenue to the auctioneer. Thus, in this problem, the set of feasible social choiceTfunctions is given by F = FBIC FIIR . The objective is to maximize the totalexpected revenue of the seller which is given by#\" nXti (θ)Eθ [w(u1 (f (θ), θ1 ), . . . , un (f (θ), θn ))] = −Eθi=1\nNote that in the above objective function, we have used f (θ) and not f (s∗ (θ)).This is because in the set of feasible social choice functions, we are considering onlyBIC social choice functions and for these functions we have s∗ (θ) = θ ∀ θ ∈ Θ.Thus, Myerson’s optimal auction design problem can be formulated as the followingoptimization problem.\" n#Xmaximizeti (θ)(21.5)− Eθf (·) ∈ Fi=1whereF = {f (·) = (y1 (·), . . . , yn (·), t1 (·), . . . , tn (·))|f (·) is BIC and IIR} .We now invoke Myerson’s characterization theorem (Section 19.7) to the abovesituation. First we recall the following notation:• ti (θ̂i ) = Eθ−i [ti (θ̂i , θ−i )] is bidder i’s expected transfer when he announces histype to be θ̂i and that all the bidders j 6= i truthfully reveal their types;• yi (θ̂i ) = Eθ−i [yi (θ̂i , θ−i )] is the expected probability that bidder i would receivethe object given that he announces his type to be θ̂i and all bidders j 6= itruthfully reveal their types; and• Ui (θi ) = θi yi (θi ) + ti (θi ) (we can take unconditional expectation because typesare independent).We can say that an SCF f (·) in the above context would be BIC iff it satisfiesthe following two conditions(1) yi (·) is non-decreasing in θi for all i = 1, . . . , n\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nbook\nOptimal Mechanisms and Myerson Auction\n(2) Ui (θi ) = Ui (θi ) +\nRθi\n325\nyi (s)ds ∀ θi ∈ Θi ; ∀ i = 1, . . . , n\nθi\nAlso, we can invoke the definition of interim individual rationality to assert thatthe SCF f (·) in the above context would be interim IR iff it satisfies the followingconditionsUi (θi ) ≥ 0 ∀θi ∈ Θi ; ∀ i = 1, . . . , nwhere it is assumed that the expected utility of not participating in the mechanismis 0.In view of the above setup, the optimal auction design problem (21.5) can berewritten as follows.θi\nn ZXmaximize(θi yi (θi ) − Ui (θi )) φi (θi )dθi(yi (·), Ui (·))i∈N i=1\n(21.6)\nθi\nsubject to(i) yi (·) is non-decreasing in θi ∀ i = 1, . . . , nP(ii) yi (θ) ∈ [0, 1], ni=1 yi (θ) ≤ 1 ∀i = 1, . . . , n, ∀ θ ∈ ΘRθi(iii) Ui (θi ) = Ui (θi ) + yi (s)ds ∀ θi ∈ Θi ; ∀ i = 1, . . . , nθi\n(iv) Ui (θi ) ≥ 0 ∀ θi ∈ Θi ; ∀ i = 1, . . . , nWe first note that if constraint (iii) is satisfied then constraint (iv) will be satisfiediff Ui (θi ) ≥ 0 ∀ i = 1, . . . , n. As a result, we can replace the constraint (iv) with(iv’) Ui (θi ) ≥ 0 ∀ i = 1, . . . , nNext, substituting for Ui (θi ) in the objective function from constraint (iii), we getθiθiZZnX θi yi (θi ) − Ui (θi ) − yi (s)ds φi (θi )dθii=1 θ\nθi\ni\nIntegrating by parts the above expression, the auctioneer’s problem can be writtenas one of choosing the yi (·) functions and the values U1 (θ1 ), . . . , Un (θn ) to maximizeZθ1...θ1\nZθn \"Xnθn\ni=1\nyi (θi )Ji (θi )\n#\" nYi=1\n#φi (θi ) dθn . . . dθ1 −\nnXi=1\nsubject to constraints (i), (ii), and (iv’), where\u0012\u0013 \u0012\u0013Φi (θi )1 − Φi (θi )Ji (θi ) = θi −= θi −φi (θi )φi (θi )\nUi (θi )\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n326\nbook\nGame Theory and Mechanism Design\nwhere, Φi (·) is the cumulative distribution function corresponding to the densityφi (·) and we denote Φi (θi ) = 1 − Φi (θi ). The quantities Ji (θi )’s are called virtualvaluations. It is evident that solution must have Ui (θi ) = 0 for all i = 1, . . . , n.Hence, the auctioneer’s problem reduces to choosing functions yi (·) to maximize#\" n#Zθ1 Zθn \"XnYyi (θi )Ji (θi )φi (θi ) dθn . . . dθ1...θ1\nθn\ni=1\ni=1\nsubject to constraints (i) and (ii).Let us ignore constraint (i) for the moment. Then inspection of the above expression indicates that yi (·) is a solution to this relaxed problem iff for all i = 1, . . . , n,we have(0 : if Ji (θi ) < max {0, maxh6=i Jh (θh )}(21.7)yi (θ) =1 : if Ji (θi ) > max {0, maxh6=i Jh (θh )}Note that Ji (θi ) = max {0, maxh6=i Jh (θh )} is a zero probability event.In other words, if we ignore the constraint (i), then, yi (·) is a solution to thisrelaxed problem iff the object is allocated to a bidder who has highest non-negativevalue for Ji (θi ). Now, recall the definition of yi (·). It is easy to write down thefollowing expressionyi (θi ) = Eθ−i [yi (θi , θ−i )]\n(21.8)\nNow, if we assume that Ji (·) is non-decreasing in θi then it is easy to see thatabove solution yi (·), given by (21.7), will be non-decreasing in θi , which in turnimplies, by looking at expression (21.8), that yi (·) is non-decreasing in θi . Thus, thesolution to this relaxed problem actually satisfies constraint (i) under the assumptionthat Ji (·) is non-decreasing. Assuming that Ji (·) is non-decreasing, the solutiongiven by (21.7) seems to be the solution of the optimal mechanism design problem.The condition that Ji (·) is non-decreasing in θi is met by many of the commondistribution functions, for example, uniform and exponential.So far we have computed the allocation rule for the optimal mechanism and nowwe turn our attention to the payment rule. The payment rule ti (·) must satisfy∀i ∈ N ,Zθiti (θi ) = Eθ−i [ti (θi , θ−i )] = Ui (θi ) − θi yi (θi ) =\nyi (s)ds − θi yi (θi )\n(21.9)\nθi\nLooking at the above formula, we can say that if the payment rule ti (·) satisfies thefollowing formula (21.10), then it would also satisfy the formula (21.9).Zθiti (θi , θ−i ) =\nyi (s, θ−i )ds − θi yi (θi , θ−i ) ∀ θ ∈ Θθi\n(21.10)\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nOptimal Mechanisms and Myerson Auction\nbook\n327\nThe above formula can be rewritten more intuitively, as follows. For any vector θ−i ,let us definezi (θ−i ) = inf {θi |Ji (θi ) > 0 and Ji (θi ) ≥ Jj (θj ) ∀ j 6= i}Then zi (θ−i ) is the infimum of all winning bids for bidder i against θ−i , so(1 : if θi > zi (θ−i )yi (θi , θ−i ) =0 : if θi < zi (θ−i )This gives usZθi\n(yi (s, θ−i )ds =\nθi\nθi − zi (θ−i )0\nFinally, the formula (21.10) becomes(−zi (θ−i )ti (θi , θ−i ) =0\n: if θi ≥ zi (θ−i ): if θi < zi (θ−i )\n: if θi ≥ zi (θ−i ): if θi < zi (θ−i )\nThat is bidder i must pay only when he is allocated the object and he pays anamount equal to his lowest possible winning bid. This completes the specificationof the payment rule.Some Observations on Myerson’s AuctionMonotone Assumption on Virtual ValuationsThe assumption that the virtual valuation function Ji (·) is monotone non-decreasingin θi (i = 1, . . . , n) is satisfied if each of the distributions φi (·) is such that its hazardrate:φi(1 − Φi )is monotone increasing. This condition is satisfied by many popular distributionssuch as uniform and exponential. In case this assumption is violated, there is awork-around using the so called ironing procedure described by Myerson [1]. Theidea is to use a nearest monontonic transformation of the virtual valuations insteadof the actual virtual valuations.Myerson’s Auction is DSICWhile formulating the optimal auction problem, the incentive compatibility requirement is only BIC. However, it turns out that the Myerson auction is in fact DSIC[1] which is a happy byproduct of the way the auction is designed.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n328\nGame Theory and Mechanism Design\nMyerson’s Auction is not Allocatively EfficientWhen the various bidders have differing distribution function Φi (·) then, the bidder who has the largest value of Ji (θi ) is not necessarily the bidder who has bidthe highest amount for the object. Thus Myerson’s optimal auction need not beallocatively efficient and therefore, need not be ex-post efficient.Symmetric BiddersIf the bidders are symmetric, that is, Θ1 = . . . = Θn = Θ and Φ1 (·) = . . . = Φn (·) =Φ(·), then the allocation rule would be precisely the same as that of first price andsecond price auctions. In such a case the object would be allocated to the highestbidder. In such a situation, the optimal auction would also become allocativelyefficient. Also, note that in such a case the payment rule that we described abovewould coincide with the payment rules in second price auction. In other words, thesecond price auction (Vickrey auction) is the optimal auction when the bidders aresymmetric. Therefore, many a time, the optimal auction is also known as modifiedVickrey auction.21.3\nEfficient Optimal Auctions\nKrishna and Perry [2] have argued in favor of an auction which will maximize therevenue subject to AE, DSIC, and IIR constraints. The Green Laffont theorem(Chapter 18) tells us that any DSIC and AE mechanism is necessarily a VCG mechanism. So, we have to look for a VCG mechanism which will maximize the revenueto the seller. Krishna and Perry [2] define social utility as the value of an efficientallocation:nXvj (k ∗ (θ), θj )SW (θ) =j=1\nSW−i (θ) =\nX\nvj (k ∗ (θ), θj )\nj6=i\nWith these functions, we can write the payment rule in Clarke’s pivotal mechanismasti (θ) = SW−i (0, θ−i ) − SW−i (θ)That is, payment by the agent i is the externality he is imposing by reportingtype to be θi rather than zero. The authors of [2] generalize it. Fix a vector,s = (s1 , s2 , . . . , sn ) ∈ Θ called as basis because it defines the payment rule. TheVCG mechanism with basis s is defined byti (θ|si ) = SW (si , θ−i ) − SW−i (θ)\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nOptimal Mechanisms and Myerson Auction\nbook\n329\nIt can be seen that this new mechanism is also DSIC. Now choosing an appropriatebasis, one can always find an optimal auction in the class of VCG mechanisms.Krishna and Perry [2] have shown that the classical Vickrey auction is an optimaland efficient auction for a single indivisible item. They have also shown that theVickrey auction is an optimal one among VCG mechanisms for multiunit auctions,when all the bidders have downward sloping demand curves.21.4\nSummary and References\nIn this chapter, we have described the Myerson auction which represents an important result in mechanism design theory. The Myerson auction maximizes theexpected revenue of an auctioneer (or seller) who seeks to allocate a single indivisible item to one of a set of bidders, subject to Bayesian incentive compatibility andinterim individual rationality. In fact, it turns out that the auction is also DSICthough it may not be allocatively efficient. When the bidders are symmetric, theMyerson auction turns out to be AE and in fact the same as the Vickrey auction.The Myerson auction can also be developed for buying a single indivisible item.Before describing the Myerson auction, we set up the optimal mechanism designproblem. An appropriate feasible set of mechanisms for determining an optimalmechanism is the so called incentive feasible set which is the set of all SCFs thatare BIC as well as interim individual rational.After describing the Myerson auction, we briefly described efficient optimal auctions which are auctions that maximize the revenue subject to AE, DSIC, and IIR.Vickrey auction again turns out to be an efficient optimal auction for a single indivisible item.For a detailed treatment of the Myerson auction, the classic paper by Myerson[1] and the excellent textbook by Vijay Krishna [2] are highly recommended.Riley and Samuelson [3] also independently studied the problem of design of anoptimal auction for selling a single indivisible object. They assume the bidders tobe symmetric.The Myerson optimal mechanism for the reverse auction setting has been presented in the monograph by Narahari, Garg, Narayanam, and Prakash [4].The Myerson auction has been extended and enhanced in many ways in the context of many applications. The next chapter (Chapter 22) discusses an applicationand extension of the Myerson auction to the problem of sponsored search auctions.References[1][2]\nRoger B. Myerson. “Optimal auction design”. In: Mathematics of Operations Research 6(1)(1981), pp. 58–73.Vijay Krishna. Auction Theory. Academic Press, San Diego, California, USA, 2002.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n330\nGame Theory and Mechanism Design\n[3]\nJ.G. Riley and W.F. Samuelson. “Optimal auctions”. In: American Economic Review 71(3)(1981), pp. 383–392.Y. Narahari, Dinesh Garg, Ramasuri Narayanam, and Hastagiri Prakash. Game TheoreticProblems in Network Economics and Mechanism Design Solutions. Springer, London, 2009.\n[4]\n21.5\nExercises\n(1) Consider a sealed bid auction with one seller and two buying agents. There is asingle indivisible item which the seller wishes to sell. The bidders are symmetricwith independent private values distributed uniformly over [0, 1]. Whoever bidshigher will be allocated the item. For this auction:• What is the equilibrium bidding strategy of a bidder in the first price auction?• What is the expected revenue in the first price auction?• What is the expected revenue in the second price auction?• What is the expected revenue in the Myerson auction?(2) Myerson auction is clearly Bayesian incentive compatible (since it is one of theconstraints). The Myerson auction has also be shown to be dominant strategyincentive compatible. Attempt a proof of this.(3) Develop the Myerson auction for the case of a reverse auction where an auctioneer wishes to buy an indivisible object to minimize the expected cost subject toBIC and IIR constraints (Hint: see [4]).(4) Examine the difficulties encountered in applying Myerson auction to the casewhen instead of one single indivisible object, we have multiple identical objects.In particular, look at the case when you have two objects.\nbook\n December 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nChapter 22\nMechanism Design for Sponsored SearchAuctions\nThe sponsored search auction problem was introduced briefly as an example inChapter 1. In this chapter, we study this problem in more detail to demonstrate acompelling application of mechanism design. We first present a mechanism designformulation of this problem. Using this formulation, we describe two well knownmechanisms for sponsored search auctions – generalized second price (GSP) andVickrey-Clarke-Groves (VCG). We then present an optimal auction mechanism(OPT) which is an extension of the Myerson’s optimal auction mechanism discussed in the previous chapter. The OPT mechanism maximizes the search engine’s expected revenue subject to Bayesian incentive compatibility and individualrationality of the bidders. We then make a comparative study of GSP, VCG, andOPT mechanisms. This chapter is based on the paper [1] and also on Chapter 3 in[2].\nThe advertisers-supported web site is one of the successful business models in the weblandscape. In a relatively short time, advertising on the Internet has been embracedby advertisers and marketers across all industry sectors. Sponsored search is now akey determinant of revenue performance of any search engine company. Our interestin this chapter lies in studying sponsored search based advertising as a mechanismdesign problem.22.1\nSponsored Search Auction\nWhen an Internet user (which we will sometimes refer to as the user, searcher, orcustomer) enters a keyword (that is a search phrase) into a search engine, the usergets back a page with results, containing both the links most relevant to the queryand the sponsored links, that is, paid advertisements . When a sponsored link isclicked, the user is sent to the respective advertiser’s web page. The advertiser thenpays the search engine a certain amount of money for directing the user to its webpage. Figure 22.1 depicts the result of a search performed on Google using thekeyword camera. There are two different stacks – the left stack contains links thatare most relevant to the query term, and the right stack contains the sponsored links.Often, a few sponsored links are placed immediately above of the search results.These sponsored links are clearly distinguishable from the actual search results.331\nbook\nDecember 27, 2013\n11:21\n332\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nHowever, the visibility of a sponsored search link depends on its location (slot)on the result page. Typically, a number of merchants (advertisers) are interested\nFig. 22.1: Result of a search performed on Google\nin advertising alongside the search results of a keyword. However, the number ofslots available to display the sponsored links is limited. Therefore, against everysearch performed by the user, the search engine faces the problem of matching theadvertisers to the slots. In addition, the search engine also needs to decide on a priceto be charged to each advertiser. An advertiser naturally prefers a slot with highervisibility. Hence, search engines need a system for allocating the slots to advertisersand deciding on a price to be charged to each advertiser. Due to increasing demandsfor advertising space, most search engines are currently using auction mechanismsfor this purpose. These auctions are called sponsored search auctions. In a typicalsponsored search auction, advertisers are invited to submit bids on keywords, that is,the maximum amount they are willing to pay for a user clicking on the advertisement(ad for short). This is typically referred by the term Cost-Per-Click (CPC). Basedon the bids submitted by the advertisers for a particular keyword, the search engine(which we will sometimes refer to as the auctioneer or the seller) picks a subset ofadvertisements along with the order in which to display them. The actual pricecharged also depends on the bids submitted by the advertisers.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nMechanism Design for Sponsored Search Auctions\n22.2\nbook\n333\nSponsored Search Auction as a Mechanism Design Problem\nConsider a search engine that has received a query from a user, and it immediatelyfaces the problem of invoking an auction for selling its advertising space among theavailable advertisers for this particular query word. Let us assume the following.(1) There are n advertisers interested in this particular keyword, and N ={1, 2, . . . , n} represents the set of these advertisers. Also, there are m slots available with search engine to display the ads and M = {1, 2, . . . , m} represents theset of these advertising slots.(2) αij is the probability that a user will click on the ith advertiser’s ad if it isdisplayed in j th position (slot), where the first position refers to the top mostposition. We assume that αij satisfy the following condition:1 ≥ αi1 ≥ αi2 ≥ . . . ≥ αim ≥ 0 ∀i ∈ N.\n(22.1)\nNote, here we are assuming that click probability αij does not depend on whichother advertiser has been allocated to what other position. We refer to thisassumption as absence of allocative externality among the advertisers.(3) Each advertiser precisely knows the value derived out of each click performedby any user on his ad. We assume this value is independent of the position ofthe ad and only depends on whether a user clicks on the ad or not. However,the advertiser does not know the values derived by the other advertisers outof a single user-click. Formally, this is modeled by supposing that advertiser iobserves a parameter or signal θi that represents his value for each user click.The parameter θi is referred to as advertiser i’s type. The set of possible typesof advertiser i is denoted by Θi .(4) Each advertiser perceives any other advertiser’s valuation as a draw from someprobability distribution. Similarly, each advertiser knows that the other advertisers regard his own valuation as a draw from some probability distribution.More precisely, for advertiser i, i = 1, 2, . . . , n, there is some cumulative distribution function Φi (·) from which he draws his valuation θi . Let φi (·) be thecorresponding probabilityfunction. We\u0003\u0002 assume\u0003 that θi takes values from\u0002 densitya closed real interval θi , θi . That is, Θi = θi , θi . We also assume that anyadvertiser’s valuation is statistically independent from any other advertiser’svaluation. That is, Φi (·), i = 1, 2, . . . , n are mutually independent. We refer tothis assumption as independent private values assumption.(5) Each advertiser i is rational and intelligent in the sense of maximizing an expected value of a utility function ui : X × Θi → R, where X is the set ofoutcomes, which will be defined shortly.(6) The probability distribution functions Φi (·), the type sets Θ1 , . . . , Θn , and theutility functions ui (·) are common knowledge among the advertisers. Note thatutility function ui (·) of advertiser i depends on both the outcome x and thetype θi . Although the type θi is not common knowledge, by saying that ui (·)\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n334\nbook\nGame Theory and Mechanism Design\nis common knowledge we mean that for any given type θi , the auctioneer (thatis, search engine in this case) and every other advertiser can evaluate the utilityfunction of advertiser i.In view of the above modeling assumptions, the sponsored search auction problemcan now be precisely stated as follows. For any search phrase, each interestedadvertiser i, bids an amount bi ≥ 0, which depends on his actual type θi . Now eachtime the search engine receives this search phrase, the search engine determines,based on the bid vector (b1 , . . . , bn ), (a) the winning advertisers along with theorder in which their ads will be displayed against the search results and (b) theamount that will be paid by each advertiser if the user clicks on his ad. These arecalled allocation and payment rules, respectively. A sponsored search auction canbe viewed as an indirect mechanism M = ((Bi )i∈N , g(·)), where Bi ⊂ R+ is theset of bids that an advertiser i can ever report to the search engine and g(·) is theallocation and payment rule. Note, if we assume that for each advertiser i, the setof bids Bi is the same as type set Θi , then indirect mechanism M = ((Bi )i∈N , g(·))becomes a direct revelation mechanism D = ((Θi )i∈N , f (·)), where f (·) becomesthe allocation and payment rule. In the rest of this chapter, we will assume thatBi = Θi ∀ i = 1, . . . , n. Thus, in view of this assumption, we can regard a sponsoredsearch auction as a direct revelation mechanism.The various components of a typical sponsored search mechanism design problemare listed below.Outcome Set XAn outcome in the case of a sponsored search auction may be represented by avector x = (yij , pi )i∈N,j∈M , where yij is the probability that advertiser i is allocatedto the slot j, and pi denotes the price-per-click charged from advertiser i. The setof feasible alternatives is thenmnXXyij ≤ 1 ∀i ∈ N,yij ≤ 1 ∀j ∈ M,X = (yij , pi )i∈N,j∈M yij ∈ [0, 1] ∀i ∈ N, ∀j ∈ M ;i=1\nj=1\npi ≥ 0 ∀i ∈ N } .\nNote that randomized outcomes are also included in the above outcome set. Thisimplies that randomized mechanisms are also part of the design space.Utility Function of Advertisers ui (·)The utility function of advertiser i can be given, for x = (yij , pi )i∈N,j∈M , bymXyij αij  (θi − pi ).ui (x, θi ) = j=1\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nMechanism Design for Sponsored Search Auctions\nbook\n335\nSocial Choice Function f (·) (Allocation and Payment Rules)The general structure of the allocation and payment rule for this case isf (b) = (yij (b), pi (b))i∈N,j∈Mwhere b = (b1 , . . . , bn ) is a bid vector of the advertisers. The functions yij (·) formthe allocation rule, and the functions pi (·) form the payment rule.Linear EnvironmentThrough a slight modification in the definition of allocation rule, payment rule, andutility functions, we can show that a sponsored search auction is indeed a directrevelation mechanism in a linear environment (see Section 19.7). To transform theunderlying environment to a linear one, we redefine the allocation and payment ruleas below.f (b) = (y(b), ti (b))i∈N,j∈M\u0011\u0010Pmy(b)αwhere y(b) = (yij (b))i∈N,j∈M and ti (b) =ij pi (b). The quantity ti (b)j=1 ijcan be viewed as the expected payment made by the advertiser i to the search engineagainst every search query received by the search engine, and when the bid vectorof the advertisers is b = (b1 , . . . , bn ).Now, we can rewrite the utility functions in following manner:ui (f (b), θi ) = θi vi (y(b)) − ti (b)\u0010P\u0011my(b)αwhere vi (y(b)) =. The quantity vi (y(b)) can be interpreted asijijj=1the probability that advertiser i will receive a user click whenever there is a searchquery received by the search engine and when the bid vector of the advertisers isb = (b1 , . . . , bn ). Now, it is easy to verify that the underlying environment here islinear.In what follows, we illustrate three basic mechanisms for sponsored search auctions with respect to the above model.• Generalized first price (GFP) mechanism• Generalized second price (GSP) mechanism• Vickrey-Clarke-Groves (VCG) mechanismFor each of these mechanisms, we describe the allocation rule yij (·) and paymentrule pi (·).22.3\nGeneralized First Price (GFP) Mechanism\nThe allocation and payment rules under this mechanism are the following [3].\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n336\nGame Theory and Mechanism Design\nGFP: Allocation RuleIn this mechanism, the m advertising slots are allocated to advertisers in descendingorder of their bids. Let b(k) be the k th highest element in (b1 , . . . , bn ). Similarly,let (b−i )(k) be the k th highest element in (b1 , . . . , bi−1 , bi+1 , . . . , bn ). In view of thesedefinitions, we can say that if b = (b1 , b2 , . . . , bn ) is the profile of bids received fromthe n advertisers, then the first slot is allocated to the advertiser whose bid is equalto b(1) . Similarly, the second slot is allocated to the advertiser whose bid is equal tob(2) , and so on. That is, for all i ∈ N and all j ∈ M ,(1 : if bi = b(j)yij (b) =(22.2)0 : otherwise.If two advertisers have the same bid, then the tie can be broken by an appropriaterule.GFP: Payment RuleEvery time a user clicks on a sponsored link, an advertiser pays an amount equalto the amount of the advertiser’s bid. That is, if b = (b1 , b2 , . . . , bn ) is the profile ofbids received from the n advertisers then, for all i ∈ N ,(bi : if advertiser i’s ad is displayedpi (b) =(22.3)0 : otherwise.\n22.4\nGeneralized Second Price (GSP) Mechanism\nThe primary motivation for this auction mechanism was instability of the GFPmechanism. In particular, it has been shown by Edelman, Ostrovsky, and Schwarz[3] that under the GFP mechanism, truth telling is not an equilibrium bidding strategy for the advertisers, and this fact leads to instability in the system, which in turnleads to inefficient investments on behalf of the advertisers. The GFP mechanismalso creates volatile prices, which in turn cause allocative inefficiencies.GSP: Allocation RuleGSP: Allocation Rule 1This rule is the same as the allocation rule of GFP mechanisms, that is, the slotsare allocated to the advertisers in descending order of their bids.GSP: Allocation Rule 2In this rule, the first slot is allocated to the advertiser i ∈ N for whom the quantityαi1 bi is the maximum. If there is a tie then it is broken by an appropriate rule. Now\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nMechanism Design for Sponsored Search Auctions\nbook\n337\nthis advertiser is removed from the set N , and an advertiser among the remainingones is chosen for whom αj2 bj (where j ∈ N \\ {i}) is a maximum. The second slotis allocated to this advertiser. In similar fashion, all the other slots are allocated.GSP: Allocation Rule 3Here, for each advertiser, an estimated Click-Through-Rate (CTR) is computed.This is the ratio of the number of clicks received by the ad to the number of timesthe ad was displayed against the search results. Now the advertisers are rankedin decreasing order of the ranking scores, where ranking score of an advertiser isdefined as the product of the advertiser’s bid and estimated CTR. In the rest of thechapter, we assume that click probabilities depend only on the positions of the adsand are independent of the identities of the advertisers. That is, α1j = α2j = . . . =αnj = αj ∀j ∈ M . We also assume that the allocation rule in a GSP mechanismis the same as the allocation rule 2, which would be the same as allocation rule 1because of the previous assumption.GSP: Payment RuleIn this auction mechanism, every time a user clicks on a sponsored link, an advertiserpays an amount equal to the bid of the advertiser who is just below him in theranking of the displayed ads plus a minimum increment. The advertiser whosead appears at the bottom-most position is charged the amount of the highest bidamong the disqualified bids plus the minimum increment. If there is no such bidthen he is charged nothing. If b = (b1 , b2 , . . . , bn ) is the profile of bids received fromthe n advertisers, then because of the assumptions we made earlier regarding theallocation rule in the GSP mechanism, the price per click that is charged to anadvertiser i would be given by(P\u0001m(j+1) y (b): if either m < n or n ≤ m but bi 6= b(n)ijj=1 bpi (b) =0: otherwisewhere b(j+1) is the (j + 1)th highest bid which is the same as the bid of an advertiserwhose ad is allocated to position (j + 1). We have ignored the small incrementbecause all the future analysis and results are insensitive to this amount.22.5\nVickrey–Clarke–Groves (VCG) Mechanism\nOn the face of it, the GSP mechanism appears to be a generalized version of thewell known Vickrey auction, which is used for selling a single indivisible object. Butas shown by Edelman, Ostrovsky, and Schwarz [3], and also shown in the later partof this chapter, the GSP mechanism is indeed not a generalization of the classicalVickrey auction to the setting where a set of ranked objects is being sold. In this\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n338\nbook\nGame Theory and Mechanism Design\nsection, our objective is to develop the Clarke mechanism for the sponsored searchauction. We refer to this as the VCG mechanism, following standard practice.VCG: Allocation RuleBy definition, the VCG mechanism is allocatively efficient. Therefore, in the caseof a sponsored search auction, the allocation rule y ∗ (·) in the VCG mechanism isy ∗ (·) =\nnn marg max Xarg max X Xbi vi (y(b)) =(bi αij )yij (b).y(·) i=1yij (·) i=1 j=1\n(22.4)\nIn the previous section, we have already seen that the greedy allocation rule isa solution to (22.4). Moreover, under the assumption that click probabilities areindependent of advertisers’ identities, the allocation y ∗ (·) allocates the slots to theadvertisers in the decreasing order of their bids. That is, if b = (b1 , b2 , . . . , bn ) is theprofile of bids received from the n advertisers then y ∗ (·) must satisfy the followingcondition:(1 : bi = b(j)∗(22.5)yij(b) =0 : otherwise.We state below an interesting observation regarding GFP and GSP mechanisms,which is based on the above observations.Proposition 22.1. If click probabilities depend only on the positions of the adsand are independent of the identities of the advertisers, then(1) The GFP mechanism is allocatively efficient.(2) The GSP mechanism is allocatively efficient if it uses allocation rule 2, which isthe same as allocation rule 3.(3) The allocation rule for the VCG mechanism, which is an efficient allocation, isgiven by (22.5). Moreover, this allocation rule is precisely the same as the GFPallocation rule and allocation rule 3.VCG: Payment RuleAs per the definition of the VCG mechanism, the expected payment ti (b) madeby an advertiser i, when the profile of the bids submitted by the advertisers isb = (b1 , . . . , bn ), must be calculated using the following Clarke’s payment rule: XX∗ti (b) = bj vj (y ∗ (b)) − bj vj (y−i(b))(22.6)j6=i\nj6=i\n∗ (·) is an efficient allocation of the slots among the advertisers when adverwhere y−itiser i is removed from the scene. Substituting value of y ∗ (·) from Equation (22.5)P∗and making use of the fact that vi (y ∗ (b)) = mj=i yij (b)αj , Equation (22.6) can be\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nMechanism Design for Sponsored Search Auctions\nbook\n339\nwritten as follows:Case 1 (m < n):t(j) (b) = αj p(j) (b)(j+1) + t(j+1) (b) : if 1 ≤ j ≤ (m − 1) βj b= αm b(m+1): if j = m0: if m < j ≤ n\n(22.7)\nwhere• t(j) (b) is the expected payment made by the advertiser whose ad is displayed inj th position, for every search query received by the search engine and when thebid profile of the advertisers is b = (b1 , . . . , bn ),• p(j) (b) is the payment made by the advertiser, whose ad is displayed in j th position, for every click made by the user and when the bid profile of the advertisersis b = (b1 , . . . , bn ),• βj = (αj − αj+1 ), and• b(j) has its usual interpretation.Case 2 (n ≤ m):t(j) (b) = αj p(j) (b)(βj b(j+1) + t(j+1) (b)=0\n: if 1 ≤ j ≤ (n − 1): if j = n.\n(22.8)\nUnfolding of Equations (22.7) and (22.8) results in the following expressions forpayments:Case 1 (m < n): hPim−11(k+1) + αm b(m+1)βbkk=j αjαj1 (j)t (b) = b(m+1)p(j) (b) =αj0\n:\nif 1 ≤ j ≤ (m − 1)(22.9): if j = m: if m < j ≤ n.\nCase 2 (n ≤ m):p\n(j)\n1 (j)(b) =t (b) =αj\n(\n1 Pn−1(k+1)k=j βk bαj\n:\nif 1 ≤ j ≤ (n − 1)\n0\n:\nif j = n.\n(22.10)\nThus, we can say that Equation (22.5) describes the allocation rule for the VCGmechanism and Equations (22.9) and (22.10) describe the payment rule for the VCGmechanism.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n340\n22.6\nbook\nGame Theory and Mechanism Design\nOptimal (OPT) Mechanism\nIn this section, our goal is to compute the allocation and payment rule f (·) thatresults in an optimal mechanism for the sponsored search auction. This calls forextending Myerson’s optimal auction to the case of the sponsored search auction. Wefollow a line of attack that is similar to that of Myerson [4]. Recall that we formulatedthe sponsored search auction as a direct revelation mechanism D = ((Θi )i∈N , f (·))in a linear environment, where the utility function of an advertiser i is given bymXyij (b)αj  (θi − pi (b))ui (f (b), θi ) = j=1\n= vi (y(b))(θi − pi (b))= θi vi (y(b)) + ti (b)where\u0011\u0010Pmis the valuation function of the advertiser i andy(b)α• vi (y(b)) =ijjj=1can be interpreted as the probability that advertiser i will receive a user clickwhenever there is a search query received by the search engine and when thebid vector of the advertisers is b.• ti (b) = vi (y(b))pi (b) can be viewed as the expected payment made by advertiseri to the search engine against every search query received by the search engineand when the bid vector of the advertisers is b.OPT: Allocation RuleIt is convenient to define• ti (bi ) = Eθ−i [ti (bi , θ−i )] is the expected payment made by advertiser i when hebids an amount bi and all the advertisers j 6= i bid their true types.• v i (bi ) = Eθ−i [vi (y(bi , θ−i ))] is the probability that advertiser i will receive a userclick if he bids an amount bi and all the advertisers j 6= i bid their true types.• Ui (θi ) = θi v i (θi )−ti (θi ) gives advertiser i’s expected utility from the mechanismconditional on his type being θi when he and all other advertisers bid their truetypes.The problem of designing an optimal mechanism for the sponsored search auctioncan now be written as one of choosing functions yij (·) and Ui (·) to solve:Maximizeθi\nn ZXi=1 θ\ni\nsubject to\n(θi v i (θi ) − Ui (θi )) φi (θi )dθi\n(22.11)\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nbook\nMechanism Design for Sponsored Search Auctions\n341\n(i) v i (·) is non-decreasing ∀i ∈ NPPn(ii) yij (θ) ∈ [0, 1], mj=1 yij (θ) ≤ 1,i=1 yij (θ) ≤ 1 ∀i ∈ N, ∀j ∈ M, ∀θ ∈ ΘθiR(iii) Ui (θi ) = Ui (θi ) + v i (s)ds ∀i ∈ N, ∀θi ∈ Θiθi\n(iv) Ui (θi ) ≥ 0 ∀i ∈ N, ∀θi ∈ Θi .In the above formulation, the objective function is the total expected payment received by the search engine from all the advertisers. Note that constraints (iv) arethe advertisers’ interim individual rationality constraints while constraint (ii) is thefeasibility constraint. Constraints (i) and (iii) are the necessary and sufficient conditions for the allocation and payment rule f (·) = (yij (·), ti (·))i∈N,j∈M to be Bayesianincentive compatible (Myerson’s characterization theorem – Section 19.7). Theseconstraints are taken from [4] and have already been presented in Chapter 21.We have a critical observation to make here. Note that in the above optimizationproblem, we have replaced the bid bi by the actual type θi . This is because weare imposing the Bayesian incentive compatibility constraints on the allocation andpayment rule, and, hence, every advertiser will bid his true type. Thus, while dealingwith the OPT mechanism, we can safely interchange θi and bi for any i ∈ N .Note first that if constraint (iii) is satisfied, then constraint (iv) will be satisfiediff Ui (θi ) ≥ 0 ∀i ∈ N . As a result, we can replace the constraint (iv) with(iv’) Ui (θi ) ≥ 0 ∀i ∈ N.Next, substituting for Ui (θi ) in the objective function from constraint (iii), we getθiθiZZnX v i (θi )θi − Ui (θi ) − v i (s)ds φi (θi )dθi .i=1 θ\nθi\ni\nIntegrating by parts the above expression, the search engine’s problem can be writtenas one of choosing the yij (·) functions and the values U1 (θ1 ), . . . , Un (θn ) to maximizeZθ1...θ1\nZθn \"Xnθn\n##\" nnXYUi (θi )φi (θi ) dθn . . . dθ1 −vi (y(θi , θ−i ))Ji (θi )i=1\ni=1\ni=1\nsubject to constraints (i), (ii), and (iv’), whereJi (θi ) = θi −\n1 − Φi (θi ).φi (θi )\nIt is evident that the solution must have Ui (θi ) = 0 for all i = 1, 2, . . . , n. Hence,the search engine’s problem reduces to choosing functions yij (·) to maximizeZθ1...θ1\nZθn \"Xnθn\ni=1\nvi (y(θi , θ−i ))Ji (θi )\n#\" nYi=1\n#φi (θi ) dθn . . . dθ1\nDecember 27, 2013\n11:21\n342\nWorld Scientific Book - 10.25in x 7.5in\nbook\nGame Theory and Mechanism Design\nsubject to constraints (i) and (ii).Let us ignore the constraint (i) for the moment. Then an inspection of theabove expression indicates that yij (·) is a solution to this relaxed problem iff for alli = 1, 2, . . . , n we have0 ∀j = 1, 2, . . . , m: if Ji (θi ) < 01 ∀j = 1, 2, . . . , m < n : if Ji (θi ) = J (j)yij (θ) =(22.12)1 ∀j = 1, 2, . . . , n ≤ m : if Ji (θi ) = J (j)0: otherwisewhere J (j) is the j th highest value among Ji (θi )s.In other words, if we ignore the constraint (i) then yij (·) is a solution to thisrelaxed problem if and only if no slot is allocated to any advertiser having negativevalue Ji (θi ), and the rest of the advertisers’ ads are displayed in the same order asthe values of Ji (θi ). That is, the first slot is allocated to the advertiser who has thehighest nonnegative value for Ji (θi ), the second slot is allocated to the advertiserwho has the second highest nonnegative value for Ji (θi ), and so on.Now, recall the definition of v i (·). It is easy to write down the following expression:v i (θi ) = Eθ−i [vi (y(θi , θ−i ))]mXyij (θi , θ−i )αj  .= Eθ−i \n(22.13)(22.14)\nj=1\nNow if we assume that Ji (·) is nondecreasing in θi , it is easy to see that the abovesolution yij (·), given by (22.12), will be nondecreasing in strategy. Contracts transform365\nbook\nDecember 27, 2013\n11:21\n366\nWorld Scientific Book - 10.25in x 7.5in\nbook\nGame Theory and Mechanism Design\ngames with less desirable equilibria to games with more desirable equilibria. Weillustrate contracts and correlated strategies through the examples below.Example 25.1 (Modified Prisoner’s Dilemma with a Contract).In the game shown in Figure 25.1, let us say the two players sign the following contract(call it contract 1).(1) If both players sign this contract, then player 1 (player 2) chooses to play the strategyx1 (x2 ).(2) If the contract is signed by only player 1, player 1 would choose y1 .(3) If the contract is signed by only player 2, player 2 would choose y2 .Call the action of signing the contract by player i (i = 1, 2) as ai . We can now expandthe strategy sets as S1 = {x1 , y1 , a1 } and S2 = {x2 , y2 , a2 }. The transformed game has thepayoff matrix shown in Figure 25.2.\n1x1y1\nx22, 26, 0\n2y20, 61, 1\na1\n6, 0\n1, 1\na20, 61, 12, 2\nFig. 25.2: Payoff matrix with contract 1The transformed game now has a new equilibrium (a1 , a2 ) which is a weakly dominantstrategy equilibrium yielding payoffs (2, 2). The profile (y1 , y2 ) continues to be an equilibrium but is not a dominant strategy equilibrium.\u0003\nExample 25.2 (Modified Prisoner’s Dilemma with Additional Contract).Even better payoffs could be achieved if a second contract (call it contract 2) is introducedin addition to contract 1 above. This additional contract commits the players to a correlatedstrategy. This contract is as follows.• If both players sign this new contract, then a coin will be tossed. In the event of a heads,they will implement (x1 , y2 ) and in the event of a tails, they will implement (y1 , x2 ).• If player 1 alone signs this new contract, then player 1 chooses y1 .• If player 2 alone signs this new contract, then player 2 chooses y2 .If b1 and b2 represent the actions of players 1 and 2 corresponding to signing of this newcontract, the extended payoff matrix would be as shown in Figure 25.3. This new game hasthe following equilibria:• (y1 , y2 ) with payoffs (1, 1)• (a1 , a2 ) with payoffs (2, 2)• (b1 , b2 ) with payoffs (3, 3)• ((0, 0, 32 , 31 ), (0, 0, 23 , 13 )) where the mixed strategy (0, 0, 23 , 13 ) for player 1 means a1 withprobability 32 and b1 with probability 13 . This equilibrium leads to a payoff of 35 for bothplayer 1 and player 2.It turns out that none of the above equilibria are dominant strategy equilibria.\n\u0003\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nCorrelated Strategies and Correlated Equilibrium\nbook\n367\n21\nx2\ny2\na2\nb2\nx1y1\n2, 26, 0\n0, 61, 1\n0, 61, 1\n0, 61, 1\na1b1\n6, 06, 0\n1, 11, 1\n2, 21, 1\n1, 13, 3\nFig. 25.3: Modified prisoner’s dilemma with contract 1 and contract 225.2\nCorrelated Strategies\nThe choice of pure strategies by players in a game may be correlated perhaps becausethe players are observing the same or related random events before making theirchoices. A correlated strategy captures the above feature. Moreover, a correlatedstrategy, as illustrated in the examples above, also captures cooperative play by themembers of a coalition.Definition 25.1 (Correlated Strategy). Let Γ = hN, (Si ), (ui )i be a strategicform game. A correlated strategy for a non-empty subset C (also called coalition)of the players is any probability distribution over the set of possible combinations ofpure strategies that these players can choose.In other words, a correlated strategy, τC for a given coalition C belongs to ∆(SC )whereSC = ×i∈C SiN is called the grand coalition and the symbol τN denotes a correlated strategy ofthe grand coalition.Example 25.3 (Correlated Strategies). Let N = {1, 2, 3}; S1 = {x1 , y1 }; S2 ={x2 , y2 }; S3 = {x3 , y3 , z3 }. If C = {2, 3}, thenSC = S2 × S3 = {(x2 , x3 ), (x2 , y3 ), (x2 , z3 ), (y2 , x3 ), (y2 , y3 ), (y2 , z3 )}A correlated strategy for the coalition C is a probability distribution on SC . For example,111, 12, 12) would correspond to (x2 , x3 ) with probability 41 , (x2 , y3 ) with probability( 14 , 14 , 41 , 121\u00034 , and so on.\nNote. A correlated strategy τC ∈ ∆(×i∈C Si ) can be implemented as follows. Areliable mediator or a referee picks randomly a profile of pure strategies in SCaccording to distribution τC . The mediator asks each player to play the strategychosen in this pure strategy profile.\nDecember 27, 2013\n11:21\n368\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nNote. Let S, as usual, denote:S = SN = ×i∈N SiSuppose α ∈ ∆(S) is any correlated strategy for all players. Let Ui (α) denote theexpected payoff to player i when α is implemented. It can be easily seen thatXUi (α) =α(s)ui (s)s∈S\nLet U (α) = (U1 (α), . . . , Un (α)) denote the expected payoff allocation to players whenthey implement α.Note. Given any allocation in the set {U (α) : α ∈ ∆(S)}, there exists a contractsuch that if all the players signed this contract, then they would get this expectedpayoff allocation.Note. The set of possible expected payoff allocations {U (α) : α ∈ ∆(S)} can beshown to be a closed and convex subset of Rn . When there is no confusion, we willuse u(α) instead of U (α).Correlated Strategies and Mixed StrategiesIt is important to understand the difference between a correlated strategy and amixed strategy profile. A correlated strategy for the grand coalition N is a memberof ∆(×(Si )) whereas a mixed strategy profile is a member of ×(∆(Si )). Given anymixed strategy profile σ of all players, we can always find a correlated strategy ofall players α such that ui (α) = ui (σ) ∀i ∈ N . However, given a correlated strategyα of all the players, it may not always be possible to find any mixed strategy profileσ such that ui (σ) = ui (α) ∀i ∈ N .Contract Signing GameA vector of correlated strategies of all possible coalitions is called a contract. Moreformally, a contract is defined as follows.Definition 25.2 (Contract). Consider the vector τ = (τC )C⊆N . Note thatτ ∈ ×C⊆N (∆(×i∈C Si )) .The vector τ of correlated strategies of all coalitions is a contract.Note that τC for C ⊆ N gives the correlated strategy that would be implementedby players in C if C were the set of players to sign the contract. Clearly, a contractdefines (in fact induces) an extended game and this extended game is called thecontract signing game.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nCorrelated Strategies and Correlated Equilibrium\nbook\n369\nExample 25.4 (Contract in terms of Correlated Strategies). We have discussed two contracts in the context of the modified prisoner’s dilemma. Note that contract1 is described by (τ1 , τ2 , τ{1,2} ) where τ1 = (x1 : 0, y1 : 1); τ2 = (x2 : 0, y2 : 1); τ{1,2} =((x1 , x2 ) : 1; (x1 , y2 ) : 0; (y1 , x2 ) : 0; (y1 , y2 ) : 0). The payoff matrix in Figure 25.2 defines the contract signing game induced by contract 1. Contract 2 is given by (τ1 , τ2 , τ{1,2} )where τ1 = (x1 : 0, y1 : 1); τ2 = (x2 : 0, y2 : 1); τ{1,2} = ((x1 , x2 ) : 0; (x1 , y2 ) : 12 ; (y1 , x2 ) :12 ; (y1 , y2 ) : 0). The payoff matrix in Figure 25.3 defines the contract signing game inducedby contract 1 and contract 2.\u0003\nConcept of Individual RationalityClearly, players may not be willing to sign any contract that is proposed. For example, in the modified prisoner’s dilemma game of Figure 25.1, player 1 will not agreeto sign a contract that would commit the players to implement (x1 , y2 ) since it giveshim a payoff 0. Player 1 can always guarantee himself a payoff of 1 by not signing anything and simply choosing y1 . We now investigate which contracts a playerwould be really interested in signing. In Chapters 6 and 7, we have already seenthe notion of a security level or maxmin value for a player, which is the minimumguaranteed payoff the player can assure himself when the rest of the players arefree to play any strategies. The following provides a natural way of defining such asecurity level:vi = max\nmin\nτi ∈∆(Si ) sN −i ∈SN −i\nui (τi , sN −i )\nwhereSN −i = SN \\{i} ; sN −i ∈ SN −i .The expected utility ui (τi , sN −i ) is given by:Xui (τi , sN −i ) =τi (si )ui (si , sN −i ).si ∈Si\nFor example, in the modified prisoner’s dilemma problem (Figure 25.1), v1 = v2 = 1.Individually Rational Correlated StrategyIt is reasonable for player i to sign a contract to play a correlated strategy α onlyif ui (α) ≥ vi . This is called the individual rationality or participation constraint forplayer i. This leads to the following definition.Definition 25.3 (Individually Rational Correlated Strategy). A correlatedstrategyα ∈ ∆(S1 × · · · × Sn )for all the players in N is said to be individually rational ifui (α) ≥ vi ∀i ∈ N.\nDecember 27, 2013\n11:21\n370\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nIt can be shown, using a two player zero-sum game interpretation of the abovesituation, that the security level vi also satisfiesvi =\nmin\nmax ui (si , τN −i )\nτN −i ∈∆(SN −i ) si ∈Si\nwhereτN −i = τN \\{i} ∈ ∆(SN −i ).The expected utility ui (si , τN −i ) is given byXui (si , τN −i ) =τN −i (sN −i )ui (si , sN −i ).sN −i ∈SN −i\nvi is the best expected payoff that player i is guaranteed to get against any correlatedstrategy that the other players could use against player i. A minmax correlatedstrategy against player i is any correlated strategy τN −i ∈ ∆(SN −i ) of the rest ofthe players which forces the payoff of player i to be equal to his minmax value vi .Equilibria of the Contract Signing GameSuppose the players make their decisions about which contract to sign independently.Then, the following proposition holds.Proposition 25.1. Given any individually rational correlated strategy α, there exists a contract τ with τN = α such that all players signing this contract is a Nashequilibrium of the contract signing game.Proof: Let α ∈ ∆(S) be an individually rational correlated strategy. That isui (α) ≥ vi ∀i ∈ NConsider the contract τ = (τC )C⊆N such that τN = α and τN −i is a minmaxstrategy against player i. τC for all other coalitions (that is, coalitions other thanN, N − 1, . . . , N − n) could be chosen arbitrarily. Let (a1 , . . . , an ) be the profile ofcontract signing strategies for this contract. Note that this profile corresponds tothe situation when all the players sign the contract. Now,ui (a1 , . . . , an ) = ui (α) (since τN = α).Therefore, we get for all i ∈ N ,ui (a1 , . . . , an ) ≥ viFor any si ∈ Si such that si 6= ai , note that the profile (si , a−i ) corresponds to thesituation when player i plays si and the rest of the players sign the contract. Wehave,ui (si , a−i ) = ui (si , τN −i ) ≤ visince τN −i is a minmax strategy against player i. Therefore,ui (ai , a−i ) ≥ ui (si , a−i ) ∀si ∈ Si ∀i ∈ N\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nCorrelated Strategies and Correlated Equilibrium\nbook\n371\nThus (a1 , a2 , . . . , an ) is a Nash equilibrium of the contract signing game.\u0004Thus any individually rational correlated strategy α ∈ ∆(S) will lead to a contract such that all players signing the contract is a Nash equilibrium of the contractsigning game. It also turns out that in any Nash equilibrium of a contract signinggame, the expected payoffs for players would be at least their respective securitylevels. This is stated in the next proposition.Proposition 25.2. Consider any Nash equilibrium (s∗i , s∗−i ) of a contract signinggame induced by a correlated strategy α. Then, ui (s∗i , s∗−i ) ≥ vi ∀i ∈ N .Proof: Consider any Nash equilibrium (s∗i , s∗−i ) of a contract signing game andsuppose ui (s∗i , s∗−i ) < vi for some player i. Now player i can decide not to sign thecontract and instead play the strategy that guarantees him the minmax value vi .This immediately provides the contradiction.\u0004Following the two propositions above, it is clear that{u(α) : α ∈ ∆(S) and ui (α) ≥ vi ∀i ∈ N }is exactly the set of payoff allocations that can be achieved in Nash equilibria of thecontract signing game when every player has the option to sign nothing and choosean action in Si . This set is also the set of expected payoff allocations correspondingto individually rational correlated strategies. This set can be shown to be closedand convex .Example 25.5 (Payoff Allocations in the Modified Prisoner’s Dilemma).Consider the modified prisoner’s dilemma game with payoff matrix as in Figure 25.1. Theexpected payoff in a correlated strategy is a convex combination of the payoffs in differentstrategy profiles and hence the set of all payoff allocations for the above game is the convexset with extreme points (0, 6), (6, 0), and (1, 1). See Figure 25.4. Note that this set is alsoclosed and that the point (2, 2) is in the interior of this convex set. The set of possibleexpected payoff allocations satisfying individual rationality is the triangle with corners at(1, 1), (5, 1), and (1, 5) as shown. This is because v1 = 1 and v2 = 1 for this example. Notethat this set is also closed and convex.\u0003\n25.3\nGames with Communication\nWe have so far seen how contracts can transform a game with less desirable equilibriato a game with more desirable equilibria. However, in many situations, players maynot be able to commit themselves to binding contracts. The reasons for this couldbe many [1]:• Player’s strategies may not be observable to the enforcers of contracts.• There may not be adequate sanctions to guarantee compliance with contracts.\nDecember 27, 2013\n11:21\n372\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nFig. 25.4: Payoff allocation vectors under correlated strategies for the modified prisoner’sdilemma problem\n• Player’s strategies might actually involve inalienable rights (that is, players maynot be able to transfer their rights).In these above situations also, it may still be possible for the players to communicateand coordinate among themselves, and achieve a self-enforcing equilibrium withdesirable payoff structures. Such games correspond to games with communication.A game with communication is one, in which, in addition to the strategy optionsexplicitly specified, the players have a range of implicit options to communicate witheach other. A game with communication need not have any contracts. Such a gamemay still achieve interesting results in spite of contracts being absent.Example 25.6 (A Game with Communication). Consider a two player gamehaving the payoff matrix shown in Figure 25.5. Clearly, this game has three Nash equilibria.• (x1 , x2 ) with payoff allocation (5, 1)• (y1 , y2 ) with allocation (1, 5)• Mixed strategy Nash equilibrium (( 21 , 12 ), ( 12 , 12 )) which yields the outcome (2.5, 2.5).Note that (y1 , x2 ) is not a Nash equilibrium though it is clearly a desirable outcome.It can be realized through a binding contract. However, if contracts cannot be used, weare not sure whether we can achieve the payoff profile 94, 4) or even anything better than\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nCorrelated Strategies and Correlated Equilibrium\nbook\n373\n21\nx2\ny2\nx1y1\n5, 14, 4\n0, 01, 5\nFig. 25.5: A two player game to illustrate games with communication(2.5, 2.5). It turns out that correlated strategies exist that achieve a better allocation than(2.5, 2.5) as shown by the following example.\u0003\nExample 25.7 (Correlated Strategy 1). Let us say players choose to toss a coinand select the outcome (x1 , x2 ) with probability 12 and the outcome (y1 , y2 ) with probability12 . This refers to the following correlated strategy\u0012\u001311α = (x1 , x2 ); ; (x1 , y2 ) : 0; (y1 , x2 ) : 0; (y1 , y2 ) :22Note that u1 (α) = u2 (α) = 3. To implement this correlated strategy, players can toss a coinand choose the outcome (x1 , x2 ) in the event of a heads and choose the outcome (y1 , y2 )in the event of a tails. In order to implement this, communication and coordination arerequired. The outcome suggested by this correlated strategy will be self-enforcing sinceneither player will gain by unilaterally deviating from this.The above correlated strategy can also be implemented with the help of a trusted mediator who helps the players to communicate and share information: the mediator recommends, randomly, with probability 0.5 each the profiles (x1 , x2 ) and (y1 , y2 ). Assume thateach player comes to know only the strategy recommended to him by the mediator.• Player 1, if recommended x1 by the mediator thinks that player 2 is recommended x2 .Believing that player 2 obeys the recommendation x2 , player 1 finds it a best responseto choose x1 and thus accepts the mediator’s recommendation.• Player 1, if recommended y1 by the mediator thinks that player 2 is recommended y2 .Believing that player 2 obeys the recommendation y2 , player 1 finds it a best responseto choose y1 and again accepts the mediator’s recommendation.• Player 2, if recommended x2 by the mediator thinks that player 1 is recommended x1 .Believing that player 1 obeys the recommendation x1 , player 2 finds it a best responseto choose x2 and thus accepts the mediator’s recommendation.• Player 2, if recommended y2 by the mediator thinks that player 1 is recommended y1 .Believing that player 1 obeys the recommendation y1 , player 2 finds it a best responseto choose y2 and again accepts the mediator’s recommendation.Thus mediation can also be used to implement the above correlated strategy.\n\u0003\nExample 25.8 (Correlated Strategy 2). We now explore a different correlatedstrategy that can be realized with the help of a mediator. Consider the correlated strategy\u0013\u0012111α = (x1 , x2 ) : ; (x1 , y2 ) : 0; (y1 , x2 ) : ; (y1 , y2 ) :333Note that u1 (α) = u2 (α) = 103 . To implement this correlated strategy, the mediator recom-\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n374\nGame Theory and Mechanism Design\nmends, randomly, with probability 31 , each of the profiles (x1 , x2 ), (y1 , y2 ), (y1 , x2 ). Againassume that each player comes to know only the strategy recommended to him by themediator.• Suppose the mediator recommends x1 to player 1. Then player 1 knows that player 2is recommended x2 . When player 2 plays x2 (as recommended by the mediator), it is abest response for player 1 to play x1 , so he would be happy to play x1 and thus acceptthe recommendation of the mediator.• Suppose the mediator recommends y1 to player 1. Then player 1 knows that the mediator would recommend the mixed strategy x2 : 0.5; y2 : 0.5 to player 2. When player2 plays the above mixed strategy, then player 1 gets a payoff of 2.5 if he plays x1 andgets a payoff of 2.5 even if he plays y1 . Thus player 1 can be indifferent between x1 andy1 and will not mind accepting the recommendation of the mediator to play y1 .The above shows that player 1 would be happy to follow the recommendation of the mediatorif player 1 expected player 2 also to follow the recommendation of the mediator.Similarly, it can be shown that player 2 would be happy to do as recommended by themediator under the belief that player 1 would do as recommended by the mediator.The above shows that the two players can reach a self-enforcing understanding to obeythe mediator if the mediator recommends the correlated strategy\u0013\u0012111;(x,y):0;(y,x):;(y,y):(x1 , x2 ) :1 2121 2333In other words, even though the mediator’s recommendation is not binding on the twoplayers, the two players find it in their best interest to follow it. Thus there is a Nashequilibrium of the transformed game with mediated communication without contracts. Thisis the idea behind the notion of correlated equilibrium which is discussed next.\u0003\n25.4\nCorrelated Equilibrium\nConsider the following setup of a game with communication. Let Γ = hN, (Si ), (ui )ibe any finite strategic form game. Assume that there is a mediator who chooses apure strategy profile (s1 , . . . , sn ) according to a probability distribution α ∈ ∆(S)which is common knowledge among the players. The observer recommends to playeri (i = 1, . . . , n) the pure strategy si but does not reveal s−i to player i. Based onthe recommendation, the player either obeys it or chooses any other strategy fromhis strategy set Si . Let δi : Si → Si describe player i’s choice of a strategy based onthe mediator’s recommendation. That is, δi (si ) gives the strategy that the player ichooses to play when the mediator recommends si to him. δi (si ) = si means thatthe player i obeys the mediator when the mediator recommends si .Definition 25.4 (Correlated Equilibrium). Given a finite strategic form gameΓ = hN, (Si ), (ui )i, a correlated strategy α ∈ ∆(S) recommended by a mediator iscalled a correlatedXequilibrium ifui (α) ≥α(si , s−i ) ui (δi (si ), s−i ) ∀δi : Si → Si ∀i ∈ N.(25.1)(si ,s−i )∈S\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nCorrelated Strategies and Correlated Equilibrium\nbook\n375\nNote that when a correlated equilibrium is recommended, every player finds it a bestresponse to obey the recommendation of the mediator. Thus a correlated equilibriumis any correlated strategy for the players which could be self-enforcingly implementedwith the help of a mediator who can make non-binding recommendations to eachplayer.Computing Correlated EquilibriaIt can be shown that the inequalities (25.1) are equivalent to the following set ofinequalities.Xα(s)[ui (si , s−i ) − ui (s0i , s−i )] ≥ 0 ∀si ∈ Si ; ∀s0i ∈ Si ; ∀i ∈ N. (25.2)s−i ∈S−i\nThe equivalence can be shown by fixing si and unfolding the original inequalities (leftas an exercise). Equation (25.2) asserts that no player i could expect to increase hisexpected payoff by using some disobedient action s0i when the mediator recommendssi . The constraints (25.2) are called strategic incentive constraints. They are theconstraints to be satisfied by a mediator’s correlated strategy for ensuring that allplayers could rationally obey the recommendations. It can also be noted thatα(s) ≥ 0, ∀s ∈ SX\nα(s) = 1\ns∈S\nNote. It can be shown that the set of all payoff allocations under correlated equilibria in a finite game is a compact and convex set. Recall that the set of all payoffallocations under correlated strategies as well as the set of payoff allocations underindividually rational correlated strategies are also compact and convex.Let us look at the following linear program:Xmaxui (α)i∈N\nsubject toX\n\u0002\u0003α(s) ui (si , s−i ) − ui (s0i , s−i ) ≥ 0 ∀i ∈ N ∀si ∈ Si ∀s0i ∈ Si\ns−i ∈S−i\nα(s) ≥ 0 ∀s ∈ SX\nα(s) = 1\ns∈S\nAny feasible solution of this linear program will give a correlated equilibrium. Anoptimal solution of this linear program will give a correlated equilibrium that maximizes the social welfare.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n376\nbook\nGame Theory and Mechanism Design\nExample 25.9 (Computation of correlated equilibria). Consider\nthe\ngame\nshown in Figure 25.5. The linear program here is:maximize 6 α(x1 , x2 ) + 0 α(x1 , y2 ) + 8 α(y1 , x2 ) + 6 α(y1 , y2 ) subject to\n(5 − 4) α (x1 , x2 ) + (0 − 1) α (x1 , y2 ) ≥ 0(4 − 5) α (y1 , x2 ) + (1 − 0) α (y1 , y2 ) ≥ 0(1 − 0) α (x1 , x2 ) + (4 − 5) α (y1 , x2 ) ≥ 0(0 − 1) α (x1 , y2 ) + (5 − 4) α (y1 , y2 ) ≥ 0α (x1 , x2 ) + α (x1 , y2 ) + α (y1 , x2 ) + α (y1 , y2 ) = 1This yields the solutionα (x1 , x2 ) =\n111; α (y1 , x2 ) = ; α (y1 , y2 ) = ; α(x1 , y2 ) = 0333\nThis shows that the above correlated strategy yields the maximum total payoff to the twoplayers. The above also shows that the sum of expected payoffs cannot exceed 6 23 undernon-binding mediated communication scenario.\nFig. 25.6: Payoff allocation vectors under correlated strategies and correlated equilibria\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nCorrelated Strategies and Correlated Equilibrium\nbook\n377\nFigure 25.6 shows the sets of all payoff allocations for this example under correlatedstrategies (convex hull with corner points (0, 0), (1, 5), (5, 1), (4, 4)), under individually rational correlated strategies (convex hull with corner points (1, 1), (1, 5), (5, 1), (4, 4)) , and10under correlated equilibria (convex hull with corner points (1, 5), (5, 1), (3, 3), ( 103 , 3 )). \u0003\nWe can now ask the following question: Can we select a small number of (perhapsa single) desirable or best outcomes among the above sets. For two player games,this issue was settled by the Nash bargaining theorem which we discuss in the nextchapter. For multi-player games (including two player games), a variety of solutionconcepts have been suggested: The core, Shapley value, bargaining sets, nucleolus,etc. We will be studying these in the other following chapters.\n25.5\nSummary and References\nThe key learnings from this chapter include the following.• Games with contracts and games with communication provide different ways ofmodeling cooperation among players. Contracts and communication transformgames with less desirable equilibria to games with more desirable equilibria.Correlated strategies provide the framework for defining games with contractsand games with communication.• Given a coalition of players, a correlated strategy of the players is a probabilitydistribution on the space of strategy profiles of these players. A correlatedstrategy captures cooperation among the players in that coalition. A correlatedstrategy also enables to express the fact that the choice of pure strategies byplayers may be correlated since they might be observing the same or similarrandom events in deciding which pure strategies to play.• A correlated strategy of the grand coalition is said to be individually rational ifthe expected payoff for each player under this correlated strategy is at least thesecurity value or minmax value of the player. An individually rational correlatedstrategy induces a Nash equilibrium in the contract signing game.• A correlated equilibrium is a correlated strategy of the grand coalition whichleads to all players self-enforcingly obeying the recommendations of a mediatorwho implements the correlated strategy.• The set of all correlated equilibria could be computed as feasible solutions ofa linear program. Using this linear program, we can also compute correlatedequilibria that maximize social welfare.• The following sets of payoff allocations are convex and closed. (1) Set of allpayoff allocations under correlated strategies (2) Set of all payoff allocationsunder individually rational correlated strategies which is the same as the set ofallocations under Nash equilibria of contract signing games (3) Set of all payoffallocations under correlated equilibria.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n378\nGame Theory and Mechanism Design\nThe material discussed in this chapter draws upon mainly from the book byMyerson [1]. The concept of correlated equilibrium was first introduced by RobertAumann [2]. There are many recent papers on efficient algorithms for computingcorrelated equilibria. The reader is referred to the book by Chalkiadakis, Elkind,and Wooldridge [3]. For an excellent detailed treatment of correlated strategies andcorrelated equilibria, we refer the reader to the books by Peleg and Sudholter [4]and Maschler, Solan, and Zamir [5].\nReferences[1][2][3][4][5]\n25.6\nRoger B. Myerson. Game Theory: Analysis of Conflict. Harvard University Press, Cambridge,Massachusetts, USA, 1997.Robert J. Aumann. “Subjectivity and correlation in randomized strategies”. In: Journal ofMathematical Economics 1 (1974), pp. 67–95.Georgios Chalkiadakis, Edith Elkind, and Michael Wooldridge. Computational Aspects ofCooperative Game Theory. Morgan & Claypool, 2011.B. Peleg and P. Sudholter. Introduction to the Theory of Cooperative Games. Kluwer Academic, Boston, USA, 2003.Michael Maschler, Eilon Solan, and Shmuel Zamir. Game Theory. Cambridge UniversityPress, 2013.\nExercises\n(1) Given a strategic form game and a mixed strategy profile σ, find a correlatedstrategy α such that ui (α) = ui (σ) ∀i ∈ N .(2) Suppose (σ1∗ , . . . , σn∗ ) is a mixed strategy Nash equilibrium of a strategic formgame Γ = hN, (Si ), (ui )i. Define a correlated strategy induced by the aboveequilibrium:α(s1 , . . . , sn ) = σ1∗ (s1 ) . . . σn∗ (sn ); ∀si ∈ Si ∀i = 1, . . . , n.Show that such a correlated strategy is a correlated equilibrium.(3) If α is a correlated equilibrium of a strategic form game, show that ui (α) isequal to the maxmin value of i for each i = 1, . . . , n.(4) If α is a correlated equilibrium of a matrix game, show that u1 (α) is equal tothe value in mixed strategies of the game.(5) Give a simple example of a strategic form game such that the space of all payoffprofiles achievable under mixed strategy profiles is the same as the space of allpayoff profiles achievable under correlated strategies.(6) Give a simple example of a strategic form game such that the space of all payoffprofiles achievable under mixed strategy profiles is a strict subset of the spaceof all payoff profiles achievable under correlated strategies.(7) Given a strategic form game, define the minmax value under correlated strategies\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nCorrelated Strategies and Correlated Equilibrium\nbook\n379\nas:vi =\nmin\nmax ui (si , τN −i )\nτN −i ∈∆(SN −i ) si ∈Si\nShow, using a two player zero-sum game interpretation of the above game, thatthe value vi also satisfiesvi = max\nmin\nτi ∈∆(Si ) sN −i ∈SN −i\nui (τi , sN −i )\nwhereui (τi , sN −i ) =\nX\nτi (si )ui (si , sN −i )\nsi ∈Si\n(8) Given a finite strategic form game, show that the following sets are closed andconvex.• The space of all payoff allocations achievable under correlated strategies• The space of all payoff allocations achievable under individually rationalcorrelated strategies• The space of all payoff allocations achievable under correlated equilibria(9) Show the equivalence of the set of inequalities presented in equation (25.2) andthe set of inequalities presented in equation (25.1).(10) Compute all correlated equilibria of2\n2\n1\nx2\ny2\n1\nx2\ny2\nx1y1\n2, 26, 0\n0, 61, 1\nx1y1\n2, 20, 0\n0, 01, 1\n(11) Consider the following two player game:A\nA5, 5\nB1, 1\nB\n1, 1\n3, 3\nFor this game,• compute the set of all payoff utility pairs possible (a) under correlated strategies (b) under individually rational correlated strategies.• compute all correlated equilibria that maximize the sum of utilities of thetwo players.(12) Consider the following two player game:A\nA4, 1\nB0, 0\nB\n3, 3\n1, 4\nDecember 27, 2013\n11:21\n380\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nFor the above game, compute:• the space of all payoff allocations under mixed strategy profiles• the space of all payoff allocations under mixed strategy Nash equilibria• the space of all payoff allocations under correlated strategies• the space of all payoff allocations under individually rational correlatedstrategies• the space of all payoff allocations under correlated equilibria(13) Suppose σ ∗ = (σ1∗ , . . . , σn∗ ) is a mixed strategy Nash equilibrium of a strategicform game. Consider the correlated strategy ασ∗ ∈ ∆(S) defined byασ∗ (s1 , . . . , sn ) = σ1∗ (s1 ) × · · · × σn∗ (sn ).Show that the above correlated strategy is a correlated equilibrium.(14) Programming Assignment. Computing correlated equilibria of a finitestrategic form game is an important computational problem. We have shownthat these can be computed as feasible solutions of a linear program. Designand develop a program to compute correlated equilibria and welfare maximizingcorrelated equilibria. Also, compute the spaces of allocations under correlatedstrategies, under individually rational correlated strategies, and under correlatedequilibria.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nChapter 26\nThe Two Person Bargaining Problem\nThe Nash bargaining theory, based on the brilliant work of John Nash, representsone of the earliest and most influential results in cooperative game theory. Giventwo rational and intelligent players and a set of feasible allocations from amongwhich a unique allocation is to be chosen, the Nash bargaining theory proposes anelegant axiomatic approach to solve the problem. This chapter sets up the problem,presents the axioms of Nash bargaining theory, and provides a proof of the Nashbargaining result.\n26.1\nNash Program\nCooperation refers to coalitions of two or more players acting together with a specificcommon purpose in mind. Since rationality and intelligence are two fundamental assumptions in game theory, any cooperation between players must take into accountthe objective of maximizing their own individual payoffs. As we have seen in theprevious chapter, the notion of cooperation which is closely tied with the notion ofcorrelated strategies can be developed without abandoning the basic tenets underlying non-cooperative game theory. This has been emphasized by John Nash himself[1, 2]. According to Nash, cooperative actions can be considered as the culminationof a certain process of bargaining among the cooperating players and consequently,cooperation between players can be studied using core concepts of non-cooperativegame theory. In this bargaining process, we can expect each player to behave according to some bargaining strategy that satisfies the original utility maximizationcriterion as in standard non-cooperative game theory.The ingenious idea of Nash is to define a cooperative transformation that willtransform a strategic form game into another strategic form game that has an extended strategy space for each player. The extended strategy set for a player hasall the strategies of the original game and also additional strategies that capturebargaining with the other players to jointly plan cooperative strategies. This is onthe lines of what we have studied in the previous chapter on games with contractsand games with communication. We will illustrate this with the standard exampleof the prisoner’s dilemma problem which provides a classic example for illustratingthe benefits of cooperation.381\nbook\nDecember 27, 2013\n11:21\n382\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nNC\nNC−2, −2\nC−10, −1\nC\n−1, −10\n−5, −5\nClearly, the rationality of the players suggests the equilibrium (C, C) which isobviously not an optimal option for the players. The two players here have a strongincentive to bargain with each other or sign a contract to transform this game intoone which has equilibria that are better for both the players. The concept of a Nashprogram for cooperative game theory is to define cooperative solution concepts suchthat a cooperative solution for any given game is a Nash equilibrium of some cooperative transformation of the original non-cooperative game. The notion of Nashprogram was introduced by Nash in his classic paper [2]. If we carefully describeall the possibilities that are feasible when the players bargain or sign contracts witheach other, we may end up with a game that has numerous equilibria. This meansthe Nash program may not lead to a unique cooperative solution. This means thatwe should have a sound theory of cooperative equilibrium selection. This is what theNash bargaining theory offers in an axiomatic and rigorous, but in a highly intuitiveway.26.2\nThe Two Person Bargaining Problem\nAccording to Nash, the term bargaining refers to a situation in which• two individuals have the possibility of concluding a mutually beneficial agreement• there is a conflict of interest about which agreement to conclude• no agreement may be imposed on any player without that player’s approval.The following assumptions are implicit in Nash’s formulation: when two playersnegotiate or an impartial mediator arbitrates, the payoff allocations that the twoplayers ultimately get should depend only on:• the payoffs they would expect if the negotiation or arbitration were to fail toreach a settlement, and• the set of payoff allocations that are jointly feasible for the two players in theprocess of negotiation or arbitration.The two person bargaining problem has been applied in many important contextsincluding:• Management labor arbitration where the management negotiates contracts withthe labor union• International relations, where two nations or two groups of nations work outagreements on issues such as nuclear disarmament, military cooperation, antiterrorist strategy, bilateral emission control initiatives, etc.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nThe Two Person Bargaining Problem\nbook\n383\n• Duopoly market games where two major competing companies work out adjustments on their production to mutually maximize their profits• Bilateral trade situations where a buyer and seller engage in bargaining over thetrade• Supply chain contracts where a buyer and a supplier work out a mutually beneficial contract that facilitates a long-term relationship• Negotiation protocols in multiagent systems• Property settlement disputes between corporations or individuals\nThe Bargaining ProblemThe two person bargaining problem consists of a pair (F, v) where F is called thefeasible set and v is called the disagreement point.• F , the feasible set of allocations, is a closed, convex subset of R2 .• The disagreement point v = (v1 , v2 ) ∈ R2 represents the disagreement payoffallocation for the two players. It is also called the status-quo point or the defaultpoint or de facto point. This gives the payoffs for the two players in the eventthat the negotiations fail. It may be noted that v is invariably chosen to belongto the feasible set F .• The set F ∩ {(x1 , x2 ) ∈ R2 : x1 ≥ v1 ; x2 ≥ v2 } is assumed to be non-empty andbounded.Rationale Behind the Assumptions• Convexity of F : This has the following rationale. It is reasonable for the twoplayers to agree to correlated strategies. Consequently, if the utility allocationsx = (x1 , x2 ) and y = (y1 , y2 ) are feasible and 0 ≤ λ ≤ 1, then the expectedutility allocation λx + (1 − λ)y can be achieved by planning to implement acorrelated strategy which assigns probability λ to x = (x1 , x2 ) and probability(1 − λ) to y = (y1 , y2 ).• Closedness of F : This means any convergent sequence in F will converge to apoint that belongs to F . It would be strange if we have a sequence of allocationsbelonging to F and the limiting allocation does not belong to F . In fact, withoutthis assumption, it may happen that there may not exist a solution to thebargaining problem since the limit of a sequence may not be in F . Closednessof F is therefore a natural topological requirement.• The third assumption is the set F ∩ {(x1 , x2 ) ∈ R2 : x1 ≥ v1 , x2 ≥ v2 } is nonempty and bounded. This assumption implies that (a) there exists some feasibleallocation that is at least as good as the disagreement point for both players,however (b) unbounded gains over the disagreement point are not possible. Boththese requirements are clearly reasonable.\nDecember 27, 2013\n11:21\n384\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nConnection to Two Player Non-Cooperative GamesSuppose Γ = h{1, 2}, S1 , S2 , u1 , u2 i is a two person strategic form game. If thestrategies of the players can be regulated by binding contracts, then one possibilityfor the feasible set F is the set of all allocations under correlated strategies:F = {(u1 (α), u2 (α)) : α ∈ ∆(S1 × S2 )} whereui (α) =\nX\nα(s)ui (s)\ns∈S\nWe could also choose the set of allocations under individually rational correlatedstrategies (recall that the payoffs for players under individually rational correlatedstrategies will be at least the respective minmax values). If the players’ strategiescannot be regulated by binding contracts then a possibility for F would be the setof all allocations under correlated equilibria:F = {(u1 (α), u2 (α)) : α is a correlated equilibrium of Γ}There are several possibilities for the disagreement point v. The first possibility isto let vi be the minmax value for player i.v1 =v2 =\nmin\nmax u1 (σ1 , σ2 )\nmin\nmax u2 (σ1 , σ2 )\nσ2 ∈∆(S2 ) σ1 ∈∆(S1 )\nσ1 ∈∆(S1 ) σ2 ∈∆(S2 )\nThe above choice is quite reasonable and scientific because the minmax value for aplayer is the minimum guaranteed payoff to the player even in a strictly competitivesetting where the other player always tries to hurt this player the most.A second possibility is to choose some focal Nash equilibrium (σ1∗ , σ2∗ ) of Γ andletv1 = u1 (σ1∗ , σ2∗ ); v2 = u2 (σ1∗ , σ2∗ )A focal Nash equilibrium is one which becomes a natural choice for the players dueto some external factors prevailing at the time of allocation.A third possibility is to derive v = (v1 , v2 ) from some rational threats. Thetheory of rational threats has been proposed using rationality-based arguments andthe reader is referred to the book by Myerson [3] for more details.A sound theory of negotiation or arbitration must allow us to identify, given anybargaining problem (F, v), a unique allocation vector in R2 that would be selected asa result of negotiation or arbitration. Let us denote this unique allocation by f (F, v).Thus the bargaining problem involves finding an appropriate solution function f (.)from the set of all two-person bargaining problems into R2 , which is the set of payoffallocations.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nThe Two Person Bargaining Problem\n26.3\nbook\n385\nThe Nash Axioms\nJohn Nash used a brilliant axiomatic approach to solve this problem. He first cameup with a list of properties an ideal bargaining solution function is expected tosatisfy and then proved that there exists a unique solution that satisfies all of theseproperties. The following are the five axioms of Nash:(1) Strong Efficiency(2) Individual Rationality(3) Scale Covariance(4) Independence of Irrelevant Alternatives (IIA)(5) SymmetryLet us use the notation f (F, v) = (f1 (F, v), f2 (F, v)) to denote the Nash bargainingsolution for the bargaining problem (F, v).Axiom 1: Strong EfficiencyGiven a feasible set F , we say an allocation x = (x1 , x2 ) ∈ F is strongly Paretoefficient or simply strongly efficient iff there exists no other point y = (y1 , y2 ) ∈ Fsuch that y1 ≥ x1 ; y2 ≥ x2 with strict inequality satisfied for at least one player.An allocation x = (x1 , x2 ) ∈ F is weakly Pareto efficient or weakly efficient iff thereexists no other point y = (y1 , y2 ) ∈ F such that y1 > x1 ; y2 > x2 .The strong efficiency axiom asserts that the solution to any two person bargainingproblem should be feasible and strongly Pareto efficient. Formally, f (F, v) ∈ F andthere does not exist any x = (x1 , x2 ) ∈ F such that x1 ≥ f1 (F, v); x2 ≥ f2 (F, v)with xi > fi (F, v) for at least some i ∈ {1, 2}. This implies that there should beno other feasible allocation that is better than the solution for one player and notworse than the solution for the other player.Axiom 2: Individual RationalityThis axiom states that f (F, v) ≥ v which implies that f1 (F, v) ≥ v1 ; f2 (F, v) ≥ v2 .This means, neither player should get less in the bargaining solution than he/shecould get in disagreement. Figure 26.1 illustrates Axioms 1 and 2.Axiom 3: Scale CovarianceThis axiom is stated as follows. For any numbers λ1 , λ2 , µ1 , µ2 with λ1 > 0, λ2 > 0,define the set G = {(λ1 x1 + µ1 , λ2 x2 + µ2 : (x1 , x2 ) ∈ F } and the point w =(λ1 v1 + µ1 , λ2 v2 + µ2 ). Then the solution f (G, w) for the problem (G, w) is given byf (G, w) = (λ1 f1 (F, v) + µ1 , λ2 f2 (F, v) + µ2 )In the above, the bargaining problem (G, w) can be derived from (F, v) by applyingan affine utility transformations which will not affect relevant properties of the utility\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n386\nbook\nGame Theory and Mechanism Designx2\nf (F, v)\nF\n(v1 , v2 )x1\nFig. 26.1: Illustrating strong efficiency and individual rationality\nx2\nG\n(λ1 f1 + µ1 , λ2 f2 + µ2 )\n(λ1 v1 + µ1 , λ2 v2 + µ2 )\nF\nf (F, v)\n(v1 , v2 )\nx1\nFig. 26.2: Illustration of scale covariance\nfunctions. The axiom implies that the solution of (G, w) can be derived from thatof (F, v) by the same transformation. Figure 26.2 illustrates this axiom.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nThe Two Person Bargaining Problem\nbook\n387\nAxiom 4: Independence of Irrelevant AlternativesThis axiom states that, for any closed convex set G,G ⊆ F and f (F, v) ∈ G =⇒ f (G, v) = f (F, v)The axiom asserts that eliminating feasible alternatives (other than the disagreement point) that would not have been chosen should not affect the solution. Theeliminated alternatives are referred to as irrelevant alternatives. This axiom is illustrated in Figure 26.3. If a mediator or referee were to select a solution by maximizingsome aggregate measure of social gain, that is,f (F, v) = max M (x, v)x∈F\nwhere M (x, v) is a measure of social gain by choosing x instead of v, then Axiom 4can be shown to be always satisfied.x2\nf (F, v)G(v1 , v2 )\nF\nx1\nFig. 26.3: Independence of irrelevant alternatives\nAxiom 5: SymmetryThis axiom asserts that if the positions of players 1 and 2 are completely symmetricin the bargaining problem, then the solution should also treat them symmetrically.Formally,v1 = v2 and {(x2 , x1 ) : (x1 , x2 ) ∈ F } = F =⇒ f1 (F, v) = f2 (F, v)This axiom is illustrated in Figure 26.4.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n388\nGame Theory and Mechanism Design\nx2\nf (F, v)\nF\nSymmetric\n(v1 , v2 )\nF\nx1\nFig. 26.4: Illustration of symmetry\n26.4\nThe Nash Bargaining Solution\nUsing ingenious arguments, Nash showed that there exists a unique solution thatsatisfies all the five axioms. The following theorem presents the solution.Theorem 26.1. Given a two person bargaining problem (F, v), there exists a uniquesolution function f (., .) that satisfies Axioms (1) through (5). The solution functionsatisfies, for every two person bargaining problem (F, v),\u0001argmax(x1 − v1 )(x2 − v2 )(x1 , x2 ) ∈ Fx1 ≥ v1 ; x2 ≥ v2\nf (F, v) ∈\nAn Illustrative ExampleFigure 26.5 shows a closed convex set F which is actually the convex hull enclosingthe points (4, 0), (1, 1), and (0, 4). Suppose F is the feasible set and (1, 1) is thedefault point. It can be shown that the Nash bargaining solution is (2, 2). Thisillustrates Pareto efficiency, individual rationality, and symmetry. We shall define anew feasible space G obtained by the following scaling: λ1 = λ2 = 21 ; µ1 = µ2 = 1.Consider the bargaining problem (G, w) with w = ( 23 , 32 ) that is obtained usingw = (λ1 v1 + µ1 , λ2 v2 + µ2 ). Using scale covariance, the Nash bargaining solutionbecomes (2, 2). If H is the feasible space obtained using λ1 = λ2 = 21 ; µ1 = µ2 = 0,then the problem (H, ( 12 , 21 )) illustrates another instance of scale covariance.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nbook\nThe Two Person Bargaining Problem\n389\nx2\n4\nx2 = x1\n(1, 3)\n3\n(2, 2)\n2\nG\n( 23 , 32 )\n(3, 1)\n1( 12 , 21 )\n(1, 1)H\nFx1\n1\n2\n3\n4\nFig. 26.5: An example to illustrate Nash axioms26.5\nProof of the Nash Bargaining Theorem\nFirst we prove the theorem for a special class of two person bargaining problemscalled essential bargaining problems and subsequently, we generalize this to theentire class of problems. A two person bargaining problem (F, v) is said to beessential if there exists at least one allocation y ∈ F that is strictly better for boththe players than the disagreement allocation v, that is, y1 > v1 and y2 > v2 .Proof for Essential Bargaining ProblemsWe are given an essential two person bargaining problem (F, v). Clearly, there existssome y = (y1 , y2 ) ∈ F such that y1 > v1 and y2 > v2 .Recall the definition of a quasiconcave function from Chapter 10: A functionf : S → R where S is non-empty and convex is said to be quasiconcave iff (λx + (1 − λ)y) ≥ min(f (x), f (y)) ∀x, y ∈ S ∀λ ∈ [0, 1]f is strictly quasiconcave iff (λx + (1 − λ)y) > min(f (x), f (y)) ∀x, y ∈ S x 6= y ∀λ ∈ (0, 1)It is known that a strictly quasiconcave function will have a unique optimal solution\nDecember 27, 2013\n11:21\n390\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\n(maximum). Consider the optimization problem:\u0001max(x1 − v1 )(x2 − v2 )(x1 , x2 ) ∈ Fx1 ≥ v1 ; x2 ≥ v2where (v1 , v2 ) ∈ F . The function (x1 − v1 )(x2 − v2 ) is strictly quasiconcave (sincewe are dealing with an essential bargaining problem) and therefore it has a uniquemaximizer. Therefore the above optimization problem has a unique optimal solution.Call this solution as (x∗1 , x∗2 ).Let F ⊂ R2 be convex and closed. Suppose v = (v1 , v2 ) ∈ F andF ∩ {(x1 , x2 ) ∈ R2 : x1 ≥ v1 ; x2 ≥ v2 }is non-empty and bounded. Suppose the function f (F, v) satisfies the five axioms (1)strong efficiency (2) individual rationality (3) scale covariance (4) independence ofirrelevant alternatives, and (5) symmetry. Then the Nash bargaining theorem statesthat f (F, v) = (x∗1 , x∗2 ) which happens to be the unique solution of optimizationproblem above.The proof of the Nash bargaining theorem proceeds in two parts. In Part 1, weshow that the optimal solution (x∗1 , x∗2 ) of the optimization problem above satisfiesall the five axioms. In Part 2, we show that if f (F, v) satisfies all the five axioms,then f (F, v) = (x∗1 , x∗2 ). We use the following notation for the objective function inthe rest of this proof:N (x1 , x2 ) = (x1 − v1 )(x2 − v2 )The objective function is appropriately called the Nash Product.Proof of Part 1We have to show that the optimal solution (x∗1 , x∗2 ) of the optimization problemabove satisfies all the five axioms. We do this sequentially.Strong EfficiencyWe have to show that there does not exist (xˆ1 , xˆ2 ) ∈ F such that xˆ1 ≥ x∗1 andxˆ2 ≥ x∗2 with at least one inequality strict. Suppose such a (xˆ1 , xˆ2 ) exists. Sincethere exists a (y1 , y2 ) ∈ F such that y1 > v1 and y2 > v2 , the maximum value of theNash product in the optimization problem is strictly greater than zero. Since theobjective function N (x1 , x2 ) is increasing in x1 and x2 , we haveN (xˆ1 , xˆ2 ) > N (x∗1 , x∗2 )which is not possible since N (x∗1 , x∗2 ) is the maximum possible value of N (x1 , x2 ) inthe optimization problem.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nThe Two Person Bargaining Problem\nbook\n391\nIndividual RationalityThis is immediately satisfied, being one of the constraints in the optimization problem.Scale CovarianceFor λ1 > 0, λ2 > 0, µ1 , µ2 , defineG = {λ1 x1 + µ1 , λ2 x2 + µ2 ) : (x1 , x2 ) ∈ F }Consider the problemmax (y1 − (λ1 v1 + µ1 ))(y2 − (λ2 v2 + µ2 ))\n(y1 ,y2 )∈G\nThis can be written using y1 = λ1 x1 + µ1 and y2 = λ2 x2 + µ2 asmax (λ1 x1 + µ1 − (λ1 v1 + µ1 ))(λ2 x2 + µ2 − (λ2 v2 + µ2 ))\n(x1 ,x2 )∈G\nThe above problem is the same asmax\n(x1 ,x2 )∈G\nλ1 λ2 (x1 − v1 )(x2 − v2 )\nwhich attains maximum at (x∗1 , x∗2 ). Therefore the problemmax (y1 − (λ1 v1 + µ1 )) (y2 − (λ2 v2 + µ2 ))\n(y1 ,y2 )∈G\nattains maximum at (λ1 x∗1 + µ1 , λ2 x∗2 + µ2 ).Independence of Irrelevant AlternativesWe are given G ⊆ F with G closed and convex. Let (x∗1 , x∗2 ) be optimal to (F, v)and let (y1∗ , y2∗ ) be optimal to (G, v). It is also given that (x∗1 , x∗2 ) ∈ G.• Since (x∗1 , x∗2 ) is optimal to F which is a superset of G, we haveN (x∗1 , x∗2 ) ≥ N (y1∗ , y2∗ )• Since (y1∗ , y2∗ ) is optimal to G and (x∗1 , x∗2 ) ∈ G, we haveN (y1∗ , y2∗ ) ≥ N (x∗1 , x∗2 )Therefore we haveN (x∗1 , x∗2 ) = N (y1∗ , y2∗ )Since the optimal solution is unique, we then immediately obtain(x∗1 , x∗2 ) = (y1∗ , y2∗ )SymmetrySuppose we have {(x2 , x1 ) : (x1 , x2 ) ∈ F } = F and v1 = v2 . Since v1 = v2 , wecan use v1 and v2 interchangeably. We can therefore say that (x∗1 , x∗2 ) maximizes(x1 − v2 )(x2 − v1 ). Since the optimal solution is unique, we should have (x∗1 , x∗2 ) =(x∗2 , x∗1 ) which immediately yields x∗1 = x∗2 .\nDecember 27, 20 v(C) is called the worth or value of the coalition C and it captures the totalamount of transferable utility that the members of C could earn without any helpfrom the players outside of C.Definition 27.2 (TU Game). A cooperative game with transferable utility is defined as the pair (N, v) where N = {1, . . . , n} is a set of players and v : 2N → Ris a characteristic function, with v(∅) = 0. We call such a game also as a game incoalition form, or game in characteristic form, or coalitional game, or TU game.Note. Under the assumption of transferable utility, specifying a single number foreach coalition is enough to describe what allocations of utility can be achieved bythe members of the coalition.Non-Transferable Utility (NTU) GamesGames without transferable utility (also called NTU coalitional games or games inNTU coalitional form) are defined as follows.Definition 27.3 (NTU Game). An NTU coalitional game is a pair (N, V ) whereN is a set of players N and V (·) is a mapping with domain 2N such that, for anycoalition C ⊂ N ,• V (C) is a non-empty closed and convex subset of R|C| , and• The set {x : x ∈ V (C) and xi ≥ vi ∀i ∈ C} is a bounded subset of R|C| , wherevi = max{yi : y ∈ V ({i})} < ∞ ∀i ∈ N.In the above definition, V (C) is the set of expected payoff allocations that themembers of coalition C could guarantee for themselves if they act cooperatively. AnNTU game is a generalization of a TU game. In the remainder of the discussion, wewill consider only TU games.\nDecember 27, 2013\n11:21\n404\nWorld Scientific Book - 10.25in x 7.5in\nbook\nGame Theory and Mechanism Design\nExamples of TU GamesExample 27.5 (Divide the Dollar Games). The Divide the Dollar - Version 1game discussed in Example 27.1 has the following characteristic function.v({1, 2, 3}) = 300v({1, 2}) = v({1, 3}) = v({2, 3}) = 0v({1}) = v({2}) = v({3}) = 0Version 2 of the game (Example 27.2) has the characteristic function:v({1, 2, 3}) = v({1, 2}) = 300v({2, 3}) = v({1, 3}) = 0v({1}) = v({2}) = v({3}) = 0Version 3 of the game (Example 27.3) has the characteristic function:v({1, 2, 3}) = v({1, 2}) = v({1, 3}) = 300v({1}) = v({2}) = v({3}) = v({2, 3}) = 0Version 4 of the game (majority voting game) (Example 27.4) has the characteristic form:v({1, 2, 3}) = v({1, 2}) = v({2, 3}) = v({1, 3}) = 300v({1}) = v({2}) = v({3}) = 0\n\u0003Note. In the sequel, we will follow a slight abuse of notation while referring tothe argument of the v(·) function: we shall drop the braces and commas whilerepresenting sets; for example, instead of v({2, 3}), we will simply write v(23), etc.,whenever there is no confusion.Example 27.6 (A Voting Game). This example is taken from [2]. Consider thatthe Parliament of a certain Nation has four political parties 1, 2, 3, 4 with 45, 25, 15, 12members respectively. To pass any bill, at least 51 votes are required. This situation couldbe modeled as a TU game with N = {1, 2, 3, 4} andv(1) = v(2) = v(3) = v(4) = 0v(12) = v(13) = v(14) = v(123) = v(124) = v(134) = v(234) = v(1234) = 1v(23) = v(24) = v(34) = 0\n\u0003Example 27.7 (Minimum Spanning Tree Game). Suppose multiple users are tobe connected to a shared resource (for example, a power plant, a synchrotron, a radiotelescope, a computational cluster, a logistics hub, a centralized drainage system, etc.). Inorder to utilize this resource, a user should either be directly connected to the facility orbe connected to some other connected user. Figure 27.1(a) provides a picture of a typical\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nbook\nCoalitional Games with Transferable Utility\n405\nnetwork of customers consisting of three players 1, 2, 3 and a central shared facility F . Weprovide several typical examples of such a network below.• Players 1, 2, 3 could correspond to three different industrial units and the facility Fcould be a power plant from which the units draw their power. The edges in the graphcorrespond to high capacity power lines and the weights on the edges correspond to thecost of power distribution.• Players 1, 2, 3 could correspond to three different city corporations and F could correspond to a drainage system. The edges represent the drainage connections between thepairs of locations and the edge weights correspond to the cost of maintaining and usingthe connections.• Players 1, 2, 3 could correspond to pick up points in a logistics network and F could bea logistics hub. The edges correspond to the roads in the network and the edge weightscorrespond to the distances.\n4\n4\n1\n2\n6\n1\n12\n6\n1\n5\n3\n2\n5\n2F\n3\nF\n3\n3\n(a)\n(b)\nFig. 27.1: A network of users connected to a central facility FSuppose each player gets a benefit of 10 units when he gets connected to F directlyor indirectly. Note that, given a coalition C ⊆ {1, 2, 3}, the minimum cost incurred bythe members of coalition C to get connected to F is given by the sum of edge weights in aminimal spanning tree involving F and the members of C. For example, suppose C = {2, 3}.Then the minimum cost corresponding to C would be given by the sum of costs of edgesin a minimal spanning tree involving the vertices 2, 3, F . Such a minimal spanning treeconsists of the edges (2, F ) and (2, 3) and therefore has total cost 3. If C = {1, 2, 3}, then,the minimum cost would be the sum of edges of a minimal spanning tree involving thevertices 1, 2, 3, F , which can be seen to be 7. Figure 27.1(b) depicts the minimal spanningtree involving 1, 2, 3, F through the thick edges.We can in a natural way, define the worth of each coalition as the total benefit thataccrues to the members of the coalition minus the minimum cost incurred in providingconnectivity from all members of the coalition to F . For example, v(23) would be 20 − 3since 20 is the total benefit that accrues to players 2 and 3 and the cost of the minimalspanning tree involving the nodes 2, 3, F is 3 units. We can now model the above situationas a TU game with characteristic function given byv(∅) = 0; v(1) = 10 − 5 = 5; v(2) = 10 − 1 = 9; v(3) = 10 − 3 = 7v(12) = 20 − 5 = 15; v(13) = 20 − 8 = 12; v(23) = 20 − 3 = 17; v(123) = 30 − 7 = 23.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n406\nbook\nGame Theory and Mechanism Design\nSuch a game formulation would be useful in determining how the costs and profits could beshared by the players involved.\u0003\nExample 27.8 (A Logistics Game). Figure 27.2 shows a logistics network that provides connectivity between two important cities S and T. There are five logistics hubs A, B,C, D, E which are intermediate points from S to T. Transportation is provided by serviceproviders 1, 2, 3, 4. Each edge in the network is labeled by two quantities namely the serviceprovider and the cost of service. For example, the label 3, 15 on the directed edge from Ato B means that service provider 3 provides the logistics service from A to B at a cost of15 units. Assume that movement from S to T fetches a revenue of 100 units. The objectiveis to choose an optimal path from S to T that maximizes the profit obtained while movingfrom S to T. We can formulate this as a cooperative game with N = {1, 2, 3, 4} and withcharacteristic functionv(1) = v(2) = v(3) = v(4) = 0v(12) = v(13) = v(14) = v(23) = v(24) = v(34) = v(234) = v(123) = 0v(134) = 100 − 60 = 40v(124) = 100 − 55 = 45v(1234) = 100 − 35 = 65A game such as above would be valuable in determining profit sharing protocols among thelogistics providers.\u00033,50\nA\n3,15\nB\n1,10\n2,15\nS\nE\n4,0\nT\n1,10\n2,15C\n3,10\nD1,40\nFig. 27.2: A logistics network\nTransforming Strategic Form Games to TU GamesIf we have a strategic form game model of interactions among players and we wishto model cooperation among these players, there are several natural ways of defining\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nCoalitional Games with Transferable Utility\nbook\n407\nthe characteristic function of a TU game. Three of the more common representationsare: (1) Minimax representation, (2) Defensive equilibrium representation, and (3)Rational threats representation. For more details on these, we refer the reader tothe book by Myerson [1] and the book by Maschler, Solan, and Zamir [3].ImputationsDefinition 27.4 (Imputation). Given a TU game (N, v), an imputation is anallocation x = (x1 , . . . , xn ) ∈ Rn that satisfies• Individual Rationality : xi ≥ v({i}) ∀ i ∈ NP• Collective Rationality :i∈N xi = v(N )An imputation keeps all individual players happy and also distributes the total valueof the grand coalition among the players (Pareto efficiency).Definition 27.5 (Domination of Imputation). An imputation x = (x1 , . . . , xn )of a TU game (N, v) is said to dominate an imputation y = (y1 , . . . , yn ) if there existsa coalition C such thatXxi ≤ v(C); and xi > yi ∀i ∈ Ci∈C\nExample 27.9 (Imputations and Domination). We make several observationsconcerning the notion of domination. Consider the majority voting game.(1) The allocations (150, 150, 0) and (100, 0, 200) are both imputations while the allocations(0, 0, 0), (100, 50, 50) are not imputations. The imputation (150, 150, 0) dominates theimputation (100, 0, 200) since the coalition {1, 2} is such that 150 > 100 and 150 > 0.(2) Given two imputations x and y, it is possible that neither dominates the other. Animmediate example would be the majority voting game where the imputation x =(150, 150, 0) neither dominates nor is dominated by the imputation y = (0, 150, 150).(3) The relation of domination is not transitive and cycles of domination are possible. Againan immediate example would be majority voting game where imputation (0, 180, 120)dominates imputation (150, 150,0) which dominates imputation (90, 0, 210) which inturn dominates (0, 180, 120).\n\u000327.3\nTU Games with Special Structure\nIn this section, we define several special classes of TU games.Monotonic GamesA monotonic TU game is one in which as we add players to a coalition, the worthof the coalition does not decrease.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n408\nbook\nGame Theory and Mechanism Design\nDefinition 27.6 (Monotonic Game). A TU game (N, v) is called monotonic ifv(C) ≤ v(D) ∀C ⊆ D ⊆ N.Example 27.10. It can be verified that both the minimum spanning tree game (Example27.7) and the logistics game (Example 27.8) are monotonic. In fact, all the examples wehave discussed so far in this chapter are monotonic. A simple example of a non-monotonicgame would be (N, v) with N = {1, 2} and v(1) = 10; v(2) = 20; v(12) = 15.\u0003\nSuperadditive GamesSuperadditive games are TU games where the value of union of any two disjointcoalitions is at least as much as the sum of values of the individual coalitions, thatis, two disjoint coalitions, on coming together, produce a non-negative additionalvalue beyond the sum of the individual values.Definition 27.7 (Superadditive Game). A TU game (N, v) is said to be superadditive ifv(C ∪ D) ≥ v(C) + v(D) ∀ C, D ⊆ N such that C ∩ D = φExample 27.11. The majority voting game with N = {1, 2, 3} and v given by v(1) =v(2) = v(3) = 0 and v(12) = v(13) = v(23) = v(123) = 300 is a superadditive game. Theminimum spanning tree game discussed in Example 27.7 is also a superadditive game. \u0003\nExample 27.12 (A Non-Superadditive Game). The following three player gameis not superadditive.v(1) = 10; v(2) = 15; v(3) = 20; v(12) = 20; v(13) = 30; v(23) = 35; v(123) = 40\n\u0003Note. Note that a monotonic game need not be superadditive and a superadditivegame need not be monotonic. It would be instructive to construct examples ofgames in all the four cases: (a) monotonic as well as superadditive (b) monotonicbut not superadditive (c) non-monotonic but superadditive (d) neither monotonicnor superadditive.Essential and Inessential GamesDefinition 27.8 (Essential Superadditive Game). A(N, v) is said to be inessential ifXv(i) = v(N )i∈N\nand essential otherwise.\nsuperadditive\ngame\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nCoalitional Games with Transferable Utility\nbook\n409\nIf (N, v) is inessential then,X\nv(i) = v(C) ∀ C ⊆ N\ni∈C\nTherefore (v(1), v(2), . . . , v(n)) is the only possible imputation for an inessentialgame. On the other hand, there are infinitely many imputations possible for anessential game.Strategic Equivalence of TU GamesDefinition 27.9. Two TU games (N, v) and (N, w) are said to be strategicallyequivalent if there exist constants c1 , c2 , . . . , cn and b > 0 such thatXw(C) = b(v(C) +ci ) ∀ C ⊆ Ni∈C\nIntuitively, strategic equivalence means that the “dynamics” among the playerswould be identical in the two games.An important result concerning strategic equivalence is that any superadditive,essential n-person characteristic form game G is strategically equivalent to a uniquegame withN = {1, 2, . . . , n}v(1) = v(2) = · · · = v(n) = 0; v(N ) = 10 ≤ v(C) ≤ 1 ∀ C ⊆ NThis unique game is called the 0-1 normalization of the original game.Triangular Representation for Three Person Superadditive GamesThe imputations in any three person game with v(1) = v(2) = v(3) = 0 andv(N ) = 1 can be represented using an interesting triangular representation. Thisrepresentation uses the following property: Suppose P is any point in an equilateraltriangle with height h. Then the sum of the perpendicular distances from P to thethree sides of the triangle is equal to h (see Figure 27.3).Example 27.13. If we consider the majority voting game with v(1) = v(2) = v(3) =0; v(12) = v(13) = v(23) = v(123) = 1 then any point ρ = (x1 , x2 , x3 ) inside the trianglerepresents an imputation because x1 ≥ 0; x1 ≥ 0; x2 ≥ 0; x3 ≥ 0; x1 + x2 + x3 = 1. Figure27.4 depicts several representative imputations.\u0003\nExample 27.14 (Bargaining in Majority Voting Game). Consider the majority voting game where we have N = {1, 2, 3} and v(1) = v(2) = v(3) = 0; v(12) = v(13) =v(23) = v(123) = 300. Suppose we start with an allocation (150, 150, 0) which indicates\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n410\nGame Theory and Mechanism Design3\nh\nx2\nx1P\nx32\n1\nFig. 27.3: An equilateral triangle, x1 + x2 + x3 = h\n3S\nT\nQ\n1\n2R\nFig. 27.4: Q = ( 12 , 14 , 14 ) ; R = ( 14 , 34 , 0); S = (0, 0, 1) ; T = ( 14 , 14 , 12 ) are imputations\na coalition between players 1 and 2. Player 3 can entice player 1 by proposing an allocation such as (180, 0, 120). Player 2 can now propose an allocation such as (0,120,180) anddraw player 3 out of the coalition with player 1. In this particular game, bargaining can goon endlessly without any allocation being agreed upon. A graphical representation of thisendless negotiation is presented in Figure 27.5.\u0003\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nbook\nCoalitional Games with Transferable Utility\n411\n3(20,0,280)(0,30,270)(60,0,240)\n(0,120,180)(150,0,150)\n(180,0,120)\n2\n1(150,150,0)\n(60,240,0)\nFig. 27.5: Chain of unending negotiations in majority voting gameConvex GamesConvex games are those TU games where the marginal contribution of any player toa coalition rises as more players join the coalition. That is, players have an incentiveto join larger coalitions than smaller coalitions. Formally convex games are definedas follows.Definition 27.10 (Convex Game). A TU game is said to be convex ifv(C ∪ D) + v(C ∩ D) ≥ v(C) + v(D) ∀C, D ⊆ N.Note. In the above definition, suppose C and D are disjoint. Then we obtainv(C ∪ D) ≥ v(C) + v(D) ∀ C, D ⊆ N with C ∩ D = ∅The above is precisely the definition of superadditivity. Thus every convex game issuperadditive. The converse need not be true.In the following propositions, we provide two equivalent definitions for convexgames. The proof of these propositions is left as an exercise.Proposition 27.1. A TU game (N, v) is convex iffv(C ∪ {i}) − v(C) ≤ v(D ∪ {i}) − v(D) ∀C ⊆ D ⊆ N ∀i ∈ N \\ D.Proposition 27.2. A TU game (N, v) is convex iffv(C ∪ E) − v(C) ≤ v(D ∪ E) − v(D) ∀C ⊆ D ⊆ N ∀E ⊆ N \\ D.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n412\n27.4\nGame Theory and Mechanism Design\nCost Games\nThe TU games we have discussed so far are referred to as profit games since theworth v(C) of a coalition C represents the total (maximum) value that could beearned together by the members of the coalition without any help from other players(not belonging to the coalition C). If on the other hand, the worth of a coalitionC represents the minimum total price the members of the coalition have to pay ifthe coalition were to form, then the resulting TU game is called a cost game. Costgames are complementary to profit games as illustrated in the following example.Often, cost games may be more natural to the given setting than profit games asshown in the following example.Example 27.15 (Cost Game). Consider the minimum spanning tree game we discussed in Example 27.7. Let us define the worth of each coalition as the minimum costincurred by the members of coalition C to get connected to F . Recall that, given a coalitionC ⊆ {1, 2, 3}, the minimum cost incurred by the members of coalition C to get connectedto F is given by the sum of edge weights in a minimal spanning tree involving F and themembers of C. The characteristic function of the cost game in this situation is:v(∅) = 0; v(1) = 5; v(2) = 1; v(3) = 3v(12) = 5; v(13) = 8; v(23) = 3; v(123) = 7.Such a game formulation would be useful in determining how the costs could be shared bythe players involved.\u0003\n27.5\nSummary and References\nThe following are the salient aspects of this chapter.• A natural extension of the Nash bargaining solution will not work for cooperativegames containing three or more players since Nash bargaining only takes intoaccount negotiations among all players in the grand coalition. This is illustratedclearly by the different versions of the divide the dollar problem.• Coalition formation and negotiation among players in a cooperative game couldinvolve intricate analysis since the negotiations might proceed endlessly andplayers may always find it in their benefit to leave a coalition and join a newcoalition. Cooperative game theory provides a set of solution concepts to suggestoutcomes that represent an acceptable and scientific end result of these complexnegotiations.• A transferable utility (TU) game or characteristic form game represents a cooperative game through a characteristic function v : 2N → R that associates avalue or worth to each coalition of players. The worth of a coalition is the totalutility the players of the coalition will be able to earn by themselves. Once acharacteristic function is defined, the rest of the analysis can follow.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nCoalitional Games with Transferable Utility\nbook\n413\n• A key issue in TU games is to derive the characteristic function v(·) to faithfullyreflect the effect of cooperation among different subsets of players. Often, thephysics of the underlying problem will naturally suggest a way of computing thecharacteristic function for different coalitions.• An imputation in a TU game (N, v) is an allocation of payoffs to the playerssuch that the sum of all payoffs is equal to v(N ) and the payoff for each playeri ∈ N is at least v({i}).• Superadditive games are TU games where the value of union of any pair of disjoint coalitions is no less than the sum of the values of the individual coalitions.Three person superadditive games can often be represented using a convenienttriangular representation.• Convex games are those in which a player’s marginal contribution to any coalition is less than or equal to his marginal contribution to any superset of thecoalition. Intuitively, marginal contribution of a player monotonically increaseswhen more players join that coalition. Convex games are superadditive but notvice-versa.• Cost games are TU games in which the the worth of a coalition is measuredby the minimum cost incurred by the players rather than the maximum profitthey can make by themselves. The TU games that are usually studied are calledprofit games and cost games are complementary to them.The material in this chapter is mostly based on the books by Myerson [1] andStraffin [4]. The recent book by Maschler, Solan, and Zamir [3] is another valuablereference. The next three chapters deal with different solution concepts for TUgames.References[1][2][3][4]\n27.6\nRoger B. Myerson. Game Theory: Analysis of Conflict. Harvard University Press, Cambridge,Massachusetts, USA, 1997.Yoam Shoham and Kevin Leyton-Brown. Multiagent Systems: Algorithmic, Game-Theoretic,and Logical Foundations. Cambridge University Press, New York, USA, 2009, 2009.Michael Maschler, Eilon Solan, and Shmuel Zamir. Game Theory. Cambridge UniversityPress, 2013.Philip D. Straffin Jr. Game Theory and Strategy. The Mathematical Association of America,1993.\nExercises\n(1) Provide an example of a a TU game in which every imputation is such that itis dominated by some other imputation.(2) Construct examples of TU games for the following situations:• Monotonic and superadditive\nJanuary 7, 2014\n11:47\n414\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\n• Monotonic but not superadditive• Superadditive but not monotonic• Neither superadditive nor monotonic(3) Show that the following game (called communication satellite game) is superadditive. Is it convex? (Source: [3]).v(1) = 3; v(2) = 2; v(3) = 1; v(12) = 8; v(13) = 6.5; v(23) = 8.2; v(123) = 11.2(4) Consider a TU game (N, v) where N = {1, 2, 3} andv(1) = v(2) = 1; v(3) = 2; v(12) = v(23) = v(13) = 4; v(123) = 5.Is this game superadditive? Is it convex? (Source: [3]).(5) Give an example of a TU game that is superadditive but not convex.(6) Show that the 0-1 normalization of any three person constant sum game (thatis, a TU game where, for every coalition C ⊆ N , v(C) + v(N \\ C) is a constant)is the three person majority voting game. (Source: [4]).(7) Given two TU games (N, v) and (N, w), and a number λ ∈ [0, 1], define a convexcombination of the games as the game (N, z) wherez(C) = λv(C) + (1 − λ)w(C) ∀C ⊆ N.If (N, v) and (N, w) are convex, then would (N, z) also be convex? Prove yourresult.(8) Prove Proposition 27.1: A TU game (N, v) is convex if and only ifv(C ∪ {i}) − v(C) ≤ v(D ∪ {i}) − v(D) ∀C ⊆ D ⊆ N ; ∀i ∈ N \\ D.(9) Prove Proposition 27.2: A TU game (N, v) is convex if and only ifv(C ∪ E) − v(C) ≤ v(D ∪ E) − v(D) ∀C ⊆ D ⊆ N ∀E ⊆ N \\ D.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nChapter 28\nThe Core of Coalitional Games\nGiven a transferable utility game (N, v), there are two key questions that are offundamental interest: (1) Which coalition(s) will form? (2) How should a coalitiondivide its value among its members? An answer to the second question has abearing on the answer for the first question. In this chapter, we start studyingthe answers to these questions using the notion of the core, a central notion incooperative game theory. We discuss the significance of the core of a TU gamewith several illustrative examples and present several key results concerning thissolution concept.\n28.1\nThe Core: Definition and Examples\nThe core is a set solution concept, that is, it is a set of payoff allocations each ofwhich could be a possible solution to the given TU game Let N = {1, . . . , n} be aset of players and let (N, v) be a TU game. A payoff allocation x = (x1 , . . . , xn )is any vector in Rn . xi is the utility payoff to player i, i ∈ N . We first define thenotions of feasible allocation, individually rational allocation, coalitionally rationalallocation, and collectively rational allocation.Definition 28.1 (Feasible Allocation). An allocation x = (x1 , . . . , xn ) ∈ Rn issaid to be feasible for a coalition C ifXxi ≤ v(C)i∈C\nIf an allocation x is feasible for C, the players in C can achieve their respectiveallocations in x by dividing among themselves the worth v(C) that they would beable to earn by cooperating together.Definition 28.2 (Rational Allocations). A payoff allocation x = (x1 , . . . , xn ) issaid to be individually rational ifxi ≥ v({i}) ∀i ∈ NIt is said to be collectively rational ifX\nxi = v(N )\ni∈N\n415\nbook\nDecember 27, 2013\n11:21\n416\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nIt is said to be coalitionally rational ifXxi ≥ v(C) ∀C ⊆ Ni∈C\nNote that coalitional rationality implies individual rationality. We have, in theprevious chapter, defined the notion of an imputation. It can be seen that an imputation is a payoff allocation that is individually rational and collectively rational.Collective rationality is the same as (Pareto) efficiency.Definition 28.3 (The Core). The core of a TU game (N, v), denoted by C(N, v),is the set of all payoff allocations that are coalitionally rational and collectively rational.)(nXXxi = v(N );xi ≥ v(C) ∀C ⊆ NC(N, v) = (x1 , . . . , xn ) ∈ Rn :i=1\ni∈C\nIn other words, the core is the set of all imputations that are coalitionally rational.Definition 28.4 (Blocking). We say a coalition C can improve on an allocationx = (x1 , . . . , xn ) ∈ Rn ifXv(C) >xii∈C\nWe also say that the coalition C blocks allocation x.The above definition implies that C can improve upon x iff there exists some allocation y such that y is feasible for C and every player in C can get strictly higherpayoff in y than in x (that is yi > xi ∀i ∈ C).Definition 28.5 (The Core: An Alternative Definition). The core of (N, v)is the set of allocations x such that x is feasible for N and no coalition C ⊆ N canimprove upon it.We can make the following observations on the concept of the core.Note. If an allocation x that is feasible for N is not in the core, then there wouldexist some coalition C such that the players in C could all do strictly better thanin x by cooperating together and dividing the worth v(C) among themselves.Note. If an allocation x belongs to the core, then it implies that for each player, aunilateral deviation will not make the player strictly better off. This means x is aNash equilibrium of an underlying contract signing game.Note. The core is an appealing solution concept in the light of the assumption thatall coalitions can negotiate effectively. Each allocation in the core could be viewedas resulting out of effective negotiations.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nThe Core of Coalitional Games\nbook\n417\nNote. The core of a TU game can be empty. If the core is empty, then we areunable to draw any conclusions about the game. At the same time, if the coreconsists of a large number of elements, then also, we have difficulty in preferringany particular allocation in the core.Note. The core of a TU game can be shown to be convex and compact. Convexityand compactness are two desirable properties satisfied by the core. For a proof ofthis result, the reader is referred to the book by Maschler, Solan, and Zamir [1].The Core: Some ExamplesExample 28.1 (Divide the Dollar Game). For the Divide the Dollar game (Version 1), C(N, v) is given by.\b\n(x1 , x2 , x3 ) ∈ R3 : x1 + x2 + x3 = 300, x1 ≥ 0, x2 ≥ 0, x3 ≥ 0\nThe core treats the three players symmetrically and includes all individually rational, Paretoefficient allocations. In Version 2 of the game (where players 1 and 2 by themselves can earn300 without the involvement of player 3), the core will be\b\n(x1 , x2 , x3 ) ∈ R3 : x1 + x2 = 300, x1 ≥ 0, x2 ≥ 0, x3 = 0\nIf players 1 and 2 can earn 300 together without player 3 or players 1 and 3 can earn 300together without player 2 (Version 3 of the game), it can be seen that the core consists ofjust a single element, namely (300, 0, 0).If the players get a nonzero allocation whenever any two players suggest the same allocation (Version 4 of the game - three person majority game), it can be seen that the core isempty. The following two insights provide a rationale for the emptiness of the core in thiscase. First, when any player i obtains a positive payoff in a feasible allocation, the othertwo players must get less than 300 which they would be able to gain by themselves. Second,regardless of what the final allocation is, there is always a coalition that could gain if thatcoalition gets one final opportunity to negotiate effectively against this allocation.\u0003\nExample 28.2 (A Three Player TU Game). This example is taken from [2].Here, N = {1, 2, 3} and v(1) = v(2) = v(3) = 0; v(12) = 0.25; v(13) = 0.5; v(23) =0.75; v(123) = 1. Note that (x1 , x2 , x3 ) ∈ C(N, v) iffx1 ≥ 0; x2 ≥ 0; x3 ≥ 0x1 + x2 ≥ 0.25; x1 + x3 ≥ 0.5; x2 + x3 ≥ 0.75;x1 + x2 + x3 = 1This would mean x1 ≤ 0.25; x2 ≤ 0.5; x3 ≤ 0.75. The core is depicted in Figure 28.1and happens to be a trapezoid with vertices at (0, 0.25, 0.75), (0, 0.5, 0.5), (0.25, 0, 0.75), and(0.25, 0.5, 0.25).\u0003\nDecember 27, 2013\n11:21\n418\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nFig. 28.1: Core of the game in Example 28.2 is a trapezoidExample 28.3 (House Allocation). This example is originally from the book by vonNeumann and Morgenstern [3]. Player 1 has a house which she values at Rs 1 million andwishes to sell the house. There are two potential buyers, player 2 and player 3 who havea valuation of Rs 2 million each and who also have with them Rs 2 million each. Supposeplayer 1 sells the house to player 2 at a price p million where 1 ≤ p ≤ 2. Then the utilityof player 1 is p million; utility of player 2 is (2 − p) + 2 = 4 − p million; and the utility ofplayer 3 is 2 million. A similar situation arises if player 1 sells house to player 3 at a pricep million, where 1 ≤ p ≤ 2. We thus get the characteristic form of the game as:v(1) = 1; v(2) = 2; v(3) = 2; v(12) = v(13) = v(23) = 4; v(123) = 6An allocation (x1 , x2 , x3 ) ∈ C(N, v) iffx1 ≥ 1; x2 ≥ 2; x3 ≥ 2; x1 + x2 ≥ 4; x2 + x3 ≥ 4; x1 + x3 ≥ 4; x1 + x2 + x3 = 6.The only allocation that satisfies the above equations is (2, 2, 2) which is the lone elementin the core. This corresponds to player 1 selling her house at the maximum possible priceof Rs. 2 million.\u0003\nExample 28.4 (Core of MST Profit Game). Consider the minimum spanningtree game with N = {1, 2, 3}, discussed in Example 27.7:v(1) = 5; v(2) = 9; v(3) = 7; v(12) = 15; v(13) = 12; v(23) = 17; v(123) = 23\nbook\nJanuary 10, 2014\n9:51\nWorld Scientific Book - 10.25in x 7.5in\nThe Core of Coalitional Games\nbook\n419\nThe equations defining the core are given byx1 ≥ 5; x2 ≥ 9; x3 ≥ 7 x1 + x2 ≥ 15; x1 + x3 ≥ 12; x2 + x3 ≥ 13; x1 + x2 + x3 = 23.The above equations imply that the core is given by the set{(x1 , x2 , x3 ) : 5 ≤ x1 ≤ 6; 9 ≤ x2 ≤ 11; 7 ≤ x3 ≤ 8; x1 + x2 + x3 = 23}Clearly this is an uncountably infinite set. Note that the core allocation for player 2 is thehighest as expected; the core allocation for player 1 is the least which is again according tointuition.\u0003\nExample 28.5 (A Glove Market). This example shows that core may be non-emptyin some pathological cases. First we consider a simple case and then generalize it. Let therebe 5 suppliers of gloves. Of these the first two players can each supply one left glove and theother three players can supply one right glove each. Suppose NL = {1, 2} is the set of leftglove suppliers and NR = {3, 4, 5} the set of right glove suppliers. Suppose the worth of eachcoalition is the number of matched pairs that it can assemble. For example, if C = {1, 3},the worth of C is 1, whereas if C = {3, 4}, the worth of C is 0. In general, given C ⊆ N ,v(C) = min{|C ∩ NL |, |C ∩ NR |}The core of this game can be seen to be the singleton {(1, 1, 0, 0, 0)}.On the other hand, if NL = {1, 2, 3} and NR = {4, 5}, the core of the game would bethe singleton {(0, 0, 0, 1, 1)}. If the cardinalities of the two sets NL and NR are equal, thenthe core takes a different form altogether. For example, if NL = {1, 2} and NR = {3, 4},the core of the game would contain many elements including ( 12 , 12 , 12 , 12 ).We will now generalize the example to n = 2, 000, 001. Of these, 1, 000, 000 players caneach supply one left glove and the other 1, 000, 001 players can each supply one right glove.The core of this game consists of the unique allocation x such thatxi = 1 if i ∈ NL= 0 if i ∈ NRThe reason for this is:Xi∈NL\nxi +\nX\nxj ≥ 1, 000, 000 ∀k ∈ NR\nj∈NR \\{k}\nSuppose that some right glove supplier has some positive payoff in a feasible allocation.Then the total payoff to the other 2, 000, 000 players must be less than 1, 000, 000, whichthey could improve by making 1, 000, 000 matched pairs among themselves, without thisdistinguished right glove supplier. An economic interpretation of the example is as follows.Since right gloves are in excess supply, they have a market price of 0. If we add just twomore left glove suppliers, the unique core allocation would switch toxi = 0 if i ∈ NL= 1 if i ∈ NR\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n420\nGame Theory and Mechanism Design\nin which every left glove supplier gets zero payoff while every right glove supplier gets payoff1. It would be interesting to see what the core would be if there are 1, 000, 000 left glovesuppliers and 1, 000, 000 right glove suppliers.\u0003\nEpsilon CoreThe instability displayed by the core for large games (such as the glove marketexample) can be somewhat overcome using the notion of ε-core or ε-approximatecore. Given any number ε ≥ 0, an allocation x is in the ε-core of the coalitionalgame (N, v) iffXxi = v(N )i∈N\nX\nxi ≥ v(C) − ε|C| ∀C ⊆ N\ni∈C\nIf x is in the ε-core, then no coalition C would be able to guarantee all its membersε more than what they get in x.Example 28.6 (Epsilon Core of Glove Market). For the glove market example,an allocation x is in the ε-core iffmin{xi : i ∈ NL } + min{xj : j ∈ NR } ≥ 1 − 2εThis means the worst-off left glove supplier and the worst-off right glove supplier togethermust get at least 1 − 2ε. With 1, 000, 000 left glove suppliers and 1, 000, 001 right glovesuppliers, if ε > 0.0000005, then for any number λ such that 0 ≤ λ ≤ 1, the allocation xsuch thatλ∀i ∈ NRxi = 1 − λ ∀i ∈ NL ; xi =1.000001is in the ε-core of the above glove market game.\u0003\n28.2\nCharacterization of Games with Non-Empty Core\nThe classic, independent findings of Shapley and Bondereva provide a characterization of games with non-empty core, using linear programming [4, 5]. To understandthis characterization, we first look into the following linear program (LP), given aTU game (N, v).minimize x1 + x2 + . . . + xn subject toX\nxi ≥ v(C) ∀C ⊆ N i; (x1 , . . . , xn ) ∈ Rn .\ni∈C\nThe above LP determines the least amount of transferable utility which is necessaryfor an allocation so that no coalition can improve upon it. Note that this LPdefinitely has a solution if it is feasible. This is because all the inequalities are of\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nThe Core of Coalitional Games\nbook\n421\nthe greater than or equal to type and also because of the structure of the inequalities.Let (x∗1 , x∗2 , . . . , x∗n ) be an optimal solution of this LP. Then we knowXx∗i ≥ v(C) ∀C ⊆ Ni∈C\nIn particular, x∗1 + . . . + x∗n ≥ v(N ). There are two possibilities:(1) x∗1 + . . . + x∗n = v(N ). In this case, all solutions of this LP will constitute thecore C(N, v). In fact, the core will consist precisely of the solutions of this LP.(2) x∗1 + . . . + x∗n > v(N ). In this case, it is clear that the C(N, v) is empty.Example 28.7 (Divide the Dollar Game). Recall Version 4 of the divide the dollargame (majority voting game) where N = {1, 2, 3} and v(1) = v(2) = v(3) = 0; v(12) =v(23) = v(13) = v(123) = 300. The linear program would be:minimizesubject to\nx1 + x2 + x3x1 , x2 , x3 ≥ 0x1 + x2 ≥ 300x2 + x3 ≥ 300x1 + x3 ≥ 300x1 + x2 + x3 ≥ 300x1 , x2 , x3 ∈ R\nThe unique optimal solution of this LP is:x∗1 = x∗2 = x∗3 = 150Since x∗1 + x∗2 + x∗3 = 450 > 300 = v({1, 2, 3}), the core is empty.Now consider Version 3 of the Divide the Dollar game. Recall for this game that N ={1, 2, 3} and v(1) = v(2) = v(3) = v(23) = 0; v(12) = v(13) = v(123) = 300. The LP hereis:minimizesubject to\nx1 + x2 + x3x1 , x2 , x3 ≥ 0x1 + x2 ≥ 300x1 + x3 ≥ 300x2 + x3 ≥ 0x1 + x2 + x3 ≥ 300\nThe unique optimal solution here is:x∗1 = 300; x∗2 = x∗3 = 0The optimal value is 300. Since x∗1 + x∗2 + x∗3 = v(N ), the core consists of a single element(300, 0, 0).\u0003\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n422\nGame Theory and Mechanism Design\nExample 28.8 (Duals of the Linear Programs for Divide the Dollar). Letus first examine the dual of the LP for the majority voting game. The objective function ofthe dual LP is:α(1)[v(1)]+α(2)[v(2)]+α(3)[v(3)]+α(12)[v(12)]+α(23)[v(23)]+α(13)[v(13)]+α(123)[v(123)]The dual LP for the majority voting game will be:maximizesubject to\n300[α(12) + α(23) + α(13) + α(123)]α(1) + α(12) + α(13) + α(123) = 1α(2) + α(12) + α(23) + α(123) = 1α(3) + α(13) + α(23) + α(123) = 1α(1) ≥ 0; α(2) ≥ 0; . . . ; α(123) ≥ 0\nAn optimal solution of this dual LP is given by:12α(1) = α(2) = α(3) = α(123) = 0α(12) = α(13) = α(23) =\nHere the core is empty. Now we examine the dual of the LP for Version 3 of the game. Thedual LP is:maximize300[α(12) + α(13) + α(123)]subject to α(1) + α(12) + α(13) + α(123) = 1α(2) + α(12) + α(23) + α(123) = 1α(3) + α(13) + α(23) + α(123) = 1α(1) ≥ 0; α(2) ≥ 0; . . . ; α(123) ≥ 0The optimal value of the dual is again, clearly, 300. The optimal solution is α(12) = α(13) =1\u00032 with all other α(·) values zero.\nShapley - Bondereva CharacterizationIn general, the primal LP is:minimize\nX\nxi subject to\ni∈N\nX\nxi ≥ v(C) ∀C ⊆ N xi ∈ R ∀i ∈ N.\ni∈C\nThe dual LP is given by:maximize\nX\nα(C)v(C) subject to\nC⊆N\nXC⊇{i}\nα(C) = 1 ∀i ∈ N ; α(C) ≥ 0 ∀C ⊆ N.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nThe Core of Coalitional Games\nbook\n423\nLet us apply the strong duality theorem here. Recall: if the primal (dual) has anoptimal solution, then the dual (primal) has an optimal solution and the optimalvalues are the same. It is easy to see that an optimal solution exists for the aboveprimal. Hence by applying the strong duality theorem, given a TU game (N, v),there exists an allocation x∗ ∈ Rn and a vector α∗ (C)C⊆N such thatX\nx∗i ≥ v(C)\ni∈C\nα∗ (C) ≥ 0 ∀C ⊆ NX\nα∗ (C) = 1 ∀i ∈ N\nC⊇{i}\nThis is illustrated by both Example 28.7 and Example 28.8 presented above. Let usnow impose the following condition:XXα(C) = 1 ∀i ⊆ N =⇒α(C)v(C) ≤ v(N )C⊆N\nC⊇{i}\nThat is, feasibility of the dual implies that the value of the objective function of thedual is ≤ v(N ). We know that the optimal value of the primal ≥ v(N ). Since theLP has a solution, the optimal solution therefore will have value v(N ). This ensuresthat the core is non-empty. This means we have a necessary and sufficient conditionfor the non-emptiness of the core. This necessary and sufficient condition is calledbalancedness.Definition 28.6 (Balanced TU Games). A TU game (N, v) is said to be balanced ifXXα(C) = 1 ∀i ∈ N =⇒α(C)v(C) ≤ v(N )C⊆N\nC⊇{i}\nWe are now in a position to state the important theorem that we have just nowproved.Theorem 28.1. The core of a TU game (N, v) is non-empty iff the game (N, v) isbalanced.The components of any optimal solution (x∗1 , x∗2 , . . . , x∗n ) of the above optimization problem are called balanced aspirations of the players. The phrase is appropriatesinceXx∗i ≥ v(C) ∀C ⊆ Ni∈C\nThe aspirations are balanced by the fact that (x1 + x2 + . . . + xn ) is minimized.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n424\n28.3\nGame Theory and Mechanism Design\nThe Core of Convex Games\nRecall from Chapter 27 that a TU game (N, v) is said to be convex if for every i ∈ N ,the marginal contribution of player i to larger coalitions is larger. Interestingly, thecore of any convex game is non-empty. The following result on convex games exhibitsan allocation that surely belongs to the core of the game.Proposition 28.1. Given a convex game (N, v), the allocation x = (x1 , . . . , xn )defined byx1 = v({1})x2 = v({1, 2}) − v({1})...xn = v({1, 2, . . . , n}) − v({1, 2, . . . , n − 1})belongs to the core of the game. That is, x ∈ C(N, v).Proof: It can be easily verified for the allocation x = (x1 , . . . , xn ) defined above,that x1 + . . . + xn = v(N ) and therefore X is collectively rational. It remains to beshown that x is coalitionally rational. That is, we have to show thatXxi ≥ v(E); ∀E ⊆ N.i∈E\nNote that N = {1, 2, . . . , n}. Suppose E is any coalition of players in N . We canwrite E = {i1 , i2 , . . . , ik } for some k ≤ n. We can assume without loss of generalitythat i1 < i2 < · · · < ik . This will enable us to observe that{i1 , i2 , . . . , ij−1 } ⊆ {1, 2, . . . , ij − 1}; ∀j ∈ {1, 2, . . . , k}.At this point, recall proposition 27.1 which states that a TU game (N, v) is convexiffv(C ∪ {i}) − v(C) ≤ v(D ∪ {i}) − v(D) ∀C ⊆ D ⊆ N ∀i ∈ N \\ D.Choosing C = {i1 , i2 , . . . , ij−1 }; D = {1, 2, . . . , ij − 1}; and i = ij ∈ N \\ D, weimmediately obtainv({i1 , i2 , . . . , ij }) − v({i1 , i2 , . . . , ij−1 )} ≤ v({1, 2, . . . , ij }) − v({1, 2, . . . , ij − 1}).Using the above, we next observe thatxi1 = (v({1, 2, . . . , i1 }) − v({1, 2, . . . , i1 − 1})) ≥ (v({i1 }) − v(∅)),xi2 = (v({1, 2, . . . , i2 }) − v({1, 2, . . . , i2 − 1})) ≥ (v({i1 , i2 }) − v({i1 })),and so on untilxik = (v({1, 2, . . . , ik }) − v({1, 2, . . . , ik − 1})) ≥ (v({i1 , i2 , . . . , ik }) − v({i1 , i2 , . . . , ik − 1})).\nSumming the above k inequalities and simplifying, we obtainxi1 + xi2 + · · · + xik ≥ v({i1 , i2 , . . . , ik }) = v(E).\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nThe Core of Coalitional Games\nbook\n425\nThe above is clearly true for any E ⊆ N , thus proving coalitional rationality.\n\u0004\nThe above proposition immediately leads to the following result which showsthat any allocation obtained through a permutation of the set N will also work.We first define some notation. Let Π(N ) denote the set of all permutations ofN = {1, 2, . . . , n}. Suppose π ∈ Π(N ) is any permutation. Let P (π, i) denote theset of players who are predecessors of i in the permutation π. That isP (π, i) = {j ∈ N : π(j) < π(i)}.Define the marginal contribution of player i to his predecessors in π bym(P, i) = v(P (π, i) ∪ {i}) − v(P (π, i)).Proposition 28.2. Suppose (N, v) is a convex game and π ∈ Π(N ) is any permutation. Then the allocation y π = (m(π, 1), m(π, 2), . . . , m(π, n)) belongs to the coreof (N, v). That is, y π ∈ C(N, v).We will be using the above proposition in the next chapter to prove that the Shapleyvalue of any convex game belongs to the core of the game.28.4\nThe Core of Cost Games\nWe have seen in Chapter 27 that TU games where the worth of a coalition is givenby the total minimum cost incurred by the players in the coalition are called costgames. When we work with cost games, the definition of the Core will involve ≤instead of ≥:()XXC(N, v) = (x1 , . . . , xn ) ∈ Rn :xi ≤ v(C) ∀C ⊆ N ;xi = v(N ) .i∈C\ni∈N\nExample 28.9 (Core of MST cost game). Consider the cost game with N ={1, 2, 3} corresponding to the minimum spanning tree game:v(1) = 5; v(2) = 1; v(3) = 3; v(12) = 5; v(13) = 8; v(23) = 3; v(123) = 7The equations defining the core are given byx1 ≤ 5; x2 ≤ 1; x3 ≤ 3 x1 + x2 ≤ 5; x1 + x3 ≤ 8; x2 + x3 ≤ 7; x1 + x2 + x3 = 7.The above equations imply that the core is given by the set{(x1 , x2 , x3 ) : 4 ≤ x1 ≤ 5; −1 ≤ x2 ≤ 1; 2 ≤ x3 ≤ 3; x1 + x2 + x3 = 7}Note that the core allocation for player 2 could even be negative, meaning player 2 canactually receive money. It would be interesting to compare this with the core of the MSTprofit game (example 28.4).\u0003\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n426\n28.5\nGame Theory and Mechanism Design\nSummary and References\nWe summarize here the important concepts discussed in this chapter.• Given a characteristic form game or TU game (N, v), the core of the gameconsists of all allocations that are coalitionally rational and collectively rational.Given an allocation x = (x1 , . . . , xn ) in the core, no coalition C of players willbe able to block x because the worth of the coalition, v(C), is less than or equalto the sum of the allocations in x of players of C. The elements of the core canbe interpreted as Nash equilibria of an appropriate, underlying contract signinggame.• The core of a TU game can be empty, may be a countable set, or may evenbe an uncountable set. A game with empty core (majority voting game beingan immediate example) implies that negotiations among players may be neverending. The core of a TU game will always be convex and compact.• If the core consists of a large number of elements, the difficulty would be howto select a particular best element from the core. Other solution concepts incooperative game theory could be useful here.• Shapley and Bondereva have provided a characterization of TU games with nonempty core. They have independently proved, using LP duality, that a TU gamehas non-empty core if and only if it is balanced.• An appropriate linear programming formulation can be used to determinewhether or not a given TU game has non-empty core. The linear programcan be used to compute the elements of the core.• In order to compute the core of a cost game, we need to reverse the inequalitiesin the core equations from ≥ to ≤.• The core of a convex game is non-empty.The discussion presented in this chapter follows that of Myerson [6] and Straffin[2]. The foundations for the results on the core have been laid in the classic papersby Gerard Debreu and Herbert Scarf [7] and Herbert Scarf [8]. The balancednesscharacterization of the core is by Bondereva [4] and Shapley [5]. For an excellentdetailed treatment of the core and key results concerning the core, we refer thereader to the books by Peleg and Sudholter [9] and Maschler, Solan, and Zamir [1].In the next chapter, we discuss the Shapley value.References[1][2][3 ]\nMichael Maschler, Eilon Solan, and Shmuel Zamir. Game Theory. Cambridge UniversityPress, 2013.Philip D. Straffin Jr. Game Theory and Strategy. The Mathematical Association of America,1993.John von Neumann and Oskar Morgenstern. Theory of Games and Economic Behavior.Princeton University Press, 1944.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nThe Core of Coalitional Games[4][5][6][7][8][9]\n28.6\nbook\n427\nO.N. Bondereva. “Some applications of linear programming methods to the theory of cooperative games”. In: (In Russian) (1963).Lloyd S. Shapley. “On balanced sets and the core”. In: Naval Research Logistics Quarterly14 (1967), pp. 435–460.Roger B. Myerson. Game Theory: Analysis of Conflict. Harvard University Press, Cambridge,Massachusetts, USA, 1997.Gerard Debreu and Herbert Scarf. “A limit theorem on the core of an economy”. In: International Economic Review 4 (1963), pp. 235–246.Herbert E. Scarf. “The core of an n-person game”. In: Econometrica 35 (1967), pp. 50–69.B. Peleg and P. Sudholter. Introduction to the Theory of Cooperative Games. Kluwer Academic, Boston, USA, 2003.\nExercises\n(1) A constant sum TU game (N, v) is one in whichv(C) + v(N \\ C) = cwhere c is some constant. Show that the core of any essential, constant sumgame is empty. (Source: [2]).(2) Consider the glove market example. What will be the core of this game if thereare 1, 000, 000 left glove suppliers and 1, 000, 000 right glove suppliers?(3) Consider the following variant of the real estate example. Player 1 has a valueof Rs. 1 million; player 2 has value of Rs. 2 million; and player 3 has a value ofRs. 3 million for the house. Player 2 has Rs. 3 million cash, so also player 3.Formulate an appropriate TU game and compute the core. (Source: [2]).(4) Consider a three person superadditive game with v(1) = v(2) = v(3) =0; v(12) = a; v(13) = b; v(23) = c; v(123) = d where 0 ≤ a, b, c ≤ d. Computethe core for this game. When is the core non-empty for this game? (Source:[2]).(5) Find the core of the communication satellites game defined as follows:v(1) = v(2) = v(3) = 0v(12) = 5.2; v(13) = 2.5; v(23) = 3; v(123) = 5.2(Source: [2]).(6) Consider a TU game (N, v) where N = {1, 2, 3} andv(1) = v(2) = 1; v(3) = 2; v(12) = V (23) = v(13) = 4; v(123) = 5.What is the core of this game? (Source: [1]).(7) Compute the core of the logistics game discussed in Chapter 27. Recall thatN = {1, 2, 3, 4} and the characteristic function isv(1) = v(2) = v(3) = v(4) = 0v(12) = v(13) = v(14) = v(23) = v(24) = v(34) = v(234) = v(123) = 0v(134) = 40; v(124) = 45; v(1234) = 65\nJanuary 7, 2014\n12:9\n428\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\n(8) Consider a game with five players where player 1 is called a big player and theothers are called small players. The big player with one or more small playerscan earn a worth of 1. The four small players together can also earn 1. LetN = {1, 2, 3, 4, 5}v(C) = 1 if 1 ∈ C and |C| ≥ 2= 1 if |C| ≥ 4= 0 otherwiseCompute the core for this game. (Source: [1]).(9) Let us consider a version of divide the dollar problem with 4 players and totalworth equal to 400. Suppose that any coalition with three or more players willbe able to achieve the total worth. Also, a coalition with two players will be ableto achieve the total worth only if player 1 is a part of the two player coalition.Set up a characteristic function for this TU game and compute the core.(10) Consider another version of divide the dollar problem with 4 players and totalworth equal to 400. Any coalition containing at least two players and havingplayer 1 would be able to achieve the total wealth of 400. Similarly, any coalitioncontaining at least three players and containing player 2 also would be able toachieve the total wealth of 400. Set up a characteristic form game for thissituation and compute the core.(11) It has been stated that the core of a TU game is convex and compact. Provethis result.(12) A market game is a TU game that consists of a set B of buyers and a set S ofsellers such that N = B ∪ S and B ∩ S = ∅, andv(C) = min(|C ∩ B|, |C ∩ S); ∀C ⊆ N.Compute the core of a market game. (Source: [1]).(13) Consider a TU game with N = {1, 2, 3, 4} and v(C) = 0 for all coalitions C ofcardinality 1 or cardinality 3; v(C) = 30 for all coalitions C of cardinality 2;and v(C) = 50 for all coalitions C of cardinality 4. Compute the core of thisgame. (Source: [1]).(14) Programming Assignment. Design a program that, given a TU game, wouldformulate an appropriate LP and tell us whether the core of the game is emptyor non-empty finite or non-empty infinite. In case the core is non-empty andfinite, the program should output the elements of the core.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nChapter 29\nThe Shapley Value\nThe Shapley value is a popular solution concept in cooperative game theory thatprovides a unique allocation to a set of players in a coalitional game. Like the Nashbargaining solution, the Shapley value is based on a set of axioms that determine theallocations to different players based on the axioms. The Shapley value faithfullycaptures the marginal contributions of the players in deciding the allocations. Ithas found widespread applications in a variety of engineering applications. In thischapter, we present the Shapley axioms and prove the existence and uniquenessof the Shapley value. We present several illustrative examples and also prove keyresults.\nGiven a coalitional game, the core may be empty or may be very large or evenuncountably infinite. These certainly cause difficulties in getting sharp predictionsfor the game. The Shapley value is a solution concept which is motivated by the needto have a solution concept that would predict a unique expected payoff allocationfor every given coalitional game. The Shapley value concept was proposed usingan axiomatic approach by Shapley in 1953, as a part of his doctoral dissertation atthe Princeton University. Given a game in coalitional form (N, v), we denote theShapley value by φ(N, v) = (φ1 (N, v), . . . , φn (N, v)) where φi (N, v) is the expectedpayoff to player i. When there is no confusion, we use φ(v) instead of φ(N, v), φi (v)ninstead of φi (N, v), etc. Also, note that v ∈ R2 −1 , where we have omitted v(∅)which is obviously equal to 0.The Shapley value tries to capture how coalitional competitive forces influencethe possible outcomes of a game. It describes a reasonable or fair way of dividing thegains from cooperation given the strategic realities captured by the characteristicfunction. It crucially uses the marginal contributions of players as a guiding factor.\nNote. In this chapter, as we have done in some earlier chapters, we shall (by slightabuse of notation) denote sets {1}, {2}, {3}, {1, 2}, {1, 2, 3} simply by 1, 2, 3, 12,123, respectively. This is purely for the sake of convenience.\n429\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n430\nGame Theory and Mechanism Design\nLloyd Shapley can be considered as one of the most influential game theorists of all time. In particular, he is the mostimportant contributor to cooperative game theory. He has madenumerous pioneering contributions which have started new areas in game theory. He is a co-recipient with Alvin Roth of theNobel Prize in Economic Sciences for the year 2012. Many concepts, lemmas and theorems have been named after him. Theseinclude, first and foremost, the Shapley value, a popular solutionconcept in cooperative game theory.Shapley’s pioneering contributions include: (1) Bondareva - Shapley theorem (seeprevious chapter) which provides a necessary and sufficient condition for the nonemptiness of the core of a coalitional game and which also implies that convex gameshave non-empty cores (2) Gale - Shapley algorithm [1] which provides the first andperhaps the most used solution to the stable marriage problem (3) Aumann - Shapleypricing that pioneered the pricing of products and services that share resources (4)Shapley - Folkmann lemma which settled the question of convexity of addition ofsets (5) Shapley-Shubik power index [2] for determining voting power. Moreover,stochastic games were first proposed by Shapley as early as 1953 [3]. Potential gameswhich are extensively used by researchers these days were proposed by Monderer andShapley in 1996 [4]. His joint work with Maschler and Peleg on the kernel and thenucleolus is quite path breaking and so is his work with Robert Aumann on nonatomic games and on long-term competition.Shapley was born in 1923 in Cambridge, Massachusetts and he was a genius inmathematics from an early age. He joined Harvard university for his undergraduatestudies and got his A.B. Degree in 1948. During 1943 - 45, he worked for the AmericanMilitary and as a Sargeant in Army Corps in 1943, he brilliantly broke the Sovietweather code and was decorated with a Bronze star at the age of 20. He startedworking with Albert Tucker at the Princeton University in 1949 and got his Ph.D.in 1953. The work on what is now called the Shapley value was carried out duringthis period. The title of his doctoral dissertation was Additive and Nonadditive SetFunctions. John Nash and Shapley were contemporaries working with the celebratedAlbert Tucker. From 1954 to 1981, Shapley spent 27 years at the Rand Corporationas research mathematician and produced many path breaking results. Since 1981, hehas been at the University of California, Los Angeles, working in the Department ofEconomics as well as the Department of Mathematics.\n29.1\nThe Shapley Axioms\nLet (N, v) be a game in coalitional form. Let π be a permutation on the set N . Let(N, πv) be the coalitional game with the permuted value function given byπv({π(i) : i ∈ C}) = v(C), ∀ C ⊆ NThis means that the role of any player i ∈ N , in the game (N, v) is essentially thesame as the role of player π(i) in (N, πv).Example 29.1.\nSuppose N = {1, 2, 3}. Consider the permutation π on N de-\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nThe Shapley Value\nbook\n431\nfined by π(1) = 3; π(2) = 1; π(3) = 2. Then the game (N, πv) will be the following: πv(1) = v(2); πv(2) = v(3); πv(3) = v(1); πv(12) = v(23); πv(23) =v(13); πv(13) = v(12); πv(123) = v(123).\u0003Shapley proposed three axioms to describe the desirable properties that we wouldexpect a good solution concept to satisfy: (1) Axiom 1 : Symmetry; (2) Axiom 2 :Linearity; (3) Axiom 3 : Carrier.Axiom 1: Symmetryn\nFor any v ∈ R2 −1 , any permutation π on N , and any player i ∈ N , the symmetryaxiom states thatφπ(i) (πv) = φi (v)Informally, the Shapley value of a player relabeled by a permutation, under thepermuted value function is the same as the Shapley value of the original playerunder the original value function. This axiom implies that only the role of a playerin the game should matter. The labels or specific names used in N are irrelevant.Axiom 2: LinearityLet (N, v) and (N, w) be any two coalitional games. Suppose p ∈ [0, 1]. Define anew coalitional game (N, pv + (1 − p)w) as follows.(pv + (1 − p)w)(C) = pv(C) + (1 − p)w(C) ∀C ⊆ NAxiom 2 states that, given any two coalitional games (N, v) and (N, w), any numberp ∈ [0, 1], and any player i ∈ N ,φi (pv + (1 − p)w) = pφi (v) + (1 − p)φi (w)In other words, the Shapley value of a player for a convex combination of coalitionalgames is the convex combination of Shapley values of the player in the individualgames. This axiom asserts that the expected payoff to each player is the same beforeresolution of uncertainty and after resolution of uncertainty.Axiom 3: CarrierDefinition 29.1 (Carrier). A coalition D is said to be a carrier of a coalitionalgame (N, v) ifv(C ∩ D) = v(C) ∀C ⊆ NIf D is a carrier and i ∈/ D, thenv({i}) = v({i} ∩ D) = v(φ) = 0\nDecember 27, 2013\n11:21\n432\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nIf D is a carrier of (N, v), all players j ∈ N \\ D are called dummies in (N, v) becausetheir entry into any coalition cannot change the worth of the coalition. Also, forany C ⊆ N and i ∈/ D,v(C ∪ {i}) = v((C ∪ {i}) ∩ D) = v(C ∩ D) = v(C)Intuitively, D includes all influential players (it might also include non-influentialplayers but it will not exclude any influential player). If D is a carrier and i ∈ N ,then for any C ⊆ N ,v(C) = v(C ∩ D) = v(C ∩ (D ∪ {i}))Hence, D ∪ {i} for any i ∈ N is also a carrier. In fact, the set N is always a carrier.This means that v(D) = v(N ). This can also be seen fromv(D) = v(D ∩ N ) = v(N )It is however possible that no proper subset of N is a carrier.nThe Carrier Axiom (Axiom 3) states that, for any v ∈ R2 −1 and any coalitionD that is a carrier of (N, v),Xφi (v) = v(D) = v(N )i∈D\nThe carrier axiom immediately implies thatφi (v) = 0 ∀ i ∈/DXφi (v) = v(N )i∈N\nThis axiom asserts that the players in a carrier set should divide their joint worth(which is equal to the worth of the grand coalition) among themselves. This meansthe dummies are allocated nothing. The above expression also illustrates a key factthat the Shapley value always divides the worth of the grand coalition among theplayers of the game. This means that Shapley value implicitly assumes the formationof the grand coalition (however some of these players may be dummy players whodo not get anything allocated).Note. Throughout the rest of this chapter, we will denote, for the sake of convenience, the set N \\ {i} by the notation N − i.29.2\nShapley’s Theorem and Examples\nWith the above three axioms in place, we are now in a position to state the celebratedresult due to Shapley [5].n\nTheorem 29.1. There is exactly one mapping φ : R2 −1 → Rn that satisfies Axiomn1, Axiom 2, and Axiom 3. This mapping satisfies: ∀i ∈ N, ∀v ∈ R2 −1 ,X |C|! (n − |C| − 1)!{v(C ∪ {i}) − v(C)}φi (v) =n!C⊆N −i\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nThe Shapley Value\nbook\n433\nThe term |C|! (n−|C|−1)!can be interpreted as the probability that in any pern!mutation, the members of C are ahead of a distinguished player i. The termv(C ∪ {i}) − v(C) gives the marginal contribution of player i to the worth of thecoalition C. Thus the above formula for φi (v) gives the expected contribution ofplayer i to the worth of any coalition.Suppose there is a collection of n resources and each resource is useful in itsown way towards executing a certain service. Suppose v(N ) is the total value thatthis collection of resources would create if all the resources are deployed for theaccomplishment of the service. Let us focus on a certain resource, say resource i.Now, this resource will make a marginal contribution to every subset C of N − iwhen it is included to the set C. We can choose the set C in (|C|! |n−|C|−1|!) waysand when this is divided by n!, we obtain the probability of choosing a particularsubset C. Thus the Shapley value of resource i is the average marginal contributionthat resource i will make to any arbitrary coalition of resources that is a subset ofN − i.Alternatively, imagine that there is committee room where an important discussion is in progress and only one person can enter the committee room at a time.Suppose the committee room currently consists of individuals belonging to a certain coalition C with the rest of the individuals outside the committee room. Anindividual i 6∈ C entering the committee room will contribute in a certain way tothe ongoing discussion in the committee room. The contribution of i will prettymuch depend on how influential, powerful, and articulate the individual i is. If thecommittee room is equally likely to have any coalition that is a subset of N − i, thenthe average contribution i would make to any arbitrary such coalition would be theShapley value of i.Example 29.2 (Divide the Dollar Game). First, let us consider Version 3 (Example 27.3). Recall that N = {1, 2, 3}; v(1) = v(2) = v(3) = v(23) = 0; v(12) = v(13) =v(123) = 300. The Shapley value expression for φ1 (v) would be:φ1 (v) =\n1122(v(1) − v(∅)) + (v(12) − v(2)) + (v(13) − v(3)) + (v(123) − v(23))6666\nSimilarly,φ2 (v) =\n2112(v(2) − v(∅)) + (v(12) − v(1)) + (v(23) − v(3)) + (v(123) − v(13))6666\n1122(v(3) − v(∅)) + (v(13) − v(1)) + (v(23) − v(2)) + (v(123) − v(12))6666It can be easily seen thatφ3 (v) =\nφ1 (v) = 200; φ2 (v) = 50; φ3 (v) = 50Also, it can be easily verified from the above expressions thatφ1 (v) + φ2 (v) + φ3 (v) = v(123)\nDecember 27, 2013\n11:21\n434\nWorld Scientific Book - 10.25in x 7.5in\nbook\nGame Theory and Mechanism Design\nIt can also be verified easily that φ = (100, 100, 100) for Version 1 (Example 27.1) andVersion 4 (Example 27.4) of the game, while φ = (150, 150, 0) for Version 2 (Example 27.2)of the game.\u0003\nExample 29.3 (Minimum Spanning Tree Game). Consider the minimum spanning tree game considered in Example 27.7. Recall that N = {1, 2, 3} andv(∅) = 0; v(1) = 5; v(2) = 9; v(3) = 7v(12) = 15; v(13) = 12; v(23) = 17; v(123) = 23.Following the expressions in the previous example, it can be shown thatφ1 (v) = 5.5; φ2 (v) = 10; φ3 (v) = 7.5Notice that the payoff allocation to player 2 is the highest which is clearly justified. Also,it is logical that player 1 gets the least allocation while player 3’s allocation is greater thanthat of player 1. Also, note that this allocation belongs to the core of the game.\u0003\nExample 29.4 (Glove Market). Consider the glove market game (Example 28.4)with 2, 000, 001 players, having one 1, 00, 000 left glove suppliers and 1, 000, 001 right glovesuppliers. We have seen that the core of this game is a singleton. Here, the Shapley value ofany right-glove supplier is the probability that he would find in any coalition more left glovesuppliers than right-glove suppliers. Here the Shapley value for each right-glove supplier is0.499557 and for each left glove supplier is 0.500443. Note that the Shapley value is ableto capture the effect of coalitional forces better than the core. Also note that the Shapleyvalue does not belong to the core.\u0003\nExample 29.5 (Apex Game). In this game, there are five players: N = {1, 2, 3, 4, 5}.Player 1 is called the big player and the other players are called small players. The bigplayer with one or more small players can earn a worth of 1. The four small players togethercan also earn 1.v(C) = 1 if 1 ∈ C and |C| ≥ 2= 1 if |C| ≥ 4= 0 otherwiseThe Shapley value is\u0012φ(v) =\n3 1 1 1 1, , , ,5 10 10 10 10\nNote that the core of this game is empty.\n\u0013\n\u0003\nExample 29.6 (A Logistics Game). Figure 29.1 shows a logistics network that provides connectivity between two important cities S and T. There are five hubs A, B, C, D,E which are intermediate points from S to T. The transportation is provided by service\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nbook\nThe Shapley Value\n435\n3,50\nA\n3,15\nB\n2,15\n1,10S\nE2,15\n4,0\nT\n1,10C\n3,10\nD1,40\nFig. 29.1: A logistics networkproviders 1, 2, 3, 4. We have already seen this example in Chapter 27, where we formulatedthis as a TU game with N = {1, 2, 3, 4} and with characteristic functionv(1) = v(2) = v(3) = v(4) = 0v(12) = v(13) = v(14) = v(23) = v(24) = v(34) = v(234) = v(123) = 0v(134) = 40; v(124) = 45; v(1234) = 65It can be shown that the Shapley values here are given by φ(v) = (20, 20, 5, 20). This canbe shown to belong to the core of this game.\u0003\n29.3\nProof of the Shapley Theorem\nThe proof proceeds in two parts. In Part 1, we show that the formula for φi (v)satisfies all the three axioms. In Part 2, we show that there exists a unique mappingφ that satisfies all the three axioms.Proof of Part 1SymmetryObserve that in the formula for φi (v), what only matters about a coalition is whetherit contains i and the number of players it contains. Thus relabeling does not affectthe value in any way. This observation clearly shows that symmetry (Axiom 1) issatisfied.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n436\nbook\nGame Theory and Mechanism Design\nLinearityTo show linearity, we have to show thatφi (pv + (1 − p)w) = pφi (v) + (1 − p)φi (w)We have, by definition, for any p ∈ [0, 1],(pv + (1 − p)w)(C) = pv(C) + (1 − p)w(C) ∀C ⊆ N\n(29.1)\nNote that φi (pv + (1 − p)w) is equal toX |C|! (n − |C| − 1)!((pv + (1 − p)w)(C ∪ {i}) − (pv + (1 − p)w)(C))n!\nC⊆N −i\nBy expanding this and applying equation (29.1), linearity can be established.Carrier AxiomSuppose D is a carrier of (N, v). Then, we know thatv(C ∩ D) = v(C) ∀C ⊆ NWe have also seen thatv({i}) = 0 ∀ i ∈ N \\ D and v(D) = v(N )If we take a look at the formula for the Shapley value, it is very clear thatφi (v) = 0 ∀i ∈ N \\ Dsincev(C ∪ {i}) = v((C ∪ {i}) ∩ D) = v(C ∩ D) = v(C)We have to show for all carriers D thatXφi (v) = v(D)i∈D\nSubstituting the formula for φi (v) from the Shapley theorem and simplifying, wecan show thatXφi (v) = v(N )i∈N\nSince D is a carrier, we have v(D) = v(N ), hence the carrier axiom follows.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nThe Shapley Value\nbook\n437\nProof of Part 2Here we show that there exists a unique mapping φ that satisfies the three axioms.First we prove that the mapping φ is a linear transformation by making the followingobservations.• Let (N, z) be the coalitional game that assigns worth zero to every coalition,that is, z(C) = 0 ∀C ⊆ N . Then Axiom 3 (carrier axiom) implies thatφi (z) = 0 ∀i ∈ N\n(29.2)\n• From Axiom 2, we haveφi (pv + (1 − p)w) = pφi (v) + (1 − p)φi (w)Choosing w = z in the above, we getφi (pv) = pφi (v) ∀i ∈ N\n(29.3)\nEquations (29.2) and (29.3) together with the linearity axiom imply that φ is alinear transformation.Suppose L(N ) denotes the set of all non-empty subsets of N . Clearly, |L(N )| =n2 − 1 and hence R|L(N )| is a (2n − 1)-dimensional vector space. Let D ⊆ N be anycoalition. Define for D, a coalitional game (N, wD ):wD (C) = 1 if D ⊆ C= 0 otherwiseThis implies that a coalition C has worth 1 in wD if it contains all the players inD and has worth zero otherwise. The game (N, wD ) is called the simple D-carriergame. To get a feel for this game, we discuss a simple example before resuming theproof.Example 29.7 (D-carrier game). Let N = {1, 2, 3}. Let w1 , w2 , w3 , w12 , w13 , w23 ,and w123 be the characteristic functions of the D-carrier games corresponding to the coalitions {1}, {2}, {3}, {1, 2}, {1, 3}, {2, 3}, {1, 2, 3}, respectively. For instance, w12 would be:w12 (1) = 0; w12 (2) = 0; w12 (3) = 0; w12 (12) = 1; w12 (13) = 0; w12 (23) = 0; w12 (123) = 1We can write all the w values as follows. Note that each one is a 7-tuple.w1 = (1, 0, 0, 1, 1, 0, 1)w2 = (0, 1, 0, 1, 0, 1, 1)w3 = (0, 0, 1, 0, 1, 1, 1)w12 = (0, 0, 0, 1, 0, 0, 1)w13 = (0, 0, 0, 0, ≥ 0; x1 + x2 + x3 = 300To get a feel for the definition of a stable set, let us try out different test cases.• Suppose the imputation (300, 0, 0) ∈/ Z is suggested. Now, the imputation (0, 150, 150) ∈Z is such that the coalition {2, 3} will block (300, 0, 0).• Let us explore the imputation x = (100, 100, 100) ∈/ Z. The imputation (150, 150, 0) ∈ Zis such that the coalition {1, 2} will block x. If we consider imputation (150, 0, 150) ∈ Z,then the coalition {1, 3} will block x. The imputation (0, 150, 150) ∈ Z is such that thecoalition {2, 3} will block x.On the other hand, we observe that (150, 150, 0) ∈ Z is not dominated by either (150, 0, 150)or (0, 150, 150).\u0003\nGiven a TU game, a stable set may or may not exist. The problem of existence of astable set was open for a long time until William Lucas finally constructed, in 1968, a10 person game for which there was no stable set. This counterexample was gleefullywelcomed by many frustrated researchers working on this open problem. Stable setscan offer valuable insights into coalitional dynamics, however the limitations arisebecause• there may be many stable sets• there may not be any stable set• they may have a quite complex structure.30.2\nBargaining Set\nThis solution concept was introduced by Aumann and Maschler [1] in 1964. Theintuition behind this solution concept is as follows. When players debate among\nDecember 27, 2013\n11:21\n450\nWorld Scientific Book - 10.25in x 7.5in\nbook\nGame Theory and Mechanism Design\nthemselves about a proposed division of total worth, there may be unsatisfied players who might object to the proposal. These objections could lead to certain counterobjections by some other players. An objection that does not lead to any counterobjection will become a justified objection. The bargaining set consists of all imputations where each imputation is such that no player has any justified objectionagainst any other player. We shall first formalize the notion of an objection and acounter objection.Definition 30.7 (Objection). An objection by a player i against another playerj and a payoff allocation x is a pair (y, C) where y is another payoff allocation andC is a coalition such thati∈Cj∈/Ce(C, y) = 0yk > xk ∀k ∈ CExample 30.3 (Majority Voting Game). Recall again the three person majorityvoting game. Let i = 1, j = 2, and x = (50, 100, 150). An objection by player 1 againstplayer 2 and the payoff allocation x is a pair (y, C) wherey = (125, 0, 175)C = {1, 3}Note that i ∈ C; j ∈/ C; e(C, y) = 0; y1 > x1 and y3 > x3 .\n\u0003\nDefinition 30.8 (Counterobjection). Given a player i’s objection (y, C) againstplayer j and a payoff allocation x, a counterobjection by player j is any pair (z, D)where z is another payoff allocation and D is a coalition such thatj∈Di∈/DC ∩ D 6= φe(D, z) = 0zk ≥ xk ∀k ∈ Dzk ≥ yk ∀k ∈ C ∩ DExample 30.4 (Majority Voting Game). For the objection described in Example30.3, a counter objection by player 2 would be the pair (z, D) wherez = (0, 125, 175); D = {2, 3}; C ∩ D = {3}; e(D, z) = 0;z2 ≥ x2 ; z3 ≥ x3 ; z3 ≥ y3The above example motivates the definition of a bargaining set.\n\u0003\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nOther Solution Concepts in Cooperative Game Theory\nbook\n451\nBefore we define a bargaining set, we introduce some additional notation. Let(N, v) be a TU game and suppose Q is a partition of N . We define()XnI(Q) = x ∈ R : xi ≥ v({i}) ∀i ∈ N,xi = v(C) ∀C ∈ Qi∈C\nOne can immediately note that if Q = {N }, that is the partition consisting of onlyone part namely the entire set N , then I(Q) is exactly the set of all imputations of(N, v).\nDefinition 30.9 (Bargaining Set). Given a TU game (N, v) and a partition Qof N , a bargaining set is a collection of payoff allocations x ∈ Rn such that(1) x ∈ I(Q)(2) For any coalition D in Q and for any two players i, j ∈ D, there exists acounterobjection to any objection by i against j and x.Example 30.5 (Apex Game). Recall the apex game that we have studied earlier:N = {1, 2, 3, 4, 5}v(C) = 1 if 1 ∈ C and |C| ≥ 2= 1 if |C| ≥ 4= 0 otherwiseWe have seen that the core and the Shapley value are given by\u0012\u00136 1 1 1 1Core (N, v) = ∅; φ(N, v) =, , , ,10 10 10 10 10Consider the partition Q = {N }. With respect to this partition, the bargaining set can beshown to be\u001a\u001b11(1 − 4λ, λ, λ, λ, λ) :≤λ≤137An immediate observation we make is that the Shapley value of this game belongs to thisbargaining set. There are three representative situations here that we need to look at so asto confirm that the above is the bargaining set.• Situation 1: Assume that the small players do not all get the same payoff. In this case,suppose small player i gets strictly less than small player j. Then player i would havean objection in collaboration with the big player 1 that player j would not be able tocounter.• Situation 2: Suppose all the small players manage to get a payoffgreaterthan 71 . Then\u0001\u00013 4player 1 would have, for example, an objection 7 , 7 , 0, 0, 0 , {1, 2} for which player3 or player 4 or player 5 would not be able to counter.1, then player 1 would get• Situation 3: If all the small players get an amount less than 139greater than 13 . Then each of the small players canimmediately\u0001\u0001 object. For example,4441, {2, 3, 4, 5} which player 1 would, 13, 13, 13player 2 could have an objection 0, 13not be able to counter.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n452\nbook\nGame Theory and Mechanism Design\nCoalition structure(partition)\nBargaining Set\n{{1}, {2}, {3}}{{1, 2}, {3}}\n{(0, 0, 0)}{(20, 40, 0)}\n{{1, 3}, {2}}{{1}, {2, 3}}{{1, 2, 3}}\n{(20, 0, 60)}{(0, 40, 60)}{(15, 35, 55)}\nTable 30.1: Bargaining sets for different partitions\nFor the above apex game, if Q = {{1, 2}, {3}, {4}, {5}} then the set\u001b\u001a11(1 − α, α, 0, 0, 0) : ≤ α ≤42would be the bargaining set.\n\u0003\nExample 30.6. This example is taken from [2]. Consider a three player game withN = {1, 2, 3} and characteristic function:v(1) = v(2) = v(3) = 0; v(12) = 60; v(13) = 80; v(23) = 100; v(123) = 105It can be shown that the core is empty here. The Shapley values can be shown to beφ1 (N, v) = 25; φ2 (N, v) = 35; φ3 (N, v) = 45Consider the situation facing players 2 and 3 if they decide to form a coalition, leaving outplayer 1. The two players 2 and 3 will have to share 100 units and if they do admit player1 into their coalition, they will have to share 105 units among three players. In the lattercase, players 2 and 3 may actually end up getting less than what they would have possiblygot if only two of them formed a coalition. In addition to this, there is also time and effortspent in extra negotiation, so players 2 and 3 may desist from inviting player 1 to jointheir coalition. This leads to the partition {{1}, {2, 3}}. It can be shown that (0, 40, 60) isthe only stable allocation for this partition. In fact, for each of the five possible coalitionstructures, there is exactly one allocation in the bargaining set, as shown in Table 30.1.If the value of the grand coalition changes to 135 instead of 105, then the bargaining setfor the partition {{1, 2, 3}} will be exactly equal to the core:\b(x1 , x2 , x3 ) ∈ R3 : x1 ≥ 0; x2 ≥ 0; x3 ≥ 0; x1 ≤ 35; x2 ≤ 55; x3 ≤ 75; x1 + x2 + x3 = 135The bargaining sets for other coalition structures will remain the same as before.\n\u0003\nSome Observations on the Bargaining Set• The core is a (possibly empty) subset of the bargaining set of (N, v) relative tothe partition Q = {N }.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nOther Solution Concepts in Cooperative Game Theory\nbook\n453\n• Given a partition Q, if I(Q) is non-empty, then the bargaining set relative to Qis non-empty.• Recall that a TU game (N, v) is said to be superadditive if for all coalitionsC, D ⊆ N,C ∩ D = ∅ =⇒ v(C ∪ D) ≥ v(C) + v(D)If the game (N, v) is superadditive, then for any partition Q, the set I(Q) isnon-empty and hence the bargaining set with respect to Q is also non-empty.• The Shapley value need not belong to the bargaining set corresponding to anygiven partition. Thus the allocations suggested by a bargaining set need not befair in the sense of Shapley value.30.3\nKernel\nThis solution concept was proposed by Davis and Maschler [3]. The kernel of a TUgame (N, v) is defined with respect to a partition Q of N (like the bargaining set).In fact, like the bargaining set, the kernel is also a subset of I(Q). The intuitionbehind the kernel is that if two players i and j belong to the same coalition in Q,then the highest excess that i can make in a coalition without j should be the sameas the highest excess that j can make in a coalition without i. While defining thekernel, we focus on the maximum excess a player would be able to make.Definition 30.10 (Kernel). Given a TU game (N, v) and a partition Q of N , thekernel is a set of allocations x ∈ Rn such that(1) x ∈ I(Q)(2) For every coalition C ∈ Q and every pair of players i, j ∈ C,max\ne(D, x) = max e(E, x)\ni∈D\nj∈E\nD⊆N −j\nE⊆N −i\nExample 30.7 (A Four Person Game). Consider the following four person game:N = {1, 2, 3, 4}Q = {{1, 2}, {3, 4}}i = 1; j = 2I(Q) = {(x1 , x2 , x3 , x4 ) : x1 ≥ 0; x2 ≥ 0; x3 ≥ 0; x4 ≥ 0; x1 + x2 = v(12); x3 + x4 = v(34)}The kernel of (N, v), with respect to Q will be the set of all allocations (x1 , x2 , x3 , x4 ) fromI(Q) satisfying:max e(D, x) = max e(E, x)D⊆{1,3,4}\nE⊆{2,3,4}\n1∈D\n2∈E\nmax\ne(D, x) = max\nD⊆{1,2,3}\nE⊆{1,2,4}\n3∈D\n4∈E\ne(E, x).\n\u0003\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n454\nGame Theory and Mechanism Design\nExample 30.8 (Apex Game). For the five player apex game considered earlier, thekernel with the partition {{1, 2, 3, 4, 5}} is {( 73 , 17 , 17 , 17 , 17 , )} where as with the partition{{1, 2}, {3}, {4}, {5}} the kernel is {( 21 , 12 , 0, 0, 0)}.\u0003\n30.4\nNucleolus\nThe Shapley value of a TU game is a solution concept that is primarily based ona certain notion of fairness in allocation. The nucleolus which is also a uniqueallocation, like the Shapley value, is primarily based on bargaining considerations.This solution concept was proposed by David Schmeidler (1970) [4].Recall that the excess of a coalition C with respect to an allocation x is a measureof unhappiness of C with allocation x. Let us say we find an imputation thatminimizes the largest among all excesses e(C, x). This means the chosen imputationmakes the most unhappy coalition as little unhappy as possible. The nucleolus isbased on this idea and minimizes not only the level of unhappiness of the mostunhappy coalition but also the levels of unhappiness of the second most unhappycoalition, third most unhappy coalition, etc.Example 30.9. Consider a three player game [2] with N = {1, 2, 3} and characteristicfunction defined byv(1) = v(2) = v(3) = 0v(12) = 60; v(13) = 80; v(23) = 100v(123) = 105Given an allocation x = (20, 35, 50), the excess values for the coalitions are as follows.e(1, x) = −20; e(2, x) = −35; e(3, x) = −50e(12, x) = 5; e(13, x) = 10; e(23, x) = 15e(123, x) = 0In the above, the largest excess is e(23, x) = 15. Let us try to reduce this by trying theallocation y = (15, 35, 55) (say). Now we notice thate(12, y) = 10; e(13, y) = 10; e(23, y) = 10If we try to lower this any further, it would raise at least one other excess beyond 10.Thus the allocation y achieves the lowest excess for any coalition. In general, there maybe multiple imputations which minimize the second largest excess to obtain a subset of theabove set of imputations. Next, we minimize the third largest excess, fourth largest excess,etc. until, as shown in [4], we end up with a unique imputation. This unique imputation iscalled the nucleolus.\u0003\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nOther Solution Concepts in Cooperative Game Theory\nbook\n455\nDefining NucleolusConsider any allocation x = (x1 , . . . , xn ) and let ek (x) be the k th largest excessgenerated by any coalition with allocation x. This means the cardinalities of thestated sets satisfy:|{C ⊆ N : e(C, x) ≥ ek (x)}| ≥ k|{C ⊆ N : e(C, x) > ek (x)}| < kNow, x belongs to the core C(N, v) implies e1 (x) ≤ 0. Suppose we denote by J(k)the set of all imputations that minimize ek where ek is the k th largest excess and byI(N, v) the set of all imputations of (N, v). ThenJ(1) = arg min e1 (x)x∈I(N,v)\nIf the core is non-empty, then J(1) ⊆ C(N, v). We can define J(2), J(3), . . . , J(2|N | −1) as follows.J(k) = arg min ek (x)\nfor k = 2, 3, . . . , 2|N | − 1\nx∈J(k−1)\nIt was shown by Schmeidler [4] that the set J(2|N | − 1) is a singleton and this pointis called the nucleolus of the TU game (N, v).Note that when the core is non-empty, for any imputations in the core, all theexcesses are zero or negative. For finding the nucleolus, we choose the imputation inthe core which makes the least negative excess as negative as possible. Geometrically,the nucleolus is a point in the core whose distance from the closest wall of the coreis as large as possible. Intuitively, the nucleolus is a point in the core that is as farinside the core as possible. We note a few other aspects about this solution concept.For details, the reader is referred to [2].• The nucleolus always exists and is unique.• If the core is non-empty, the nucleolus belongs to the core.• The nucleolus always belongs to the bargaining set for the grand coalition. Also,it always belongs to the kernel.• The nucleolus is not necessarily equal to the Shapley value.• The nucleolus can be computed by solving a series of linear programs.30.5\nThe Gately Point\nThis solution concept was proposed by Dermot Gately (1974) [5]. Like the nucleolus,this is also based on the bargaining ability of the players. Suppose we have a TUgame (N, v) with N = {1, 2, . . . , n}. Let us focus on player i. If player i breaks awayfrom the grand coalition, it might result in a loss (or gain) for the players. Suppose\nDecember 27, 2013\n11:21\n456\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nx = (x1 , . . . , xn ) is the original allocation for the grand coalition. Then the loss tothe player i due to breakup is xi − v({i}). The joint loss to the rest of the players isXxj − v(N \\ {i})j6=i\nThe disruption caused by player i breaking away can be measured in terms of socalled propensity to disrupt which is defined asPj6=i xj − v(N \\ {i})di (x) =xi − v({i})The Gately point is defined as an imputation that minimizes the maximum propensity to disrupt. It can be shown that minimizing the maximum propensity to disruptcan be achieved by making the propensities to disrupt of all the players equal.Example 30.10. Consider a three player game with N = {1, 2, 3} andv(1) = v(2) = v(3) = 0v(12) = 4; v(13) = 0; v(23) = 3v(123) = 6With respect to the allocation x = (2, 3, 1), the propensities to disrupt are given byd1 (x) =\n1; d2 (x) = 1; d3 (x) = 12\n36 12If we try to equalize the propensities to disrupt, we end up with the allocation y = ( 1811 , 11 , 11 )which yields5d1 (y) = d2 (y) = d3 (y) =6The above allocation y turns out to be the Gately point.\u0003\nWe now state a few observations about Gately point.• Gately point does not necessarily belong to the core if the core is non-empty.• The concept of Gately point can be extended by considering propensities to disrupt of coalitions rather than individual players. The resulting solution conceptis called disruptive nucleolus which has been shown to belong to the core if thecore is non-empty.30.6\nSummary and References\nCooperative game theory is replete with a variety of solution concepts. In thischapter, we have studied five different solution concepts. These concepts are basedon the following notions:• Imputation: An imputation of a TU game is an allocation x = (x1 , . . . , xn ) suchthat the sum of the xi ’s is the same as the value v(N ) of the grand coalition,with each xi no less than v({i}).\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nOther Solution Concepts in Cooperative Game Theory\nbook\n457\n• Excess: The excess of a coalition C with respect to an allocation x is the differPence (v(C) − i∈C xi ). This could be described as the level of unhappiness ofthe coalition C.• Domination: An imputation x = (x1 , . . . , xn ) is said to dominate another imputation y = (y1 , . . . , yn ) if there exists a coalition C such that the excess of Cwrt x is non-negative and every xi is strictly greater than yi for all i ∈ C.The solution concepts studied in this chapter include:(1) Stable Sets: A stable set of a TU game is a set of allocations (in fact, imputations) Z satisfying internal stability as well as external stability. Internalstability means that no imputation in Z is dominated by any other imputationin Z. External stability means that every imputation not in Z is dominated bysome imputation in Z.(2) Bargaining Set: A bargaining set with respect to a partition of the set of playersis a set of imputations where each imputation is such that no player will objectto the imputation since it will attract a counter objection from another player.(3) Kernel : Given a partition Q of the set of players N , the kernel contains payoffallocations such that if players i and j belong to the same coalition in Q, thehighest excess that player i can make in a coalition without j is the same as thehighest excess that player j can make in a coalition without i.(4) Nucleolus: The nucleolus always belongs to the kernel and is a unique imputationthat minimizes the level of unhappiness of the most unhappy coalition, thesecond most unhappy coalition, etc.(5) Gately Point: This is an imputation that minimizes the maximum tendency ofplayers to break away from the grand coalition.The choice of which solution concept to use in a given situation depends on what isbeing studied. The computation of the solution concepts is in general hard exceptin special cases.This chapter has relied extensively on the textbooks of Myerson [6], Straffin [2],and Maschler, Solan, and Zamir [7]. These references may be looked into for moredetails. The book by Straffin [2] discusses illustrative case studies on all the abovesolution concepts. The original references for the solution concepts discussed hereare: stable sets [8], bargaining sets [1], kernel [3], nucleolus [4], and Gately point [5].Computation of the solution concepts discussed in this chapter is an importantissue. The book by Chalkiadakis, Elkind, and Wooldridge [9] has a detailed discussion on this important topic.References[1]\nR. Aumann and M. Maschler. “The bargaining set for cooperative games”. In: Advances inGame Theory. Princeton University Press, 1964, pp. 443–476.\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\n458\nGame Theory and Mechanism Design\n[2]\nPhilip D. Straffin Jr. Game Theory and Strategy. The Mathematical Association of America,1993.M. Davis and M. Maschler. “The kernel of a cooperative game”. In: Naval Research LogisticsQuarterly 12 (1965), pp. 223–259.David Schmeidler. “The nucleolus of a characteristic function game”. In: SIAM Journal onApplied Mathematics 17 (1969), pp. 1163–1170.Dermot Gately. “Sharing the gains from regional cooperation: A game theoretic applicationto planning investment in electric power”. In: International Economic Review 15 (1974),pp. 195–208.Roger B. Myerson. Game Theory: Analysis of Conflict. Harvard University Press, Cambridge,Massachusetts, USA, 1997.Michael Maschler, Eilon Solan, and Shmuel Zamir. Game Theory. Cambridge UniversityPress, 2013.John von Neumann and Oskar Morgenstern. Theory of Games and Economic Behavior.Princeton University Press, 1944.Georgios Chalkiadakis, Edith Elkind, and Michael Wooldridge. Computational Aspects ofCooperative Game Theory. Morgan & Claypool, 2011.\n[3][4][5]\n[6][7][8][9]\n30.7\nExercises\n(1) For the majority voting game (Example 30.2), compute any other stable sets ifit has any.(2) Prove that the kernel of the apex game having five players with the partition {{1, 2, 3, 4, 5}} is {( 37 , 17 , 17 , 17 , 71 )} while with respect to the partition{{1, 2}, {3}, {4}, {5}}, the kernel is {( 12 , 12 , 0, 0, 0)}. What will be the kernelwith respect to the partition {{1}, {2, 3, 4, 5}}?(3) Show that the nucleolus of the apex game with five players is ( 73 , 17 , 71 , 17 , 17 ).(4) Consider a three person superadditive game with v(1) = v(2) = v(3) =0; v(12) = a; v(13) = b; v(23) = c; v(123) = d where 0 ≤ a, b, c ≤ d. Compute the nucleolus and Gately point for this game.(5) For the following three player game, compute the core, Shapley value, kernel,nucleolus, and Gately point.v(1) = v(2) = v(3) = 0v(12) = 4; v(13) = 0; v(23) = 3; v(123) = 6(6) Programming Assignment. Study the computational issues involved in computing the solution concepts discussed. It will be an interesting project to implement efficient computational algorithms for determining the solution concepts.\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nChapter 31\nStable Matching\nThe Sveriges Riksbank Prize in Economic Sciences, in Memory of Alfred Nobel,for the year 2012 was awarded to Lloyd S. Shapley and Alvin E. Roth. The prizeis in recognition of their pioneering contributions to theory of stable allocationsand the practice of matching market design. The theory of matching and matchingalgorithms involves use of concepts in equal measure from non-cooperative gametheory, cooperative game theory, and mechanism design. In this chapter, we describe matching algorithms and bring out their connection to game theory.\n31.1\nThe Matching Problem\nOne of the common problems encountered in real life is that of matching, which isthe process of allocating one set of resources or individuals to another set of resourcesor individuals. Common examples include matching buyers to sellers in a market;matching resources to tasks; allocating home seekers to houses; matching new doctors to hospitals; matching students to schools; matching job-seeking engineers tocompanies; matching advertisers to sponsored slots on a search engine page, etc.There are also examples with deep societal impact such as matching kidneys or human organs to needy patients. The matching has to be accomplished in a way thatthe preferences that the individuals may have, are honored, and the social welfare(measured in a reasonable way) is maximized. On the face of it, the problem looksdeceptively simple, however, when the number of individuals/resources involved islarge and in addition, certain inevitable, practical constraints have to be satisfied,the problem becomes complex and finding even feasible solutions (let alone optimalsolutions) could be hard.A key requirement of any solution to the matching problem is stability. Informally, a solution is stable if the solution cannot be improved upon, through a reallocation or further trading. Shapley and Roth have brilliantly pioneered the researchand practice of the matching problem in complementary ways: In the 1960s, Shapley investigated the deep questions underlying the theory of matching and came upwith an extremely elegant theory for solving the problem while Roth, in the 1980s,discovered a creative opportunity for exploiting the abstract theory of Shapley topractical problems and came up with masterly implementations to several practical459\nbook\nDecember 27, 2013\n11:21\n460\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nproblems waiting for better solutions. In the 1990s and beyond, several non-trivialextensions to the matching theory were proposed by Roth and other researchersto take into account practical issues such as strategic manipulation by the users ofthe matching market. Matching theory and matching markets currently constitute alively and active area of research not only in economics but also in computer science,Internet advertising, and social computing.\nAlvin Elliot Roth was born on December 19, 1951. His firstdegree was in operations research at the Columbia University.He completed his M.S. in 1973 and Ph.D. in 1974 both in Stanford University again in operations research. During 1975-82,he taught at the University of Illinois and he next taught atthe University of Pittsburgh during 1982-98. In 1998, he joinedthe Harvard University where he is currently Gund Professor ofEconomics and Business Administration Emeritus in the Harvard Business School. Since 2013, he is Craig and Susan McCawProfessor of Economics at Stanford University.Roth is a recipient of numerous honors including Alfred P. Sloan Fellowship,Guggenheim Fellowship, Fellowship of the American Academy of Arts and P, 182, 484Complexity class - PPAD, 182, 183Complexity class - P, 182, 484Complexity class - TFNP, 183Computing Nash equilibria, 170Consistency of beliefs, 190Constant sum game, 132Continuous games, 165Contract, 368Contract signing, 366Contract signing game, 368Convex game, 411, 440Cooperative game, 26Coordination game, 46Core, 415–417Core - convex games, 423Core - cost games, 425Core - glove market, 419Core - minimum spanning tree game, 418Core of divide the dollar, 417Correlated equilibria computation, 375Correlated equilibrium, 374–376Correlated strategy, 365, 367, 373Correspondence, 149Cost game, 412Counter-objection, 450Crowdsourcing, 12dAGVA mechanism, 292, 293dAGVA mechanism - bilateral trade, 295dAGVA mechanism - budget balance, 293dAGVA mechanism - individual rationality,296dAGVA theorem, 292DARPA red balloon challenge, 12De-facto point, 383Default point, 383Deferred acceptance algorithm, 463, 464Dictatorial SCF, 244Dictatorship, 261, 262Direct mechanism, 212Disagreement point, 383Divide the dollar - version 1, 399Divide the dollar - version 2, 400Divide the dollar - version 3, 401Divide the dollar game, 6, 404\nDivide the dollar problem, 399Dominant mixed strategy equilibrium, 106Dominant strategy implementation, 233Dominant strategy incentive compatibility,237, 238Dominated strategies - iteratedelimination, 108Domination by imputation, 448Domination in mixed strategies, 106Domination of imputation, 407DSIC, 237, 238DSIC - necessary and sufficient condition,238DSIC implementation of BIC rules, 358DSIC mechanisms - characterization, 357Duopoly pricing game, 49, 70Dutch auction, 306Dynamic game, 26Effective negotiation, 401Efficient allocation, 415Efficient optimal auctions, 328Egalitarian solution, 394, 395End of line problem, 183English auction, 306Entry game, 35Epsilon core, 420Epsilon core - glove market, 420Essential bargaining problem, 394Essential game, 408Ex-post efficiency, 243, 272Excess, 447Expected Groves mechanism, 293Extensive form game, 26, 31, 34Extensive form to strategic form, 37External stability, 448Feasible allocation, 415Feasible set for bargaining, 383First price auction, 197, 306First price sealed bid auction, 228Fixed point theorem, 149, 150Focal Nash equilibrium, 384Game theory - history, 6Game with contracts, 365Games with incomplete information, 189Gately point, 455–457Generalized first price mechanism, 335\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nIndex\nGeneralized second price mechanism, 336Gibbard, Allan, 249Gibbard-Satterthwaite theorem, 251, 253,254, 263Gibbard-Satterthwaite theorem implications, 253Gibbard-Satterthwaite theorem - proof,254, 256Grand coalition, 401, 407, 412Green-Laffont theorem, 286Green-Laffont theorem - firstcharacterization, 277Green-Laffont theorem - secondcharacterization, 277Groves mechanism, 273, 276Groves mechanism - budget balance, 285Groves theorem, 275Groves theorem - proof, 275Groves, Theodore, 275GSP mechanism, 336\nbook\n489\nIndividual rationality, 288, 369Individual rationality - exante, 289Individual rationality - expost, 288Individual rationality - interim, 288Individual rationality - Nash axiom, 385Individual rationality - sealed bid auction,291Individually rational - interim, 324Individually rational allocation, 415Induced Bayesian game, 230Inessential bargaining problem, 393Inessential game, 408Intelligence, 23Interdependent values, 358Internal stability, 448Kakutani’s fixed point theorem, 151Kernel, 453, 457\nHarsanyi, John, 190, 191, 207House allocation algorithm, 465Hurwicz, 237Hurwicz, Leonid, 207, 208\nLemke-Howson algorithm, 176Linear preferences, 297Linearity of Shapley value, 431Logistics game, 406Lower contour set, 255Lower value, 133\nImperfect information, 27, 37Implementability, 225Implementation by direct mechanism, 223Implementation by indirect mechanism,227Implementation in Bayesian Nashequilibrium, 233Implementation in dominant strategies, 232Implementation in multiple equilibria, 349Implementation in Nash equilibrium, 351,354Implementation of social choice function,231Imputation, 407, 416Incentive compatibility, 9, 237Incentive compatibility - expost, 354Incentive feasible set, 323Incomplete information, 27Independence of irrelevant alternatives, 261Independence of irrelevant alternatives Nash axiom, 387Independent private values, 311Indirect mechanism, 212\nMajority voting game, 401, 404, 407Marginal contribution, 278, 279Marriage problem, 462Maskin monotonicity, 353, 355Maskin, Eric, 207–209Matching algorithms, 460Matching market, 9Matching markets, 465Matching pennies game, 74, 132Matching pennies with observation, 31Matching pennies with simultaneous play,34Matching pennies without observation, 32Matching problem, 459Matrix games, 131Maxmin strategy, 79, 80, 133Maxmin value, 79, 80, 82, 133Maxmin value in mixed strategies, 104Maxminimization, 139Mechanism design - computational issues,360Mechanism design - examples, 205Mechanism design environment, 210\nDecember 27, 2013\n11:21\n490\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nMechanism design for sponsored search,332Mechanism design history, 207Mechanism design space - quasilinearsetting, 297Mediator, 373Minimax theorem, 142Minimum spanning tree game, 404Minmax strategy, 81, 134Minmax value, 79, 81, 82, 134, 384Minmax value in mixed strategies, 105Minmaximization, 139Mixed strategy, 93Mixed strategy Nash equilibrium, 95Mixed strategy Nash equilibrium necessary and sufficient condition, 98Monotonic game, 407Monotonic social choice function, 255Morgenstern, Oskar, 23MST game, 404Multiple Nash equilibria, 78Myerson optimal auction, 323Myerson’s characterization theorem, 299,324Myerson, Roger, 207, 209Myerson–Satterthwaite theorem, 296Nash bargaining solution, 387Nash equilibrium - interpretations, 76Nash equilibrium as a fixed point, 151, 152Nash product, 390Nash program, 381Nash theorem, 154Nash, John, 69, 207Network formation, 280No negative externality condition, 290No single agent effect, 287No veto power, 356Nobel prize, 78, 259Non-cooperative game, 26Non-dictatorial SCF, 244Non-empty core, 420Non-symmetric company’s dilemma game,48Non-transferable utility game, 403Normal form game, 26Nucleolus, 454, 455, 457Objection, 450\nOPT mechanism for sponsored search, 339Optimal allocation, 462Optimal mechanism design problem, 322Ordinal preference relation, 252Ordinal utilities, 116Outcome - extensive form game, 39Outcomes, 210Outline of the book, 14Pairwise independence, 259, 261Paretian property, 261Pareto optimal, 243Perfect information, 27, 37Pigou’s network, 52, 73Pivotal mechanism, 277Preference aggregation problem, 212Preference elicitation problem, 211Preferences, 20Preferences over lotteries, 117Prisoner’s dilemma game, 47Procurement exchange game, 75Procuring an indivisible item, 217Project choice, 267Public project problem, 219, 269, 280, 349Public project problem - individualrationality, 289Pure strategy Nash equilibrium, 67Quasi-linear, 216Quasilinear environment, 267Quasilinear preferences, 267Quasilinearity - consequences, 271Randomized strategy, 93Rational preference relation, 251, 252, 259Rationality, 21Revelation theorem for Bayesian Nashequilibrium, 240Revelation theorem for dominant strategyequilibrium, 240Revenue equivalence - Bayesian auctions,308Revenue equivalence - benchmark model,310Revenue equivalence - symmetry, 312Revenue equivalence theorem, 310, 312Revenue equivalence theorem - proof, 312Risk averse, 126Risk loving, 126\nbook\nDecember 27, 2013\n11:21\nWorld Scientific Book - 10.25in x 7.5in\nIndex\nRisk neutral, 126, 311Roberts theorem, 357Rock-paper-scissors, 141Rock-paper-scissors game, 45, 132Roth, Alvin, 460Saddle point, 135–137Satterhwaite, Mark, 250Scale covariance - Nash axiom, 385Schelling point, 78Schelling, Thomas, 78Sealed bid auction, 51, 192Second price auction, 63, 199, 307Second price sealed bid auction, 229Security strategy, 138Security value, 79, 133Selling an indivisible object, 215, 224Selten game, 193–196Selten, Reinhard, 191, 207Shapley - Shubik power index, 441Shapley theorem, 432, 435Shapley value, 429Shapley value - alternative formula, 439Shapley value - convex game, 440Shapley-Bondereva characterization, 420,422Shortest path problem, 211Simultaneous move game, 20Social choice function, 211Social choice functions - examples, 213Social choice functions - properties, 242Social network analysis, 13Social planner, 223Social utility function, 321Social welfare functional, 260Sperner’s lemma, 155, 157Sperner’s lemma to Brouwer’s theorem, 160Sponsored search auction, 10, 331Stability, 9Stable allocation, 461Stable marriage, 462Stable matching, 459Stable set, 447, 449, 457Static game, 26Status-quo point, 383Strategic form game, 19Strategic form game - definition, 19Strategic form game - interpretation, 43\nbook\n491\nStrategic form game with incompleteinformation, 189Strategy - extensive form game, 37Strategy in a Bayesian game, 191Strict total preference relation, 260Strict total preference relations, 252Strictly competitive games, 131Strong efficiency - Nash axiom, 385Strong implementation, 350Strongly dominant strategy, 59Strongly dominant strategy equilibrium, 59Strongly dominated strategy, 59Strongly dominating strategy, 59Student coordination game, 2, 19Student-optimal allocation, 462Students proposing algorithm, 463Subgame, 82Subgame perfect equilibrium, 84Sufficient conditions for PSNE, 153Superadditive game, 408Supplier selection problem, 213Support of a mixed strategy, 98, 169Symmetry - Nash axiom, 387Symmetry of Shapley value, 431Tragedy of the commons game, 50, 62, 71Transferable utility game, 403Triangular representation, 409TU game, 403, 412Two person zero-sum game, 131Type agent representation, 193Type of a player, 189Unanimity, 259, 261Undominated imputation, 448Upper hemicontinuity, 150Upper value, 134Utilitarian solution, 394, 395Utilities, 21Utility axiom - completeness, 118Utility axiom - continuity, 120Utility axiom - decomposability, 119Utility axiom - monotonicity, 119Utility axiom - substitutability, 118Utility axiom - transitivity, 118Value in matrix games, 134VCG mechanism - individual rationality,289\nDecember 27, 2013\n11:21\n492\nWorld Scientific Book - 10.25in x 7.5in\nGame Theory and Mechanism Design\nVCG mechanisms, 254, 274, 277VCG mechanisms - example, 278Very weakly dominant strategy, 61Very weakly dominant strategyequilibrium, 61Very weakly dominated strategy, 61Vickrey auction, 4, 278, 279Vickrey, William, 207, 274von Neumann - Morgenstern Axioms, 117von Neumann - Morgenstern utilitytheorem, 120von Neumann, John, 22Voting game, 404Weak budget balance, 268Weak preference reversal property, 255Weakly dominant strategy, 60Weakly dominant strategy equilibrium, 60Weakly dominated strategy, 60Winner determination in auctions, 304Worth of a coalition, 403\nbook\n",
      "topic": "mathematical_economics"
    },
    "1": {
      "title": "(A National Bureau of Economic Research monograph) Frederic S Mishkin - A rational expectations approach to macroeconometrics-University of Chicago Press (1983).txt",
      "text": " A RationalExpectations Approach toMacroeconometrics\nTesting PolicyIneffectiveness andEfficient-MarketsModels\nFrederic S. Mishkin\nme etneee crn\n_ Economiceer ce \nA Rational ExpectationsApproach toMacroeconometrics \n \n \nA National Bureauof Economic ResearchMonograph \n&\nA RationalExpectationsApproach toMacroeconometricsTesting PolicyIneffectiveness and\nEfficient-MarketsModels\nFrederic S. Mishkin\nThe University of Chicago Press\nChicago and London \nThe University of Chicago Press, Chicago 60637The University of Chicago Press, Ltd., London\n© 1983 by the National Bureau of Economic ResearchAll rights reserved. Published 1983\nPaperback edition 1983\nPrinted in the United States of America\n90 89 87 8685 543\nLibrary of Congress Cataloging in Publication Data\nMishkin, Frederic S.A rational expectations approach to macro-econometrics.\n(A National Bureau of Economic Research monograph)Bibliography: p.Includes index.1, Rational expectations (Economic theory)2. Macroeconomics. 3. Econometrics. I. Title.II. Series.HBI72.5.M57_ 1983 339’.0724 82-20049ISBN 0-226-53186-4 (cloth)0-226-53187-2 (paper ) \nNBER Board of DirectorsOfficers\nWalter W. Heller, chairman\nFranklin A. Lindsay, vice-chairmanEli Shapiro, president\nDavid G. Hartman, executive director\nDirectors at Large\nMoses AbramovitzGeorge T. Conklin, Jr.Morton EhrlichEdward L. GinztonDavid L. GroveWalter W. HellerFranklin A. Lindsay\nRoy E. Moor\nDirectors by University Appointment\nCharles H. Berry, Princeton\nOtto Eckstein, Harvard\nWalter D. Fisher, Northwestern\nJ. C. LaForce, California, Los Angeles\nPaul McCracken, Michigan\nDaniel McFadden, Massachusetts Instituteof Technology\nAlmarin Phillips, Pennsylvania\nGeoffrey H. MooreMichael H. MoskowJames J. O'LearyPeter G. PetersonRobert V. RoosaRichard N. Rosett\nCharles A. Walworth, treasurerSam Parker, director of finance andadministration\nBert Seidman\nEli Shapiro\nStephen StamasLazare Teper\nDonald S$. WassermanMarina v.N. Whitman\nJames L. Pierce, California, BerkeleyNathan Rosenberg, Stanford\nJames Simler, Minnesota\nJames Tobin, Yale\nWilliam S. Vickrey, ColumbiaDudley Wallace, Duke\nBurton A. Weisbrod, WisconsinArnold Zellner, Chicago\nDirectors by Appointment of Other Organizations\nCarl F. Christ, American EconomicAssociation\nRobert C. Holland, Committee forEconomic Development\nStephan F. Kaliski, Canadian EconomicsAssociation\nAlbert G. Matamoros, National Associa-tion of Business Economists\nDouglass C. North, Economic HistoryAssociation\nRudolph A. Oswald, AmericanFederation of Labor and Congress ofIndustrial Organizations\nDirectors Emeriti\nArthur Burns\nJoel Popkin, American StatisticalAssociation\nG. Edward Schuh, American AgriculturalEconomics Association\nAlbert Sommers, The ConferenceBoard\nJames C. Van Horne, American FinanceAssociation\nCharles A. Walworth, American Instituteof Certified Public Accountants\nEmilio G. ColladoSolomon FabricantFrank Fetter\nThomas D. FlynnGottfried Haberler\nAlbert J. Hettinger, Jr.\nGeorge B. Roberts\nMurray Shields\nBoris ShishkinWillard L. ThorpTheodore O. Yntema \nRelation of the Directors to theWork and Publications of theNational Bureau of Economic Research\n1. The object of the National Bureau of Economic Research is to ascertain and to presentto the public important economic facts and their interpretation in a scientific and impartialmanner. The Board of Directors is charged with the responsibility of ensuring that the workof the National Bureau is carried on in strict conformity with this object.\n2. The President of the National Bureau shall submit to the Board of Directors, or to itsExecutive Committee, for their formal adoption all specific proposals for research to beinstituted.\n3. No research report shall be published by the National Bureau until the President hassent each member of the Board a notice that a manuscript is recommended for publicationand that in the President’s opinion it is suitable for publication in accordance with theprinciples of the National Bureau. Such notification will include an abstract or summary ofthe manuscript’s content and a response form for use by those Directors who desire a copy ofthe manuscript for review. Each manuscript shall contain a summary drawing attention tothe nature and treatment of the problem studied, the character of the data and theirutilization in the report, and the main conclusions reached.\n4. For each manuscript so submitted, a special committee of the Directors (includingDirectors Emeriti) shall be appointed by majority agreement of the President and VicePresidents (or by the Executive Committee in case of inability to decide on the part of thePresident and Vice Presidents), consisting of three Directors selected as nearly as may beone from each general division of the Board. The names of the special manuscript commit-tee shall be stated to each Director when notice of the proposed publication is submitted tohim. It shall be the duty of each member of the special manuscript committee to read themanuscript. If each member of the manuscript committee signifies his approval within thirtydays of the transmittal of the manuscript, the report may be published. If at the end of thatperiod any member of the manuscript committee withholds his approval, the President shallthen notify each member of the Board, requesting approval or disapproval of publication,and thirty days additional shall be granted for this purpose. The manuscript shall then not bepublished unless at least a majority of the entire Board who shall have voted on the proposalwithin the time fixed for the receipt of votes shall have approved.\n5. No manuscript may be published, though approved by each member of the specialmanuscript committee, until forty-five days have elapsed from the transmittal of the reportin manuscript form. The interval is allowed for the receipt of any memorandum of dissent orreservation, together with a brief statement of his reasons, that any member may wish toexpress; and such memorandum of dissent or reservation shall be published with themanuscript if he so desires. Publication does not, however, imply that each member of theBoard has read the manuscript, or that either members of the Board in general or the specialcommittee have passed on its validity in every detail.\n6. Publications of the National Bureau issued for informational purposes concerning thework of the Bureau and its staff, or issued to inform the public of activities of Bureau staff,and volumes issued as a result of various conferences involving the National Bureau shallcontain a specific disclaimer noting that such publication has not passed through the normalreview procedures required in this resolution. The Executive Committee of the Board ischarged with review of all such publications from time to time to ensure that they do not takeon the character of formal research reports of the National Bureau, requiring formal Boardapproval.\n7. Unless otherwise determined by the Board or exempted by the terms of paragraph 6, acopy of this resolution shall be printed in each National Bureau publication.\n(Resolution adopted October 25, 1926, as revised through September 30, 1974) \nTo My Father \n1.\nContents\nAcknowledgments\nIntroduction\nPart I Econometric Theory and Methodology\n2.\nThe Econometric Methodology\nAppendix 2.1 Identification and TestingAppendix 2.2 An Annotated ComputerProgram\nAn Integrated View of Tests of Rationality,Market Efficiency, and the Short-Run Neutralityof Aggregate Demand Policy\nPart 2. Empirical Studies\n4.\n5.\nAre Market Forecasts Rational?\nMonetary Policy and Interest Rates:\nAn Efficient Markets—Rational\nExpectations Approach\nAppendix 5.1 Estimates of the ForecastingEquations\nAppendix 5.2 Additional Experiments Usingthe Two-Step Procedure\nDoes Anticipated Aggregate Demand PolicyMatter?\nxi\n27\n32\n44\n59\n76\n97\n103\n110x\nContents\n \nAppendix 6.1 Output and UnemploymentModels with Barro and Rush SpecificationAppendix 6.2 Results with Nominal GNPGrowth and Inflation as the Aggregate DemandVariable\nAppendix 6.3 Results Not Using PolynominalDistributed Lags\nAppendix 6.4 Jointly Estimated ForecastingEquations\nConcluding Remarks\nReferences\nIndex\n129\n133\n143\n150\n156\n159169 \nAcknowledgments\nThis book developed from a line of research that I have pursued forseveral years. In the process I built up an intellectual debt to manyindividuals who provided me with comments on my work and, by sodoing, improved it substantially. My former colleague, Andrew Abel, isowed the greatest debt. Part of this book—Chapter 3 and Appendix 2.1 toChapter 2—is based on joint research we worked on together at theUniversity of Chicago. Andy not only stimulated my thinking in this lineof research but also showed me how much fun joint work can be. I alsothank the following other individuals who gave me valuable comments:Ben Bernanke, John Bilson, Olivier Blanchard, Edwin Burmeister, Den-nis Carlton, Eugene Fama, Robert Flood, Jacob Frenkel, David Galen-son, Peter Garber, Clive Granger, Nathaniel Gregory, Lars Hansen,Fumio Hayashi, Dennis Hoffman, John Huizinga, Stephen LeRoy,Robert Lucas, Thomas Mayer, Bennet McCallum, Merton Miller,Ronald Michener, Michael Mussa, A. R. Nobay, Charles Plosser, Tho-mas Sargent, Don Schlagenhauf, William Schwert, Steven Sheffrin,Robert Shiller, Kenneth Singleton, Gary Skoog, and Mark Watson. Ibenefited from comments at seminars where I presented preliminaryversions of this work—at the American Economic Association wintermeetings; Cornell University; the University of California at Berkeley, atDavis, and at San Diego; the University of Chicago; the University ofPennsylvania; the University of Michigan; the Université de Montreal;the University of Virginia; the Massachusetts Institute of Technology; theNational Bureau of Economic Research; and New York University. Thestudents in my Economics 431 course during the Winter of 1982 at theUniversity of Chicago performed the role of human guinea pigs bysubjecting themselves to my teaching of this book. Their reactions andcomments are greatly appreciated.\nxixii Acknowledgments\n \nI thank June Nason and Alyce Monroe for their typing services, andAlan Brazil and Douglas McTaggart for excellent research assistance.\nThis book makes use of material from my articles published in Amer-ican Economic Review, Journal of Finance, Journal of Monetary Eco-nomics, and Journal of Political Economy. 1 am grateful to each of thesejournals for permission to use material from these articles.\nResearch support from the National Science Foundation (NSF grantsSES-7912655 and SES-8112004) is gratefully acknowledged. This work ispart of the National Bureau of Economic Research’s Program in Eco-nomic Fluctuations. The usual disclaimer applies. \n1 Introduction\nThe recognition in recent years that expectations are extremely impor-tant to economic decision making has led to a major revolution inmacroeconomic analysis. The rational expectations hypothesis de-veloped initially by Muth (1961) has played a critical role in this revolu-tion. Simply put, it states that expectations reflected in market behaviorwill be optimal forecasts using all available information. (A more precisedefinition will be developed in Chap. 2.) When this hypothesis is em-ployed to describe expectations formation, serious doubts arise about theuse of existing large-scale macroeconometric models for policy analysis(Lucas 1976). With additional assumptions about labor market behavior,the effectiveness of any deterministic policy rule to promote macroeco-nomic stabilization is even called into question (Sargent and Wallace1975).\nThe rational expectations hypothesis has significant implications aswell for the way macroeconometric models should be estimated. It leadsto serious doubts about the traditional criteria for identifying and estimat-ing these models—the exclusion of variables from some behavioral equa-tions and not from others (Sims 1980). Yet we are not left helpless,because it does provide restrictions of a different sort which do allowidentification and estimation, restrictions applying across equations (Sar-gent 1981).\nThis book pursues a rational expectations approach to macroecon-ometrics, yet it is not a comprehensive treatment of the subject. Instead itexplores a particular class of models, widely discussed in the macro-economics literature, which emphasize the effects from unanticipated,rather than anticipated, movements in variables. In these models, cross-equation restrictions implied by rational expectations are of central im-portance. These restrictions can be a powerful tool of analysis, making it\n12 Introduction\n \neasier to isolate the phenomenon we want to study. The following chap-ters will discuss and develop theoretically a unified econometric treat-ment of these models, and the resulting empirical analysis, based onMishkin (1981a, 1981b, 1982a, 1982b, 1982c), will provide evidence onsome of the more important macro issues debated today.\nHow does the econometric methodology in this book fit into the overallsubject of rational expectations macroeconometrics? Other econometricmethodology recently developed is designed to analyze models wheremore structure has been imposed than in the class of models discussedhere. For example, see Chow (1980), Hansen and Sargent (1980), Sar-gent (1978), Taylor (1979), and Wallis (1980), all of which can be foundin the Lucas and Sargent (1981) collection. Hansen and Sargent (1980)provide a prominent example of this alternative approach to estimatingrational expectations models. Their techniques can be used to look at the“deep structure” of economic relationships by estimating parametersdescribing tastes and technology. This allows the researcher to analyzeproblems that are out of reach of the techniques described in this book.\nHowever, there are advantages to the econometric approach here.Estimation is simple to execute with the techniques of this book andreadily available computer packages, as the following chapter makesclear; this is less true of techniques such as Hansen and Sargent’s. Feweridentifying assumptions are required to implement the econometric mod-els analyzed here because the models are less structural. Because econ-omists disagree strenuously about what is the appropriate structure of theeconomy (see the discussion in Sims 1980), empirical results obtainedwith fewer identifying assumptions are worth studying. The main conclu-sion to be drawn from these remarks is not that one set of econometricmethodology is preferable to another; rather, all these techniques areneeded for us to obtain a better understanding of how the economyworks.\nBecause the investment in reading a book is far greater than that inreading a short journal article, the reader deserves to be convinced thathe or she will be involved in a productive activity. The first step in thisprocess is to show that the methodology in this book is well worthstudying because it is applicable to a wide range of research problems.With the increasing prominence of rational expectations in the last fewyears, there has been a veritable explosion in the number of empiricalstudies that either use or can use the methodology outlined in this book.These include studies of consumption behavior (Bilson 1980; Flavin1981), the question whether government bonds are net wealth (Plosser1982), the behavior of foreign exchange markets (Dornbusch 1980;Frenkel 1981; Hartley 1983; Hoffman and Schlagenhauf 19815), thedemand for money (Carr and Darby 1981), money and interest rates(Makin 1981; Mishkin 1981a, 1982c; Shiller 1980), money and stock3 Introduction\n \nprices (Rozeff 1974), the rationality of inflation and interest rate forecasts(Mishkin 19815), asset returns and inflation (Bodie 1976; Fama andSchwert 1977, 1979; Jaffee and Mandelkar 1976; Nelson 1976; Schwert1981), relative price variability and inflation (Fischer 1981), the effects ofnominal contracting on stock returns (French, Ruback, and Schwert1981), stock exchange seats as capital assets (Schwert 1977a), regulatoryeffects of the securities exchange commission (Schwert 1977b), costs offinancial intermediation and the Great Depression (Bernanke 1982), andthe policy ineffectiveness proposition (Barro 1977, 1978, 1979; Barro andHercowitz 1980; Barro and Rush 1980; Bjorklund and Holmlund 1981;Germany and Srivastava 1979; Gordon 1979; Grossman 1979; Hoffmanand Schlagenhauf 1981a; Leiderman 1979, 1980; Makin 1982; Mishkin1982a, 1982b; Sargent 1976a; Sheffrin 1979; Small 1979; Wogin 1980).\nThis broad list of empirical topics above should persuade the readerthat future research can profit from use of the methodology developed inthe following chapters. However, the reader may still want to ask, Whatspecifically is to be gained by reading this book? It is designed to be readon several levels and a brief “road map” of the analysis should helpanswer this question and save the reader both time and effort. The mainbody of the book is divided into two parts. Part 1 on econometric theoryand methodology is the more technical. It will be of particular interest tothe reader already convinced that the class of models analyzed in thisbook is worth studying, and who may want to pursue empirical workalong these lines.\nThe opening chapter of Part 1 describes the models to be analyzed inthis book and discusses the details of their estimation. It covers suchtheoretical statistical issues as the consistency and efficiency of differentestimation procedures. However, it is primarily a practical “how to”chapter that should help the interested researcher to apply the book’seconometric techniques. To aid in the applications, an appendix to thischapter contains an annotated computer program that has been used togenerate empirical results in Part 2 of the book. This program makes useof a standard econometric package available on many universities’ com-puters and the techniques outlined here should be easily accessible tomost researchers. Another purpose of this chapter is to provide sufficientinformation on the techniques used in the empirical work in the followingchapters, so that this work is opened to scientific scrutiny. This chapter,however, also is intended to be a fairly general treatment because thetechniques discussed are applicable to many empirical issues not analyzedin this book.\nThe next chapter treats theoretically the relationship among tests ofrationality, market efficiency, and the short-run neutrality of policy. Itprovides information about how the tests conducted in this book relate toother tests in the literature, and it discusses the circumstances in which4 Introduction\nthe resulting test statistics are generally valid. This chapter is useful inunderstanding both the empirical tests in this book and some of theprevious literature on rational expectations models.\nPart 2 is much less technical and contains empirical studies on topics ofpotentially widespread interest. Chapters in Part 2 will be sufficientlyself-contained so as not to require knowledge of Part 1 to be understood.Readers who are interested in the macroeconomic issues studied here butwho are not technically inclined, or who are not yet convinced of thevalue of the econometric techniques, should read this section first. Theymay then find it worth investing in a careful reading of Part 1.\nThe opening chapter of Part 2 provides information on the question ofwhether market forecasts are rational. Recent studies have found thatforecasts of interest rates and inflation derived from well-known surveysare not consistent with the rational expectations hypothesis. For reasonsdiscussed in this chapter, the survey measures may not reflect marketbehavior. We then want to know whether markets display rationality ofexpectations in contrast to the survey measures. If they do, doubt is caston the survey measures as a description of market behavior. Tests similarto those conducted on survey data are used to provide evidence on thisissue for the bond market. They do cast doubt on the usefulness of thesesurvey measures and indicate for the most part that bond market fore-casts are rational.\nChapter 5 explores the relationship of monetary policy with both long-and short-term interest rates. The impact of a money stock increase onnominal interest rates has been hotly debated in the monetary economicsliterature. The view most commonly held—also a feature of most struc-tural macroeconometric models—has an increase in the money stockleading, at least in the short run, to a decline in interest rates. Monetaristsdispute this view because they believe it ignores the dynamic effects of amoney stock increase. The use of the rational expectations (orequivalently, the efficient markets) hypothesis in this analysis imposes atheoretical structure on the relationship that permits easier interpretationof the empirical results as well as more powerful statistical tests. In theinterest of ascertaining the robustness of the results, many differentempirical tests are conducted, and they do not support the propositionthat increases in the money supply are correlated with declines in interestrates.\nRecent equilibrium business cycle models, which incorporate featuresof the natural-rate model with the assumption that expectations arerational, lead to an important neutrality result: Anticipated changes inaggregate demand will not evoke an output or employment response.One deterministic policy rule is, therefore, as good as any other from thepoint of view of stabilizing the economy. Chapter 6 conducts an empiricalinvestigation of this policy ineffectiveness proposition. Not only do the5 Introduction\nresults strongly reject the proposition, but, in addition, unanticipatedmovements in aggregate demand policy are not found to have a largerimpact on output and unemployment than anticipated movements.The final chapter furnishes some concluding remarks and a generalperspective on the empirical results and the econometric methodology.PART\n \n1 Econometric Theoryand Methodology \n2 The EconometricMethodology\n2.1. The Models\nThe rational expectations hypothesis asserts that the market’s subjec-tive probability distribution of any variable is identical to the objectiveprobability distribution of that variable, conditional on all available pastinformation. Following the literature, we will restrict our attention tolinear models and focus only on the first moments of distributions; thisyields models which are analytically and empirically more tractable. Therational expectations implication central to this book’s analysis is thefollowing: the expectation assessed by the market equals the true con-ditional expectation using all available past information. For a variableX, this can be written as\n(1) E,A(Xb,— 1) = E(Xilb,—1),where\n¢,-1 = the set of information available at time ¢t — 1,E,n(. . .lb;-1) = the subjective expectation assessed by the market,E(. . .|b,_,) = the objective expectation conditional on ,_.\nThe application of rational expectations to financial markets—where itis referred to as market efficiency—shows why the rational expectationshypothesis should be taken seriously in explaining empirical phenomena.Tests of market efficiency usually focus on either holding period returnsor prices of securities. For example, let y, denote the return from holdinga particular security from f — 1 tof, where the return includes both capitalgains and intermediate cash income such as dividends or interest pay-ments. Rational expectations, as in equation (1), then implies the follow-ing condition:\n(2) ELy: — Em(Velby— 1) lb,— 1] = 0.910 Econometric Theory and Methodology\nThe condition above is too general to be testable. To give it empiricalcontent we must specify a model of market equilibrium that relatesE,,(y:\\6;—) to some subset of past information, ,_4,\n(3) Ex (¥ilby—1) = f(%—-1) = Vr,\nwhere 0,_, is contained in $,_;. For ease of exposition, f(,_1), therepresentation of the model of market equilibrium, will be denoted by J,.Combining equations (2) and (3) yields the efficient markets condition\n(4) E(y, —Vilb;— 1) =9.\nThis condition implies that y, — ¥, should be uncorrelated with any pastavailable information. When Y, the equilibrium return (or, in looseparlance, a ‘‘normal’”’ return), is viewed as determined by such factors asrisk and the covariance of y, with the overall market return (see Fama1976a), the above condition can be stated in a slightly different way.Market efficiency, or equivalently rational expectations, implies that nounexploited profit opportunities will exist in securities markets: at today’sprice, market participants cannot expect to earn a higher than normalreturn by investing in that security.\nThe condition in (4) is analogous to an arbitrage condition. Arbitra-geurs who are willing to speculate may perceive unexploited profit oppor-tunities and will purchase or sell securities until the price is driven to thepoint where this condition holds approximately. An example may clarifythe intuition behind this argument. Assume that for a security, y, — Y,,which is sometimes called an “excess” return, is positively correlated withsome piece of past information known at time tf — 1, let us say thecompany’s past earnings. If today the company’s past earnings are knownto be high, then a higher return than normal for this security is to beexpected over the subsequent period. This is a contradiction because anunexploited profit opportunity would now exist. Market efficiency im-plies that, if this opportunity occurred, the security would be bid up inprice until the expected return fell to the normal return. The positivecorrelation between past earnings and the “excess” return for this secu-rity would then disappear.\nSeveral costs involved in speculating could drive a wedge between theleft- and right-hand side of (4). Because the collection of information isnot costless, arbitrageurs would have to be compensated for that cost andothers incurred in their activities, as well as for the risk they bear.(Indeed, as Grossman and Stiglitz (1976) point out, if (4) held exactly,efficient-markets theory would imply a paradox. If all information werefully reflected in a market as eq. [4] specifies, obtaining informationwould have a zero return. Since there would be no incentive to collectinformation, it would remain uncollected and unknown. The marketwould then not reflect this information.) Transaction and storage costs11 The Econometric Methodology\n \nwould also result in violations of equation (4). Yet financial securitieshave the key feature of homogeneity, for they are merely paper claims toincome on real assets. Transactions and storage costs will then be small,while compensation of arbitrageurs and the cost of collecting informationshould not be large relative to the total value of securities traded. Thusdeviations from the condition in (4) should not be large.\nThere are two conclusions to be drawn from the discussion above.First, although the efficient markets or rational expectations condition in(4) may not hold exactly, it is an extremely useful approximation formacroeconomic analysis. Second, this condition should be a usefulapproximation even if not all market participants have expectations thatare rational. Indeed, even if most market participants were irrational, wewould still expect the market to be rational as long as some marketparticipants stand ready to eliminate unexploited profit opportunities. Itis important to emphasize this point when discussing whether surveyforecasts should be used in analyzing market behavior, as Chapter 4indicates.\nA model that satisfies the efficient-markets condition in (4) is\n(5) Y=, + (X,- XB + €,,where\n€, = a disturbance with the property E(e,|,_ ;) = 0—thus ¢, is seriallyuncorrelated and uncorrelated with X7;X,= the vector containing variables relevant to the pricing of thesecurity at time ¢;X; = the vector of one-period-ahead rational forecasts of X,, that is,Xp = En Xib,—1) = E(Xilb;—1)5B = vector of coefficients.\nThat the model above satisfies (4) is easily verified by taking expectationsconditional on ¢,_; of both sides of (5). This yields\n(6) E(yilb,—1) = Gib, 1) + E(X, — Xilb,—)B+ Eleldb,—1) =¥;\nwhich clearly satisfies (4).\nFor expositional convenience, we refer to model (5) as “the efficient-markets model.” Note, however, that the model embodies not onlymarket efficiency (or, equivalently, rational expectations) but also amodel of market equilibrium. This model stresses that only when newinformation hits the market will y, differ from ,. This is equivalent to theproposition that only unanticipated changes in X, can be correlated withYe —~ Yee\nAs the empirical work later in the book demonstrates, the efficient-markets model is useful in attacking such interesting questions as the12 Econometric Theory and Methodology\nrationality of interest rate and inflation forecasts in the bond market andthe relationship of monetary policy to interest rates. The econometricmethodology outlined here is worth studying for this reason alone. Yet itis also worth studying because there are many other applications of theefficient markets model (e.g., Dornbusch 1980; French, Ruback, andSchwert 1981; Frenkel 1981; Hartley 1983; Hoffman and Schlagenhauf1981b; Plosser 1982; Rozeff 1974; Schwert 1977a, 1977b).\nThe other model analyzed in the empirical section of this book displaysthe neutrality property that only unanticipated and not anticipated coun-tercyclical policy will have an effect on business cycle fluctuations. Thismodel displays the policy ineffectiveness proposition of Sargent andWallace (1975) that a constant money growth rule is not dominated byany rule with feedback. As usually estimated, it has the form\nN(7) Y= Tet 2% B(Xii~ Xr) +\nwhere\ny,= unemployment or real output at time f;\nY, = natural or equilibrium level of unemployment or real output attime ¢;\nX, = an aggregate demand variable, such as money growth, inflation ornominal GNP growth;\nX; = anticipated X, conditional on information available at t — 1;\n8; = coefficients;\n€, = error term which might be serially correlated but is assumed to beuncorrelated with the right-hand-side variable.\nIn the case where the number of lags, N, equals zero and J, is adistributed lag on past y,, this is the model estimated by Sargent (1976a).The Barro (1977, 1978) model has N > 0 andj, is represented as a timetrend or a linear combination of such variables as the minimum wage anda measure of military conscription. Other empirical applications of thismodel include Barro 1979; Barro and Hercowitz 1980; Barro and Rush1980; Bjérkland and Holmlund 1981; Germany and Srivastava 1979;Gordon 1979; Grossman 1979; Hoffman and Schlagenhauf 1981a;Leiderman 1979, 1980; Makin 1982; Sheffrin 1979; Small 1979; andWogin 1980. Following Modigliani (1977), this model will be referred toas the Macro Rational Expectations (MRE) model.\nThe methodology discussed here is also worth studying for its usefulapplications in many recent empirical studies which analyze the differen-tial effects of anticipated versus unanticipated movements in explanatoryvariables. These studies make use of the general model\nN N(8) Yee Tet & BAM -1~ Xi) + % XTi t & joint procedure is only y7(4) = 15.45, with amarginal significance level of .0039. Obviously, the bias of the two-stepprocedure against ‘the neutrality null hypothesis is not negligible.\nThe two-step procedure suffers also from a conceptual problem moreminor than the econometric criticisms of the procedure. It assumes thatthe OLS 4, the estimate of y which minimizes the mean-squared forecast-ing error, is used in forming expectations in the y equation. Rationality ofexpectations implies only that subjective probability distributions do notdiffer from the true probability distributions. This implies that the ywhich is expected to minimize the mean-squared forecasting error is usedin forming expectations and not the actual 4 which minimizes the mean-squared error. Thus, in finite samples, the two-step procedure makes anoverly strong assumption about expectations formation. This criticism isanother way of stating the conceptual difficulty with using regressionequations to measure anticipations of variable values early in the sampleperiod when later data are used in estimating the regression relationship.Anticipations are made with information from the future as well as fromthe past, which clearly goes beyond the rational expectations principle.Note that the joint estimation procedure does not suffer from this prob-26 Econometric Theory and Methodology\n \nlem. As rationality implies in this case, the y which is expected tominimize the mean-squared forecasting error is used to form expectationsin the y equation. As a practical matter, however, this criticism of thetwo-step procedure is not extremely important, because the OLS ¥’s arenot very different from the jointly estimated ’s and asymptomaticallythey will not differ.\nOne last point about estimation methodology is worth discussing.Someone used to analyzing the neutrality proposition with the two-stepprocedure will tend to focus on the deterioration in fit from the imposi-tion of the neutrality constraints of the y equation alone. Such a tendencywill be highly misleading in the case of the estimated equations from thejoint procedure. In the joint estimation procedure, if constraints areimposed on the y equation, the deterioration in fit is spread over both thisequation and the forecasting equation. Thus the deterioration in the yequation fit will not be as severe as when the fit of the forecastingequation is not allowed to change, as in the two-step procedure. How-ever, the likelihood ratio statistic in either (23) or (24) demonstrates thatthe deterioration of fit in both equations is involved in testing constraints.Therefore, strong rejections can occur even though there is only a smalldecline in R? (or rise in the standard error) of the y equation.‘\nThe specification of the forecasting equation in previous empiricalwork sometimes violates a rational expectations principle. The theory ofrational expectations implies that X; in the y equation should be anoptimal, one-period-ahead forecast conditional on information availableat time ¢ — 1. Thus, an appropriate forecasting equation should rely onlyon lagged explanatory variables. The procedure for specifying the fore-casting equations here does satisfy this principle. However, this is nottrue in empirical studies which have used the Barro (1977) specificationfor the money growth forecasting equation. They include a contempora-neous variable (FEDV,, the deviation of federal expenditures from the\n4, The most striking example in Chapter 6 occurs when results of the model 2.1 (seetables 6.1 and 6.2) are compared with the 5.1 results (see table 6.5). The comparison is alittle tricky because the model 2.1 is not strictly nested in model 5.1 because of thepolynomial distributed lag specification, but it is still interesting to see what test statisticsarise if we ignore this problem. The pseudolikelihood ratio statistic using (23) of the nullhypothesis 8, = 8, ... = 829 = O and Bg = . . - Bao = 0 equals 11.69 with a marginalsignificance level of .0199. Thus the hypothesis is rejected at the 5 percent level even thoughthere is only a small change in the R? and standard error of the output equation in going from2.1 to 5.1. A numerical explanation of the pseudolikelihood ratio statistic illustrates thepoint in the text. The maximum likelihood estimates of the standard errors of the 2.1 and 5.1output equations are, respectively, .00796 and .00774. The percentage difference, calcu-lated as the change in the logs, is 2.8 percent. The maximum likelihood standard errors for2.1 and 5.1 money growth equations are, respectively, .00409 and .00394, with a percentagedifference of 3.7 percent. Both of these percentage differences are added up in calculatingthe likelihood ratio statistic in (23), which is 92[2 (.028 + .037)] ~ 12.27 The Econometric Methodology\nnormal level) as an explanatory variable in the forecasting equation. Yetit is unlikely that the market has complete knowledge of this variable attime t — 1. That this is a possibly serious misspecification can be seen asfollows. Denoting the contemporaneous variable by A,, the forecastingequation can be written as\n(29) X,= Z,-,yY + EA, + uy.\nUsing rational expectations and denoting E(. . . |,_ ;) by E,_;, unantici-pated X, is\n(30) X,— XP = X,— E,\\X, = X,— (Z,-1y + EE, Ad)= (X,- Z,yy—€A,) + €(A, — E,-1A)=u, + (A, — E,-1A)).\nExpression (30) is not equivalent to the residual from the forecastingequation, for it differs by an expression involving unanticipated A,. It isvalid to use residuals from the forecasting equation to proxy for unantici-pated X only if there are no errors in forecasting A,. As is shown in thenext chapter, this misspecification can render test statistics for rationalityinvalid. Note, however, the more accurately A,can be predicted, the lessserious this misspecification becomes.\nThis chapter’s discussion of the specification of the lag length N sug-gests that MRE models with fairly long lags deserve study. The criterionfor specifying the lag length Nin earlier studies, on the other hand, resultsin a fairly short lag length—on the order of two years. The lag length ischosen by cutting off the lags when the coefficients on the unanticipatedvariables are no longer statistically significant in the MRE equation. Ifthe MRE hypothesis is not valid, then choosing the lag length from anMRE equation is inappropriate for testing this hypothesis. This is then afurther justification for experimenting with MRE models with longer laglengths, as is done in Chapter 6.\nAppendix 2.1: Identification and Testing\nThe various tests discussed in this chapter depend on estimation of theparameters 8; and y* in the unconstrained system (17). More specifically,neutrality requires that the estimate of 8; not differ significantly fromzero, and rationality requires that the estimate of y* not differ signifi-cantly from y. These restrictions are testable only if the relevant para-meters are identified, that is, if observational equivalence is avoided. Ifnot all of the parameters are identified, then only some of the restrictionsor linear combinations of restrictions are testable.\nAppendix 2.1 is based on joint work with Andrew Abel (Abel and Mishkin 1983, sec. 5).28 Econometric Theory and Methodology\nA procedure is outlined here for determining identification by analyz-ing an interesting special case of systems (16)-(20), where Z, _ , is rewrit-ten as shown below in system (17):\nM(Al) X= Z,-iYit Ur~ N MMt + 3, (x. _ ay 2,-1.1} B;\nN([M+ (2 2-5-1988) +\nj=0\\i=0\nwhere\nX, = ak-element row vector of variables relevant for determining y,;k21.Z,-; = a(p + k)-element row vector of variables dated t — i which areused in predicting X,. It contains the k elements of X,_; as wellas p other variables; p = 0.y, =a scalar.\ny; and 7 = (p + k) matrices of parameters.B,; and 8; =k x 1 column vectors of parameters.\nObserve that this system embodies the exclusion restriction that Z,_;does not enter the y equation except as it enters terms representing X7_;.The exclusion restriction is crucial to the discussion of identification andhypothesis testing. Note that (A1) embodies the following simplifyingassumptions: (a) the same lag length applies to all variables used topredict X, in the first equation; and, (b) in the second equation the samelag length, N, is used for both anticipated and unanticipated X,. Theseassumptions, which are made for expositional clarity, can be relaxed andthe following discussion can be generalized in a straightforward manner.Note also that the row vector Z,_;, which is used in the time-series modelfor predicting X,, contains the k-element row vector X;,_;, since laggedvalues of the dependent variable are often useful in prediction. In addi-tion, the row vector Z,_; contains p other variables at time t — i, where p= 0. It is assumed that u, and e, are uncorrelated and that E(u;lb,;_1) =E(e,\\,;_1) = 0. Finally, recall that the rationality restriction is y; = yj, i= 1,...,M, and the neutrality restriction is 8; = 0,7 = 0,...,N.The first step in determining identification is to analyze the ordercondition. Consider, for example, the most unconstrained system (A1) inwhich y;, y;*, B;, and 8; are the free parameters to be estimated. Observethat y; can be estimated by OLS on the first equation in (Al). Theremaining parameters y;*, 8;, and 8; are estimated from the secondequation in (A1). The most constrained form of this second equation is29 The Econometric Methodology\nN M+N(A2) y= 9B; + Dy Z,_)01+ €;ic i\n0¢ =a (p + k) X 1 column vector of parameters which is zero if§ = 0,7 =0,...,Nandyf = y,i=1,...,M= © [n-w8) + 8), 1 < is Mand 0 <j <N.t+j=Note that forj = 1,... , N, the residual @,_; can be expressed as a linearcombination of the other right-hand-side variables Z,_,,... , Z;-m—n-That is, only the residual at time ¢, %,, is not perfectly correlated with theother right-hand-side variables. Hence, the most unconstrained form ofthis equation that can be estimated by OLS is\na M+N(A3) Wr = ABs + a Z,— 181 + &-\nSince there are k elements in 8, and (M + N) (p + k) elements in the 6coefficients, equation (A3) can be used to estimate at most k + (M + N)(p + k) parameters. As long as this number of estimable parametersexceeds the number of free parameters contained in the B, 5, and y*coefficients, the order condition is satisfied.\nIdentification depends on the rank condition as well as the ordercondition. The rank condition is particularly important in the identifica-tion of (A3) because, in general, it need not be satisfied at the same timeas the order condition. This failure to satisfy the rank condition becomesclear if we rewrite (A1) as\nM(A4) Xi= 3 Ziv +ul\nMrk k kXP = ea Zi-i¥i + Ui;\nvee * j208 2B) + 25; 8) = 1-i-jVi |>where X7, yj, y/*, and wu; are the sth columns of X,, y;, y*, and u,,respectively. The scalars B; and 8; are the sth elements of 8; and 8,,respectively.30 Econometric Theory and Methodology\nNote that for any particular s, say s,, the system will be unchanged by adoubling of all the elements of y;\"? for all i and a halving of 8;? — ;° forall j. Because of this observational equivalence, the parameters 8,° — 8;?and y;\"° are not identified even when the order condition is satisfied. Arestriction on any element of 8;° or y;\"? is sufficient to identify theseparameters. If we apply this argument to each of the k values of s, it isclear that k additional restrictions are needed for identification. Therestrictions will be provided if either neutrality (8; = 0) or rationality(y; = y7) is treated as a maintained hypothesis. Thus, only if neitherneutrality nor rationality is maintained will the rank condition fail to besatisfied in situations when the order condition is satisfied.\nTests of hypotheses are conducted by comparing the residual sums ofsquares from constrained and unconstrained systems. The number ofrestrictions tested (and hence the number of degrees of freedom in the y”statistic) equals the number of identified parameters estimated in theunconstrained system, less the number of identified parameters esti-mated in the constrained system. To illustrate this calculation using theprocedures above, consider in the efficient-markets case in which N = 0,the test of rationality under the maintained hypothesis of neutrality. Thelast equation in the constrained system (where 8, = 0, y; = y;‘) contains kparameters (the elements of 8), all of which are identified. The lastequation in the unconstrained system (where 8, = 0) contains k + Mk(p+ k) parameters. However, as explained above, only k + M(p + k)parameters can be estimated. Only if k = 1 will all of the parameters inthe unconstrained system be identified. However, even if k > 1, there areM(p + k)testable restrictions. These restrictions are linear combinationsof the restrictions y — y* = 0 (see the next chapter for an example).\nAnother test which may be conducted in the efficient-marketsframework (N = 0) is a test of the null hypothesis of neutrality under themaintained hypothesis of rationality. Recall that the last equation of theconstrained system (y; = y;*,8, = 0) contains k parameters (the elementsof 8), and observe that the last equation of the unconstrained system(y; = y*) contains 2k parameters (the elements of B and 8,). In both theconstrained and unconstrained systems, all parameters are identified andall k neutrality restrictions are testable.\nA third test in the efficient-markets framework is a test of the jointhypothesis of neutrality and rationality. As in the first two tests, all kparameters of the last equation in the constrained system are identified.In the unconstrained system the last equation contains 2k + Mk(p + k)parameters (k elements of 8, k elements of 8, and Mk(p + k) elements ofy7,i = 1,..., M), but, as explained above, only k + M(p + k)parameters can be estimated. Therefore, under no circumstances will allparameters of this equation be identified. However, there are M(p + k)testable restrictions that are linear combinations of the restrictions y —y* = Oand 6, = 0.31 The Econometric Methodology\nThe interpretation of these efficient-markets tests depends on whathypothesis is maintained. In particular, the test statistic associated withthe joint test of rationality and neutrality is identical to the test statisticfor the test of rationality, under the maintained hypothesis of neutrality.This follows because, although the free parameters in the unconstrainedsystems are different, the estimated coefficients are identical. Further-more, the constrained systems are the same. Because of the equivalenceof the two tests, one cannot determine whether a rejection is due to aviolation of rationality alone or a violation of both rationality and neu-trality.\nTests of policy neutrality under the maintained hypothesis of rational-ity as in Barro (1977, 1978) and in Chapter 6 furnish another interestingcase. These models assume that the deviation of current output from itsnatural level is affected only by the current and N lagged surprises in asingle policy variable (i.e., k = 1 and N > 0). To obtain identification ofthe coefficients on surprises in the policy variable, these studies implicitlyplace restrictions on the covariance of e, with both u, and with laggeddisturbances. There are two alternative conditions sufficient for iden-tification of the 8 coefficients, that is, the coefficients on anticipatedpolicy. One condition, discussed and used by Barro (1977, 1978, 1979),Leiderman (1980), and in Chapter 6, is the exclusion restriction p = 1.That is, the time-series model for the policy variable X, contains at leastone variable that is not directly included in the y equation. The y equationin the constrained system (where 8; = 0 and y, = yj‘) contains N + 1parameters (B,, ..., By), and in the unconstrained system (whereYi = yi) it contains 2(N + 1) parameters (B,,... ,Byand8,,... , yn).In each of these systems, all of the parameters are identified because thenumber of free parameters is less than the number of estimable parame-ters, 1 + (M + N) (p + 1). Therefore all of the N + 1 neutralityrestrictions are testable.\nThe alternative sufficient condition for identification is M > N; that is,the number of lags in the time-series model for the policy variable X,exceeds the number of lagged surprises in the y equation. Although thiscondition formally leads to identification, it requires strong a prioriknowledge of lag lengths. Without this prior knowledge we are faced withthe observational equivalence problem raised by Sargent (19765).\nTo identify 5, at least one of the two conditions above must hold. Onerecent example in which this does not occur is in Grossman (1979). Hisspecification of the time-series equation describing his policy variable(nominal GNP growth) does not include any variable other than laggeddependent variables. Moreover, the number of lags in the output equa-tion exceeds that in the time-series equation for the policy variable.Therefore, the 8 coefficients in his model are not identified, with theresult that not all the neutrality constraints can be tested.32 Econometric Theory and Methodology\n \nAppendix 2.2: An Annotated Computer Program\nThe computer program here demonstrates how the models discussed inthis book can be estimated. The particular example is chosen fromChapter 6 to illustrate the general principle of estimating models where(1) current and lagged values of both anticipated and unanticipatedvariables have explanatory power, and (2) the error term is specified tofollow an autoregressive process. The program makes use of the PROCNLIN nonlinear estimation procedure in the widely available computerpackage SAS, described in the SAS User’s Guide (1979). The detaileddiscussion of this sample program should not only allow a user of SAS toexploit the techniques described in this book, but also should provideenough of the program’s logic so that it can be modified for use with othereconometric packages with nonlinear estimation capabilities. It should benoted that the PROC NLIN procedure of SAS does have one majoradvantage: it can handle extremely large problems that are beyond thecapability of other packages. This is not important for a small estimationproblem, but it is crucial for estimation of models such as those found inChapter 6 which have over fifty parameters. My experience with SAS’snonlinear estimation routine has been a happy one: it converges quicklyand is not prohibitively expensive to use.\nThe program here estimates over the period 1954:1-1976:4 a modelconsisting of (A5), a forecasting equation for money growth, and (A6),an output equation in which both anticipated and unanticipated moneygrowth matter.\n4 4(AS) M1IG=y,+ 2uMIG,-; + ay Yiea RTB,_;4+ 2, Yirs SURP,_; + tr,7(A6) log (GNP,) = c+ tTIME + > 8,(M1G,_;— M1G}_,)\n7+ 2,58 M1Gi_;+&,where€, = Pi€s—1 + P2€:—2 + P3€r-3 + P4er—-4 t+ Mr,4 4 4MIG; = y. + 2% M1G,_;+ oy Vira RTB,_;+ 2, Yrs SURP, -;.i= i= i=The cross-equation restrictions are that the y; are identical in (A5) and(A6). The variables are as defined in Chapter 6. Note that this exampledoes not make use of the polynomial distributed lag (PDL) restriction.\nThe interested reader is referred to Kmenta (1971) to see how the PDLrestriction can be imposed by “‘scrambling” variables.33 The Econometric Methodology\nThe basic idea of the program is to stack the data so that the system ofthe two linear equations, (A5) and (A6), can be written as one equationwith the appropriate nonlinear constraints. Estimation with the nonlinearprocedure PROC NLIN is then fairly straightforward.\nNotes for Program Listing in Exhibit Al\nThe SAS data set ONE contains the data used in estimation. The 120quarterly observations run from 1947:1 to 1976:4. A number appended tothe variable name indicates how many times it is lagged. For example,M1Gis unlagged money growth while M1G1 is money growth lagged oneperiod. LGNP equals log (GNP) and C is the constant term.\nLines 1-17: The new data set ONEA created from ONE weights thevariables in the forecasting equation by HETA in order to correct for theheteroscedasticity across equations. The value of HETA is chosen so thatthe weighted sum of squared residuals in each equation approach eachother. The procedure for doing this will be explained when the outputfrom the program is discussed.\nLines 18-21: The LGNP variable is dropped from the data set and theM1G variable is renamed as LGNP. This operation is necessary for thestacking operation conducted later.\nLines 22-24: The new data set ONER will correspond to the outputequation and it adds the constant term to the data set ONE.\nLines 25-76: Here the stacking operation is conducted in order tocreate the data set EST used in estimation. The outcome of this operationwill be discussed first so that we may more easily follow the steps taken toachieve it. Each variable will have 240 observations with the first 120corresponding to the output equation and the second 120 correspondingto the forecasting equation. If the weighted variables are denoted by thesuperscript A, then the resulting LGNP variable written in matrix nota-tion 1s:\nLGNP}o47.1\nLGNP 976.4LGNP =M1G4oq7.1\nM1G%o76.434 Econometric Theory and Methodology\n \nHence the first 120 observations correspond to the dependent variable ofthe output equation while the second 120 observations correspond to thedependent variable of the forecasting equation (appropriately weightedfor heteroscedasticity). The variables with an A added to their namescorrespond to the appropriately weighted explanatory variables in theforecasting equation, while those without A (except for LGNP) corre-spond to the explanatory variables in the output equation. For example,\nM1G1jo47:1 0\nM1G1=| M1Glyor.4 |MIGIA=] 00 M1G1f547:10 M1G1i576:4\nIn the case of M1G1, the 120 observations corresponding to the forecast-ing equation are set to zero, while in the case of M1G1A the 120 observa-tions corresponding to the output equation are set to zero.\nLines 25-26 conduct the first stacking operation to create data setTWO. All the variables have 240 observations. The operations in lines18-21 result in a LGNP variable of the form shown above, with the first120 observations containing the dependent variable of the output equa-tion and the second 120 containing the dependent variable of the fore-casting equation. For all other variables, the first 120 observations fromthe data set ONER correspond to the output equation, and the second120 observations from the data set ONEA correspond to the forecastingequation. Lines 27-35 add to a new data set THREE the variables with anA which are identical to their counterparts without A. Lines 36-37 havedata set EST created from data set THREE. Lines 38-63 set to zero thesecond 120 observations of the variables with no A, and lines 64-76 set tozero the first 120 observations of the variables with an A. The stackedvariables described above are the outcome of these operations.\nLines 77-78: These lines set the first twenty-eight observations of bothsets of 120 observations in LGNP to a missing value. This ensures thatwhen PROC NLIN is used in the following lines, the 1947:1-1953:4observations are excluded from the sample period and estimation overthe 1954:1-1976:4 sample period results.35 The Econometric Methodology\nLines 79-247: Here the actual estimation is carried out with PROCNLIN. The parameters have slightly different names than in (A5) and(A6) above: CO corresponds to c, T to 7, MO-M7 to By-B7, EO-E7 to80-87, AO-A12 to yo-y12, and RHO1—RH04 to p,-py.\nLines 79-80: The convergence criterion is set and the residuals fromthe estimation are stored as the variable RESID in the data set DRESID.\nLines 81-117: The starting values for the parameters are provided.\nLines 118-135: Variables are generated here to facilitate calculationsof the derivatives in lines 193-247. If these derivatives are not needed,then these lines can be deleted.\nLines 136-139: Anticipated money growth, EM, is generated.\nLines 140-151: Unanticipated money growth, UM, and its lags aregenerated.\nLines 152-162: Lags of EM are generated.\nLines 163-178: The fourth-order autoregressive correction for serialcorrelation in the output equation (A6) requires the transformation hereof the UM and EM variables into RUM and REM, as shown.\nLines 179-192: The model consisting of both the output and forecastingequation is written down here. Note that it incorporates the necessarytransformation to allow for the serial correlation correction. The stackingoperation in previous lines ensures also that this model captures thecross-equation restrictions and the appropriate heteroscedasticity correc-tion.\nLines 193-247: The derivatives of the model in lines 179-192 arecalculated here. The version of SAS used to estimate this model requiredthese derivatives. Later versions of SAS may not require them, in whichcase these lines and lines 118-135 can be deleted.\nLines 248-259: Here the standard errors of both output and forecastingequations are calculated. They are used, as will be shown below, tocalculate HETA for the heteroscedasticity correction and to decide whenthe last iteration is reached. Lines 248-250 retain only the residuals in thedata set DRESID. Lines 251-259 use PROC MEANS to calculate thestandard error first of the output equation and then of the weightedforecasting equation.\nDiscussion of the Output in Exhibit A2\nThe first page of the SAS output shows the convergence to the mini-mum sum of squared residuals, and pages 3-5 show the asymptoticcorrelation matrix of the parameter estimates. Only pages 2, 6, and 7 aredisplayed as they are of the greatest interest. Page 2 contains the parame-ter estimates, their asymptotic standard errors, and the sum of squaredresiduals of the system. For example, the coefficient of the constant termin the output equation is 6.18857905 with an asymptotic standard error of04752109. The sum of squared residuals of the system, which is needed36 Econometric Theory and Methodology\n \nto calculate the likelihood ratio tests discussed in the chapter, is.01012971. Pages 6 and 7 show the standard errors of the output equationand the weighted forecasting equation, respectively, in the standarddeviation column. The standard error of the output equation is.00738342, and the standard error of the weighted forecasting equation is.00753653.\nThe iterative procedure that corrects for heteroscedasticity across theequations continues as follows. The variables in the forecasting equationare weighted by the ratio from the previous iteration of the standard errorof the forecasting equation to the standard error of the output equation.This means that the weighting variable HETA from the previous iterationneeds to be multiplied by the standard error of the weighted forecastingequation divided by the standard error of the output equation. In theexample here, the next iteration would therefore multiply the previousiteration’s HETA by .00753653 + .00738432, which equals 1.020612595.That is, line 3 of the program would be modified to insert *1.020612595just before the semicolon, and the program would then be run. Note thatcomputational costs have been lowered by using the last iteration’sparameter estimates as starting values in lines 81-117. The criterion forterminating the iterative procedure can be varied but, in the empiricalwork reported in this book, if the standard errors of the weighted fore-casting equation and the output equation differed by less than 22 per-cent, then no further iterations were performed. Thus the results re-ported in Exhibit A2 are the final iteration.\nProcedures for Calculating theLikelihood Ratio Tests\nTo carry out the tests in Chapter 6, the first system estimated was themost constrained where anticipated money has no effect on output butrationality is still imposed. The only changes needed in the computerprogram are to eliminate terms involving REM and EM from the modeland derivative statements and to delete lines 92-99 and 203-210. Thenext, less constrained system estimated has anticipated money affectingoutput and makes use of the program in Exhibit A1. The first iterationuses the same HETA value used in the final iteration of the most con-strained system. The likelihood ratio test of neutrality described in Chap-ter 2 is conducted by comparing the sum of squares of the less constrainedsystem obtained from the first iteration, with the sum of squares for thefinal iteration of the most constrained system. Further iterations are thenperformed for this system in which anticipated money matters until thetermination criterion is reached.\nThe most unconstrained system is subject neither to rationality nor toneutrality, and as there are now no binding constraints across the twoequations of the system, each can be estimated separately. The forecast-37 The Econometric Methodology\ning equation can be estimated by OLS while the output equation isestimated by deleting lines 1-21, 25-76, 78, and 188-191 from the pro-gram in Exhibit Al and modifying the derivatives statements appropri-ately. Note that the CO and AO parameters are not identified and so oneof them should be set to a constant. As discussed in Appendix 2.1, at leastone other parameter will not be identified and PROC NLIN will auto-matically set it to a constant in estimation. In some cases when moreparameters are unidentified, the most unconstrained output equation iseven more linear, and so takes an even simpler form.\nThe likelihood ratio tests of neutrality and rationality jointly, or ofrationality alone, compare the sum of squared residuals of the appro-priately weighted most unconstrained system with those of the moreconstrained systems, estimation of which is discussed above. The appro-priately weighted sum of squared residuals for the most unconstrainedsystem equals the sum of squared residuals from the most unconstrainedoutput equation, added to the sum of squared residuals from the OLSestimated forecasting equation, divided by the square of the HETA valueused in the constrained system’s final iteration.Exhibit Al Program Listing and Output\n \nDATA ONEA;\nSET ONE;\nH variance of47 An Integrated View\nresiduals in (8), a correction must be made for this heteroscedasticity (seeMullineaux 1978). Note that testing the cross-equation restriction y = y*is equivalent to testing w = 0, in (5), since(9) & = (ZZ) 1 Zi(X— X°) = (ZjZ) 1X\n~ (ZZ) ZX = 4-9,where X, and X° aren x 1 vectors with X, and X7, respectively, in row t.Similarly Z, is a matrix of n rows with Z,,_; in row ¢.\nNow suppose that Z, is not empty, so that relevant variables areexcluded from (7) and (8). In this case, the estimates ¥ and 4* generallywill not be consistent estimates of a, and aj‘, respectively, even if ex-pectations are rational. However, rationality of expectations still impliesthat plim ¥ = plim ¥* because, as shown above, ¥ — 4* is numericallyequal to ® and plim ® = 0. Another way to understand this finding is tocalculate the plims of 7 and ¥*. They are\n(10) plim ¥ = a + (Z{Z,)~1Z{Z202,(11) plim 9* =af + (Z{Z)~'Zi Zs.\nRationality implies that a, = aj, a2 = a}, and hence plim ¥ = plim 4*.As is obvious from (10) and (11), the equality of plim ¥ and plim 4*reflects the equal asymptotic bias in the two estimates.\nThis section has analyzed tests of rationality in the presence of someobservable measure of expectations. The general conclusion is that arejection of y = y* or, equivalently, of w = 0, is a rejection of rationalexpectations regardless of the completeness of the information set speci-fied by Z,. The two alternative procedures discussed here are thus tests ofrationality under quite general conditions.\nIn the absence of direct observations of expectations, we must inferinformation on expectations from observed market behavior. The nextsection discusses the use of security price data to test for the rationality ofexpectations.\n3.3 Test of Rationality and Market Efficiency\nThe most common tests of rationality (efficiency) in capital marketsfocus on the condition derived in the previous chapter:\n(12) E(y, — Vilb—1) = 0,\nwhere y, is a one-period return for a security and ¥, is the expected returngenerated from a model of market equilibrium. Equation (12) aboveimplies that y, — ¥;7 should be uncorrelated with any past information ino,~1. It is the basis for a common test of market efficiency (see Fama1976a) in which the null hypothesis that a = 0 is tested in the regressionequation below:48 Econometric Theory and Methodology\n(13) W=I+Z, 10+ bywhere\nZ,—1 = variables contained in $,-4,a =coefficients,4, =error term where E(,\\¢,_ 1) is assumed to equal zero.\nA test of the null hypothesis that a = 0 is a test of the joint hypothesisof market efficiency (rationality) and the model of market equilibrium,no matter what past information is included in Z.\nThe “‘efficient-markets model” of the previous chapter that satisfies(12) is:\n(14) Ye = Jit (X,— XP )B +e,where\n€, = ascalar disturbance with the property E(e,\\,_ 1) = 0—thus e isserially uncorrelated and uncorrelated with X7,\nX,= the k-element row vector containing variables relevant to thepricing of the security at time ¢,\nX? = the k-element row vector of one-period-ahead rational forecastsof X,, that is, Xp = E(X;\\d,-1),\nB =k x 1 vector of coefficients.\nAs in Chapter 2, the linear forecasting equation for the k variables in X,is(15) X,=Z1y tu,where\ny=/ x k matrix of coefficients.u,=k-element row vector of disturbances where E(u;\\b,—1) isassumed to equal zero.\nWhen we apply rational expectations, (14) becomes\n(16) Y= I+ (Xi - ZV )B +e,where y = y*.\nThe system of (15) and (16) can be estimated with the methodologyoutlined in the previous chapter. The cross-equation constraints impliedby market efficiency (rationality), - = y*, can be tested with a likelihoodratio test and are analogous to the rationality constraints for the regres-sions (7) and (8). Although expectations are not directly observable, wecan test their rationality by maintaining the equilibrium model of ¥ andthe condition that only contemporaneous unanticipated movements in X,are correlated with y, — y,. Any rejection of the constraint y = ‘y* couldindicate a failure either of the rationality of expectations about X, or of49 An Integrated View\nthe maintained equilibrium model. This interpretation of such a test isdiscussed in the previous chapter.\nTwo questions arise about the econometric properties of this proce-dure. First, does it provide a test of market efficiency (rationality) underthe maintained model of ¥, even if Z,_, excludes variables relevant toforecasting X,? Second, what is the relation of this test to the common testfor market efficiency using equation (13)? These questions are related;the following theorem provides answers.\n3.3.1. TheoremConsider the system of equations(a) X,=Z,1¥+ Ur,d= TE + (Xi — ZV )B + eswhere _X, is a k-element row vector, Z,_, is an /-element row vector, y,and ¥, are scalars, y and y* are / x k parameter matrices, B isa k x 1\nparameter vector, u, is a k-element row vector, and ¢, is a scalar. Consideralso the equation\n(b) WAV t+Z1at+ wy,\nwhere a is an/ x 1 parameter vector. The quasi-likelihood ratio test ofthe null hypothesis y = -y* in (a) is asymptotically equivalent to a quasi-Ftest of the null hypothesis a = 0 in (b). (The quasi-likelihood ratio andquasi-F tests are constructed as if the disturbances, u,, €,, and , are i.i.d.normal.)\nOutline of Proof\n(See Abel and Mishkin [1980] for a more detailed and formal proof.)The key insight in the proof of this theorem is to observe that the system(a) can be rewritten-as\n(17) X,=Z,1y +t,Ye =r t (XK - Zr VB + 2-19 + &,\nwhere 6 = (y — y*)B. The null hypothesis y = y* will be true only if6 = 0, and this constraint can be tested using the nonlinear least-squaresprocedures described in the previous chapter. The constraint that y is thesame in both equations in (17) is not binding, so we can estimate theparameters in (17) by OLS on each equation. Specifically, the estimateis obtained by OLS on the first equation. Treating Y, as known, 6 and 6are obtained from an OLS regression of y, — ¥,on X, — Z,_, Y and Z,_}.Since the residuals from the first equation in (17), X, — Z,-1 4, areorthogonal to Z,_ , by construction, the estimate of @ will not be affectedif X, — Z,_, ¥ is omitted from the list of regressors when OLS is appliedto the second equation in (17). Thus the estimate of @ is numerically50 Econometric Theory and Methodology\nidentical to, and has the same distribution as, the OLS estimate of « in(b). Although the test statistic associated with the null hypothesis a = 0may differ in small samples from the test statistic associated with the nullhypothesis 6 = 0, these test statistics will be asymptotically equal.\n3.3.2 Remarks\nThe theorem is valid regardless of the properties of the error terms uand e. If they are not i.i.d., the two test procedures will be asymptoticallyequivalent, but neither will yield test statistics with the assumed asymp-totic distributions. If the contemporaneous correlation of u and € is zero,the OLS regression of y on & (& = .X — Z 4) and Z will provide consistentestimates of both 8 and 8. If the contemporaneous correlation of u and €is unknown, then B is unidentified. Nevertheless, in this case the OLSestimate of 6 is still consistent and the theorem continues to apply. Since8 is, in general, unidentified, there is an alternative demonstration of thistheorem. The maximized value of the likelihood function is not affectedby an arbitrary choice of 8. Therefore, set B equal to zero, and observethat we now have a seemingly unrelated system (Zellner 1962) in whichthe right-hand-side variables are identical in each equation. The esti-mates of y and 6 thus can be obtained from OLS equation by equation.\nObserve that the second equation in (17) contains a model of marketequilibrium. The proof outlined above treats y, as known. If it is unknownand assumed to be a linear function of past variables W,_,, then W,_,must also be included as explanatory variables in the time series modelfor X,. The orthogonality of the residuals in the equations for X, with theother right-hand-side variables in the second equation of (17) is thuspreserved, and the proof of the theorem may proceed as above. Thisbecomes clear in the proof of the corollary in Section 3.4. Of course, if thecoefficients of W,_, in the model of market equilibrium are estimated,then we cannot test the rationality restriction that y, — ¥, is uncorrelatedwith W,_,. The question of the testability of such restrictions has beendiscussed in Appendix 2.1.\nObserve also that 8 = (y — y*)B is an/ x 1 vector. Thus the test of6 = 0 (or, equivalently, « = 0) is a test of only / constraints. However,there are / x k constraints in-y = y*. Therefore, all these constraints aretestable only if k = 1. Even when k > 1, imposing the constraint -y = -y*places only / binding restrictions on the system in (a). For example,consider the case in which / = k = 2. The system of equations can bewritten as\n(18) Xie = YuZir—-1 + YaZor—1 + Uae,Xor = V2Z 1-1 + Yo2Z2,1-1 + Uae,\nYe = BX, + BoXy — Bi + VB2)Zi-1— (y31Bi + ¥32B2)Zoe-1 + €-51 An Integrated View\nThe four parameters y, can be estimated from the first two equations. IfCov(€,, u;;) is known to be zero, we can estimate 81, Bz, (yiiBi + Yi2B2),and (y318, + y32B2) from the third equation. Since we cannot estimatethe four elements yj, separately, we cannot separately test the fourrestrictions y;; = yj. However, we can test / = 2 linear combinations ofthe rationality restrictions.\n(19) (Ya — YA)B1 + C2 — Y)B2 = 0 for i = 1 and 2.\nIf we do not know the covariances of €, and u;,, then B, and B, are notidentified. However, we can still test whether the two linear combinationsabove are equal to zero. To see this, rewrite the third equation as\n(20) ye = [On YEBi + 12 — Viz Bal Z1.2—1 + [a1 — YE)B1+ (22 — ¥32)Ba] Z2.0—-1 + Bitar + Botlar + €r-\nObserve that the coefficients of Z,;,_, and 2, in the rewritten equa-tion are the testable linear combinations of rationality restrictions.\n3.3.3 Implications\nThe most interesting implication of the above theorem is similar to thefinding in Section 3.2: a rejection of the cross-equation restriction y = y*is a rejection of market efficiency or, equivalently, rationality (maintain-ing the model of market equilibrium) whether or not the information setin Z, is complete. This is demonstrated by noting that the test of y = y*is asymptotically equivalent to the test of a = 0, which is clearly a test ofthe efficient-markets condition (12), regardless of what past informationis included in Z. However, if the model generating X, is not correctlyspecified, then in general there is an errors-in-variables bias that leads toinconsistent estimates of B and y. Nonetheless, any asymptotic bias in ¥will be identical to that in ¥*.\nThe theorem implies further that rationality (or market efficiency)does not rule out significant correlations of y, — ¥, with current variables.Therefore, if information not available at time t — 1 is included in theZ,—, vector—as in earlier work mentioned in Chapter 2—then neitherprocedure provides a test of rationality.\n3.4. Tests of the Short-Run Neutrality ofAggregate Demand Policy\nSargent (1976) discusses tests of a classical equilibrium macroecono-metric model with a Lucas (1973) supply function of the form\n(21) y=, t+ (X,- X)B +e,52 Econometric Theory and Methodology\nwherey, =a scalar representing output or unemployment at time r,¥, = the equilibrium (natural rate) level of output or unemployment attime ¢,X,=a k-element vector of aggregate demand variables, such as theprice level or the money supply at time f,e, = scalar disturbance term with the property E(e,|6,-;) = 0.\nThis equation has the neutrality property that only unanticipatedchanges in X, have an effect on y, — Y,. Note that it is one form of theMRE equation discussed in the preceding chapter and has the same formas the efficient-markets model (14). As before, we must specify how ¥,,the equilibrium level of output or unemployment, is calculated in order togive the supply function empirical content. A particular specificationoften used with the Lucas supply function is\nL(22) y= 2 NY-iSuppose that X, is generated by the forecasting modelLU(23) X= Zyt Wir-i + Ur,whereZ,-, = an/J-element row vector of predetermined variables other thanlagged y,,y =an/ x k matrix of coefficients,wu; =a k-element row vector of coefficients.\nNote that (23) has the same form as the forecasting model (15) in thepreceding section, except that in (23) we distinguish between laggedvalues of y, and other predetermined variables. We assume for themoment that E(u,!,_ 1) = 0 and combine (21)-(23) to obtain the system\nLv(24) X= Z1yt 2% Wir-i + Urs\nL’ LYe = (X,- Z-1y* - 2 vty.-}8 + 2 NY-it &\nwith the cross-equation rationality constraints y = y* and); = 7,i = 1,..., L’. Any rejection of these constraints could indicate a violation ofthe null hypothesis of rationality, or of the maintained hypothesis of theequilibrium model.\nSargent (1976a) uses Granger (1969) causality tests to test the jointhypothesis of rationality of expectations and the equilibrium model de-scribed in (21) in (22) above, which embodies the neutrality of antici-pated policy. Substituting (22) into (21) and taking expectations con-ditional on $,_;, we have53 An Integrated View\nL(25) E(ylb,-1) = 2 NYr-1 = E(Vdle- 1, Yr-25 + + Ye):\nIn other words, the optimal linear forecast for y, does not benefit from theuse of other information besides past y’s. Hence, the equilibrium modelin Sargent (19762) requires that any past information, Z,_,, fails toGranger-cause y,. Specifically, if OLS is used to estimate the parametersv; and a in the regression equation,\nLU’(26) y= Writ Zp-10 + Bes\nwhere L' = L, the estimate of a should not differ significantly from zero.\nThe relationship between tests of the cross-equation constraints in (24)and the Granger-causality test in (26) is made clear by the followingcorollary.\nCorollary\nIf L = L, then a quasi-likelihood ratio test of the null hypothesis y =y* in (24) is asymptotically equivalent to a quasi-F test of the nullhypothesis that a = 0 in (26).\nOutline of Proof\nAs in the proof of the theorem, the unconstrained system (24) can berewritten as\nLU(27) X= Ziyt % WiYr-i t Ue,L Ly= (x.- Zi1Y¥- es -)B + a NVr-iLU+ Z,_ 18, + > 9iy:-i + €,\nwhere 6, = (y — y*)R and 6; = (W; — W*) fori =1,...,L,andit canbeestimated by OLS on each equation. Note that since 0, and A; are bothcoefficients of y,_; in (27), the separate parameters 0, and \\; are notidentified for i = L. Hence, the constraints ; = Wj for i = L are nottestable. In order to test the testable cross-equation restrictions, thesystem (27) can be estimated by OLS on each equation, as explained inthe proof of the theorem in Section 3.3. Since the estimated residualsfrom the first equation will be orthogonal to Z,_, andy,_;fori=1,...,L,, the deletion of this residual vector from the second equation will notaffect the OLS estimates of the coefficients on Z,_, and y,_;. Hence, asinthe previous proof, the least-squares estimates of « and 0, will be numer-54 Econometric Theory and Methodology\n \nically identical, and the test statistics associated with the null hypothesesa = 0 and 6, = 0 will be asymptotically equal.\nRemarks\nObviously, OLS cannot be applied directly to the second equation of(27) as it is written since for i < L, y,_; appears twice on the right-handside because we must estimate the parameters of the y, model. OLS canbe used after this equation has been rewritten to eliminate the perfectcollinearity of right-hand-side variables. Thus we cannot obtain testablerestrictions on ; fori = 1,. . . , L. However, the constraints 0; = 0 andhence p; = yf fori = L + 1,..., L’ are testable with the identifyingrestriction that the lag length L in (22) is shorter than the lag length L’ in(23). This seems a rather strong assumption to impose on the basis of apriori knowledge, and one should be cautious in interpreting resultsbased on estimates of 6; in this case.\nImplications\nIt is important to consider the effects of specifying the list of variablesincluded in Z,_, incorrectly. Irrelevant predetermined variables in Z,_,will not lead to inconsistent parameter estimates but will, in general,reduce the power of tests. On the other hand, excluding relevant vari-ables from Z,_; will lead to a breakdown of the assumption thatE(u,\\,_) = 0, and will lead to inconsistent estimates of y. Even in thiscase, however, any rejection of the constraint y = y* in (24) indicates afailure of rationality, or of the equilibrium model which embodies neu-trality, since a rejection of this constraint indicates that Z Granger-causesy. As demonstrated above, this implication holds regardless of the in-formation included in Z.\nThe procedure outlined therefore provides a test of the joint hypoth-esis of rationality and the equilibrium model, even if relevant predeter-mined variables are omitted from Z,_,. This result can be used to showthat Lucas’s (1972) conjecture that tests of neutrality cannot be con-ducted when there is a change in policy regime is not always correct. Ifthere are two policy regimes in the sample period 1 to T with the breakoccurring at T,, then there is a separate forecasting equation for eachregime: for example,\n(28) X,=Z,.ytuy,  fort=1toT,-1,X,=Z,-1y2t uy ‘for t= T, to T.\nUsing dummy variables, we can write one forecasting equation for both\nregimes:\n(29) X,=Z,1y,+ Zh .€+u,  fort=1to T,55 An Integrated View\n \nwhere0 fort=1to T,-1Zi =Zi-1 for t= T, to T€=y-Vuy fort=1to T,-1u, =\nUx, for t= T, to T\nNeglecting to take account of a change in policy regime is, therefore,equivalent to omitting the relevant set of variables Z*_, from the fore-casting equation. But as we have seen, even if Z,_ , excludes this relevantinformation because its variables are chosen without considering thechange in policy regime, a test of the cross-equation restriction y = y*continues to be a test of the joint hypothesis enbodying neutrality. Animportant caveat, however, needs to be mentioned. The change in policyregime could alter the population variances of the error terms in both theforecasting equation and the output or unemployment equations. Unlessattention is devoted to correcting potential heteroscedasticity that canarise as a result, the test statistics may lead to misleading inference.\nMcCallum (1979a) and Nelson (1979) emphasize the point raised bySargent (1973, 1976b) that the Granger-causality tests are tests of theneutrality of anticipated policy only if (1) lagged values of X, — X¢ do notenter the supply function (21), or (ii) the disturbance e, in (21) is seriallyuncorrelated. That is, if either of these two conditions does not hold, thenit is possible for Z to Granger-cause y even though anticipated policy isneutral.\nThe analysis in the present chapter demonstrates these points also. Thecorollary above breaks down if there are lagged surprises in (21) andhence in (24). Although the contemporaneous residual from the firstequation in (27) is, by construction, orthogonal to Z,_, and y,_;, thelagged residuals are not. Thus, the test of y = y* will no longer beequivalent to a Granger-causality test. Granger-causality will no longerbe a test of the joint hypothesis of rationality and the model of equilib-rium output.\nNow consider the case in which only contemporaneous innovations inX, appear in (21) and (24), but ¢, is serially correlated, implying that p, isserially correlated. Here, the corollary holds and the Granger-causalitytest is asymptotically equivalent to the test of y = y*. However, since theright-hand sides of both (24) and (26) include lagged dependent vari-ables, the estimates of « and 6, will no longer be consistent. Test statisticsfrom both procedures are invalid in this case. To obtain valid test statis-tics for the joint hypothesis, we correct the supply function (21) for serialcorrelation by quasi-differencing and generate specification with a seri-56 Econometric Theory and Methodology\nally uncorrelated error. The resulting specification will contain lagged aswell as current X, — X7. We are then dealing with the case above wherethe Granger-causality test is no longer a test of the joint hypothesis.\n3.5 Summary and Conclusions\nThe framework in this chapter ties together a range of issues in testingrationality, financial market efficiency, and the short-run neutrality ofaggregate demand policy. Two main themes stand out in this integratedframework:\n1. The cross-equation tests of rationality, market efficiency, and short-run neutrality discussed here are asymptotically equivalent to more com-mon single-equation regression tests.\n2. The exact specification of the relevant information set used inrational forecasts is not necessary for the cross-equation tests of rational-ity, market efficiency, and short-run neutrality to have desirable asymp-totic properties.PART\n2 Empirical Studies \n4 Are MarketForecasts Rational?\n4.1 Introduction\nThis chapter presents tests of the rationality of both inflation andshort-term interest rate forecasts in the bond market. These tests makeuse of security price data to infer information on market expectations. Acloser look at whether market forecasts of inflation and interest rates arerational seems necessary in light of recent work (Pesando 1975; Carlson1977; Mullineaux 1978; Friedman 1980) that evaluates the inflation andinterest rate forecasts from the Livingston and Goldsmith-Nagan sur-veys. A frequent empirical result in these studies is that the surveyforecasts are inconsistent with the restrictions implied by the theory ofrational expectations. What conclusions about the behavior of marketexpectations should we draw from these results?\nOne view which associates survey forecasts with market forecasts takesthese empirical results to be evidence that the market is not exploiting allinformation in generating its forecasts. The Friedman (1980) study isparticularly disturbing in this regard because it uses data from the Gold-smith-Nagan interest rate survey which is made up of interest rate fore-casts from actual participants in the market.\nAn alternative view, Pesando (1975) for example, holds that marketsprobably do display rationality of expectations. Irrationality in theLivingston and Goldsmith-Nagan survey data would then indicate thatthese data cannot be used in empirical work to describe market expecta-tions.\nThe latter view receives support for two reasons. Survey data arefrequently believed to be inaccurate reflections of the behavior of marketparticipants and are considered unreliable. More important is a pointemphasized in Chapter 2 that is often ignored in discussing the propertiesof expectations. Not all market participants need be rational for a market\n5960 Empirical Studies\n \nto display rational expectations. The behavior of a market is not necessar-ily the same as the behavior of the average individual. As long as unex-ploited profit opportunities are eliminated by some participants in amarket, then the market will behave as though expectations are rationaldespite irrational participants in that market. Therefore, survey forecastsdo not necessarily describe the forecasts inherent in market behavior, andthe irrationality of survey forecasts does not in itself imply that marketforecasts are also irrational.\nOne purpose of this chapter is to provide indirect evidence on theusefulness of survey data like Livingston’s and Goldsmith-Nagan’s fordescribing the expectations reflected by markets. In particular, this chap-ter contains direct tests of the rationality of the bond market’s interestrate and inflation forecasts, tests similar to those found in the studiesmentioned in the opening paragraph. Because these tests are designed touse actual price data to infer information on market expectations ratherthan relying on survey data, they can provide direct information on therationality of a particular market. They permit a clearer interpretation ofresults that indicate irrationality in survey forecasts. The empirical workin this chapter thus will shed light not only on the value of these surveysfor further research, but also on the rationality of expectations in suchmarkets as those in which bonds are traded.\n4.2 Tests of Forecast RationalityRationality of expectations requires that(1) E(X, — X\\b,_1) = 0,\nwhere X; is the one-period-ahead forecast of a variable X,, generated atthe end of period t — 1, and $,_, is the set of information available at theend of ¢ — 1. This implies that the forecast error, X, — X;, should beuncorrelated with any information or linear combinations of informationin o,-1-\nThis implication is the basis of the tests of rationality found in thestudies of survey forecasts mentioned above. Consider the followingregression equations where we assume that E(u,,!b,_1) = E(u2,/,—1)= 0:\nk\n(2) X= by + 2 bX,-i + Un,k\n(3) Xp = Co + 2 CMa t Me.\nThese equations can be estimated with ordinary least squares (OLS), andunder the hypothesis of rational expectations Modigliani and Shiller61 Are Market Forecasts Rational?\n(1973) point out that the estimated b; coefficients should not differsignificantly from the estimated c; coefficients. This null hypothesis that\n(4) b;=c; for alli=0,...,k\nis subjected to a conventional F test in the survey forecast studies. A moredetailed discussion of the rationale behind this test can be found inChapter 3.\nThe theory of efficient markets leads to restrictions similar to those in(4) which can also be easily tested. Market efficiency (or, equivalently,rational expectations) implies that securities prices in a capital marketshould reflect all available information, and hence an expectation as-sessed by the market should equal the true expectation conditioned on allavailable information, E(. . . |b,_,). To give this concept empirical con-tent, we must specify the relationship between the probability distribu-tion of future prices and current prices. This requires a model whichdescribes how current equilibrium prices are determined. Here, themarket is assumed to equate expected, one-period, holding returnsacross securities, allowing for risk (liquidity) premiums which are con-stant over time.\nIn the case of long-term bonds, for example, the one-period returndenoted by y,, is the nominal return from holding the long-term bondfrom ¢t — 1 tot, including both capital gains plus interest payments. Themodel of market equilibrium implies that the equilibrium return J, is\n(5) Ve = Emildr-1) = 4-1 +d,where\nr,-, = the return on a one-period bond from ¢ — 1 tot(which of course equals the expected one-periodreturn)—this is just the short-term interest rate,d = the constant liquidity (risk) premium,E,,(. . . \\b;-1) = expectation assessed by the market at ¢ — 1.\nAs discussed in Chapter 2 market efficiency implies that\n(6) E(y, — Vilbr—1) = EO — 4-1 — aly 1) = 0.\nIf we call the equilibrium return of ¥, a “normal” return, then theequation above states that no unexploited profit opportunities exist in thebond market: at today’s price, market participants cannot expect to earna higher-than-normal return by investing in a long-term bond. Theefficient markets equation (6) is analogous to an arbitrage condition.Arbitrageurs who are willing to speculate may perceive unexploitedprofit opportunities and purchase or sell bonds until the price is driven tothe point where (6) holds. Thus market efficiency does not require that allparticipants in the market are rational and use information efficiently.62 Empirical Studies\nThe average behavior of an individual in the market is not a reliable guideto the market’s behavior.\nEquation (6) above implies that y, — r,_, should be uncorrelated withany past available information or linear combinations of this information.A model consistent with (6)—referred to as the efficient-marketsmodel—is\n(7) Ye=t it dt (X,- X)B +e,\nwhere an e superscript denotes expected values conditional on all pastavailable information (i.e., X; = E(X,\\b,_ 1), a one-period-ahead ra-tional forecast), and\nX, =a variable (or vector of variables) relevant to the pricing of longbonds,\n8 =a coefficient (or vector of coefficients),\n€, = an error process where E (e,!,_;) = 0 and hence ¢, is seriallyuncorrelated.\nThe efficient-markets model stresses that only when new information hitsthe market will y, differ from r,_, + d. As equation (7) makes clear, thisis equivalent to the proposition that only unanticipated changes (sur-prises) in variables can be correlated with y, — r,_1.\nThe assumption that the coefficient on r,_ , equals one in equation (7)has been subjected to empirical test by Fama and Schwert (1977) andMishkin (1978) and is not rejected. It has been tested also for the1954-1976 sample period of this chapter. A quarterly bond returns serieswas regressed on the beginning of \" — =tla seo’ ~ =8a gizo = \"'P esto’ |= 8p(4020) (90€0°) (vz10\") (810°) (vsz0\") (6Lv0\") (1610\") (z610\")wooo\" = 18 eszo. = 48 sro =°'f 990\" - =f €L20 — = 73 zoz0- =49 = egg’ =P 6r00\" =P(1120°) (8820\") (110°) (210°) (vsz0\") (840°) (€L10') (0610\")6100°- =%'8 LEso. -=98 60r0 =8f 19r0' — =f oogo’— = Sta S610\" — =92 Toro’ =S'P €900°— =P(01z0\") (ssz0') (1z10°) (€T10\") (1¥z0\") (86€0°) (6810\") (6L10\")ello - =\"'8 00607 -=58 speo’ =f seo - =f Tego — =\" 1900°'~ = Ovo’, = \"'P 6L10'— =§P(s610°) (180°) (sz10\") (ze10') (620°) (zev0\") (610°) (8020\")gto — =*8 Brel’ =18 6ezo = 8 Lizo'~ =f Z9€0' — =*a rilo =\" 6rro’ = \"'p 9620'— =\"P(osto\") (<sb0\") (1z10\") (s120\") (0z2z0\") (€690°) (610°) (8z€0\")87z0' - =18 68st = 88 910 =tY 1soo’ =f 8gco— =a rego = fa Tero =\"'p OIpo'— =*p(9810°) (94L0') (S110\") (z9€0\") (9920\") (8sI1\") (€810\") (pps0\")€€zo' - = \"8 ogsz. = 8 or00' - ='f sero’ =U 90r0' — =\"a so90° = * 6sco’ = \"2 ozso' — =P(6120\") (szor) (€I10\") (950°) (ov0\") (Spst’) (210°) (1r80\")S610’ — =918 8620 — ='3 pgto— =°Y “eve =f 60r0' — =%a Ley ='a 9zeo’ = \"lp e108’ ='P\n(€100°) (s000\")\n9100°- =\"¥ 4000 = “4\n(L698) (¥996'T) (z€00°)ze t—=\"d = p0sr'zi—- =\"d €100°- =P\n \n \nP:9L6I-1:pS61 PoLiad a[dweg\n \n(panunuos) 9°p age],715 Are Market Forecasts Rational?\n \nthat for the bond market the answer is yes. Bond market data provides noevidence that interest rate forecasts are irrational. Thus evidence ofirrationality in the Goldsmith-Nagan survey of interest rate expectationscan be interpreted as casting doubt on the accuracy of this survey measurefor describing market expectations. The accuracy of the Livingston priceexpectations data, however, is still an open question since irrationalityhas been found in both the bond market and survey data for the 1959-1969 period. This issue cannot be resolved without further empiricalresearch on the rationality of this survey data over longer sample periods.5 Monetary Policy andInterest Rates: AnEfficient Markets-RationalExpectations Approach\n5.1 Introduction\nThe impact of a money stock increase on nominal interest rates is animportant issue. The most commonly held view—also a feature of moststructural macro models—has an increase in the money stock leading, atleast in the short and medium runs, to a decline in interest rates. In thesemacro models (see Brainard and Cooper 1976; Modigliani 1974), theinterest rate decline not only stimulates investment directly but also has afurther expansionary impact on investment and consumer expenditurethrough its effect on the valuation of capital. The decline in interest ratesis thus a critical element in the transmission mechanism of monetarypolicy. In addition, the view that increases in the money stock lead to animmediate decline in interest rates has important implications for theFederal Reserve System’s conduct of monetary policy when a decline ininterest rates is desired. This view is the basis for demands by governmentofficials that the Fed not keep the rate of money growth too low and soinduce an objectionable increase in interest rates.\nMilton Friedman (1968, 1969) has criticized this view on the groundsthat it ignores the dynamic effects of a money stock increase. Friedmanconcedes that a so-called liquidity effect—where an excess supply ofmoney will create increased demand for securities, a rise in their price,and a resulting fall in interest rates—does work in the direction of adecline in interest rates when the money stock is increased. However,two other effects can counter this liquidity effect. The money stockincrease will, over time, have an expansionary effect on both real incomeand the price level. This “income and price level effect” will, through theusual arguments in the money demand function, tend to reverse thedecline in interest rates. More important for short-run effects on interestrates, increases in the money stock can also influence anticipations of\n1677 Monetary Policy and Interest Rates\ninflation. Higher expected inflation as a result of money stock increaseswould, through a Fisher (1930) relation, increase nominal interest rates.This “‘price anticipations effect” can thus not only mitigate the decline ininterest rates stemming from the liquidity effect but could also overpowerit. That interest rates are highest in countries experiencing rapid rates ofmonetary growth is casual evidence for this proposition.\nEarly work on the issue of money supply increases and interest rates,such as Cagan (1972), Gibson (1970), and Gibson and Kaufman (1968),tended to stress the “income and price level effect” more than the “‘priceanticipations effect” because these researchers believed that adjustmentsof inflationary expectations proceeded slowly. Recent work on the theoryof rational expectations and market efficiency, starting with Muth (1961),indicates that inflationary expectations can adjust quite rapidly. Thus, the“price anticipations effect’’ should, and does, receive more weight in thischapter when the effect of money supply increases on interest rates isdiscussed.\nTwo lines of empirical work bear on the issue whether increases in themoney stock lead to a decline or to a rise in interest rates. “Keynesian”macroeconometric models impose a fair amount of structure in theirestimates of financial market and income-expenditure relationships. Inthese models, increases in the money stock do lead to a substantialdecline in interest rates in the short and medium run, as, for example, inModigliani (1974) and the simulation results in this chapter. This evi-dence is suspect, however, because these models ignore constraints thatshould be imposed if financial markets are efficient. Financial marketefficiency cannot be ignored because evidence supporting it is quitestrong (see Fama 1970). Furthermore, recent work (Mishkin 1978) indi-cates that a failure to impose financial market efficiency on macroecon-ometric models can yield highly misleading results.\nAn alternative empirical approach to this issue is to estimate reducedform relationships where changes in interest rates are regressed on pastchanges in the money stock. Evidence from this approach (Gibson andKaufman 1968) does not support the view that increases in the moneystock result in a fall in interest rates. Unfortunately, this evidence suffersfrom a problem endemic to reduced form empirical work: it is difficult tointerpret the empirical results because the theoretical framework isobscure. Also, the absence of structure when changes in interest rates areregressed on changes in the money stock leads to a large number ofparameters being estimated, and this results in statistical tests with lowpower.\nNeither approach discussed above distinguishes between the effectsfrom unanticipated versus anticipated monetary policy. Yet the theory ofefficient capital markets and rational expectations does make this distinc-tion, and this suggests an alternative approach to analyzing the rela-78 Empirical Studies\ntionship of money stock increases and interest rate movements. Thischapter develops efficient-markets (or, equivalently, rational expecta-tions) models for both long- and short-term interest rates and estimatesthem using postwar quarterly data. This approach has the advantage ofimposing a theoretical structure on the problem that allows both easierinterpretation of the empirical results and more powerful statistical testsof the proposition that increases in the money stock are correlated withdeclines in interest rates. Moreover, a Keynesian, liquidity preferenceview of interest rate determination can be embedded in the efficient-markets model and tested. Finally, as a side issue, attractive tests of bondmarket efficiency result from the approach used here.\n5.2 The Model\nThe theory of efficient markets (or, equivalently, rational expecta-tions) implies that interest rates in a bond market should reflect allavailable information. More precisely, it implies that the market usesavailable information correctly in assessing the probability distribution ofall future interest rates and bond returns. Hence for long bond returns, y,,and short-term interest rates, r,,\n(1) Em (Velbr—1) = EO; -1)and\n(2) En (tlb,—1) = E(rdde-1),where\ny, = the one-period (from ¢ — 1 to ¢) nominal return fromholding long-term bonds—it includes capital gainsplus interest payments,\nr, = the one-period (short-term) interest rate at time ¢,\n¢,_1 = information available at time ¢ — 1,E(. . .lb;_1) = the expectation conditional on $,_1,E,,(. . .lb;—1) = the expectation assessed by the market at ¢ — 1.\nIn order to give this concept empirical content we must specify modelsof market equilibrium. For the case of long-term bonds, we assume, as inthe previous chapter, that the market equates expected one-period hold-ing returns across securities, allowing for risk (liquidity) premiums whichare constant over time. This model of market equilibrium implies that\n(3) En (ylbea) = ht a,\nwhere d’ = a constant liquidity premium for long-term bonds.\nA more refined model of market equilibrium allowing the risk pre-mium to vary over time is not used for long-term bonds because, asdiscussed in the previous chapter, it makes little difference to the empiri-79 Monetary Policy and Interest Rates\n \ncal tests. Combining the model of market equilibrium above with marketefficiency yields the same condition as in Chapter 4:\n(4) E(y- -1- d'Ib,-1) = 0and the same efficient-markets model(5) y= noatd+ (X,— X7)p' + €;,\nwhere an e superscript denotes expected values on all past information[ie., a rational forecast is defined as Xf = E(X,ld,_,)], and\nX, = avariable (or vector of variables) relevant to the pricing of bonds,B! =a coefficient (or vector of coefficients),\nt\ne, = serially uncorrelated error process [because E(ell,_1) = Oj.\nIn the analysis of short-term interest rates, we can no longer argue thatthe model of the market equilibrium has no effect on tests of the efficient-markets model. In this case, the model of the risk premium used heredoes contribute significantly to the explanation of the dependent vari-able. We assume, as in Fama (1976), that the one-period-ahead forwardrate equals the one-period-ahead expected short rate, plus a risk pre-mium that now varies over time with the uncertainty in short-rate move-ments, that is,\n(6) = Em (rilb;—1) + atand\n(7) dt = ay+ a; G;,\nwhere\n1-14; = forward rate for the one-period rate at time ¢ implied by theyield curve at t—1,d} = risk (liquidity) premium for ,_1F,g, = measure of uncertainty in short rate movements.\nCombining this model of market equilibrium with the rationality ormarket efficiency condition of (2) yields\n(8) E(r,~ 1-18 — a9 a, O71, 1) = 0and the corresponding efficient-markets model(9) T= 1-1F- ay— aya, + (X,— XP) B+ EF,\nwhere the s superscript is used to differentiate the 8 and e« from theircounterparts in the long-term bond model.\nThe research question posed in the first section of this chapter suggeststhat money growth is an interesting piece of information relevant to thepricing of bonds and interest rates. Substituting for X, leads to thefollowing efficient-markets models:80 Empirical Studies\n(10) Watt d't Bp(MG,— MGF) + €,(11) = 1-1 — Go— 418; + Bin(MG,— MG?) + €;,\nwhere MG, = the money growth rate at time ¢.\nAsis found in the foreign exchange market (see Mussa 1979), spot andforward rates move together, so that changes in short-term interest ratesare predominantly unanticipated. Because the long rate is closely linkedto the price of a long bond, over periods as short as a quarter thecorrelation of changes in long rates with unanticipated bond returns, y, —7,1 — d,is very negative: —.96 in the sample period used in the followingempirical work. Changes in long interest rates will thus also be predomi-nantly unanticipated. We can see how the efficient-markets models abovediffer from earlier analysis: they stress that only unanticipated move-ments in money growth can have an effect on unanticipated movementsin interest rates. Since changes in interest rates are predominantly unan-ticipated, these efficient-markets models emphasize the effects of unan-ticipated money growth movements on changes in interest rates. Incontrast, the earlier work does not distinguish between the effects ofanticipated and unanticipated money growth.\nIf unanticipated increases in money growth are associated with adecline in long rates (as might be expected from “Keynesian” macro-econometric models), the coefficient on unanticipated money growthshould be significantly positive in the long bond equation above becausey;—%~1 and the change in long rates are negatively correlated: that is,g!,>0. If unanticipated increases in money growth are associated with adecline in short rates, then the coefficient on unanticipated money growthin the short-rate equation should be significantly negative, that is, B;,<0.\nAn important caveat is in order. As noted in Chapter 2, the efficient-markets model does not guarantee that X,— X7 is exogenous so that theestimates of B are consistent. Another way to make this point is toacknowledge that the efficient-markets model does not indicate whethera significant B coefficient implies causation from its unanticipated vari-able to bond prices and interest rates. As far as market efficiency isconcerned, causation could just as well run in the other direction, or itcould be nonexistent, as in the case where new information simulta-neously affects both interest rates and the right-hand-side variable. Thus,we must be careful in interpreting empirical results on the B’s, not toascribe causation to the results without further identifying information.\nThe same caveat applies especially when we analyze the estimated B,,,coefficient. If the money supply process is seen as exogenous, the inter-pretation of the estimated 8,,’s is straightforward. The finding of asignificant positive B/,, and negative 85, will then provide evidence sup-porting the ‘Keynesian’ position that increased money growth leads, atleast in the short run, to declines in interest rates; and a failure to find this81 Monetary Policy and Interest Rates\nresult will cast doubt on this view. If the money supply process is notexogenous, however—the position taken by many critics of monetaristanalysis—then the estimated B,, coefficients may suffer from simul-taneous equation bias and give a misleading impression about how in-creases in the money supply affect interest rates. Because this chapterprovides no evidence on the exogeneity of the money supply process, the8,, estimates must be viewed as providing information only on the cor-relations of unanticipated money growth and the movements in interestrates. Interpretation of these correlations is deferred to the concludingremarks at the end of the chapter.\nThe liquidity preference approach to the demand for money (seeGoldfeld 1973; and Laidler 1977) indicates that interest rates are relatednot only to money growth but also to movements in real income, the pricelevel, and inflation. Adding this information to the X vector of theefficient-markets models, noting that unanticipated inflation is equiva-lent to the unanticipated price level, leads to the following:\n(12) Y= M14 d'+ Bi,(MG,— MG?) + B\\(YG,— YGF)+ BL(a,— mf) + €;(13) 1 =,-1F— ay a,0,+ Bin(MG,— MG?)\n+ B\\(YG,— ¥G7) + BL (m,— ty) + €where\nYG, = growth rate of real income,a = inflation rate,Bm» By, Ba = Coefficients.\nThese equations are really efficient-markets analogs to the typical moneydemand relationship found in the literature. In addition, they captureelements of interest rate models of the Feldstein and Eckstein (1970)variety.\nThe magnitude and sign of the 8 coefficients in equations (10)-(13)depend on the time-series processes of the money supply, real income,and price level, even when the sign and magnitude of these coefficientsare assumed to reflect an underlying structural theory such as liquiditypreference. If the time-series processes of real income and the price levelare such that an unanticipated rise in these variables is not followed bymore than a compensating decline in these variables, then a liquiditypreference view implies that the coefficients of unanticipated incomegrowth and inflation should be negative in the long bond equation (12)—that is, B!, < 0, 6’, < 0—and positive in the short-rate equation (13)—thatis, B, > 0, BL > 0. In this case, an unanticipated increase in incomegrowth should lead to higher interest rates, currently and in the future.The negative effect of an unanticipated increase in inflation on bond82 Empirical Studies\nreturns follows from the resulting reduction in real money balances,which also leads to rising interest rates. The unanticipated inflation effectshould be further strengthened if, as in the Cagan (1956) adaptive ex-pectations model, expected inflation rises when actual inflation is aboveits expected value. In this case, an unanticipated rise in inflation pro-motes a rise in nominal interest rates either through a Fisher (1930)relation or because expected inflation is a separate argument in themoney demand function, as in Friedman (1956).\nNote also that the more persistent the time-series process of inflationand income growth—that is, the more an unanticipated increase in thesevariables leads to further increases—the more powerful the unantici-pated income and inflation effects on interest rates indicated by thetheoretical structure discussed above. Clearly, the importance of the“income and price level” and “‘price anticipations” effects also depend onthe time-series process of money growth. Thus the B,,, coefficients alsowill not be invariant to changes in the money growth, time-series process.\nWe now turn to the actual estimation of the efficient-markets models ofequations (10)-(13), with the warning that some caution must be exer-cised when interpreting results from estimates of these equations becausethe direction of causation cannot be established in this framework.\n5.3. Empirical Results\n5.3.1 The Data\nPostwar quarterly data is used in the empirical work below. The longbond models are estimated over the sample period 1954-1976. However,six-month Treasury Bills were not issued before 1959, and since thesix-month bill rate is needed to calculate the forward rate in the short ratemodels, these models are estimated over the 1959-1976 period. The datasources and definitions of variables used in these estimations are asfollows:\ny; = quarterly return from holding a long-term government bondfrom the beginning to the end of the quarter,\nr, = the ninety-day Treasury Bill rate, the last trading day of thequarter in fractions at an annual rate in the short rate equa-tions, but r,_ , is at a quarterly rate in the long bond equations,\nR= 4] 1 — (360 — 180 rsix,_ 1)\na (360 = 907-1)where\nrsix, = the six-month (180 days) bill rate at the end of quarter—infractions at an annual rate,83 Monetary Policy and Interest Rates\nM1G,= growth rate of M1 (quarterly rate) = the first differencedseries of the log of the average level of M1 in the last month ofthe quarter,\nM2G = growth rate of M2 (quarterly rate) = the first differencedseries of the log of the average level of M2 in the last month ofthe quarter,\nIPG, = growth rate of industrial production (quarterly rate) = thefirst differenced series of the log of industrial production in thelast month of the quarter,\nat, = the CPI inflation rate (quarterly rate) = the first differencedseries of the log of CPI in the last month of the quarter.\nUnless otherwise noted, all these variables have been constructed fromseasonally adjusted data except for ,, ,_ ,f, and y,, which do not requireseasonal adjustments. The bond return series was obtained from theCenter for Research in Security Prices (CRSP) at the University ofChicago and is described in Fisher and Lorie (1977) and Mishkin (1978).The Treasury Bill data was supplied by the Federal Reserve Board. TheIPG, and mr, variables were constructed from data in the Department ofCommerce’s Business Statistics and Survey of Current Business. The M1and M2 data were obtained from the Board of Governors of the FederalReserve, Banking and Monetary Statistics, and the Federal Reserve Bulle-tin. All other variables used to specify the forecasting equations wereobtained from the NBER data bank.\nAs shown in Chapter 4, using averaged data in efficient-markets orrational expectations models can give misleading results. The data forbond returns and interest rates here are thus derived from security pricesat particular points in time. For the same reason, the derivation of theother variables here uses data as close to being end of quarter as possible.Industrial Production is thus made a proxy for real income in estimatingthe models rather than the more broadly based national income accountsmeasure. Similarly, the CPI has been used to calculate the inflationvariable rather than the GNP deflator. Endpoint data (or close to end-point) help unearth significant relationships between bond returns andunanticipated variables. Some experiments with quarterly averaged dataled to worse fits for efficient-markets models, fewer significant coef-ficients, and no appreciable differences as to the statistical significance ofthe B,, coefficients.\n5.3.2 The Estimation Procedure\nTo estimate the short and long rate models of equations (10)-(13),measures of anticipated money growth, industrial production growth andinflation are needed. Here, these anticipations are assumed to be rationalforecasts obtained from linear forecasting equations. The model esti-mates are produced by estimating each short or long rate equation jointly84 Empirical Studies\nwith the forecasting equations, and imposing the cross-equation restric-tions implied by rationality of expectations. See Chapter 2 for details ofthis procedure.\nIn Chapter 2 we saw that economic theory may not be a useful tool fordeciding on the specification of the forecasting equations. Thus atheore-tical statistical procedures are used here. Ifindeed economic theory is notparticularly useful in evaluating the forecasting equations, it is all themore important to check for the robustness of results to changes in thespecification of these equations. Therefore, two procedures for specify-ing the forecasting equations are used in the text, and results with severaladditional specifications are discussed in Appendix 5.2.\nThe simplest forecasting equations are univariate time-series models ofthe autoregressive type. Fourth-order autoregressions are usually suc-cessful in reducing residuals in quarterly data to white noise and are thusused here. Ordinary least-squares estimates for the M1G, M2G, IPG,and 7 equations for both sample periods used in estimation can be foundin Appendix 5.1. There is a fair amount of persistence in the time-seriesmodels for money growth and inflation, indicating that ‘income and pricelevel” and “price anticipation” effects of the sort that Friedman (1968,1969) discusses are potentially important. Although less persistence isevident in the time-series process of industrial production growth, it hasthe characteristic that a positive innovation does lead to a permanentlyhigher level of industrial production (although not in the rate of growth).Thus, as discussed in the preceding section, the unanticipated inflationand IPG coefficients may be expected to be negative in the long-ratebond equations and positive in the short-rate equations.\nThe univariate time-series models suffer from the problem of unstablecoefficients. Chow (1960) tests reported in Appendix 5.1, where thesample period has been split into equal lengths, reject in five out of eightequations the hypothesis that the coefficients of the univariate models areequal in the two subperiods. Multivariate forecasting equations thus havebeen specified by the procedure outlined in Chapter 2 which makes use ofGranger’s (1969) concept of predictive content. Each of the four vari-ables—M1G, M2G, IPG, and 7—was regressed on its own four laggedvalues as well as on four lagged values of each of the other three variablesand four lagged values of each of the following variables: the unemploy-ment rate; the ninety-day Treasury Bill rate; the balance of payments oncurrent account; the growth rate of real federal government expenditure,the high employment budget surplus; and the growth rate of federalgovernment, interest bearing debt, in the hands of the public. (Theseother variables were selected because a reading of the literature onFederal Reserve reaction functions—see Fair 1978 and the referencestherein—indicated that they might help explain money growth.) The fourlagged values of each variable were retained in the equation only if theywere jointly significant at the 5 percent level or higher.85 Monetary Policy and Interest Rates\nThe resulting multivariate time-series models for both sample periodscan be found in Appendix 5.1 along with F statistics of the joint signifi-cance test for whether the four lagged values of each variable should beincluded in the regression model. Not only do these models have a betterfit than the corresponding univariate models, but Chow tests reported inAppendix 5.1 now reject stability of the coefficients in only one out ofeight cases.\nBefore we turn to the empirical results, the measure of short-rateuncertainty, o,, used here requires some discussion. Fama (1976) calcu-lates o, as the average of the absolute value of the changes in the spot rateduring the year before ¢ and during the year following t. Because the risk(liquidity) premium must be set conditional on available information—inthis case that known at t— 1—allowing g, to be calculated from informa-tion not available at t— 1 could be problematic. An alternative, thoughsimilar, measure of a, is used in this study. The difference between theforward rate and the spot rate, that is, r,— ,_ ,F, was regressed on mea-sures of g,, calculated as the average absolute change of the bill rate over anumber of previous quarters, where the number of quarters was varied.The best fit was obtained with g, calculated from eight previous quartersof changes in the bill rate. The results are as follows:\n(14) n-,-1F= — .0001 — 1.0961 o,+ €,(.0017)  (.2937)\nR?= 1659 standard error = .0068Durbin-Watson = 1.90\nwhere8Ini hili=l8\nAs in Fama (19765), increased uncertainty in short-rate movements doeslead to an increased risk premium, and this effect is statistically significantat the 1 percent level. In addition, the a, measure used here outperformsthe Fama measure that is constructed from information unavailable att—1. The above a, measure is used in the empirical tests that follow. Itsspecification is not a critical issue to the outcomes however: if we use aFama measure of a, or exclude o, from the model altogether, the resultsdo not alter appreciably.\nG.=\n5.3.3 The Results\nThere is no strong theoretical reason to estimate the long bond orshort-rate model with one monetary aggregate versus another. Unantici-pated growth rates of both M1 and M2 are therefore used and results withadditional monetary aggregates are explored in Appendix 5.2. The re-sulting estimates of the models appear in tables 5.1 and 5.2. Panel A of86 Empirical Studies\n \nTable 5.1 Nonlinear Estimates of the Long Bond ModelUsing Seasonally Adjusted DataCoefficients ofConstantModel M1G-MI1G* M2G — M2G° IPG-IPG 1-7 TermPanel A: Using Univariate Forecasting Models11 0482 — .0014(.5961) (.0032)1.2 -0501 — .4242** — 1,8482* — .0029(.5517) (.1260) (.8028) (.0032)1.3 9174 — 0013(.5459) (.0032)1.4 7174 — .4077** — 1.7691* — .0027(.5063) (.1243) (.7880) (.0031)Panel B: Using Multivariate Forecasting Models1.5 — .2621 — 0014(.7429) (.0032)1.6 4108 — .5039** — 1.7529 — .0020(.7164) (.1568) (.9552) (.0032)1.7 -9199 — .0014(.6738) (.0032)1.8 1.0950 — .4987** — 1.8206 — .0020(.6283) (.1492) (.9353) (.0032)\nNote: Asymptotic standard errors of coefficients in parentheses.* = Significant at the 5 percent level.** = Significant at the 1 percent level.\nthese tables contains estimates which make use of the univariate forecast-ing equations, while panel B’s estimates use the multivariate forecastingmodels of the form found in Appendix 5.1. The estimates of thecoefficients are not presented here because they are not particularlyinteresting.\nAn issue basic to these results is whether the efficient-markets (rationalexpectations) model used here is valid. Previous evidence on the effi-ciency of the bond market indicates that efficient-markets models of thetype used here are a reasonable characterization of bond market behav-ior. Table 5.3 contains likelihood ratio tests, described in Chapter 2, ofthe nonlinear constraints implied by both market efficiency (rationalexpectations) and the model of market equilibrium. The test statistics donot reject the constraints for any of the long bond models in table 5.1: themarginal significance level of the statistics are never lower than .0S.These results then also provide additional evidence for the effi-cient-markets model of long bond behavior.87 Monetary Policy and Interest Rates\nTable 5.2 Nonlinear Estimates of the Short Rate ModelUsing Seasonally Adjusted Data\n \nCoefficients of\n \nConstantModel M1IG—M1G* M2G—M2G* IPG-IPG* a-7° Term a\n \nPanel A: Using Univariate Forecasting Models\n \n \n21 2788\" .0006  —1.2266**(.1088) (.0015) (2714)\n2.2 2774\"* 0352 211** 0002. —1.1514**(.1075) (.0275) (1989) (0014) (2618)\n2.3 1616 0006 —1.2563**(1085) (.0015) — (.2851)\n2.4 .1904 .0399 6545** 0002, - 1.1571**(.1053) (.0278)  (.2058)  (.0015) (2686)\n \nPanel B: Using Multivariate Forecasting Models\n \n2.5 1677 0006 —1.2761**(.1283) (.0015)  (.2863)\n2.6 2512 —.0455 5199 0004. —1.2109**(.1381) (.0493) (3272) (0016) ~—(.3015)\n27 2562 0001 —1.1807**(.1341) (.0016) — (.2917)\n2.8 .3039* —.0770 .6501* ~.0004 —1.0779**(1409) (.0471) (3314) (0016) ~—(.3069)\n \nNote: See table 5.1.\nThe table 5.3 results for the short-rate models, however, reject thenonlinear constraints at the 5 percent level in six out of eight cases. Howshould we interpret these rejections? They can result from either thefailure of rationality (market efficiency) or of the model of marketequilibrium. Both models of market equilibrium used in the long bondand short-rate models are crude: neither risk premium is derived fromutility maximizing behavior. A theoretically more justifiable risk pre-mium would, for example, exploit the covariance of bill or bond returnswith returns on alternative assets. Yet, as the regression results in equa-tion (14) indicate, the model of market equilibrium is a significant ele-ment in explaining the movements of the dependent variable in theshort-rate equation. In this situation, unlike that for the long-rate equa-tion where the model of market equilibrium appears to be unimportant inexplaining the dependent variable, its misspecification can lead to rejec-tions of the nonlinear constraints. Thus, rejections of the nonlinearconstraints occurring in the short-rate models, but not in the long bondmodels, can be attributed plausibly to misspecification in the model ofmarket equilibrium.88 Empirical Studies\nTable 5.3 Likelihood Ratio Tests of Nonlinear ConstraintsModel Likelihood Ratio Statistic Marginal Significance Level11 x°(4) = 6.45 -16801.2 x7(12) = 14.00 -30071.3 x°(4) = 3.20 524914 x2(12) = 12.43 A1181.5 x?(12) = 18.10 -11271.6 x°(24) = 33.81 .08811.7 x°(8) = 10.67 22111.8 x?(24) = 32.60 -11282A x°(4) = 12.76* 01252.2 x?(12) = 13.65 -32352.3 x7(4) = 12.46* .01432.4 x?(12) = 17.18 -14302.5 x7(8) = 21.65** -00562.6 x?(28) = 50.02** 00672.7 x°(8) = 25.69** -00122.8 x?(28) = 50.92** -0051\n \nNote: Marginal significance level is the probability of getting that value of the likelihoodratio statistic or higher under the null hypothesis.\n*Significant at the 5 percent level.**Significant at the 1 percent level.\nA suitable transformation of the unconstrained system outlined inChapter 2 yields additional evidence on the potential misspecification ofthe model of market equilibrium. The unconstrained system where the yare not equal in the forecasting and short-rate equations can be rewrittenas\n(15) X= Z,1y + Uy,% =1-1f— ag— oa, — Z,_10 + (X,— Z,_1y)B'+ &,\nwhere the y’s are constrained to be equal in the two equations. There-fore, the nonlinear constraints tested in this paper are equivalent toa = 0in the above system. It is now easy to see the following point: if the riskpremium is related to the variables in Z, yet they have been excludedfrom the model of the risk premium, then this may explain the rejectionsof the nonlinear constraints. To make this conjecture plausible, weshould expect that a model of the risk premium which is related to Zwould have reasonable characteristics. The Fama-type model, for exam-ple, does generate plausible values. The resulting risk premiums (atannual rates) have a mean of 57 basis points (1/100 of a percentage point)and a standard deviation of 30 basis points. They also move smoothly:their autocorrelations for lags of one through four are respectively .96,.91, .85, and .78. In the model which leads to the strongest rejection of89 Monetary Policy and Interest Rates\n \nthe nonlinear constraints, model 2.7, we could attribute this rejection tothe fact that a more appropriate specification of the risk premium is d? =a, + ao, + Z,_,a, where Z,_, contains the four lagged values of moneygrowth (M2G) and Treasury Bill rates (r). This latter specification leadsto values for the risk premium that are somewhat more variable and lesssmooth than the equation (14) specification, but not appreciably so. Therisk premium from this expanded specification has a mean of 57 basispoints, a standard deviation of 46 basis points, and four lagged autocor-relations of .75, .56, .49, and .29.\nViewing the rejections with the benefit of the system (15) also has theadvantage of providing us with potentially interesting information on therisk premium. The results indicate that the premium could be related tomoney growth and interest rates as well as the variability measure o.However, they give no indication that the liquidity premium is in additionrelated to the other variables in table 5.A.2 of Appendix 5.1. The resultshere thus point out a direction for future research on the risk premium.Following Nelson (1972), I also conducted more direct experiments onthe relation of the risk premium to lagged interest rates and unemploy-ment with negative results. Experiments with lagged values of r— F alsodid not add explanatory power to the model of the risk premium.\nIf a misspecified model of the risk premium is the source of therejections of the nonlinear constraints, the efficient markets-rationalexpectations model used here is fortunately still a valid framework foranalyzing the relationship of money growth and short rates. With rationalexpectations, the unanticipated X, — X7 variable will be uncorrelatedwith any past information, among which can be included the determi-nants of the risk premium which is set at t—1. Therefore, if somedeterminants of this risk premium have been excluded from the marketequilibrium model, they will be orthogonal to X, — X7. The exclusion ofthese variables, and the resulting rejection of the nonlinear constraints,will not lead to inconsistent estimates of the B coefficients. Since it is notnecessary to derive a better model of the risk premium to achieve reliableestimates of the fs, this tricky research issue, which is beyond the scopeof this study, is left to future research.\nThe unanticipated M1G coefficients in table 5.1 do not lend support tothe view that an unanticipated increase in money growth is correlatedwith a fall in long bond rates. In panel A, although both of thesecoefficients have a positive sign, they are not significantly different fromzero at the 5 percent level: asymptotic ¢ statistics are less than .1. Inaddition these coefficients are quite small. The 8 coefficients here denotethe percentage point change in the bond return from a 1 percent error inanticipations, and in our 1954-1976 sample period, a one percentagepoint rise in the quarterly bond return corresponds approximately to a 1090 Empirical Studies\n \nbasis point (1/100 of a percentage point) fall in the long bond rate. Thus,the M1G coefficients in panel A indicate that a 1 percent surprise increasein M1 is associated with only a .5 basis point decline in the long bond rate.\nThe panel B estimates of the M1G coefficients indicate that the conclu-sion on the relationship of long rates and money growth is not altered byusing multivariate versus univariate forecasting models in estimation.Again, neither of the unanticipated M1G coefficients are significantlydifferent from zero at 5 percent, and they continue to be small, with thelargest of the coefficients indicating that a 1 percent surprise increase inM1 leads to only a 4.1 basis point decline in the long bond rate. Fur-thermore, one of the unanticipated M1G coefficients is now negative.\nThe coefficients on unanticipated M2 growth in table 5.1 are morepositive than the unanticipated M1G coefficients, they nevertheless donot lend strong support to the view that unanticipated money growthshould be negatively correlated with the change in long rates. They do notdiffer significantly from zero at the 5 percent level (although in 1.3 theunanticipated M2G coefficient is significantly different from zero at the10 percent level). Also note that the M2 results in panel A and in panel Bare so similar that it is again clear that the results on unanticipated moneygrowth are not particularly sensitive to specifications of the moneygrowth forecasting model.\nHow different are these findings from those that might be inferred from“Keynesian,” structural macroeconometric models? Using a simulationtechnique discussed in Mishkin (1979) we can examine the response of amacromodel to a 1 percent surprise increase in M1. Equation 1.1 wasused to trace out the effect on M1 growth from a 1 percent innovation.The resulting M1 numbers were then used in a simulation experimentwith the MPS (MIT-Penn-SSRC 1977) Quarterly Econometric Model inorder to derive the response of this model to the 1 percent M1 innovationoccurring in the 1967:1 quarter. The MPS model indicates that this 1percent M1 innovation would lead to an immediate decline of 18.1 basispoints in the long rate. Not only is this long-rate decline several timeslarger than the maximum 4.1 basis point decline implied by the empiricalevidence in table 5.1, but also it is significantly larger at the 5 percent levelfor three of the four estimates in table 5.1 (and is almost significantlylarger for the remaining estimate). Clearly, the coefficients on unantici-pated M1 growth are quite low relative to what might be expected from astructural macroeconometric model.\nThe unanticipated inflation and industrial production coefficients intable 5.1 conform to our priors. In both the M1 and M2 efficient-marketmodels, these coefficients are negative and are either significant or nearlysignificant at the 5 percent level. The results on the coefficients of unan-ticipated industrial production growth are especially strong, with both thepanel A and panel B estimates significantly different from zero at the 191 Monetary Policy and Interest Rates\n \npercent level. Although the unanticipated inflation coefficients are verysimilar in both panels, their asymptotic standard errors rise somewhatfrom panel A to panel B. They are thus not quite significant at the 5percent level in panel B, while they are significant at this level in panel A.The similarity between the money growth as well as other coefficientestimates in panel A and panel B is encouraging, for it gives us confidencethat these results are robust to changes in the models describing expecta-tions. Further model estimates described in Appendix 5.2 with additionalspecifications for the forecasting equations yield similar results. This is animportant finding. Poor specification of expectations formation appearsto be a major concern in this line of research because it leads to errors-in-variables bias in the coefficient estimates. The important question is,How severe would this bias be? Denoting the measured X, — Xf by anmsuperscript and the true X, — X; with a T superscript, we can write\n(16) (X, — Xf\" = (X,— Xi) + v,,\nwhere y, is the measurement error. If such variables as money growth,industrial production growth, and inflation are hard to forecast—whichseems likely—then the variance of the true X, — X; forecast error will besubstantial. If the incremental predictive power of other informationbesides the past history of the forecasted variable is not large, then thevariance of the measurement error in expectations used here will be smallin relation to the variance of the true forecast error: that is, Var [(X, —X?)\"|>>Var(y,). If this occurs, the errors-in-variables bias would benegligible and should not be an important problem in this research.\nThe similarity of the model estimates despite substantial changes in thespecifications for the forecasting equations is found not only in thischapter, but also in the chapters preceding and following. This providesstrong support for the view that unanticipated increases in money growthare associated with interest rate declines. Moreover, the smaller standarderrors found for the coefficients estimated using univariate rather thanmultivariate forecasting equations provides some support for the positiontaken by Feige and Pearce (1976), that forecasts from univariate time-series models may be “economically rational” expectations. '\nThe results for the short-rate model in Table 5.2 are even more damag-ing to the view that associates a decline in interest rates with an unantici-pated money growth increase.’ All the coefficients on both unanticipatedM1 and M2 growth are positive in table 5.5, and in three cases thecoefficients are statistically significant. They indicate that a 1 percent\n1. Note that Sims (1977) has raised some questions about the statistical techniques usedby Feige and Pearce (1976), and this does cast some doubt on their evidence.\n2. Urich and Wachtel (1981) obtain similar results using weekly data. Thus, reduction ofthe unit of observation in the analysis is likely to leave the findings here intact.92 Empirical Studies\nTable 5.4 Nonlinear Estimates of the Long Bond ModelUsing Seasonally Unadjusted Data\nCoefficients of\n \nConstantModel M1G-—M1G*° M2G— M2G*° IPG-IPG° x — 1° TermPanel A: Using Univariate Forecasting Models\n4.1 — .7339* — .0017(.3631) (.0031)\n4.2 — 5879 — .2028* —2.5145** — .0026(.3631) (.0857) (.6912) (.0032)\n4.3 0001 — .0014(.3610) (.0032)\n4.4 +1426 — .2420** —2.4438** — .0024(.3330) (.0838) (7111) (.0032)\nPanel B: Using Multivariate Forecasting Models\n4.5 —1,2781** —.0014(.4504) (.0032)\n4.6 — .8078 — .4105** —2.4472** — .0020(.4339) (.1371) (.8089) (.0032)\n47 — 1404 — 0014(.4821) (.0032)\n4.8 1534 —.4741** —2.6226** — .0020(.4391) (.1396) (.8237) (.0033)\n \nNote: See table 5.1.\nsurprise increase in M1 or M2 is associated with a 16-30 basis pointunanticipated increase in the bill rate. The simulation experiment withthe MPS model that is described above indicates that a 1 percent M1surprise leads to an immediate decline of 88 basis points in the bill rate.This finding contrasts strongly with the finding here that even the leastpositive M1 coefficient is more than eight of its standard errors away fromthis figure.\nThe results on the unanticipated inflation coefficients are similar tothose in the long bond model. These coefficients are positive, as might beexpected, and are significantly different from zero in three out of fourcases. The results on the unanticipated industrial production growthcoefficients are not quite as strong as in the earlier table. They are neverstatistically significant, and in panel B they even have the wrong sign.\nThe efficient markets-rational expectations model does not specifywhether the X — X° variables should be described by seasonally adjustedor seasonally unadjusted data. This empirical issue cannot be settledeasily on theoretical grounds because it is not clear whether marketparticipants concentrate on seasonally adjusted versus unadjusted in-93 Monetary Policy and Interest Rates\nTable 5.5 Nonlinear Estimates of the Short Rate ModelUsing Seasonally Unadjusted Data\nCoefficients of\n \nConstantModel M1G-—M1G° M2G—M2G° IPG—IPG® m-7° Term a\n \nPanel A: Using Univariate Forecasting Models\n5.1 -3029** .0003. —1.1255**\n(.0652) (.0014) —(.2530)\n5.2 .2458** 0274 4687** 0001. —1.1267**(.0671) (0171) (1716) (.0014) (2464)\n53 .1926* .0003  —1.1468**(.0644) (.0015)  (.2765)\n5.4 .1967** .0440* 5459** 0001. — 1.1260**(.0624) (.0176) (1746)  (.0014) (2526)\nPanel B: Using Multivariate Forecasting Models\n5.5 -3431** 0007 —1.2403**\n(.0831) (.0015) —(.2639)\n5.6 .2484** .0386 5079 0004. —1.2037**(.0956) (.0376) (.2623)  (.0016) —(.2861)\n5.7 .3285** -.0007  —.9891**(.0918) (.0015) — (.2841)\n5.8 2011\" .0400 5788* -.0003 —1.0791**(.0986) (.0374) (.2674)-(.0016) (3021)\nNote: See table 5.1.\nformation. For this reason, the table 5.1 and table 5.2 models have alsobeen estimated with seasonally unadjusted data for the X’s. The resultingestimates and test statistics appear in tables 5.4, 5.5, and 5.6 and wereobtained by the same procedures as the previous estimates with season-ally adjusted data.\nA comparison of tables 5.45.6 with tables 5.1-5.3 indicates that thechoice of adjusted or unadjusted data is not a critical factor in thisresearch. The likelihood ratio tests of the nonlinear constraints yieldsimilar conclusions. In addition the coefficient estimates are similar,although their standard errors tend to be smaller in the seasonally unad-justed results. In the short-rate models, all the industrial productiongrowth coefficients now have the “correct’’ positive sign.\nThe seasonally unadjusted data are even less favorable to the view thatincreased money growth is associated with a decline in interest rates.Now all the M1 coefficients in the long bond model are negative, implyinga positive correlation of movements in money growth and long interestrates, and two of these coefficients are significantly different from zero atthe 5 percent level. In addition, the M2 coefficients in the long-rate model94 Empirical Studies\nTable 5.6 Likelihood Ratio Tests of Nonlinear ConstraintsModel Likelihood Ratio Statistic Marginal Significance Level41 x°(4) = 5.08 -27924.2 x7(12) = 20.83 05294.3 x7(4) = 3.27 5137\n4.4 x2(12) = 19.53 .07654.5 x7(12) = 12.10 43774.6 x7(24) = 28.48 240347 x°(8) = 7.23 -51204.8 x?(24) = 27.11 -29945A x2(4) = 9.14 .05785.2 x?(12) = 14.81 25215.3 x7(4) = 12.02* .01725.4 x2(12) = 15.01 .24075.5 x°(8) = 19.30* 01335.6 x?(28) = 49.71** .00705.7 x7(8) = 24.90** .00165.8 x?(28) = 49.96** -0065\nNote: See table 5.3.\nare less positive. For the short-rate models, all the money growth coef-ficients in table 5.4 are positive and are now statistically significant at the 5percent level, with six out of eight significant at the 1 percent level. Theseasonally unadjusted data, then, lend support to the contrary view thatunanticipated movements in money growth and interest rates are posi-tively correlated.\n5.4 Concluding Remarks\nA wide range of empirical tests of the relationship between moneygrowth and interest rates have been conducted in this chapter and inAppendix 5.2. A guiding principle of this research has been to use manydifferent empirical tests of the model in order to provide information onthe robustness of the results. In pursuit of this goal, model estimationshave been varied along the following dimensions: (1) the choice of themonetary aggregate, (2) the choice of the relevant variables to include inthe X vector, (3) the use of seasonally adjusted versus seasonally unad-justed data, (4) the specification of the forecasting models used to de-scribe expectations formation, and (5) the sample period. The largenumber of estimates provide information on the sensitivity and reliabilityof the results reported here.\nThe results point to the following conclusions. There is no empiricalsupport for the view that an unanticipated increase in the money stock isassociated with a decline in interest rates. However, there are two aspects95 Monetary Policy and Interest Rates\nof the research methodology used here which raise questions about thegeneral validity of this conclusion.\nAs we have seen, the 8 coefficients in the efficient markets—rationalexpectations models are not invariant to changes in the time-series pro-cesses of the money growth, income growth, and inflation variables. Thusthe conclusions from the estimates in this chapter provide information onthe relationship between money growth and interest rates only for thepostwar sample period. However, realize that many structural macro-econometric models displaying a negative relationship between moneygrowth and interest rates have been estimated using sample periodswhich overlap those used here. The results reported in this chapter arecertainly of interest in evaluating these models.\nA further difficulty with the present research methodology is thatmisspecification of the forecasting equations describing expectationsformation can invalidate the results on the relationship between moneygrowth and interest rates. Specifically, misspecification of expectationsformation can lead to inconsistent and biased coefficients. However,the robustness of results to different specifications of the time-seriesmodels describing expectations provides evidence that the misspecifica-tion problem is probably not very severe.\nHow should we interpret the conclusion reached above? If we arewilling to accept exogeneity of the money supply process in the postwarperiod and the efficient-markets models as true reduced forms, theinterpretation is clear-cut. The evidence here would then cast doubt onthe commonly held view that an unanticipated increase in the moneystock will lead to a decline in interest rates. Not only does this suggest thatthe Federal Reserve cannot lower interest rates by increasing the rate ofmoney growth, but it also requires some modification of the monetarytransmission mechanism embodied in structural macroeconometric mod-els. It is plausible that an unanticipated increase in money growth will notinduce a decline in interest rates because it leads to an immediate upwardrevision in expected inflation. Thus, there is still a potential effect on realinterest rates from unanticipated money growth, and the evidence in noway denies that there are potent effects of money supply increases onaggregate demand.\nAs was mentioned in Section 5.2, if unanticipated money growth is notexogeneous, then the 8,, coefficient estimates are inconsistent and canlead to misleading inference. Particularly disturbing in this regard is thecase where the Federal Reserve smooths interest rates so that an unantic-ipated increase is interest rates causes the Federal Reserve to react by anunanticipated increase in money growth. The resulting correlation ofMG,-— MG with the e, error terms (negative with / and positive with €3)tends to bias the results toward a positive association of money growthand interest rates. Thus, we cannot rule out the view in structural mac-96 Empirical Studies\nroeconometric models that an exogenous increase in money growth leadsto a decline in interest rates, despite the empirical results of this chapter.\nNote, however, the nature of money growth endogeneity required forthis reservation to hold. If money growth is endogenous in the sense thatthe Federal Reserve modifies money growth within a quarter only inresponse to past public information available at the start of the quarter,MG,— MG will not be correlated with e/ or e°. Hence the existence ofGranger (1969) “causality” running from interest rates to money growthdoes not imply that the estimates of 8,, will be inconsistent. “Causality”tests of the Sims (1972) variety, therefore, cannot shed light on theconsistency of the 8, estimates. If we are not to reject the common viewthat increases in money growth lead to interest rate declines, research of afairly subtle sort is needed to demonstrate that unanticipated moneygrowth is negatively correlated with ¢/ and positively correlated with e?.Hence, this issue cannot be resolved without further research. \n \n(o¢zt') (b60I\")SzsT* ~ 8SL0°- (b—)Oo@ww(80rT\") (98z1\")6191\" ELT’ (¢-)o@ww(12\") (08z1’)Z1b0\" — tpso\" — (7-)O7w(0zz1\") (osot\")€119\" 8659\" (I-)o7ww(9¢z1') (9201\")1L€0°— TPO\" — (b-)OIW(s2z1\") (ISTI')90€0\" osso° (€-)OIW(6821\") (ZST1\")9917\" oz\" (<—)OIW(vezr’) (8201)sie’ LLLE’ (I-)OIW(000°) (9900°) (s€00\") (€8Z0\") (bz00\") (100°) (6100\") (€100\")100\" Z100° 7600\" £600\" 9L00° 6r00\" €500° 8£00° uai9} JURISUOS,QLOI-6S61 9LOI-VS6T 9LOT-6S6T 9LET-FS6T  9LOI-6SOT ~9LOT-FS6I —9LET-6S6I — 9L61-FS6I ‘polled ajdureg2 2 OdI Dd! OtW Ot OIW DIN ro]qeueA juapuadeqSIV LIV o1V SIV viv elv ZIV TIv {POWS]PPOY] SALag-au], ayelsealuy) TV's 21981suonenby Sunsese10,4 94} Jo sayeusy = :[°¢ xipueddy“snjdins yuowAojdwia ysiy = gUNS ‘1Gep youlus9A08 Jo yMOIdJo ayer Aayenb = LqAdy ‘sonppuodxe yuoWUJoA08 [esOpaj [BOI JO YIMOIB Jo ajeI APJoWeNb = H ‘yuNosde yUaINd uO syuowAed Jo souRTeq = dOg“aye [iq Aep-Ajoutu = 4 ‘ayer uowAopduraun = Ay) ‘Idd JO Y3MOId Jo aye AJoyeNb = u ‘uoNNpold jeLysnput Jo yIMoId Jo ayer APoyeNb = Og] ‘7WJoyyMols Jo oye1 APIoqenb = OZ ‘TW JO yIMo4d Jo ayeI ApJoyenb = OT :satqeisea Jo suontuyag ‘sosoyuoed Ur syUatoYJood oY} JO JOA plepueyg -ajoN\n \n \n \n10% €0°7 861 007 6'T 96'T 96'T 161 A-d8€00\" 6£00° 6€20° LEZ\" 0200\" 9900\" 9900\" 7900\" asSsse” SOEL’ 96rT\" SPIZ ool €9Sp\" €207° zS67\" za(ZIT) (€€01’)e191 — Lest — (p-)e(sczt\") (6111)6L10°— €901° (e—)u(921°) (2111)z919° ozss (Z—)u(021°) (bpor’)166€\" 800° (T-)e(Terr) (coor)sz0z\" — gIsz’— ( b—)OdI(s¢zr\") (160T\")opel LOST’ (€-)OdI(oszt\") (T60T\")00Iz — 9PEz — (@-)OdI(811') (€00r\")vise’ pStb\" (1-)OdIQLOI-6S61 9LOI-VS6T = 9LOI-6S6T ~— 9LOT-VS6T = 9LOT-6S6T © 9LOI-HS6T —9LOT-6S6T — 9L6T-4S6T :pouiog ojdureg2 2 Dd OdI Ot OCW OIN OW so]qeueA juapuedaqSIV Liv o1V SIV viv e1Vv Tv TIW {POW\n \n(ponunuos) T-W\"s age L \n(Z8t¢\") (ostt\") (9¢01') (erst) (Sp9T’)6P07\" — 8€80°— 9080\" — 0vz0\" 96€T\" (b—)OTw(czIr\") (szer\") (L911) (LL02\") (zsL1’)LY@L’ 6LIT’ LIST” ely OIse” (€-)OTw(oo¢r’) (9¢pr') (99z1\") (seer) (psit')09r6\" $s60° $860° 195° ZLOE — (7-)O7w(pI8e') (zz) (6tIt’) (9991°) (8191°)Zell 11zs\" osos’ 8665\" 06se” (-)o7w(220°) (eer\") (6€L1') (16L1')009T° blz’ zs00° LSLI (b—-)OIW(z590°) (o0zt\") (0661\") (S8Z1°)€990° — L020'T ste — Sole’ — (€-)OIW(6b90\") (680¢\") (9061\") (ogor')9LE0\" €889° 9ees\" €€zs\" (Z-)OIW(s¢90\") (se6¢\") (281°) (ss9r\")sest +069\" TeOT\" — 9060° (1-)OIW(1z00') (6100\") (110°) (sz10\") (200°) (9100\") (100°) (z100°)€£00° €S00° L100° 8b10\" — yr00\" 9700\" S100\" 7000\" — uiI9} 1UeISUODQLOI-6S61 9L6I-PS6T —-9LGT-6S6T © 9LEI-VS6T © 9LOT-6S6T— OLET-PS6T— 9LOI-6S6T 96 1-¥S6T :porieg afduregu a OdI OdI DTW OT OIN OIN roiqeue, juopusdegs7Vv Lew oev tA rev eww Tw lw {POW\n \nS]apoyW Salsag-auNLy, aeLEANIN, TV'S AGEL \n(€100°) (s600°) (160°)000° — 000° — 1000\" ~ (b—)NQ(200°) (St00\") (p10)e00° 8100\" €L10\" (€-)NA(1Z00\") (9100°) (oz10\")9100°— 7100\" 8100\" — (t-)Nn(100°) (6000°) (9600°)700° — 9€00° — 060° — (I-)na(9L11\") (ott) (16s\") (c¢s9\")8ZEZ — 9€90° — (Aran POL — (p—)u(6e€r\") (0601\") (98°) (c€s9\")T16€\" €€87° 86° PLL8°— (c—)e(Iz11\") (€sor’) (T0L’) (679°)SOLL’ Less\" €SLI- — 98TS*— (7)(€zz1') (6L01') (€62') (tos9°)6021 Spee LitzZ- BESS — (I-)(otor\") (pez)6981\" — L087’ — (b-)DdI(6801°) (6021\")LS¢0° — 7060\" — (€-)OdI(6801°) (izL1')979¢° — IL19°— (t-)DdI(6211) (291°)8LL7' — P60\" — (1-)OdIQLOI-6S61 9L6I-FS6T  9L6T-6S61 — 9LEI-PSIL — 9LOI-6S6T — 9LOI-VS6I — 9LOI-6S6I — 9L6T-PS6T :poueg o[dureg2 a OdI Ddl OTN DUN DIN DIN :o[qeueA juspuedeqs7Vv L7w 97 sw v7 ew Tew V7 {POW\n \n(panunuos) Z\"y's aqeL, \n“T'S a1gei 20g :210N\n \n \nZZ 96'1 00°2 €0'7 S6'T 96'T 10'2 6 M-d6200\" s€00\" 0910\" 0020\" 1900° 9500\" 6500° €500\" as6818\" 6r6L\" OIL: 6STS\" LPS” zez9\" zor\" Les’ a\n(9000\") (Z€00\")100° — 600° — (p-)do@\n(800°) (9r00\")$000\" — 9100\" (€-)dog\n(800°) (Zb00°)€000° 0s00° (t-)do@\n(900°) (s€00\")\n1000\" 8500\" (I-)do@(Leb) (221°) (zeIt) (iz)O€8'I — €€£0\" 610° LL20' - (p-)4(€6Lr\") (6991\") (Zirl) (96€1\")Loge’ Isso\" ZEE0\" oszt\" (e-)4(618r\") (1e91') (€zer\") (soe1\")eszs\" Leb’ €S8p\" 9802\" (Z-)4(tost’) (zz) (o001\") (901°)€186° plz — 996\" — Lp9z ~ (I-)4“JoAg] Woosed | oy) We JUROYTIUsIC, ,*JOAg] JUodI0d ¢ 9y} 18 JUROYTUIS,\n“L€-O'€ aue JOAg] yUadIEd QT oy) 1B pue 9°7-C°Z 1B [OAQ] JUDdI0d ¢ ay) IEF JO SaNJeA [OND BYL “€8 0} Lp Wos suNI xX oOyM “(x “p)y se ATTRONOdUIAsePoInqissip oe sonsHeIs 7 YL °019Z sjenba safqeisea asa} JO Yeo Jo SBE] ANOJ dy) UO s]UDIOyJa09 dy} Jey) sisayiodAy ][][NU ay) 3891 soNsHeIs 7 SUL -a70Ny\n \n \n \n10°7 Ls on” Ss\" stl 60° 79\" is\" duns€€1 Ls\" v8\" 98\" tb 06\" er\" 69° Lagaao6ST sez or\" 68\" wz or Ly rS' 5LBZ wet abS'E €8'I 0L 0° 6L\" Ir dog6\" 69\" 2209'S Sor =£6°S +616 oz 2S8°7 44288'S e199 wz +00°€ se 1s am LL Nnwef 8D weZE6L we S0'S eI OL or orl Ig\" 0% 2ssl 80° «s0L'P ws ILE sot OL\" 91 86\" DdIel al «260° so\" «Cb O exLE'ST #287'S 286° DUNrly 99° 60\" wnfS9 LVz ze% rez OVE DIWstv Lt tw stv rev et www Uw aiqene Apow\n \naiqulieA Yyoey Jo sde] nog Jo suonenby duysesa10g uy 1aM0g A1OyeURTAXY JURIWIUSIC 10J SONSHEIS €'v's 71981103 Monetary Policy and Interest Rates\n \nTable 5.A.4 Chow Tests for the Models of Tables 5.A.1 and 5.A.2\nMarginalSignificance\nModel F Statistic Level\nAl.1 F(5,82) = 3.50** 0064\nAl.2 F(5,62) = 2.73* 0271\nA113 F(5,82) = 2.49 .0377\nAL4 F(5,62) = 1.24 3014\nALS F(5,82) = 2.81* .0216\nAl.6 F(5,62) = 3.80** 0046\nAL7 F(5,82) = 1.59 1721\nA1.8 F(5,62) = 1.83 -1200\nA2.1 F(13,66) = 1.81 .0597\nA2.2 F(9,54) = 2.94** -0065\nA2.3 F(9,74) = 1.60 -1310\nA2.4 F(9,54) = 1.80 -0895\nA2.5 F(17,58) = 1.39 1753\nA2.6 F(21,30) = 1.76 .0765\nA2.8 F(17,38) = 1.24 -2824\nNote: Tests that the coefficients are equal in the two halves of the sample period.“Significant at the 5 percent level.**Significant at the 1 percent level.\nAppendix 5.2: Additional Experiments Using the Two-Step Procedure\nBecause the two-step procedure used by Barro (1977) yields consistentparameter estimates and is far easier to execute than the joint nonlinearprocedure used in the text, it is used in tables S.A.5 and 5.A.6 to provideadditional estimates of the long bond and short-rate models.\nThe two-step procedure here does not correct for heteroscedasticitywithin each long bond and short-rate equation even though Goldfeld-Quandt (1965) tests frequently reveal that it exists. This simplifies estima-tion and does not affect the consistency of the parameter estimates.However, this two-step procedure may yield incorrect standard errorsand test statistics. Thus although tables 5.A.5 and 5.A.6 provide usefulinformation, some caution about statistical inference is warranted.\nThe first four models of panels A and B in both tables reestimate themodels in the text by the two-step procedure. As we might expect, theparameter estimates are similar to those génerated by the nonlinearprocedures of the text and yield similar conclusions. This gives us someconfidence that the two-step procedure can be used to gain furtherinformation on the robustness of this chapter’s empirical results. Usingthe two-step procedure, long bond and short-rate models were alsoestimated with alternative specifications of the forecasting equations. \n(€£00\") (9628') (9€rT') (6L8¢\")\n000° ~ olr'z— 906\" — 96Ib\"\n(b€00\") (ze66\")\n000° — €0L€\n(¢00') (882°) (Lert) (6061\")\n000° ~ L8r'7~ zS6E\"~ lez\n(r¢00\") (9¢61\")\n000° ~ SSor’\n(€¢00\") (€68\") (8tPT’) (s6ts\")\n000° ~ soz 60rb' ~ Lor\"\n(b€00\") (sges\")\n000° ~ zose’ —\n(€€00\") (ssbs\") (sger) (z00s\")\n8000\" ~ 186°1 ~ sozp’ — 798°\n(v€00\") (oes)\n000° — eT\n(€¢00\") (ogss’) (Zt¢t’) (o9rs\")000° ~ 9El'Z~ Lebp— cog’(v€00\") (€szs\")000° — Lose:\n \nS]PPOW BuNsedeJ0,4 aeULAIU Wo s[enpIsoy BUISE Vy JouRg\n \nwal wea’ JOdI~’OdI_ ss Ogn~'D€N— UN-’DUN— EW-'DEW FOTW DTW IW DINquejsuoD\n \nJo syuaIoyyo0p\nOVsv\n6sv\nssv\n“sv\nosv\nysVv\nsv\nws\nsv\nlepow\n \n(9L61-PS61 Ported atdureg)\nainpasoig dajg-om yy, ay} pue eyeq paysnf{py Ajjeuoseag Buls_ :Japoy puog Buoy ay} Jo sayeunsy S'V'S F1ge] \n(€€00°) (810°1)8000°— Hew(p¢00\")\n000° ~\n(€€00°) (910'1)8000\" ~ Sol'z—(r¢00°)\n000° —\n(€€00°) (800° 1)8000\" - LLO'Z—(pe00\")\n8000°—\n(€¢00\") (t6\")000° — €L61~(re00°)\n000° -\n(€€00\") (r66\")8000\" — L661 ~(r€00\")\n8000\" —\n(8181) (zs9S°)\n612s\" — 76£9\"(szgs\")coe\"\n(ssst\")\n€905° —\n(psst\")6Ees\" —\n(S6L1')Less —\n(e98T\")9795\" —\n(p91z\")gsst(v02z\")18st\n(6z29\")80€I°(959°)610E\"\n(809°)L6U'T(29°)Sort\n“T'W's a]qei 20g -a10K\n0z'sv6l'svsswLIsvor'swst'svvl'swel'sv\n(8569°)\nz9z9\" zsw\n(riz)8817\" Il'sv\n \ns[opoW SuNsess104 aeuRANN, wos spenpisey SuIsc) :q [aueg \n \n \n \n \n(82z\") (900°) (1602) (Tr€0\") (611)€00T- 8000°'— oles” £020\" £60\" orev(s6z\") (9100°) (4st)L601~ —— 2000°~ SLO\" 69V(08z\") (9100) (Zolz’) (Z€0') (prr0')soot- 8000°- ss Lzss\" 9r90\" IIT\" gov(96°) (z100°) (ost0\")€601-  2000°~ $600\" Lov(liz) (9100°) 9602\") (z€0\") (zsz1')€00'T~ 8000°\"~ P60\" 1090\" eer” ov(062°) (100°) (i871)8L0T- £000\" ~ 16zZ\" sow(912°) (9100) (1802\") (z€0\") (err)6L0T~ 2000\" €%9° S190\" zeoT\" rov(862°) (8100°) (L6I1’)€Z'T— 0000\" 9920\" cov(992') (9t00°) (8961) (st¢0') (tett)ZO 1000\" reso” 8eso\" 0€6z\" zOv(282) (100\") (€zzr')vortT— 2000\" LLLe rowSapo, SuNsedeJ0,4 aeuRAU WoO sjenpIsoy BuIscQ) :y Jour© wep, jh = jOd1-’0dl_ an-'9an Jun-’0NN =DAaW-'DEW DUN-'DTNDIW-'DIW_PPOWjueysuoZJo syuatoyya0_D(9461-6561 poVred ajdures)aINpIoig daig-om], oq} pue eyeg paisnipy Ayjeuoseas, suis), 1PPOP] eyY-OYS ay) jo sayeulysy oV'S FGRL“T'W'S alqes 2ag :aloyy\n \n \n \n \n(€67°) (Z100\"°) — (€ppz\") (sero) (szer’)\nIZrI- 0000\"— LED\" 1910\" 1060\"\n(967°) (100°) (set)\n9r0'T ~ €6rT\"\n(062') (€bpz’) (sev0') (6rS0\")\n8st I— 7699\" TEI0\"\n(962\")\n160°T~\n(682°) (z100°) —-(86€z\") (zzr0\") (69S1\")\n971'T- £000\" sho\" 1110\" ror\n(r6z\") (100°) (191°)\n9s0'1T-  €000\"~ S07\"\n(862°) (st00°) — (zzze\") (6190\") (6zpr\")\nTOl'T— 1000\"- —s8L€\" Oreo\" Plt’\n(s6z’) (100°) (L6€1\")\n%60'I ~ 1000\" +680\"\n(962\") (st00°) (zp te\") (6090°) (set)\n6el I~ 1000\" 0s9¢° €7€0\" 0902\"\n(€67') (st00\") (err)\noer T— 1000\" 661°S[PPoYW SuNseso10,4 aLUIAN|NA, Wo sjenpisoy Suis) :q JOUR\n0c 9V\n61'9V\n819V.\nLV9OW\noT OW\nST OV\nProv\nel 9V\nLOW\nIT ow108 Empirical Studies\nModels were estimated with residuals from the eighth-order autoregres-sive forecasting equations, as well as from multivariate models whichincluded the four lagged values of a variable even if it was significant onlyat the 10 percent level (rather than the 5 percent level as in the text). Theresults were quite close to those reported here and the results againappear robust to changes in the specification of the forecasting equation.\nBecause the Federal Reserve might have changed its reaction functionin the 1970s by paying more attention to monetary aggregates than it didpreviously, it is possible that the results here might substantially change ifthe 1970s are excluded from the sample period. Two-step estimates of thelong bond and short-rate models over the sample period ending in the1969:4 quarter fail to support this conjecture. The unanticipated IPG andx coefficients remain similar to those in tables 5.A.5 and 5.A.6: for thelong bond model, the IPG coefficients range from —.36 to —.46 and the 7coefficients from —1.69 to —2.17; and for the short-rate model, the IPGcoefficients range from —.04 to .03 and the 7 coefficients from .37 to .57.Similar conclusions about the relationship of money growth and interestrates result also from estimates using the shorter sample periods. For thelong bond model, the unanticipated M1G coefficients are now negative,ranging from —.26 to —.54 and the M2G coefficients range from .24 to.79. For the short-rate model, the money growth coefficients remainpositive, with the M1G coefficients ranging from .11 to .20 and the M2Gcoefficients from .03 to .12.\nThe most obvious choice for the monetary aggregate that is exoge-nously determined by the Federal Reserve are not M1 and M2. Asbecomes clear from such debates as those between Anderson and Jordan(1969) and De Leeuw and Kalchenbrenner (1969), other aggregates maybe a more sensible control variable for the Fed. If these aggregates aremore likely than M1 or M2 to be exogenous, their use in the models hereshould give a clearer picture of the effect of monetary policy on interestrates. For this reason, tables 5.A.5 and 5.A.6 also contain two-stepestimates of the models using the following additional variables:\nMBG = growth rate of the monetary base (quarterly rate),URG = growth rate of unborrowed reserves (quarterly rate),UBG = growth rate of the unborrowed base (quarterly rate).\nThese variables are constructed analogously to M1G and M2G from thesame data source, and the specifications for the forecasting equationswere obtained with the same procedures used for M1G and M2G.\nIn some applications the monetary base has been chosen as the Fed’scontrol variable (e.g., see Anderson and Jordan 1968), while in monetarysectors of the large structural macroeconometric models such as the MPS(see Modigliani 1974) unborrowed reserves are often the exogenouscontrol variable. On the other hand, the unborrowed base is the mone-109 Monetary Policy and Interest Rates\ntary aggregate corresponding most closely with open market operations.All three of the monetary aggregates are thus worthy candidates to beincluded in the long bond and short-rate models.\nThe results from using alternative monetary aggregates do not alter theconclusions or the relationship of monetary policy and interest rates. Inthe long bond models, the coefficients for the alternative aggregates aresomewhat less positive than those for M1 or M2. They provide even lesssupport for the view that an increase in monetary aggregates is associatedwith a fall in long interest rates. The coefficients in the short-rate modelsare almost always positive, and this is consistent with the results for M1and M2, that a surprise increase in the monetary aggregate is associatedwith a rise in short rates. \n6 Does Anticipated AggregateDemand Policy Matter?\n6.1 Introduction\nRecent theorizing has focused on business cycle models that incorpo-rate features of the natural rate model of Friedman (1968) and Phelps(1967) with the assumption that expectations are rational in the sense ofMuth (1961). An important neutrality result from this research (Lucas1973; Sargent and Wallace 1975) is that anticipated changes in aggregatedemand policy will have been taken into account already in the behaviorof economic agents and will evoke no further output or employmentresponse. Therefore, deterministic, feedback policy rules will have noeffect on output fluctuations in the economy. This policy ineffectivenessproposition of what Modigliani (1977) has dubbed the Macro RationalExpectations (MRE) hypothesis runs counter to much previous mac-roeconomic theorizing (and to views prevailing in policymaking circles).This proposition is of such importance that it demands a wide range ofempirical research for verification or refutation.\nThis chapter applies the econometric methodology developed in Chap-ter 2 to the important question whether anticipated aggregate demandpolicy matters to the business cycle. It begins with a brief review of themethodology in Section 6.2, then follows with the empirical results inSection 6.3, and ends with a section of concluding remarks.\n6.2 A Review of the Methodology\nThe tests here are based on the MRE model of the formN(1) WaT 2% BCX i 7-1) + &,\n110111 Does Anticipated Aggregate Demand Policy Matter?\n \nwhere\ny, = unemployment or real output at time ¢,y, = natural level of unemployment or real output at time ¢,X, = aggregate demand policy variable, such as money growth, infla-tion, or nominal GNP growth,X? = anticipated X conditional on information at time t—1,B; = coefficients,€, = error term.\nA forecasting equation that can be used to generate these anticipationsof X, is(2) X= Z, yt,where\nZ,—, = a vector of variables used to forecast X, available at time t— 1,=a vector of coefficients,u, = an error term which is assumed to be uncorrelated with anyinformation available at t— 1 (which includes Z,_; or u,_; forall i = 1, and hence u, is serially uncorrelated).\nA rational forecast for X, then involves simply taking expectations ofequation (2) conditional on information available at t—1:\n(3) XP= ZY.\nSubstituting into equation (1), we have\nN(4) NV+ % BX 1 Zi) +\nThe MRE hypothesis embodies two sets of constraints. The neutralityproposition implies that deviations of output and unemployment fromtheir natural levels are not correlated with the anticipated movements inaggregate demand policy. That is, 8; = 0 for all iin\nN N\n(5) WAH & Bi(X 7 Xi) + EX i+ €\nRationality of expectations implies that (5) can be rewritten asN N\n(6) Wat % BCX i Z,-iY\") + 28 Z i\" +e,\nwhere y=\".\nThe joint nonlinear estimation procedure outlined in Chapter 2 is usedhere to estimate both the constrained (2) and (4) system and the uncon-strained (2) and (6) system where y = y* is not imposed. It corrects forserial correlation with a fourth-order autoregressive (AR) specificationfor the e, error term, and this is successful in reducing the residuals to112 Empirical Studies\n \nwhite noise.' The conventional identifying assumption found in previousresearch on this topic is made that the output or unemployment equationis a true reduced form. The joint MRE hypothesis of rationality andneutrality is then tested with a likelihood ratio statistic constructed from acomparison of the two estimated systems. It is distributed asymptoticallyas x?(q) under the null hypothesis where q is the number of constraints.\nIf the joint hypothesis of rationality and neutrality is rejected, we canobtain information on how much the rationality versus the neutralityconstraints contributes to this rejection. The neutrality constraints aretested under the maintained hypothesis of rational expectations by con-structing a likelihood ratio statistic as above where the constrained systemis (2) and (4), and the unconstrained system is (2) and (6) subject tothe rationality constraints, y = y*. A separate test for the rationalityconstraints proceeds similarly: the constrained system is (2) and (6)imposing y = y*, and the unconstrained system is (2) and (6) where y =y* is not imposed.\nIn the results to follow, rejections of the MRE hypothesis occur whenthe number of lags (NV) in the unemployment or output equation is large.However, although many degrees of freedom are used up in these estima-tions, there is no allowance for the loss of degrees of freedom in thelikelihood ratio statistics. The danger thus arises that spurious rejectionsof the null hypothesis may occur because the small sample distributions ofthe test statistics differ substantially from the asymptotic distributions.\nThe nature of the problem here becomes more obvious if we look at thefollowing analogous example. In an OLS regression, a test of restrictionscan be carried out with a finite sample test, the F, or with an asymptotictest, the likelihood ratio. Asymptotically, the test statistics have the samedistribution, but misleading inference with the likelihood ratio statisticscan easily result in small samples. The F statistic is calculated as\nSSR°— SSR“\\ df7 F(q,df) = |( 22 | 47) (aan) = (SS )2]while the likelihood ratio statistic is(8) n[log (SSRISSR‘“)],\n1. In the output and unemployment equations estimates here, the Durbin-Watsonstatistics range from 1.82 to 2.26, and none indicates the presence of first-order serialcorrelation. Furthermore, the Ljung and Box (1978) adjusted Q statistics for the first twelveautocorrelations of the residuals cannot reject the null hypothesis that these autocorrela-tions are zero. The Q(12) statistics range from 5.84 to 15.0 for all the models except those inAppendix 6.1, while the critical Q(12) at 5 percent is 15.5. For the models in Appendix 6.1,the Q(12) statistics range from 8.26 to 15.90, while the critical Q(12) at 5 percent is 18.2.113 Does Anticipated Aggregate Demand Policy Matter?\nwhere\ndf = the degrees of freedom of the unconstrained model,n= the number of observations,q = the number of constraints.\nFor over 100 degrees of freedom qF(q,df) is nearly distributed as x*(q),and for small percentage differences, (SSR°— SSR“)/SSR“ is approx-imately equal to log (SSR7SSR“). Inference with the F statistic in the caseof over 100 degrees of freedom involves approximately the comparison ofdf[log(SSR7SSR\"“)] with the x2(q) distribution. Inference with the likeli-hood ratio statistic on the other hand involves the comparison ofn{log(SSR‘/SSR“)] with the x?(q) distribution. Even in the case where dfis large, if n/df is substantially greater than one, the likelihood ratioStatistic will reject the null hypothesis far more often than will the F. In thecase of the freely estimated unemployment or output model in Appendix6.3 and N = 20, the degrees of freedom of the unconstrained model forthe joint or rationality tests is 111, while the number of observations is184. The n/df of 1.7 in this case demonstrates that there is a potentiallyserious small sample bias in the likelihood ratio test when this manydegrees of freedom are used up.\nTo make certain that rejections are valid, the output and unemploy-ment models are estimated both with and without the smoothness restric-tion that the anticipated and unanticipated money growth coefficients (8;and B,) lie along a fourth-order polynomial with an endpoint constraint.This particular polynomial distributed lag (PDL) specification waschosen because it is rarely rejected by the data and it has the advantage ofusing up few degrees of freedom.’\nThe anticipated aggregate demand_X variable is constructed so that itwill be serially uncorrelated, so that a smoothness restriction is notrequired to make coefficients on unanticipated aggregate demand intel-ligible. However, anticipated aggregate demand variables are highly\n2. The PDL constraints are not rejected in models where money growth or inflation arethe aggregate demand X variable. E.g., in model 2.1, x7(4) = 3.34, while the critical valueat 5 percent is 9.49; in model 4.1, x7(17) = 12.94, while the critical value at 5 percent is27.59; and in model A9.1, x7(14) = 20.54, while the critical value at 5 percent is 23.7. ThePDL constraints receive somewhat less support in the models using nominal GNP as the Xvariable. They are not rejected for the A5.1 output model at the 5 percent level, but arenearly so: x*(17) = 26.95, while the critical x7(17) at 5 percent is 27.6. However, they arerejected at the 1 percent level in the unemployment model: x?(17) = 34.91, while the criticalx°(17) at 1 percent is 33.4. I experimented with an eighth-order PDL to see if this would fitthe data substantially better, but it did not. Although this rejection of the PDL constraints isbothersome, the fact that the unrestricted models in Appendix 6.3 yield results so similar tothose in tables 6.A.5 and 6.A.6 indicates that, imposing or not imposing, the PDL con-straints yields the same conclusions.114 Empirical Studies\n \nserially correlated, and the use of PDLs has the advantage of providingmore intelligible and more easily interpretable estimates of the anti-cipated aggregate demand coefficients, 5;. The main results reported inthis chapter thus are based on a PDL restriction. Comparing the mainresults with those in Appendix 6.3 obtained without a PDL restrictiondemonstrates that estimating with or without the restriction yields similar8 coefficients and similar statistical inference on the validity of the MREhypothesis. Therefore, we can be confident that any rejections of theMRE hypothesis are not due to small sample bias.\nThe specifications of the forecasting equations needed to estimate theMRE model are derived with the multivariate Granger (1969) procedureoutlined in Chapter 2. The policy variable, X,, is regressed on its own fourlagged values (to insure white noise residuals) as well as on four laggedvalues of the following set of macrovariables: the quarterly M1 and M2growth rate, the inflation rate, nominal GNP growth, the unemploymentrate, the Treasury Bill rate, the growth rate of real government expendi-ture, the high employment surplus, the growth rate of the federal debt,and the balance of payments on current account. The four lagged valuesof each variable are retained in the equation only if they are jointlysignificant at the 5 percent level. This results in a specification of themoney growth forecasting equation, for example, which is quite differentfrom that used by Barro (1977, 1978) and Barro and Rush (1980): inaddition to past money growth, past Treasury Bill rates and high employ-ment budget surpluses appear as explanatory variables. Weintraub(1980) also finds significant explanatory power of short-term interestrates in the money growth equation, and the magnitude of his coefficientsis similar to that found here. The specifications for the forecasting equa-tions can be found in Appendix 6.4 as well as the F statistics for significantexplanatory power of the four lagged values of each variable in thesespecifications.’\nEarlier research on the MRE hypothesis (e.g., Barro 1977, 1978, 1979;Barro and Rush 1980; Grossman 1979; Leiderman 1980) uses a fairlyshort lag length—two years or less—on the anticipated and unanticipatedX variables. This chapter looks at longer lag lengths for two reasons.Experimenting with plausible, less restrictive models that have longer laglengths is appropriate for analyzing the robustness of results because thisstrategy has the disadvantage only of a potential decrease in the power of\n3. Chow (1960) tests that split the sample into equal halves indicate that both the moneygrowth and nominal GNP growth equations have the desirable property that the stability ofthe coefficients cannot be rejected. However, stability of the coefficients is rejected for theinflation equation. For the M1 growth equation, F(13,66) = 1.37, while the critical F at 5percent is 1.88; for the nominal GNP equation, F(9,74) = .60, while the critical F at 5percent is 2.0; and for the inflation equation, F(13,55) = 3.40, while the critical F at 5percent is 1.9.115 Does Anticipated Aggregate Demand Policy Matter?\n \ntests, but not of incorrect test statistics. In addition, estimates in thischapter and in Gordon (1979) find that unanticipated and anticipatedaggregate demand variables lagged as far back as twenty quarters aresignificantly correlated with output and unemployment.\n6.3 The Empirical Results\nThe tests of the MRE hypothesis in the text use seasonally adjusted,postwar quarterly data over the 1954—1976 period. The sample starts with1954 the earliest possible starting date if models with long lags are to beestimated.‘ An advantage of excluding the early postwar years from thesample is that the potential change in policy regime occurring with theFed-Treasury Accord in 1951 is avoided. In pursuit of information onrobustness, both output and unemployment models are estimated, withM1 growth, nominal GNP growth, and inflation as the aggregate demandvariable. The natural level of unemployment or output, jj, is estimated asa time trend here, as in Barro (1978). A more complicated Barro (1977)specification has been avoided because, as Small (1979) and Barro (1979)indicate, its validity is doubtful.\n6.3.1 The Data\nThe definitions and the sources of data used in this chapter are asfollows:\nM\\G = average growth rate (quarterly rate) of M1, calculated as thechange in the log of quarterly M1, from the NBER databank.\nM2G = average growth rate (quarterly rate) of M2, calculated as thechange in the log of quarterly M2, from the NBER databank.\nRTB = average treasury bill rate at an annual rate (in fractions),from the MPS data bank.\nw = inflation (quarterly rate), calculated as the changes in the logof the GNP deflator, from the MPS data bank.\nGNP = real GNP ($billions 1972), from the MPS data bank.\nUN = average quarterly unemployment rate, from the MPS databank.\nNGNP = growth rate (quarterly) of nominal GNP, calculated as the\nchange in the log of nominal GNP, from the MPS data bank.\nThe other variables used in the search procedure for the forecastingequations were obtained from the NBER data bank.\n4. Quarterly data on such variables as SURP do not become available until 1947. Withtwenty lags on anticipated or unanticipated X,, the additional four lags in the forecastingequation and another four lags due to the fourth-order AR correction, the first twenty-eightobservations are used up. This leaves us with a 1954:1 start date.116 Empirical Studies\n6.3.2 Results with Money Growth as theAggregate Demand Variable\nThe text will focus its attention on results obtained when money growthis the aggregate demand variable in the MRE model. However, resultswith inflation and nominal GNP growth as the aggregate demand variableare presented in Appendix 6.2 and they are consistent with the moneygrowth results. The money growth results deserve more attention for tworeasons. Research with money growth as the aggregate demand variable(e.g., Barro 1977, 1978, 1979; Barro and Rush 1980; Leiderman 1980;Germany and Srivastava 1979; Small 1979) is more common in theliterature and produces results most favorable to the MRE hypothesis.The methodology employed in this research has been criticized, however,and another look at the question of whether anticipated monetary policymatters to the business cycle is called for. Furthermore, the identifyingassumption used to estimate the MRE model, that it is a true reducedform, is on firmer ground when money growth is the aggregate demandvariable. Although the exogeneity of money growth in output or unem-ployment equations is still controversial, economists are more willing toaccept the exogeneity of money growth than the exogeneity of nominalGNP growth or inflation.\nTable 6.1 summarizes the major findings by presenting the likelihoodratio tests of the MRE hypothesis with M1 growth as the aggregatedemand variable. It tells the following story: When the lag length onunanticipated and anticipated money growth is only seven, the lag lengthused by Barro and Rush (1980), the likelihood ratio tests are not unfavor-able to the MRE hypothesis. The joint hypothesis of neutrality andrationality is not rejected at the 5 percent level in either the output orunemployment models, 2.1 and 2.2. Separate tests of the rationality andthe neutrality hypotheses reject only in one case—neutrality in the em-ployment model 2.2—and even here the rejection is barely at the 5percent level. However, when the lag length is allowed to be longer—upto twenty lags in the other models of the table—strong rejections of theMRE hypothesis occur. The output model displays especially strongrejections of the joint hypothesis—the probability of finding that value ofthe likelihood ratio statistic or higher under the null hypothesis is as lowas 1 in 10,000. Here, both sets of constraints contribute to this rejection,with the neutrality and rationality hypothesis rejected at the 1 percentlevel. The long lag, unemployment models are also unfavorable to thejoint MRE hypothesis, with the rejection at the 1 percent level. How-ever, here the neutrality constraints are rejected far more strongly thanthe rationality constraints.\nExcluding relevant variables from a model results in incorrect teststatistics, and including irrelevant variables will at worst only reduce thepower of tests and make rejections even more telling. The table 6.1\"JOAg] JUsoJed | OY) 1B JURDUIUaIS,,*Jaag] JUsoI0d ¢ ay) 1B JUBDYTUSIC,“sisoyjodcy [[nu sy) JapuN sJaYSIY JO oNsHEIS ONeI pooYyTTay!] ByI JO onjea yey) BUNIE Jo ArIqeqosd oyi = Joao] aoULoyrUsIs eUITIE| a0\n \n \n6960\" 1200\" SEL\" 9€50\" [oag] souroyrudis jeurdey\n+68°61 = (I1).X wel 67= (LL) X Te €T = (11)-X pr ol =(1D)X onsHeys OBE POOYYOATAyeuoney\n890° 6£00° $970\" €66r\" JoA9] SouRoYIUsIS eUIsIE]\n*80°71= (p)_X 2aSP'SL= (p)2X L9°6 = (p)X 9e'€ = (p)X onsheis oes pooyloxr]sAqerN ayy\n¥L00\" 1000\" $880\" 6060\" [oaa] sourogiudis eurdieyl\nexbS1E=(ST)2X wn€8'Eb = (S1)X 08°77 =(S1)-X 69°77 =(ST)-X onsneis Ones pooylayxryssisoynodAy qutog29D W —'DIW 30 88k] 07 ZDIW —’OIW JO SBRLOZ = SDIW —’OIW JO SBT L = ZOIW —’DIW Jo SBeT L suonduosog‘NN CaN9)801 NN CAND)307 roqqeueA yuopuodeqwy Uy Tz Vv {POW\n \naQeLeA pueuIag ayedaid3y ayp se YMOID TV WA sIsamppodAH TY ay Jo sysaL oNeY poouray'] 19 a1g81,118 Empirical Studies\nresults therefore raise questions about previous empirical evidence fromshorter lag models that supports the MRE hypothesis, neutrality inparticular. Indeed, it appears that the shorter lag models are morefavorable to the MRE hypothesis only because misspecification yieldsincorrect test statistics.\nA look at the estimates of unemployment and output equations fromthese models leads to a deeper understanding of the test results. Table 6.2contains the output, and unemployment equations with short lags, jointlyestimated from the (2) and (4) system which impose the cross-equationrationality constraints. The resulting y estimates for the models of table6.2 and the following tables are in Appendix 6.4.\nThe table 6.2 models fit the data well, and the unanticipated moneygrowth variables have significant explanatory power: many of their coef-ficients’ asymptotic ¢ statistics are greater than four in absolute value. Thetest results in table 1 become clearer when we study the estimated outputand unemployment equations where current and lagged anticipatedmoney growth are added as explanatory variables. The table 6.3 resultsillustrate why the neutrality proposition is not rejected for the outputequation. The coefficients on anticipated money growth have no obviouspattern, are never significantly different from zero, and, in seven out ofeight cases, are smaller in absolute value than their asymptotic standarderrors. However, in the unemployment equation some coefficients onanticipated money growth are significantly different from zero at the 5percent level, and this is enough to reject neutrality. Here, the last twolag coefficients on anticipated money growth are the most significant,with asymptotic f statistics exceeding 2.5. This creates the suspicion thateven longer lag lengths for unanticipated and anticipated money growthmay lead to strong rejections of the MRE hypothesis.\nTable 6.4 contains estimates of the output and unemployment equa-tions in which longer lags (twenty) of unanticipated money growth areused as explanatory variables. Tables 6.5 and 6.6 demonstrate why strongrejections of the MRE hypothesis now occur. Many of the coefficients onanticipated money growth are now significantly different from zero at the1 percent level, with some asymptotic ¢ statistics even exceeding four inabsolute value. Of course these coefficients may be statistically significantand still unimportant from an economic viewpoint; but this is clearly notthe case. The unanticipated coefficients not only tend to be greater inabsolute value than their unanticipated counterparts, but generally theyhave higher asymptotic ¢ statistics as well. In fact, only one out oftwenty-one § coefficients is statistically significant, as opposed to nearlyhalf of the 8 coefficients. Contrary to what is implied by the MREhypothesis, anticipated monetary policy does not appear to be less impor-tant than unanticipated monetary policy. In fact, the opposite seems to bethe case.“JOAg] Word | yi 1B JUROYIUTIS,,\n*JOAg] JsoJed ¢ oy} Je JUROYIUsIS,\n‘ayes juowAojdwioun\nApoyenb a8eiaae = ‘NA ‘AND [P21 Jo 30] = 'gND) 80] “ymous Ty paredionueun = ,OLW — OLW *P:9L6L UOT” L'pS6l Ul 6z = pusn own = WILL‘p'g pure Z'9 saqqei ul [9T/QISS)Z A. sjenbe 1 ‘3-9 *wopaeyy Jo saai8ap ay) e Aq popiap (SS) sfenprsas porenbs jo wins ay} Jo 100 aenbs oy) = (ayeUINSOpaseiqun 943) UoNRNba oy} Jo JOA prepuels = |g “sasayjuared ul ase sio419 prepuels snoIduIAsy ‘pouressuos utodpus ay} YyIIM [eIWOUATOd Japso-yUNoJB BuOTe at] O} poutersuod aie 'g oY *(p) pue (Z) UL JeNba st A yey) syUIesUOD UONENbe-ssoso oy} Sutsodunt ‘waists (p) pue (Z) Oy) Woy payeWIsY -a10N\n \n \n \nSIZT=M-A 6POE' = AS LOGO = 2 TWTZ=AM-A S300. =AS 8866\" = -¥(SIL )prl =\"F — xe(107)E9L' ~ = 9 (sti zoo = \"4 (ZL Tobe\" = “9(207 )LL0° =*9 —xa(ZIL PORT = 8 (691 zor = \"6 ee(LID OOD T = \"9 |(po'6 Joror— =“d x(ssz pes, = 4dex(ET PILE OP = = °9 ee(ILE JIT TL = °d«(OE 81)07 PL — = *d ax(6rp SES =Sd(02 02)85°68— = \"9 xe(S8P)ELTZ =\"x(€9°61)08°L8- = “8 «(Lop ZIP? = Sd«(POLI P00L— = © xe(PLp 967 =xx(8ESI)IZ Eb— ='d «(OPE )LIOT = 'dx«(69°8 )10°07— =\" xe(OE7 SIL = 99(810 p70 =+ — a(PS TSS =9 (s000°)800°=+ —x(ZP0')8L1°9 =?*Nn CaND)80] sage iuapuedoqTz Vz ‘POW\n \nos?\nU+P ard +£~9td +o 38d +1o'91d + (OL -'DIA)'S X + AWE +9 =€£\n(ddd) s8e] waaag ‘ymory Kau paredionueuy :saqeiae, A10yeueldxysuonenby yuawAojdursuy pue yndyng jo sayeunsy svaulpuON, 79 a1qeL \n077T=M-A 0L6¢° = AS tS = 2\n107 = M-d\n*JPAg] JUDOJed | OY} ye JUROYTUTIC, ,\n‘Jea9] JusoIed ¢ ay} 1B JUROYIUTIC,“poutersuooqutodpua ay) yy yermoudjod Jops0-yyNoJ v SuoTe at] 0} pauresysuod are 'g pue 'J oy *,4 = A Sutsodurt ‘waysfs (g) pur (Z) 9) Wo poyeusy :aoN\nSP800°= AS 6866 = <u\n \n(ozt)ost’-— =\"9 —x(661')OPL’— = *(soz )1eo'- = 6 a (TET )OSp'T = 'd\n(8Z1\")160° = \"4(€61')szo° = 4\n«(QL Ose — = %dxe(6IL)IZTT = 1d\n \n \nwe(EC ED PS SE- = 48 Isplecte- =“d (egp')s6r =“ (ces )96° = “d«(07 ST)86'8E— = °8 ae(ZpSTOL'EL- = °9 (tps )7se = 98 «(18° )260'7 = °d(ol61)zs'sz— = 58 «+(09°ZE)8T SOL — = % (909°)z00\"- = $¢ xx(9b0' 1)ZE6'7 = $dCol'pazrz— =\"9 ««(LO'PE)6S ELL — =\" (0zz')L6€'- =\" «(L60 1)0PZ'€ = *d(sssz)Lp'L— = *@ xu(PE'0E)7S96— = *d (9LL')179\" — = *@ xu(€66\" )ES6'7 =(ep'ez)7L'ZL = 8 «(O6'rZEET9- = (esz' gos\" — =%@ «(P18 )161'7 = °d(cgot)ze'9 == \"8 (eselorsz ='9d (699')LIZ — = 'g «(665° Jesvt='d(€p'S1)Z8'OL— = °8 (0L'8 )oerI- =°9 (p9s\")zor = 8 ax(€p7 J099° = 9d(szo)ro =+ (bz 1oo'e =? (8000')800°=+ — ««(090°)P61°9 = 9\"NN CAND)80} ajqeueA juapuedesgve Ve PPoW,UEP Pad + MEd 4 EI9ed 4 TIBI + Cowes + (low - on) 's Fa + WILE +9 =\"4(Add) s8eJ uaaag ‘yyMoI1n Asuoy payedionuy pue pajyedinueuy :sajqeise A As0}eueldxysuonenby yuautdojduiauy pue yndyng Jo sayeunsy JeaurjuoN £9 qe*JeAg] JuVOIOd | OY) IB JUROYLUsISC, ,\n*[aAa] WUaosad ¢ ay) 18 JURDYIUsIS,“paurexysuoo yulodpua ay} yyta yerwousod sJaps0-yyNoyB Suole at] 0} pourerysuoo are ‘g ayy “(p) pue (Z) ur penba st A yey) syuETsUOD UONENba-sso1o oy) SuIsodurt ‘uia}sAs (p) pur (Z) dy) Wo payeUnsy :aony\n \n \n \n \n€'7=M-G 680 = AS £6P6 = 2H 00° = A-(cer )p7r =\"F — xa(ZOT)OZL'- = *d (O11 )II0'- =(voz )e90\" =F —wa(ELT OFT = 'd (zE)oer =\n(spodecz— = 09\n(zl sx = 9) (st-9z)9s‘rl- = °d (sst')s00\" | = %d\n(oorciier =°'8 (Is‘sz)iz'sz~ = *d (Loe\")190° - = *'d\n(crspsr'6 =*'d (69'pdEczr— = ‘d (z8¢)oot' - =*'d\n(se-L)L8'P1 = 4'9 +(€8'EDLY'SS— = °d (prise — ='d\n(6z'61)zr'61 = \"9 x+(L6-@Z)SS'99- = Sd (sor Joe - =°\"9\n(LE IZ)0€'7z = 19 x«(261Z)S8'EL- = 9d (ors ply — = Sd\n(sg'7z)88'e¢ = \"8 «(87 OZ)ES'SL- = (66s')86¢ - =\"\"\n(6€'72)6L 02 = *'d «(OP LDSS'69- = “9 (spoete’ — = td\n(us soes'st = “1d «(LocDPO'ES— = 'd (z99\")pst' - =2'¢\n(co. =\"'9 «(POL OE'StT— = °d (cs9)oz0, = \"9\n(I7)610 =+ — «(58° 1)r6\"E = 9 (s000°)800° = +‘NAcP\n \n7£800° = AS L866 = -¥*d (LT eee - =%dfd aa(ZIT OPEL = 'd(ole oce =(er ze = 8d(469° )r80'L = *d«(PLO J6sp'l = “Axx(Sh9°)908°L = °dxx(Z19')980°7 = SdaxlELS)SST7 = \"9«x(61S 9977 = €«(OPP )090'7 = *d+«(8ZE)8LST = 'dae(OE7)ISL = °D\n(CaND)80}rp\n2x(€S0')I8L'9 = 9\nraiqeuieA yuapuedag\nUg Pd 4 Est 4 Cost 4 TI3Id + (oT — DLW) dX + ALLE +9 =\"0c\n(ddd) s8eJ (uamy ‘yor Kau payed!\n \nuel) :safquizeA AJoyeueldxg\nsuonenby yuourfojduiauy pue yndyng jo sayeunsy seauyUuON,\n‘POW\n9 gel“Jeag] Juaosed | oy) Ye JURDyIUsIS, ,“Jaaa] Juadsed ¢ oy} ye JUROYIUSIC,\n*“poutesjsuooqutodpusa ay) Yai ferwoudjod 1apso-yyNOJ e Buoye aq] 0} poulensuod are 'g pue ‘'g yp *,4 =A Sutsodun ‘woysfs (9) pue (Z) oy} Wo] payeUnsY :aoyy\n \nST T= MO 8€800° = AS 6866 = 2<¥\n \n(LIT )901' - = \"0 (ILL )8¢z' — = %d(691:)1890, =O x (STE )ISO'T = 'd\n \n(6€€ pro = \"R (198\")P00'T = °'d(OL Jeet — = %@ (Spe ore = 8 (ez JOLT ~ = %d (ors')o86’ = °d(82Z')s8z - = 'g (pse)z7g9\" = 8g (z8¢')96r° - = (118\")606° = *d(8ze')sep'— = Fg «(OLE JEZO'T= “@ (esp )cI - = 8d (o8z')oos’ = ‘d(Ze 19g — = “Ig «(COE )ISET = °9 (19sogo = “'d (9S2\")999° = °d(8€€ oro — = °Fg (61h )6EIT = SQ (ogo )zIz@ = 9'd (oe )s7s = Sd«(6Z€')989° — = IQ ax(OPP 858 T= \"8 (OoL ety = Sd (€IL oor, = \"9x(ZZ€\")p99' — = \"IQ ax(OPP ZLOL= €8 (192')309 = \"'d (999\")ole = *d(2Ze\")8Lg° — = *'g xx(6ZP PPG T= % (ers eze =\" (oLs')soe' = °9(92€ )6zp’ — = “Ie wx(B8E EEL T= 18 (6r8'Joo8\" = 9d (sor )zor’ = 'd(eee oz — = \"'9 xx(S9EJE6TI = °Q (sog)gie = \"td wa(LET )SP9° = Od(9000°)200°=4 — «4(Z€0\")ZIZ'9 = 9CdN9D)80] :a]qeueA yuopuedegrs ‘PPOW\n \nLP 9td + 19d 490d 48d OL? + (LOIN — OWS + ANIL + 9 = CAND) 8010 07\n(ddd) s8e] Aquamy ‘yymorn Aau0p payedinuy pue payedpyueuy :saqeizeA Asoyeueldxyuonenby ind3nQ Jo sayeusy swauUON $°9 aIqeL\"JeAg] JUgoIAd | 9YI 1B JUROYIUsIC, ,“Jeaa] Juaosad ¢ ay} 1B yURDYIUsIC,“$9 819R) 995 :21I0N\n \n \n \n9TT=NM'A 867 =AS «ES =(EIL)ILE = \"9 x4(661\")069° — = “4(zoz')800- = 9 ae(Z1 OPE = 1d(96:71) Pr’ ZI- =\" (coee)zo'or = 9(28'S )er'p = %Q (I9 EEL 7Z—- = 8 (guL Leo = \"9 (oeecer'6 = °d(61'6 Joys = %@ «(LE Plol7ze- = *g (LZ7D9S 71 = 9d (eze) ieet = 88(SLODILZL = *g «(69 P1)69' Ip— = “8 (8191p st = *'d (z9'0¢)s9'p>— = ‘d(eV LD8rst = ‘te x(BTST)OV0S— = °8 ($0°61)6L'72 = “1d (86'87)68°II- = °d(16010891 = °g «(9S SDEP'9S— = °Q (96 12)¥7'97 = °'d (or z2)os'81- = “d(sso1)6e'91 = stg xx(OL'SI)L\"6S— = °8 (o0\"sz)o€'8z = *'9 (pL'sz)ss'st— = *d(ZSOLT PL = \"8 aa(LES1)99°8S— = *@ (86'L2)b8'82 = \"'d (Isez)oe Lz7- = ‘9d(ps'01)S66 == “19 «x(8E'PIOL'ZS— = %@ (65 0€)€8'Lz = *d (s6°61)60'87— = *d(Lr IDs6e€ = \"1g «x(L8°Z1)08°8€— = '@ (s¢'ze)87'sz = “'d (ve PI) Ip'st7— = 'd(t716s'€ — = \"8 (L7Z1)60'LI- = °8 (69'€€)6z' IZ = \"\"d «(9€°8 )8E°8I- = \"9(10°90 =+ — (6L' 187\" =9\"NN rajqeue A juepusdegv9 ‘PPOW,\n \n \n_ o=? =+r tard +f 98d +o-/aed +! Id +4 COTW 'e + (GOIN —' 'OIW)'S X + ALL? +9 ='NNira\n0z\n(Idd) $887] Auamy ‘yymory Aou0p payedipynuy pus payedioynueuy :sajquie, Asoyeueldxgy\nuonenby juauAojdurauy) jo sayeupsy JeauljuoN,\n9°9 A198.124 Empirical Studies\n \nInterpreting the 8 coefficients of anticipated money growth poses somedifficulties. One natural tendency is to make inferences about long-runneutrality by testing whether the sum of the 8 coefficients differs fromzero. The following implicit question is being asked: What will be theoutput or unemployment response to a permanent increase of 1 percentin the expected rate of money growth? Lucas (1976), Sargent (1971,1977), and Mishkin (1979) show that this question cannot be answeredwith reduced-form models, of which the MRE model is one example. Theparameters of the MRE model are not invariant to changes in the time-series process of money growth and thus cannot yield reliable inferencesabout what will happen when the time-series process of money growthdiffers from that in the sample period. As the money growth equations inthe appendices in this and in Chapter 5 indicate, the time-series process ofmoney growth is stationary and is quite different from a random walk.Yet a permanent increase in expected money growth is consistent onlywith a random walk time-series process. Trying to use the estimatedMRE model here to make inferences about the response to a permanentincrease in expected money growth is thus inappropriate.\nFurthermore, most structural macroeconometric models in use do notdistinguish between anticipated and unanticipated monetary policy andare incapable of interpreting the lag patterns of the 8’s versus the 8's intables 6.5 and 6.6. It is not obvious what form these lag patterns shouldtake in a model where expectations are rational, yet anticipated monetarypolicy matters. Econometric models of this type are only now beingdeveloped—Taylor (1979), for example—but to my knowledge simula-tion results displaying the reduced-form B and 6 coefficients are not yetavailable.\nOutput and unemployment models were also estimated using M2growth rather than M1 growth as the policy variable. Here the Granger(1969) criterion generates a specification of the M2 equation that includesonly past M2 growth and Treasury Bill rates as explanatory variables. Theresults are not reported here in the interests of brevity, but they indicatethat using M1 rather than M2 in the estimated models does not change theconclusions.’ However, using unanticipated M2 growth rather than M1growth does lead to some deterioration in the fit of the equations as wellas lower asymptotic t statistics.\nIt does not seem to matter, either, whether seasonally adjusted orseasonally unadjusted data are used in the empirical work here. Season-\n5. E.g., the freely estimated A14.1 M2 model does not lead to rejection of the jointhypothesis. The likelihood statistic is x7(15) = 18.1 with a marginal significance level of .26.However, the M2 results for the longer lag models explored in this chapter are just asnegative to the MRE hypothesis. E.g., the freely estimated A15.1 model with M2 data leadsto a likelihood ratio statistic for the joint hypothesis of x7(28) = 58.90 with a marginalsignificance level of .0006.125 Does Anticipated Aggregate Demand Policy Matter?\nally unadjusted M1 data in output and unemployment models give resultsnot appreciably different from seasonally adjusted data.* The empiricalwork in Chapters 4 and 5 that use models resembling the one here alsofind results not appreciably affected by the choice of seasonally adjustedover unadjusted data.\nThe money growth results here are much less favorable to the MREhypothesis than previous work. Which of the several differences in theanalysis here from that of earlier work might explain the less favorableresults? As pointed out in Chapter 2, the joint nonlinear estimationprocedure used here is even more favorable to the null hypothesis thanthe two-step procedure used in previous work, so this procedure cannotbe the cause of the rejections. Polynomial distributed lags have been usedin order to insure that rejections of the MRE hypothesis are not spurious.They have made very little difference to the results and do not appear tobe a factor in the rejections.\nThe money growth specifications yielded by the procedure used here issubstantially different from specifications in previous studies. In contrastto those, neither real government expenditures nor unemployment areexplanatory variables in the money growth equation. Because so much ofthe debate on the MRE hypothesis has focused on the specification of themoney growth equation (see Barro 1977; Small 1979; Germany andSrivastava 1979; Blinder 1980; Weintraub 1980), we may wonder whetherthis different specification is central to the findings. A comparison of thefindings here with those from the other study that analyzes postwarquarterly data, Barro and Rush (1980), should help answer this question.\nThe models of table 6.2 that have the same seven-quarter lag lengthused in Barro and Rush yield results very similar to theirs, even thoughthey use a different specification for the money growth equation. As inBarro and Rush, the models in this study fit the data well, the unantici-pated money growth variables have significant explanatory power, andthe tests of the rationality and neutrality constraints are not unfavorableto the MRE hypothesis. Most striking is the similarity of the parameterestimates. Not only do the table 6.2 models display the same pattern ofserial correlation in the residuals as the Barro and Rush results, but thelag structure has the same humped pattern and peaks at identical lags.\n6. Because a fourth-order autoregression is not sufficient to reduce the seasonallyunadjusted M1 growth to white noise, values of the unadjusted M1 growth for lags fivethrough eight replaced the SURP variables in the forecasting equation specification. Thecoefficients and asymptotic standard errors of the freely estimated A14.1 model estimatedwith unadjusted data are close to those using the adjusted data. In this case the likelihoodratio statistic of the joint hypothesis is x2(19) = 29.75 with a marginal significance level of.0551. The unadjusted results for the long lag A15.1 model are unfavorable to the MREhypothesis. So are the results using adjusted data: the likelihood ratio statistic for the jointhypothesis is x7(32) = 62.65 with a marginal significance level of .0010.126 Empirical Studies\nThe close resemblance between the table 6.2 results and those of Barroand Rush is an important finding. Although misspecification of themoney growth forecasting equation would lead to an error-in-variablesbias in the coefficients of the unemployment or output equation, thepreceding chapter has argued and found evidence that the bias should notbe severe. The similarity of the results in table 6.2 to those of Barro andRush lends support to this view, and further support comes from thesimilarity of the M2 and M1 results where the specification of the moneygrowth forecasting equation also differs.\nThe similarity of the table 6.2 and Barro-Rush results certainly showsthat using a different sample period from Barro and Rush’s is not whatcaused the MRE hypothesis to be rejected. By a process of elimination,we are left with the longer lag lengths as the key reason why this chaptercontains results so much more unfavorable to the MRE hypothesis.However, there are three other minor differences between the modelshere and those in Barro and Rush: (1) a fourth-order AR serial correla-tion correction rather than a second-order AR correction, (2) exclusionof government expenditure variables from the output and employmentequations, and (3) a different definition of the unemployment variable.Could these differences lead to the rejections found here? To ascertainthe effect of these differences, the long lag models were reestimated sothat the output and unemployment equations conformed to the Barroand Rush specification. The resulting models are found in Appendix 6.1.\nAs Barro and Rush found, the coefficient on their government expend-iture variables do have the expected sign, indicating that a rise in govern-ment expenditure is associated with higher output and lower unemploy-ment. Although the government expenditure variable does not exhibitsignificant additional explanatory power in the unemployment equation,it does so in the output equation. There the coefficient on the log ofgovernment expenditure is significantly different from zero at the 1percent level: it is over three times its standard error. However, it is notclear that actual government expenditure belongs in an output or unem-ployment equation consistent with the MRE hypothesis. Some distinc-tion between anticipated and unanticipated seems called for in this case.An attempt was made to estimate models that make this distinction, butthe attempt was not very successful: the Granger criterion led to aspecification of the government expenditure forecasting equation wherethe identification condition discussed in Chapter 2 was not satisfied: thatis, no other variables besides past government expenditure were found tobe significant explanatory variables in this equation. This is the reasonwhy, despite its use by Barro and Rush, no form of government expendi-ture was included as an explanatory variable in the models of tables6.1-6.6.127 Does Anticipated Aggregate Demand Policy Matter?\nThe basic finding in Appendix 6.1 is that the three changes in specifica-tion suggested by Barro and Rush (1980) do not appreciably affect theresults. The test statistics are quite close to those found for the models intables 6.1-6.6. The strong rejections of the MRE hypothesis hold up.Furthermore, contrary to the MRE hypothesis, anticipated monetarypolicy continues to be more important than unanticipated monetarypolicy in these results. As in tables 6.5 and 6.6, the coefficients onanticipated money growth are larger and more statistically significantthan those of unanticipated money growth.\n6.4 Conclusions\nThis chapter asks the question, “Does Anticipated Aggregate DemandPolicy Matter?” The reported findings answer this question with a strong“yes’’: anticipated policy does seem to matter.\nThe most important results are those with money growth as the aggre-gate demand variable. These results strongly reject the neutrality prop-osition of the MRE hypothesis. Furthermore, contrary to the implica-tions of the MRE hypothesis, unanticipated movements in monetarypolicy do not have a larger impact on output and unemployment thananticipated movements. The other proposition embodied in the MREhypothesis, that expectations are rational, fares better in the empiricaltests here. When the MRE component hypotheses of rationality andneutrality are tested jointly, strong rejections occur in both the outputand unemployment models. In one case, the probability of finding thesame or higher value of the likelihood ratio statistic under the nullhypothesis is only 1 in 10,000. The crucial factor in the unfavorablefindings on the MRE hypothesis appears to be the inclusion of long lags inthe output and unemployment equations. The results here thus givefurther impetus to theoretical research (see Blinder’s 1980 discussion)that is currently exploring why long lags may exist in rational expectationsmodels of the business cycle.\nModels with longer lags are less restrictive. The rejections in thesemodels are therefore very damaging to earlier evidence in support of theMRE hypothesis obtained from models with shorter lags. As discussed inChapter 2, the only cost to estimating the models with longer lags is apotential decrease in the power of the test statistics. Rejections in thiscase are thus even more telling. The failure to reject the MRE hypothesisin shorter lag models appears to be the result of an overly restrictivespecification that leads to inconsistent parameter estimates and incorrecttest statistics.\nThere is one qualification of the results that warrants further discus-sion. The methodology used here follows previous research in this area128 Empirical Studies\n \nby using the identifying assumption that the output and unemploymentequations are true reduced forms. It is not clear whether, if this assump-tion proved invalid, it might lead to rejections of the MRE hypothesiseven if the hypothesis was true. The money growth results here are thenby no means a definitive rejection of this hypothesis. However, this workdoes cast doubt on the previous evidence, also of a reduced-form nature,marshaled to support the view that only unanticipated monetary policy isrelevant to the business cycle.\nThe above qualification is even more important for the results inAppendix 6.3 where the aggregate demand variables are nominal GNPgrowth or inflation, both of which are less likely to be exogenous. How-ever, these results confirm the money growth results. Rejections ofneutrality are extremely strong. In one case, for example, the probabilityof finding that value of the likelihood ratio statistic under the null hypoth-esis of neutrality is only 1 in 200,000. The hypothesis of rational ex-pectations fares much better in these tests. Although the rationalityhypothesis does not come out unscathed—there is one rejection at the 5percent level, but just barely—it is not rejected in any other tests in thisappendix at the 5 percent level.’ This result might encourage those whoare willing to assume rationality of expectations in constructing theirmacro models, yet are unwilling to assert the short-run neutrality ofpolicy.\n7. Ido not cite the rationality test results in Appendix 6.3. In Chapter 2 I explain whythey may not be reliable because of small sample bias.“[PAg] JUdoIOd | OY} Je JUROMIUsIC, ,“Jeag] Uso1ad ¢ ay} Je JURDYTUaIC,\n‘TW UW dND/‘dXdD =D pue 47 soyWeNb Joy ainypusdxoJWOUIUIIAOS JesOPo] [B94 SI’GK AH soya ‘TLV Ul ’dXAD)30] =H ‘poutesisuos yutodpus oy) yim jetwoudjod Jopso-yinoy e SuoTe at] 0} pouressucsase 'g UL “(p) pue (Z) ur yenbo st A yey) syuresjsuos UoNeNbe-ssoso ay} Sursoduut (wu91 5g ay) sapnjout [p] aay) Waisds (p) pue (Zz) Woy saIeUINS -aloKy\n \n \n \npI Z7=M-G 8890 = AS 7186 = w7Z=M-A  80800°= AS 6866 = 2x+(L80°)879' — =“ «(OI )ELZ’ — = %dxx(680°)09h' I = 'd «(Ol )E66° = 'dx(ZP'9)00°p1 — = Sd x(€S€ 669° = 'd(oO DInI- =\" «(97°9)07'SI- = °d «(291 poe’ = %P (€9€ ozo = 8dGIT = ==8d xeLOSOU'9T- = 88 «(pS 16S = “'d a LE )S6TT = 8d(veopee- =\" x(Z9°S)06°91 — = 4 «(962 )6p9\" = *'g a(18E 68h T= 4d(ese)Isr— =\"'d xx(L7'S)P7LI- = OS «(LOE )619\" = “1d xa(Z6E LOL T= 99(r'pors- =%9 +(L6°P)OLLI- = 8 (coe Jos: = \"0 x«(€0P')P00'7 = $d(96'r)90L- =S'd «(69 P)LEOI- = \"8 (L62' por = Sd xx(SOP)ZSUZ = *d(sp's)er's- =\" xx(Pe peopl — = * (oo¢' eon’ = \"'d (68E ZIT = &(€6's)p8'6- = *'d xx(8L'€)S9'71- = “S (60¢\")oge’ = *'d ax(SPe PLOT =(ov9z1- = 9 x«(78'7)8€'6- = 'D (pz )ozp’ = 1d (697 JETS T= 'Sx(ep9)L9'71- =\" «(85° 186'7- = 9 (ore oes: = \"'d (BIZ )9EL’ = OS(op'Zog'r- =@  (F00')900°=+ —aw(€S\")98'Z - = 9 xx(OEO)6ET =@ — xe(€000°)800'=+ xx (OPT )OLS\"S = 2[Cxa — DNA) 80] (AND) 30] so1qeueA japuadaqZIV TIv sPPpoW\n \nUte +134 (Jol —'\"'O1W) dS +00 + AWLL + +9 =0csajqeiaea ainjipuedxy yUaWIUIVA0y pue (Td) Sse] Ajuamy ‘yyMoIy ABUOW payedionueuy :saqeiazeA Asoyeueldxysuonenby juaudojduiauy pue yndyng jo sayeumjsy 1eauljUON T'V'9 1q8Luonesyisads ysny pue o1leg YIMSJapoy] JusWAO;duIaU_) puke yndyng = :1°9 xIpueddyTable 6.A.2 Likelihood Ratio Tests for the Models of Table 6.A.1\n \n \nModelAll Al.2\nJoint hypothesis:\nLikelihood ratio statistic x°(15) = 43.02** x7(15) = 31.26**\nMarginal significance level -0002 0081Neutrality:\nLikelihood ratio statistic x°(4) = 13.13* x°(4) = 13.78**\nMarginal significance level 0106 0081Rationality\nLikelihood ratio statistic x°(11) = 30.45** x°(11) = 18.80\nMarginal significance level -0013 0648\n \n*Significant at the 5 percent level.**Significant at the 1 percent level.*J9A9] JWoosod | oy) 3e JUROYTUSIC,,‘JeAg] JUsoIAd ¢ ay) 1B JURDYTUaIC,\n+7 Jaysenb Jo} sinypusdxa yusuUI9A08 Je19paj [221 =\"qKAD B9yM ‘(’{XKAD)80] =H “poutrsysuod yulodpus ay} yyM JerwoudjodJapso-YLNOJ & SuOTe oI] 0} pouteysuOd oie 'g pue'g ayy *,A =A Sutsodurt ‘(w49}’N9 By) Sopnjout [9] aJoymM) wWoIsAs (9) pue (Z) 94} Wo payeUsy :aoy\n \n807 = M-d 6LL00° = AS 0666\" = 2\n \n \n(601')p9I— = %d«(EID )L96 = 1d(Ibe per = %@ (196')9IL'- =°(pI1')z80\"— = (p9¢g 169\" = °¢ (coz oze — = %d (656 ')z69\"- = °d(LLI')OLI — = ®'g (P8E)196° = 88 (pre Jess -— = °'d (or6)L99°- = *d(€0z )8rz' - = *Fg +x(66€ JETT = “9 (6br')o69' - = *'d (806')8e9'- = “d(602 poe’ ~ = “1g xx(IIh')S8h'T = °9 (ges )sgz°- =4'd (s9g°)L65°- = °(Loz )gze’ — = °'@ xx(BTP)IOL'T = 58 (€z9\")sz8\" - = \"9 (€18')ses'- = Sd(Iz )t1e — = Sg xx(9Tb')9S8°T = °Q (902 pes’ -— = Sd (8bL')Obr'— = *d(9% Jost’ — = *¢ x«(ZOP)976'T = *Q (sez eg’ - =\"d (099')oog’- = *d(est )epl — = x«(ZLE')I88'T = %@ (ps8\")o6L — =*'d (9¢5\")860'- = *d(z8z')olo’ = “'g xx(LEE)069' T= 18 (606')ILL’- =\" (99¢\")pst' = 'd(ele poz = NR xa(LEE JIZET = 8 (spo Jere - = \"0 x(Szz'Jo9s\" =x+(8€0°)6Z1° = 0 — «x(9000°)L00° = + «x (PST \")OLSS = 9CAND) 30] raiqeueA juopuadegTew {POW\n \nzi igo oe aH 13, ig? a!Uta +! Bid +! OIN's x + (DIN —'~'DIM)'S X +'00+ ANIL + +9 = CaND)80Taiqelie A ainyipuadxy yuautUsaA04) pue“(Jdd) s8e] Ayuamy ‘yyMory Aauo| pajyedionuy pue payedjoyueuy :sajqeise, Aroyeueldxguonenby jndjng jo ayeunsgy seaUlUON €'W'9 AI98]*]ag] JUdoIJod | oy) 1B JUROYTUSIC, ,“JPAg] JUadIad ¢ oY) Ie JURDYIUSIC,\n“1 JoueNb Joy ainypuadxa uoWUIIAOS [esOpay [PII = 'GKAD WoyM “GNO/’dXAD =’) ‘poulessuos julodpua oy) yyM JerwoudjodJopsJO-YLINOJ & BuOTe I] 0} poutesjsuod ose ‘g pue ’g oy *,A =A Sulsodum ‘(w191 79 ay) sapnjout [9] asym) wWaysds (9) pue (Z) sy Woy poyeMsY :aloKy\n \n \n \n \nvIZT=M-G 8590 = AS = 7LS6° =»«(060°)97S\" — = %de(Po0 ele T ='d(leZso1- =%g (zg's)ze'e - = \"9(LE°1)87'T = %@ (paery- = % (ss'1)00° = %d (€9°5)99'p- = °d(L1'2)6r'e = “8 (ZS TSEO— = 8Q (o9'z)e0'- = (e's)8e'S—- = *d(zs 'Z)os\"€ = Fg ««(99°7)6P'8— = “@ (zveeu- =\" (ol's)po'9- = “d(85°Z)ee'p = “18 xe(Z8Z)LEOI- = °9 (6L'€)67- =4'd (88\"p)6s'9- = °d(Ly DLS'b = 718 +«(66°2)08° II — = §@ (oe'p)ps — = 3d (bL'7)66°9- = SB(og Z)IS'y = Sg wa(ZVEVES TI — = °Q (€L'p)68°- = S'd (19'p)9T'L- = *d(91'°Z)Z0'p = \"8 xx(ELE)PETI— = €Q (LI's)pe'1- =\"! (o¢'p)S0'L- = 8d(o1'z)80'€ = *'g x(L6°7)S6'01 — = %@ (ps's)88'1- = *'d (6L'€)09'9- = “d(EV @)pL'l =\" xx(€9'Z)S0'8- = 'Q (us)I¢z7- =\" SLZILS— = 'd(Izzo =\" (8eZre'e— = (ig's)ol'e- =\" welES DE = °S(6 2ISb- =0 — xa(POO)TIO'=+ ax (Lb\")P9'Z— = 9[CNA — 1)/’NA) 80] raiqeueA juopusdoqVv sT2poWo=! o-!\"+ 2-19d + 1~'31d + JOLW'S gt (Gow -' ow) & +'00+ ANIL! +9= [Cwa - Dy'NA]801aiqetse A ainjpuadxg yuawus2A05 pue(Idd) s3e] Ayam ‘yyMo1y Aouo pajyedioyuy pue payedyonueuy :sajqeie, Arojyeueldxyuonenby juawAojduauy Jo ayeumsy seauljuON pv’ aqeL133 Does Anticipated Aggregate Demand Policy Matter?\nAppendix 6.2: Results with Nominal GNP Growth and Inflationas the Aggregate Demand Variable\nNominal GNP Growth as the Aggregate Demand Variable\nThe models here follow Gordon (1979) and Grossman (1979) in usingnominal GNP growth as the aggregate demand variable in the output andunemployment equations. We should be cautious in interpreting theresults because the assumptions that nominal GNP growth is exogenousand that the models are reduced forms are questionable. Nevertheless,these results will shed light on previous evidence on the MRE hypothesisusing nominal GNP growth as the X variable. Table 6.A.5 reports theoutput and unemployment equations that have been estimated from the(2) and (4) system, imposing the cross-equation constraints that the y areequal in both equations. Twenty lagged quarters of unanticipated nomi-nal GNP growth have been included in the models because coefficients onlags as far back as this are significantly different from zero at the 5 percentlevel—a result confirmed by Gordon (1979).*\nThe signs and shape of the AS.1 and A5.2 models are sensible, showingan increase in unanticipated nominal GNP growth usually associated withan increase in output or a decrease in unemployment. The fit of theseequations is good too—compare them, for example, with the results intable 6.2 and table 6.A.9—and several of the coefficients on unantici-pated nominal GNP growth even exceed their asymptotic standard errorsby a factor of 10. The good fit is not surprising because we would expectnominal GNP fluctuations to track short-run movements accurately inreal GNP or unemployment if price level movements are smooth.\nDespite these attractive results, table 6.A.6 indicates that the MREhypothesis is not supported. Both the unemployment and output modelslead to strong rejections of the joint hypothesis. Rejection in the outputmodel is at the .00001 level; in the unemployment model it is at the .0009level.’ One reason for the stronger rejections here with nominal GNPgrowth as the aggregate demand variable may be that the higher correla-tion of this aggregate demand variable with output or unemploymentleads to tests with greater power. The most interesting aspect of theseresults is that the rationality constraints contribute very little to theserejections. In both models, the data do not reject the rationality ofexpectations. The culprit behind the rejections of the joint hypothesis is\n8. See McCallum (19795) for a critique of the Gordon (1979) study.\n9. As in the money growth results, the long lags for the unanticipated and anticipatednominal GNP variables are critical to the negative findings on the MRE hypothesis. E.g., anoutput model with only seven lags of nominal GNP growth and the lag coefficients freelyestimated does not reject the joint hypothesis: x°(15) = 23.07 with a marginal significancelevel of .0827.“JPAg] Jus0s0d | oY) Ie JURDYIUSIC, ,\n*Joag] JUsoI0d ¢ ay) Ie yUROyIUdISC,\n“pauteljsuos jutodpua ay} yyM yerwoudjod Japio-yyno}\n2 SUC] dt] 0} poutesjsuos ose’ OYE “(p) pue (Z) UI Jenbo st A yey) SjuTessUOD UOIeNbe-ssoso dy} Su",
      "topic": "econometrics"
    },
    "2": {
      "title": "(Advanced Textbooks in Economics Vol 12) Kenneth J. Arrow, Frank H. Hahn - General Competitive Analysis-North Holland (1971).txt",
      "text": "this idea we must take note of a special point.The decision to supply a good in a perfectly competitive economy isnota decision to supply so-and-so much to such-and-such agents, butsimply to exchange so-and-so much of the good for other·goods. Ifthe price ruling for a good is zero and agents planto supply sorne of it,then by the assumption of free disposal (see discussion of H inSection 2.4), we may simply say that agents decide to dispose of acertain amount of the good. Clearly this decision can be carried outby our assumption, whatever the demand of other agents for thatgood may be. If this demand were greater than the amountoffered, however, then the decisions of the demanding agents couldnot be carried to fruition. From this we conclude that while wewould never be willing to regard a situation with positive excessdemand in sorne market as an equilibrium, an excess supply in amarket where the price is zero is quite consistent with our notion ofan equilibrium. All this seems agreeable to common sense and itremains to put it more formally.\n22\n5.\nEquilibrium\nEconomic agents may be taken to reach their decisions in the lightof what they want and what they can get. If tastes and technologyare given, and if the goods owned by individuals and householdsare also given, then the variables influencing their decisions are theprices prevailing in the various markets. If at sorne set of admissibleprices (i.e., for us sorne p in Sn) all these decisions can be carried outsimultaneously, then we may say that these decisions are compatibleand that the prices are equilibrium prices. There are really twosets of ideas involved in this notion of equilibrium. On the onehand, in such a situation every agent can achieve what he wishes toachieve. On the other hand, if tastes, technology, and the ownershipof goods remain given, there will be no mechanism to bring abouta change in p. Under the conditions postulated, it is argued that achange in prices is a signa!, the consequence of incompatibility inthe decisions of agents. This is a familiar notion, the \"law ofdemand and supply,\" which is discussed more extensively in Chapters11, 12, and 13.1 Since we ha ve taken pE Sn, the curve must be thought of as constructed .as\nfollows: Take any p E Sn, and suppose that at this p there is at least one pomton i's average cost curve equal to p 1• Now, say, raise p, to p{ and multiply allother prices by k < 1 so that the new p' E Sn. Again find a point on theaverage cost curve at p' that is equal to p¡. Proceed in this way to trace thewhole curve.\nDEFINITION 1 (E). p* in Sn is called an equilibrium if z(p*) =::; O,where z(p) is derived from the \"preferred\" actions of agents.That this formal definition indeed corresponds to our discussionof the equilibrium concept can be seen with the aid of the followingtheorem.THEOREM l.\nIf W and z(p*) =::; O, then z;(p*) < O implies that\nPT =O.Proof Since p* is in Sn, it follows from the assumptions of T.2.1that every element in the sum p*z(p*) is non-positive. Then, if,contrary to whaf is asserted, PT > O, it must be that p*z(p*) < O,which contradicts W. Since no price can be negative, this completes the proof.In severa! respects D.2.1 is incomplete because it does not specifythe conditions that must hold for each agent if his decision is to bethe \"best\" open to him at p*. This, however, must be postponeduntil Chapters 3 and 4. Here we must be satisfied with our ratherinformal treatment.It should also be noted that there is no reason to suppose thatthere is only one equilibrium price vector. The question of the\"uniqueness\" of an equilibrium will be fully explored in Chapter 9.\nr24\nGENERAL COMPETITIVE ANALYSIS\nMARKET EQUILIBRIUM : A FIRST APPROACH\nHere we simply introduce a piece of notation: We write E for theset of equilibrium price vectors,\nsorne judgment as to the Iikelihood that the coherence of decisionsimplied by equillbrium is attainable by actual economies. In this,however, due care will ha veto be taken ·not to confuse the statement\"an equilibrium cannot be shown to exist\" with the statement \"noequilibrium is possible.\"In Figure 2-1 we illustrate the propositiqn just established for atwo-good economy. In the diagram the horizontal axis is of unit1ength.\nE = {p J z(p) ::; O;\n6.\npE Sn}·\nThe Existence of Equilibrium-the Case of Two Goods\nThis section is to serve as an introduction to the proof that ingeneral, given our assumptions, the set E is not empty. It is hopedthat it will facilitate a proper appreciation of the roles of the variousassumptions in the proof. In what follows we take all p to be in Sn.eonsider, in a two-goocl-economy, the two price vectorsp' = (0,1)\n1\n¡,il'\n1\nl¡i,'1'1'1\n1\nand\np\" = (1,0).\nWe suppose that neither p' nor p\" is in E, else there is nothing toprove. But then it must be that z1 (p') > O and z 2(p\") > O. eonsider the fi.rst of these. By W we have Oz 1 (p') + 1z2(p') = O. If,contrary to our assertion, we had z 1 (p') ::; O, then the fi.rst termwould ~ertainly be zero and so also z 2(p') = O, which contradictsthe supposition that p' is not in E. The same argument establishesthe inequality for z 2(p\").Now Ietp(m) = mp' + (1 - m)p\"\n7. The Existence of an Equilibrium: Many GoodsWhen we turn to the economy with many goods, it is clear that thesimple procedure of Section 2.6 will not serve, although the lessonswe have.learned will continue to be of interest, as we shall see.Indeed, the best introduction to the general case is probably achievedby staying with the two-good case a Iittle longer.Take any arbitrary point pon the horizontal axis of Figure 2-1 so· that p is in Sn. At the point chosen in the figure, z 1 (p) is positiveand z 2(p) is negative. Let us adopt the following rules:(1)(2)\nRaise the price of the good in positive excess demand.Lower or at least do not raise the price of the good inexcess supply, but never lower the price below zero.\nwith 1 2m2 O.\nBy W, one oJ the numbers z 1 (p(m)) and z 2 (p(m)) is positive andthe other negative when m ,¡, 0,1, unless p(m) E E. Suppose then,without loss of generality, that z 1 (p(m 0 )) < O for sorne m 0 # 0,1.Now Iet m increase from m 0 to l. We already know that z 1 (p(O)) ispositive, and therefore, as m approaches zero, somewhere z 1 (p(m))must change sign. But, by e, it cannot change sign withoutbecoming zero. Suppose this happens at m*. Then p(m*) is in E,for, by W, it must be that z 2 (p(m*)) = O.We note the important role of e in this demonstration. Withoutit we could not exclude the possibility of a change in the sign of z 1 ,as m approaches zero, without its ever becoming equal to zero. Ofcourse we also relied heavily on W, but this assumption does notappear to be very restrictive. As was indicated in the discussion ofe, however, the Iatter will certainly exclude a number of perfectlypossible situations from consideration. Later in the book, aninvestigation of sorne of these possibilities should help us to form\n25\np\"\nFigure 2-I\n26\nGENERAL COMPETITIVE ANALYSIS\nMARKET EQUILIBRIUM : A FIRST APPROACH\n(3) Do not change the price of a good in zero excess demand.(4) Multiply the resulting price vector by a scalar, leavingrelative prices unchanged, so that the new price vector youobtain is in Sn.If we are successful in carrying out these rules we can say: Givenany p in Sn, we have a routine for finding another point in Sn·Another way of putting this is to say that our procedure gives us amapping of Sn into itself. We note that if p is an equilibrium, thenthe mapping will give us p again. The converse will al so be true:If the mapping takes us from p back to p, then equilibrium exists.The question then is: Does at least one such point exist? In ourtwo-good example the answer is clearly \"yes.\" Suppose that neitherp' nor p\" is the point we seek. We know that at p' the rules tell usto raise the price of good 1 and at p\" they tell us to raise the price ofgood 2. By W, though, we can never be asked to raise the pricesof both goods at any p. Hence, at p(m) with 1 =1= m. =1= O, the rulesinstruct us to lower the price of sorne good, say the first. But thenby C at sorne p(m*), the rules tell us not to change the price of thefirst good (because z1 (p(m*)) = 0), and then by W it follows alsothat we must not change the price of the second good. Hence,p(m*) is a point of the kind we seek.All this is really a repetition ofthe argument ofthe previous sectionin slightly different terms. When we come to the case of manygoods, our method will have to be somewhat different. As much aspossible, we shall use the economics of our problem to construct aprocedure that satisfies the rules we have given. We can use C toestablish that the rules give a continuous mapping. Then we willappeal to a mathematicaltheorem that assures us that there will beat least one point in Sn that the mapping returns to itself. W e thenwill appeal again to our economics to show that this point is theequilibrium we seek.Step 1: Construction of mapping. We first seek a continuousfunction with the following three properties:\nM1(p) > O\nif and only if z¡(p) > O,\n(2a)\nM 1(p) =O\nif Z¡(p) = 0,\n(2b)\nPt + M1(p) 2: O.\n(2c)\n27\nIt is intended that M 1(p) representan adjustment toan existing priceso that a price vector p is transformed into a new price vector withcomponents p 1 + M¡(p).Functions satisfying (2) exist; for cone example, let M¡{p) =max(- p¡, k1z1(p)), where k1 > O. Since M 1(p) is a continuous transformation of p 1 and Z¡, it is certainly continuous by C.To verify (2a), first suppose z1(p) > O. Sincep1 ;::: O, k1z;(p) >-p1, so that M 1(p) = k 1z1(p) > O. Conversely, if z1(p) ::;; O, theneither M 1(p) = k 1z1(p) ::;; O or M 1(p) = - p 1 ::;; O. It is easy to verifythat (2b) and (2c) hold.An even simpler, though less intuitive, example of a functionsatisfying (2) is M 1(p) = max(O, k 1z1(p)), k 1 > O.For functions satisfying (2), we easily deduce\nM 1(p)z1(p) ;::: O\nall i.\n(3)\nIt will be seen that if we interpret p 1 + M 1(p) as the ith componentof the new price vector that the mapping produces, given p, theprocedure for finding these new price~ satisfies rules discussed earlier.However, while all p 1 + M;(p) are certainly non-negative, there isnothing to ensure that they will add up to one. In other words, ifwe write p + M(p) as the row.vector of the new prices (componentsp1 + M¡(p)), then there is no reason to suppose that p + M(p) is inSn when p is in Sn. Since we seek a mapping of Sn into itself, wemust modify the mapping.An obvious way of doing this is as follows: Let e be the n-dimensional column vector with all components unity. Then [p + M(p)]eis certainly non-negative. If we are certain that this number isstrictly positive, then we may take the mapping given by\np + M(p)T(p) = [p + M(p)]e.\n(4)\nThe reader can now verify that (4) obeys all ofthe four rules we havelaid down, in particular, that the vector T(p) is in Sn.We now show that (4) is indeed a possible mapping by provingthat for all pE Sn, [p + M(p)]e > O. If not, then for sorne pE Sn.p + M(p) = O by 2(c). But thenO = [p + M(p)]z(p) = pz(p) + M(p)z(p) = M(p)z(p)by W. But then by (3), M¡(p)z1(p) = O, all i. Since pE Sn, itmust be that p 1 > O, so me i, so for that i, M 1(p) = - Pt < O. This,\n'¡·i\n¡,l li.\n!1\n29\nGENERAL COMPETITIVE ANALYSIS\nMARKET EQUILIBRIUM : A FIRST APPROACH\nhowever, must mean z1(p) = O, which in turn by (2b) implies thatM 1(p) = O, a contradiction. Hence, [p + M(p)]e > O for all pE Sn.\nWe have thus been able to establish that for the economy heredescribed there exists a set of \"signals \"-market prices-that willlead agents to make decisions that are mutually compatible. Thisis by no means a trivial result, and we repeat that careful reflectionon the roles of the various assumptions in establishing it is verydesirable because there are certainly economies that interest us inwhich coherence in decentralized decisions may not be possible, orat least for which it cannot be proved possible. Thus importantissues in the judgment of decentralized systems are at stake.\n28\nStep 2: The mathematical result. W e first define sorne 9f thenotions of our introductory remarks more formally.DEFINI'TION 2. (a) If T(p) is a mapping that takes points in Sn intopoints in Sn, then the mapping is said to map Sn into itself.(b) lf for sorne p* we have p* = T(p*), then p* is called afixedpoint of T(p).The theorem we use in this chapter is called Brouwer's fixed-pointtheorem, and it is stated as follows: Every continuous mapping of acompact convex set into itself has a fixed point. The proof of thisresult will be found in T.e.I; convexity is defined in D.B.7. Herewe need confirm only that the set Sn that we are interested in satisfiesth!:l requirements of the theorem.eertainly if p and p' are in Sn. then for any m with 1 ;::: m ;::: O,the vector p(m) = mp + (1 - m)p' is in Sn. since p(m) is nonnegative and p(m)e = l. Hence, Sn is convex. Since Sn is clearlybounded and since the limit point of any sequence of price vectorsin Sn is itself in S.,., Sn is compact.\n8. Equilibrium under a Weakened Continuity Condition\nwhere ,\\ = [p* + M(p*)]e - l. Take the inner product of (5) onboth sides with z(p*), and use W to find\nAs noted in Section 2.4, e implies in its present forro that thedemand for free goods is bounded. We shall want to weaken thisrestriction for severa! reasons: It is not unreasonable that demandfor at least sorne goods might approach infinity as the priceapproaches zero; as airead y noted, the non-satiation hypothesis thatunderlies Walras' law is at least partly inconsistent with satiation inany single good; the assumption that all goods are gross substitutes,an assumption frequently made in the literature on stability anduniqueness and repeatedly used by us in later chapters of this book,implies that demands may approach infinity as prices go to zero.We must be careful, however, in stating the weakened continuityassumption. A simple possibility might be to admit that an excessdemand function z1(p) can take on the value +oo in addition to finitevalues and to define continuity in an obvious extension of the usualdefinition (i.e., if z1(p) approaches infinity along one convergingsequen ce of price vectors, it must do so on every sequen ce convergingto the same limit). This assumption indeed implies the existence ofequilibrium, but it cannot be derived from a utility-maximizationtheory of household behavior. eonsider the following example.There are three goods, and the household has a utility function\nM(p*)z(p*) = .\\p*z(p*) = O.\nU(x) = x~ 12 + xª' 2 + x!i 12 ,\nAs before, M 1(p*)z1(p*) = O, all i, by (3). Hence, z1(p*) > O wouldimply M 1(p*) = O, which contradicts (2a). Hence, z1(p*) :::; O, all i.By D.2.1, p* is an equilibrium.We summarize the result of this section formally:\nwhich is in no way pathological. Let the initial endowment be oneunit of commodity 3, and suppose that p 3 = 1, while p¡ and p 2 areboth varying and approaching O. The usual calculations for demandfunctions show that\nStep 3: The fixed point of T(p) is an equilibrium.point, we have p* = T(p*), that is,\nAt the fixed\n{[p* + M(p*)]e}p* = p* + M(p*)orM(p*) = .\\p*,\n(5)\nTHEOREM 2. If F, H, w, and e, then an equilibrium for acompetitive economy with a finite number of goods exists.\nGENERAL COMPETITIVE ANALYSIS\nMARKET EQUILIBRIUM : A FIRST APPROACH\nFrom the paths along which p 1 and p 2 both approach zero, it ispossible to choose one for which pifp 2 approaches any given nonnegative real number or indeed +oo. Then x 1 (p) can be made toapproach any given non-negative real number, or +co. Thus nodefinition can be given to x 1 (0,0,1) that is consistent with continuity in any sense. We must therefore regard x(p) as undefined atthe point (0,0, 1).However, it can be seen that x 1 (p) + xip) + x 3 (p) approaches+oo. We can calculate that\nAssuMPTION 5 (B). There exists a positive finite number R such thatfor all p in S m Zt(P) > - R, all i; z(p) is bounded from below.\n30\n31\nB can be justified by supposing that the amount that can beproduced of any one good at any one time not infinitely removedfrom the present is finite, that the quantities of goods initially ownedby households also can properly be taken as finite, and that it is notfanciful to suppose that the quantity of any one service a householdis capable of supplying at a moment of time is also not infinite.Assumption B is superfluous if e is postulated, but not if it isrelaxed as below.\n1Xs(P) = (lfp¡) + (lfp2) + 1\nAssuMPTION 6 (e'). The excess-demand function, z(p), is definedfor all p » O and possibly for other p and is continuous whereverdefined. If z(p) is not defined for p = p0 , then\nand therefore certainly approaches zero as p 1 and p 2 approach O inany direction. Since p 3 = 1, p 3 x 3 (p)--¿. O. From the budget constraint,\nlim\nPtXt(P) + P2X2(p)--¿. l.\np-tpO\n2 Z¡(p) = +co.i\n¡:\nW e can calculate also that\n·¡\n1\n(1 + u v)2\n-(u+ u2 v)'where u = p 1/p 2, v = 1 + p 2. For p 2 small, v can be regarded asconstrained to a right-hand neighborhood of l. Since the righthand side is negative as u varies over positive values and v over itsrange and since it approaches -oo as u approaches O and -1 as uapproaches +oo, it is clearly negative and bounded away from O.However,P2[Xt(P) + X2(p)] = [PtXt(P) + P2X2(p)- 1]- [(Pt- P2)x1(p)- 1];\n1\n!!1,1'\n¡'¡'11\n11\nsince the first term on the right-hand side approaches O and thesecond is negative and bounded away from O, it follows thatP2[x1(p) + x 2(p)] is positive and bounded away from O. Sincep 2 --3>- O, it must be that x 1(p) + x 2(p)--¿. +co, and, since Xs(P)approaches O, x 1 (p) + x 2(p) + x 3 (p) approaches +co.It will be shown later (T.4.8) that this result is a general implicationof utility maximization. At present, we simply assume that the sumof excess demands approaches infinity whenever excess demand isundefined.Before restating the continuity assumption formally, we introduceanother.\nIn view of e', we can define, by convention,\nJil!\nJr\n~\n:1\n1'\nto take on the value +oo for all p for which z(p) is not defined.We now show that the previous equilibrium proof can be modifledso as to be valid if e is replaced by B and C'.We take M(p) to have the properties (2), but now require onlythat it be continuous wherever z(p) is defined and therefore continuous. The previous examples show that this is possible. Then(3) is still valid, as is the conclusion that [p + M(p)]e > O.For convenience of notation, let,Z(p) =\n2 z;(p).j\nNow introduce a continuous function, a(Z), defined for all realnumbers Z such that O :::; a(Z) :::; 1, all Z, a(Z) = O for Z :::; O,a(Z) = 1 for Z ;:::: Z¡, where Z 1 > 0. Then define a(p) = a[Z(p)]andif z(p) is defined,N(p) = {~~ - a(p)]M(p) + a(p)e'(6)if z(p) is undefined.Here e' is the row vector whose components are all l. N(p) is sochosen that it coincides with M(p) if Z(p) :::; O(a region in which we\nGENERAL COMPETITIVE ANALYSIS\nMARKET EQUILIBRIUM : A FIRST APPROACH\nknow any possible equilibrium must Iie) and becomes a strictlypositive vector if z(p) is undefined or indeed if Z(p) ;::: Z 1 and there·fore, by C', in any neighborhood of a point where z(p) is undefined.Obviously, N(p) is continuous wherever z(p) is defined. Supposez(p) is undefined for p = p 0 • By C', we can find a neighborhoodof p 0 such that Z(p) ;::: Z 1 for all p in the neighborhood for whichz(p) is defined. Then N(p) = e' for all such p; it also equals e' forall p for which z(p) is not defined and in particular p = p 0 , so thatN(p) is constant ate' throughout the neighborhood and is certainlycontinuous.Sin ce O ::; o:(p) ::; 1, it follows from (6) that, where z(p) is defined,M 1(p) ::; 1 implies N1(p) ;::: M 1(p) and, therefore, p1 + N 1(p) ;::: p 1 +M 1(p) ;::: O, while M 1(p) > O implies N1(p) > O and, therefore,p1 + N¡(p) > p 1 ;::: O. Hence, certainly p1 + N1(p) ;::: O, all i. Also,if M¡(p) > O, sorne i, then p + N(p) > O, so that [p + N(p)]e > O,while if M¡(p) ::; O, all i, then p + N(p) ;::: p + M(p), [p + N(p)]e ;:::[p + M(p)]e > O. Thus, if z(p) is defined, [p + N(p)]e > O; ifz(p) is not defined, then [p + N(p)]e = (p + e')e is certainly greaterthan O.It follows that the mapping\nTHEOREM 3. If F, H, N, B, and C', then an equilibrium for acompetitive economy with a finite number of goods exists.\n32j\n33\n1\n9. Restricted Futures MarketsThe economy we have been considering is an abstract one in manyrespects, but perhaps the most serious departure from what weexpect the world to be \"really Iike\" is the supposition that there areenough futures markets to produce \"coherence\" not only in themarkets for current goods, but also in the markets for future goods.This hypothesis \"telescopes\" the future into the present, andalthough this occurs at least partially in certain markets, we knowthat it does not take place either universally or over the distantfuture. There are explanations for this, which have a good deal todo with the uncertainty agents ha ve regarding the future state of theenvironment that is relevant to their present decisions. We do notnow propase to formally introduce uncertainty into the story andwill instead take a route following the signposts that are alreadyavailable to us.The first point is this: It is quite possible that when the economywe have been considering is in equilibrium, there are sorne marketsin which there are no transactions of any kind. For instance, inpartía! equilibrium analysis, where we take the prices of all goodsother than the one we are considering as given, the situation isrepresented by a supply curve that everywhere Iies above the demandcurve; both curves intersect the vertical axis. An obvious questionis \"To what extent is a market in which no transactions take placea market at all ?\" This is not our main concern. Instead, supposethat the market for the delivery of shoes next week is of thistype. Clearly it is not implied that no one contemplates eitheracquiring shoes next week or selling them next week. Instead, itmay be, for instance, that those hoping to get shoes next week on thewhole expect there to be a cost-saving innovation in their manufac·ture, while those who hope to scll thcm cxpcct no such thing.Evidently, although markets are formally in equilibrium, the systemhas failed to produce intertemporal coherence since agents havemade plans on differing views of the terms on which shoes willexchange against other things, both of which cannot be correct. Itis preferable, therefore, to say that no futures market in shoes existsif, when we stipulate such a market, every equilibrium of the system\nT()- p + N(p)p - [p + N(p)]eis a continuous transformation of the fundamental price simplex, Sn,into itself and, therefore, has a fixed point, p*. In the equationT(p*) = p*, if we substitute the definition of T(p) and solve forN(p*), we findN(p*) = .\\p*,where ,\\ = [p* + N(p*)]e - l. If z(p*) were undefined, thenN(p*) = e', from which it follows that p* » O, a contradiction sincez(p*) would then be defined. Multiply both sides of the aboveequation by z(p*); from (W), N(p*)z(p*) = O, or from (6),[1 -\no:(p*)]M(p*)z(p~)\n+ o:(p*)Z(p*) = O.\nNote that, by definition, Z(p) = e'z(p). But from (3), [1 - o:(p*)] xM(p*)z(p*) ;::: O, so that o:(p*)Z(p*) ::; O. Since o:(p*) > O wouldimply Z(p*) > O by construction, we must have o:(p*) = O. Hence,M(p*)z(p*) = O, which implies' that p* is an equilibrium price vectoras befare.\ní\n1\n34\nMARKET EQUILIBRIUM : A FIRST APPROACH\nGENERAL COMPETITIVE ANALYSIS\nso constructed is found to be one in which no transactions take placein that market.The second point is connected with the first. If the number oftransactions in a market is small (in the limit zero ), it is hard tocontinue the assumption that the agents in this market take the priceas given. The point is obvious and, in·sofar as futures markets tendto be \"narrow\" for the reasons of the previous paragraph and al sobecause the proper definition of a good for future delivery may ha veto be peculiarly fine to allow for intervening technological change,the manner in which we have incorporated futures markets into thesystem is likely to be pretty misleading in many instances. Wemight do less violence to the facts to stipulate instead that suchmarkets do not exist.The last point we can make here without a detailed discussion ofuncertainty is that our foregoing analysis has postulated that thereis only a finite number of markets. Since there is no reason tosuppose that \"time must have a stop,\" we have implicitly limited thenumber of futures markets that exist, and so also the extent in timeto which we can say that coherence of decisions is possible. Thereason for this limitation on our analysis is at least partly the desireto avoid the analytical and conceptual difficulties of infinitedimensional spaces at this stage. As economists, we recognize,however, that the limitation also makes good sense if for no otherreason than the facts of birth and death. To suppose that I nowcontract for the delivery of a pair of shoes to my grandson, whom Iexpect to be born twenty years from now, is itself somewhat fanciful.To suppose further that I have correctly foreseen the situation inwhich my grandson will find himself and that in these circumstanceshe will value the shoes in a way correctly known by me now iscertainly dubious. Even if we allow contingent futures contractssuch as, \"For a price to be paid now, deliver a pair of shoes to mygrandson if he exists and is twenty years old in forty years' time, andif not, deliver nothing,\" we would certainly expect such marketsto bepretty narrow and to become narrower as the future recedes; quiteapart from anything else, it is not clear how far the benevolence ofan individual of a given generation extends to future generations.For these reasons and others having to do with uncertainty, it isdesirable to have an analysis of a competitive system in whichuniversal futures markets are not postulated. To this we nowturn.\n10.\n./\n35\nTemporary or Short-Period Equilibrium\nThe absence of futures markets does not mean that an individualcannot engage in the intertemporal transfer of goods. If storage ispossible, I can plan today to exchange apples for oranges tomorrowby storing apples for one day. Naturally, this decision will beinfluenced by current prices, storage and transaction costs, and theprices expected to prevail in the future. Here we shall take it thateach agent regards bis price expectations as certain, or at any ratethat he is unwilling to pay anything to insure bis future transactions(i.e., to make certain that the transaction can be carried out at theterms expected). This leads to the following difficulty: Should therebe no difference between the transaction and storage costs of differentgoods, then the reader can verify that an agent would be indifferentabout which good to store, and this would lead to difficulties withassumption F. All this is due to the artificial exclusion of theforces of uncertainty. In addition, we must not forget durablegoods, that is, those goods not annihilated by a current act ofconsumption.To overcome all these difficulties with one hand tied behind ourbacks, we shall arbitrarily postulate (a) that all storing is done byhouseholds who may rent such durable production goods as theyhave to producers and (b) that all households ha ve preferences o verthe goods stored such that at any set of current and expected pricesthey store one and only one combination · of goods. The secondassumption is not as terrible as it seems, sin ce it \"mimics\" in itsconsequences the forces of uncertainty that are excluded here. Thefirst assumption is pretty hannless at the moment.So far we have made it possible, through storage, for agents toplan to exchange present for future goods in the absence of futuresmarkets. But the reverse operation cannot be carried out if thereare no futures markets at all. By assumption, there is no way I canobtain more of a good now by promising to deliver a quantity ofsorne good ata future date. In order not to exclude this possibility,we shall assume that there exists a futures market in at least onephysical good (e.g., the medium of exchange) for all relevant futuredates.It is now advisable to put all this in more formallanguage beforewe consider the difference the new set of postulated circumstanceswill make to the conclusions of earlier sections.\n·~~··.......\nl1\nGENERAL COMPETITIVE ANALYSIS\nMARKET EQUILIBRIUM : A FIRST APPROACH\nIt will be convenient to regard the services a given durableproductive good renders as distinct from that good itself. If thereare, say, m durable productive goods, there will be m additionalgoods, the services rendered by the durables. All these goods havethe same date.Let there be N current goods as defined above, and in addition, Jetthere be one physical good at a fixed location at T intervals into thefuture, for which contracts for future delivery and sale can be madt:now. There are then N + T goods altogether. The vector pis nowthe N + Y-dimensional row vector of their current prices. Inaddition, agents have expectations as to the prices at future dates forthe N physical goods currently being traded. We here ignore theinvention of new goods, regard \"location\" as inessential, and suppose that no good deteriorates through use or storage. Supposethat agents are concerned only with the future over T periods.Then we write qh as the NT-dimensional vector of prices expected byhousehold h, and if there are H households, we write q as the HNTdimensional vector of expected prices.The price relevant to the current plans of household h is (p, q~¡).As befare, we suppose that the household owns a stock of goodsrepresented by the vector x1;. Also as befare, we shall write Xhi asthe amount of the good i demanded by h either for storage or consumption. Recall here that goods are still distinguished not onlyby their physical characteristics, but also by date. We write xh asthe demand vector of household h and regard a negative componentas a plan to supply a service, which category now includes the offerof the services of a piece of productive equipment. Summationover households is again shown by the omission of the subscript h.Lastly, we write x* as the vector consisting of the first N + T components of x and x* as the vector consisting of the first N + Tcomponents of x. These components represent the N current goods.and the T futures of the single physical good assumed to have afutures market.We now introduce\nexcludes a number of matters of great economic interest, for example,investment plans by firms, it is relatively harmless for the ratherformal problem of this section. 1 At the moment, we note that A.2. 7allows us to suppose that firms do not form any price expectations.We write Yr as the production choice offirmfand, for conveniencetake it to ha ve N + T components, of which the last Tare certainlyzero. A negative component again denotes an input, whichcategory now includes the services of productive equipment hiredfrom households. As usual, the omission of the subscriptjindicatessummation over f.W e define z by\n36\n1\n1\n1\n,.1\n1.'!\n,,!¡1,\n1\n'1\nil\n1\n1[1\n,'¡1:¡.:1!1!\n1'1¡'111\n37\nz=x-x-yso that z is the vector of excess demands in the N current markets forcurrent goods and the T current markets for the future delivery ofthe o'n!y physical good with a futures market. Evidently we maytake z to depend on (p,q). We now introduceAssuMPTION .8. (a) z satisfies assumption F: z = z(p,q) is avector-valued function.(b) z satisfies assumption W: pz = O for all (p; q) considered.(e) z satisfies assumption H: z(p,q) = z(kp,kq).(d) z satisfies assumption C over SN+T for fixed q.These suppositions are neither more nor less restrictive than theywere in our earlier discussion, and we do not explain or justify themfurther here.Since z is the vector of excess demands for current goods and thesingle physical good with futures markets, we cannot deduce fromknowledge of z what the market situations for goods in subsequenttime periods will be. Accordingly, we are justified in the nomenclature of the following definition:DEFINITION 3.\n(p* ,q) is a temporary equilibrium if z(p* ,q) ::;; O.\nAssuMPTION 7. Firms cannot stock goods of any kind, they cannoten ter into \"futures\" contracts, and the production process of eachfirm can be completed in the current period.\nOnce again this definition is justified as in our earlier discussion.It is important to remember, however, that the \"coherence ofdecisions\" we talked about there now refers to the markets represented in z only.\nThis assumption is highly u nrealistic, of course, beca use it puts allintertemporal transactions in the household sector. But although it\n1 This and other assumptions will be removed in the detailed treatment inChapter 6.\n38\nGENERAL COMPETITIVE ANALYSIS\nMARKET EQUILIBRIUM : A FIRST APPROACH\nThe question of interest now is whether a temporary equilibriumexists. We prove that indeed it does.The existence of a competitive equilibrium for fixed q is assuredby the following argument: Normalizing p so that pE SN+T alsoimplies by H that the expectation vector q has been normalized.For fixed q we may write z = z(p,q) = z(p). The vector-valuedfunction z(p) has all the properties of z(p) in our previous discussionof \"existence\" except H. But H was never invoked in the proofof T.2.2. Hence, we may use the same proof to establish theexistence of a temporary equilibrium.We have shown that, whatever the expectations of agents offutureprices might be and however much these expectations may differamong agents, there exists a set of prices in the current markets suchthat all the actions agents plan to undertake in these markets canindeed be carried out. This seems to be a comforting result to have,but it is not unimportant to bear in mind that the conclusion islimited by the assumptions on which it is based and, in particular,that the proof of the existence of equilibrium prices does notconstitute a claim that these prices in fact will be established.To understand the limitations imposed by A.2.8, consider thefollowing example. When we consider a system, we take its pastas given, and in particular, we take the stock of durable productiveequipment inherited from the past as given. Suppose that theproduction opportunities open to the economy (the production set forthe economy) are such that with the inherited equipment (or ratherwith the maximum services the equipment can yield in the currentperiod), there is an upper bound on the quantity of certain laborservices that can be \"usefully\" employed. By \"usefully\" we meanthat the employment of sorne more of that labor service makespossible a change in the vector of outputs of the economy. Next,suppose that the plans of households have the following property:If the ith good is the service supplied by households we have justdiscussed, then for all p in SN+T for whichp 1 ;::: p; the amount of theservice supplied exceeds sorne fixed positive number, while forPt < p; none of it will be supplied. Of course, this violates A.2.8.(d)as the supply function of the service is not now continuous over tberelevant domain. It is now possible, in light of our other suppositions in this example, that for all p in SN+T for whichp1 :=:: p1, thedemand of firms for this household service is less than the amountoffered by households, say, because they always offer more than the\nupper bound of the amount that can be usefully employed. Thus,no equilibrium may exist. If we consider that the physiologicalneeds of people make it impossible for them to offer labor serviceswithout positive consumption and if we also take note of thespecificity of much productive equipment to particular uses, it isclear that the example is not farfetched. Of course, the same difficulty could have arisen in the world with a complete set of futuresmarkets. In that case, however, households would have had theadditional option of selling their services forward and firms may havebeen willing to buy them in conjunction with the future services ofdurable equipment, so that the realism of the postulated conditionsof the example would have been less compelling.So far it has been supposed that, given the normalization of p, theprices expected by agents may be taken as given. It is morereasonable, though, to take expected prices as influenced, at least tosorne extent, by current prices. Our main result, however, will notbe affected if we stipulate:\n39\nAssuMPTION 9. For each household h the expected price vector qhis a continuous function qh(P) of p in\nGiven this assumption, we may again eliminate q from z(p,q) andwrite the vector of excess-demand functions as z(p). In conjunctionwith A.2.8(d), we may take it that z(p) is continuous over SN+T· Wemay then use the same mapping as in Section 2.7 to map SN+T intoitself and proceed as we did there to establish the existence of anequilibrium.THEOREM 4. Under assumptions A.2.7, A.2.8, and A.2.9, a temporary equilibrium exists.It behooves us to draw attention to the restrictiveness of A.2.9.It is true that in a number of studies it has appeared that agents\nforecast prices they think will rule in the future by extrapolating frompast and present prices. Moreover, such extrapolation procedureswould satisfy the assumption under discussion. Yet we must recallthat for the purposes of an existence proof, the postulated continuity must be over the whole of SN+T• and it is harder to claimthat this is the case from the emprical evidence. In particular, it\n1\ni!lli\n'!i:'~l:'\"J,\n'1:1\ni·\n40\nGENERAL COMPETITIVE ANALYSIS\nmay be argued that there are certain p in SN+T so different from anyprices that ruled befare our investigation started that agents willconsider their routinized method of expectation formation inadequate should such p occur. If this is so (and no doubt instances ineconomic history cometo mind in which it certainly appears to ha vebeen so), then A.2.9 is unlikely to be satisfied. In any event, this isan area of economics in which our ignorance is so great that it wouldbe very unwise to regard our assumption as more than tentative and,of course, convenient for our purposes.\n11.\nShort-Period Equilibrium: A Special Case\nThe short-period model we have been considering, althoughrestricted by certain assumptions, is of a pretty general sort andcould be made more general still without too much difficulty (e.g.,we could easily do without the assumption that firms make no in tertemporal decisions). We have seen that there is a well-definedmeaning for the equilibrium of such an economy, and we have seenwhat we must postulate in order to establish that such equilibriumexists. In this section we will examine the short-period equilibriumof a somewhat different economy. It is an economy we shall wishto discuss further elsewhere in this book. For brevity, we shallrefer to it as the Leontief (L) economy beca use it is closely connectedwith the work of that economist. It is described by the followingset of assumptions:AssuMPTION 10. (a) If y1 is a possible choice for firm J, then so isky 1 with k > O. Constant returns to sea/e (CR).(b) Every possible y1 for firm f has only one non-negative component, namely y 11 • No joint production.(e) There are no durable production goods.\nIn view of CR, we may, for all y 11 > O, define, _lf_Yf -\nYrrand be certain that if y1 is a possible choice for J, then so is y~.We now suppose that the Nth component of y~ represents theinput of a labor service and postula te:AssuMPTION 11. No household can supply a labor service otherthan that represented by the Iabel N. We call this the assumption\nMARKET EQUILIBRIUM : A FIRST APPROACH\nof one non-produced input.H.\n41\nAll household demand functions satisfy\nWe shall wish to restrict the possible production choices further by12. (a) y~N < O for all y 1 =!= O that f can choose.No output without labor input.(b) For each J, there exists a vector y1 such thatAssuMPTION\nL YiJ >O.\nNN\nThe system is productive. (Note that ~his condition need hold onlyfor a suitable choice of units.)Finally, let us now take p to be an N-dimensional price vector,SN to be the N-dimensional price simplex, and define C1 by\nCr = p,- py~.Evidently C1 is the unit production cost at p when y; is chosen.postula te\nWe\nAssuMPTION 13. (a) For every p in SN there is a choice ofy~(p) suchthat Cj(p) = p 1 - py~(p) :S: p1 - py~, all possible y~.·(b) CJ(p) is continuous over SN.(e) Necessary conditions for the equilibrium of economic agentsin the L-economy at p* are\n(i) p'j :S: Cj(p*)all J,(ii) pjy11(p*) = CJ(p*)Y1r(P*)\nallf\nNo production at negative profit andzero equilibrium profits.\nThis, with one exception to be introducetllater, completes the specification of the L-economy. We shall postpone a proper discussion ofthe various assumptions until we have established certain propertiesof this economy. Here, however, we may note that CR implies asituation we took as an example of the violation of F. It is clear,therefore, that we cannot hope to discuss the L\"economy exclusivelyin terms of excess.-demand functions. It is at this stage that A.2.13(e)proves useful. This assumption is based on the Walrasian view thatproduction as such involves no costs, psychic or otherwise, otherthan the ámount that has to be paid to inputs required for production.1 Hence, if at some p a firm is found to make a profit, there is1\nA.2.13(a) and (b) can be deduced from the production conditions (see Section3.4, especially T.3.7).\n¡;\"\"1\n42\nGENERAL COMPETITIVE ANALYSIS\nMARKET EQUILIBRIUM : A FIRST APPROACH\nan inducement for sorne agents in the economy not presently engagedin production to become so engaged. The profit here referred to isthe maximum profit. By the same token, if profits are zero, thenthe scale of production is a matter of indifference to the firm CR.Our first task is to show that there exist prices satisfying A.2.13(e).Our procedure once again will be to find a mapping of SN into itselfand to show that the fixed point of this mapping is the price vectorwe seek.Consider the following mapping:\nSince then O < pt = TN(p*) and k < 1, it must be that pt =1 - V(p*) or else pt = kpt. So we have\nT1(p) = min[1; (1 ;(:rN)]Cj(p),\n1 - V(p*) > kpt,\nfrom which it then follows thatpj = T1(p*) = Cj(p*)\nf= 1, ... , N- 1; 1 >k> O\np~ = maxpj >O1\n1 - V(p*) ::;; O.\nwhereNN\n(e) If 1 - V(p) ?:: kpN, then by (7), T1(p) = Cj(p), f = 1, ... ,N- 1, and TN(p) = 1 - V(p). Adding gives\nL Tl(p) = l.\n(8)\n(9)\nLet Ym be the vector described in A.2.12(b), with f = m, y~ =Ym/Ymm; note that\n(7c)\nWe shall first verify that (7) does indeed take points of SN into pointsin SN. ·(a) By the definition of Cj(p) and the assumption of no jointproduction, we have Cj(p) ?:: O, all p and all fHence, certainlyT¡(p) ?:: O, all f, TN(p) ?:: O, all p. We note that the assumption of\"no output without labor input\" implies that V(p) can be only zerowhenpN =O.(b) Suppose that 1 - V(p) < kpN. Then by (7), T1(p) =(1 - kPN)Cj(p)/V(p),J = 1, ... , N- 1, and TN(P) = kPN· Addinggives\nm< N.\nAlso from (7), pt = O implies that\n(7b)\nL Cj(p).\n/=1, ... ,N-1,\nso that the fixed point certain1y satisfies A.2.13(e). It remains onlyto show that indeed pt > O.Since p* is in SN, the supposition that pt = O would imply that\n(7a)\nV(p) =\n43\nFrom A.2.13(a), C~(p*) ::;; p; - p*y~, so that\np~ - C~(p*) ?:: p*y~ =\nL PJY~; ?:: p~ L y~,; > O,NN\n-[\nNN\nwhere use has been made of the facts that pt = O, pj ::;; p~, and# m. From (7) and (9).\nY~; ::;; O for j\nPÍ =\nV(~*) Cj(p*) ::;; Cj(p*)\n/=1, ... ,N-l.\nSince not both these inequalities can hold, we conclude that indeedPt >O.We now note that by A.2.12(a) and A.2.13(a), pt > O impliesC¡(p*) > O, allf, and so it follows that pj > O, allf Moreover, wehave shown that there exists p* in SN, which satisfies A.13(c). Wesummarize:\n1\nSince, by A.2.13(b), the functions Cj(p) are continuous over SN,the mapping in (7) is also continuous and thus has a fixed point p*.We now show that p* satisfies the zero-profit condition. In doingthis we shall first assume that pt > O and then prove that this isindeed the case.\ni¡\ni\n; __ ,,¡t,,lL ______ _\nTHEOREM 5. If A.2.10-A.2.13 inclusive, then there exists a strictly. . p* m. SN such that p 1* = C 1*(p) ,J= 1, ... ,N- 1, andposttlvePt = 1 - V(p*).This result is pleasant, but it is not yet sufficient to establish theexistence of an equilibrium for the L-economy; it remains to show\n11\n44\nGENERAL COMPETITIVE ANALYSIS\nMARKET EQUILIBRIUM : A FIRST APPROACH\nthat all markets can be cleared at p*. (Recall that p* » O, so thatexcess supplies are inconsistent with equilibrium.) To do so, weunfortunately require another assumption:,¡¡u,¡:111\nAssUMPTION 14·. Let x'(p*) be the N - !-dimensional vector ofhousehold demand at p* for all goods other than the Nth. 1 Thenif x' is the N- !-dimensional vector of the goods owned by households, x'(p*) - x' > o.We note that for x' = O, this assumption will always hold providedhouseholds supply sorne of the labor service. However, withx' =¡6 O, the assumption is evidently quite restrictive; we will comment on this again.Now if all markets for non-labor services are cleared, we requirethat\n¿ y[¡(p*)y11(p*) = x;(p*) - x;\ni 1l,\n45\nwhich is the value of the labor services supplied by households.Hence, multiplication of both si des of (!O) by p*, since we know thatpt > O, shows that the labor market is also in equilibrium at p*.We summarize:THEOREM 6. If A.2.10-A.2.14 then a strictly positive equilibriumfor the L-economy exists.Let us discuss sorne of the features of this economy and, inparticular, examine the role of the various assumptions we havemade.We note that if an equilibrium exists, we are able to determine p*without reference to the forces of demand at all. This is one of themost striking properties of the L-economy. Moreover, we ha ve, byT.2.5,\nj= !, ... ,N-l.\np* H(p*) = - pty~(p*),\n(11)\nf\nOn writing h(p*) for the N- !-dimensional vector with componentsy 11 (p*) and H(p*) for the (N- 1) x (N - 1) matrix with typicalelement y[¡(p*), we have to solveH(p*)h(p*) = x'(p*) -\nx'\n(10)\nfor h'(p*) > O. From A.2.10(b), H(p*) is a matrix with n~n-positiveoff-diagonal elements and positive diagonal elements. Also,\n¿ pfy[iP*) = - PtY[N(p*) > 0\nby T.2.5 and A.2.12(a). Hence (see Appendix A, Remark 2), H(p*)has a non-negative inverse. This, together with A.2.14, then leadsto h(p*) > O.We are now left only with the market for labor services. By thedefinition of p*, we ha ve, writing jj* for the N.- 1 vector of pricesexcluding pt,\n¿ YrN(p*)yrr(p*),\np* = - p,~y~(p*) [H(p*)]- 1.As the example in the footnote 1 makes clear, this means that wemay express the equilibrium price of every produced commodity asmade up of the direct and indirect labor costs of producing one unitof that commodity.\nH(p*) = [\n~\nYF!\nYÍF]\nO\nwhere 1 is the diagonal unit matrix.postulate A.2.12(b), we have\n+ 1= say, -A+ 1,\nEvidently, A is non-negative, and by the\n[H(p*)]- 1 = 1 + A + A 2 + · · ·.So\np* = pJ{y~(l + A + A 2 + · · ·),\nf\nwhich is the value of the total demand for labor by firms.we have also\nThere-\n1Consider the case in which H(p*) is 2 x 2 and so y~ is 2-dimensional.Omitting the argument p*, we may write\nNN\np* H(p*)h(p*) = - Pt\nwhere y~(p*) is the N - 1 vector with components YÍN(p*).fore,\nBy W\np*(x'(p*) - x') = - ptxN(p*),1 We take the expected price vector q to be a continuous function of p andhave eliminated it from the excess-demand function.\nfrom which, for instance, p~ is given byP~ = [Y~N + YÍPYÍN + YÍFY~rY~N + · · ·]pJ{.\nThe first term in the bracket measures the direct labor input required per unitof output of firm F, the second term measures the labor input required toproduce the output of firm f required to produce one unit of output of firm F,and so on.\n¡¡,¡;1\nlil. il\n111\n11\n46\n47\nGENERAL COMPETITIVE ANALYSIS\nMARKET EQUILIBRIUM : A FIRST A;PPROACH\nSince p* is determined without reference to demand conditions, itfollows also that we now do not need any elaborate assumptions toensure that all demand functions are continuous over SN. Indeed,the theory of household behavior can be left in a most rudimentary state. All we need is H and W, the most innocuous ofthe assumptions. Por all these reasons, the L-economy has provedattractive to many economists. But 1he number of assumptions wehave made suggests that this simplicity is achieved at certain costs.The role of constant returns to scale in achieving our results isclear. If we did not make the assumption, we could not determinethe prices that do not exceed unit costs without reference to the scaleof production, and so to the forces of demand. If certain durablegoods (their services) were used in production and the quantity ofthese goods available arbitrarily specified, then once again pricescould not be determined independently of demand conditions. Asthe services of durable goods used currently are not producedcurrently, the price of these services cannot be determined from theconditions of production, but must be found from the conditions ofmarket equilibrium, which, in turn, involve the forces of demand.Moreover, we cannot determine the prices of goods currently produced until we know the prices of the services of durables. If we donot take the amount of durables as arbitrarily given, and make sornefurther assumptions, these consequenc·es can be avoided. Exactlythe same reasoning explains why we found it necessary to postulatethat there is only one kind of labor service. When we consider thevariety of such services in practice, it is clear that not too muchreliance should be placed on the L-model.The assumption of \"no output without labor input\" is somewhatstronger than is strictly required. . Its consequence is, of course, toensure that all equilibrium prices are strictly positive. Had wepostulated instead that for sorne particular good only, we could getno output without labor input, you can verify that all our argumentsand conclusions would continue to hold, except the proposition thatp* is strictly positive. Had we dropped the assumption altogether,we would have had an equilibrium situation in which all producedgoods might have a zero price-an uninteresting case. In any case,this particular assumption is not particularly unpalatable.The use we have made of the supposition that the system isproductive is evident. It enabled us to ensure a semi-positivesolution for (10).\nThe assumption that the system is productive is one we probablyshould want to impose on models other than the L-economy, and itseems quite agreeable to casual experience. Matters are ratherdifferent when it comes to the postulate that households are netdemanders of sorne produced goods and net suppliers of none(A.2.14). Without this assumption, there might be transactions ina good that can be, but is not, produced. Indeed, the equilibriummarket price of that good, that is, the situation in which the excessdemand for that good is non-positive, might then be below themínimum unit cost of producing it. Evidently the forces of demandwill be in volved ii1 the determination of prices. The assumption hasno immediate appeal unless it is argued that we may take householdsnot to hold any quantities of the producible goods. Without thispostulate, then not only might we lose the special features of theL-economy, but we will also have to proceed along different lines toprove the existence of an equilibrium, in order to deal with excessdemands not satisfying F (see Chapter 5).There remains A.2.13. In part (a) of this assumption we ensuredthe existence of a unique cost-minimizing choice y~ for all p. Thisallowed us without further argument to treat the market clearingproblem as we did in (10). The same point is involved here as inassumption F and is not at all important in a general treatment.Part (b) is explained on the same grounds as those invoked in thediscussion of C. Both assumptions can be deduced as consequences of somewhat more fundamental restrictions on the set ofpossible production choices of firms. This is done in Chapter 3,where the realism of this procedure is also considered.After all this, we may judge that the L-economy is an interestingconstruction, if for no other reason than that it helps us to understand earlier theories, such as the labor theory of value, but it seemssomewhat unlikely that a pure \"cost of production theory\" of pricesis capable of reflecting adequately the complexiti~s of the real world.There are severa! directions, however, in which the analysis can beextended. We note only one of these here.Suppose that inputs precede output by \"one period\"; productiontakes time. We are interested in situations in which the priceexpected by everyone for the period t + 1 is the same as that at t.However, the price that would actually be paid at t for a good to bedelivered at t + 1 differs from the current price for current deliveryby an arbitrarily given \"discount factor.\" This is a familiar and\n11\n48\nlli¡:h:l:::1¡;¡.¡:1\n111\nGENERAL COMPETITIVE ANALYSIS\nMARKET EQUILIBRIUM : A FIRST APPROACH\nelementary idea; we do not pro pose to discuss here the determinationof the equilibrium discount factor.We <;ontinue to postulate A.2.10-A.2.12, as well as A.2.13(a) and(b ). In particular, note that there are still no durable inputs.A.2.13(e) is modified as follows:\ncarrying out the transactions they wish to carry out, it will also betrue that, after these transactions, they will find themselves holdinggoods (if apy) in just the quantities they had planned. This simplymeans that if people can carry out the desired change in their stocks-transact so much and so much of the particular good over thegiven time interval-then they will also find that they hold as muchof the good as desired. In general, however, prices will differ notonly from one period to the next, but also from what they had beenexpected to be. The prices here are those that establish temporaryequilibrium'at each moment in time. This means that the quantitiesof various goods that agents wish to hold will differ at differentmoments of time.It is evidently both useful apd legitimate to distinguish betweenan economy in which there is the full complement of futures markets,or that behaves as though there were such a full complement, andone that is not so fortunate. The equilibrium ofthe former economymight be called a \"full\" or \"long-run\" equilibrium, while the lattermay be analyzed by means of a sequence of short-run equilibria. Inthe literature we find a further distinction, as is evident in the title ofthis section. If we think of the quantity of a good offered for sale,we must specify, for good sense, the period over which this is so, andsimilarly for the quantity demanded. Hence, both quantities havea time dimension: so-and-so much per unit of time. When we thinkof the amount of a gqod an agent wishes to store, we think of theamount he wishes to ha ve at a moment of time, and no time dimension is involved. The former are called ''flow\" variables and thelatter \"stock\" variables. If we change the units in which wemeasure time, then the flow variables are affected, but the stockvariables are not. In the literature, then, a distinction is drawnbetween a situation in which all flow markets are cleared, a jlowequilibrium, and a situation in which all agents find they have thestocks they desire, a stock equilibrium.In the light of what has already been said, this distinction canhave force only if we regard as a flow equilibrium a situation inwhich not all agents are carrying out the transactions they regard asmost satisfactory at the ruling prices, although all flow markets arecleared. Th,is goes counter to the definition of an equilibrium thatwe have employed throughout this chapter. Consider a typicalexample. It may be that ata given set of prices curren ti y ruling andgiven expected prices, flow markets are cleared because sorne agents\nAssuMPTION 13.\n(e*) A necessary condition of equilibrium is,\n1\n(i) p'J s RCj(p*)allj,* = RC*(*)*(n.. ) Pr*Yrrr P Yrra 11/,,\n::!il111!\n,¡'11·\n:.,,111 111\nwhere R is a scalar, R 2: 1 (R - l is the discount factor).The question is whether for given R, there exists p* satisfyingA.2.13(c*). Now letCj*(p) = RCj(p),/-#N,V*(p) = _2 Cj*(p),NN\nand Jet T*(p) be the mapping in (7) with the new definitions. It iseasy to check that if we just assume pt > Othe mapping d<;>es indeedhave a fixed point satisfying A.2.13(c*). However, A.2.13(b) doesnot now ensure that\np; - C**(p*) 2: p*y~,so our earlier line of proof that pt > O may fail. Indeed, it is clearthat the assumption that the system is productive cannot ensure theabove inequality for arbitrarily large R. On the other hand, theargument is clearly safe for R = l. We conclude:The time-using economy has an equilibrium satisfying A.13(c*)for any given R not exceeding sorne R. > l.The market-clearing equations are now also changed since currentinputs must be provided by the outputs of past production decisions.This is not pursued here.·\n12.\nStock and Flow Equilibrium\nIf we consider again the short-period equilibrium of the economyof Section 2.10, we see that sin ce, at p*, all agents are capable of\n49\n50\nGENERAL COMPETITIVE ANALYSIS\nr\nare prepared to satisfy what would otherwise be an excess flowdemand by holding less of a good than they would like (\" unintended\"dishoarding), while others hold more of a good than they would likeand so prevent what otherwise would be a flow excess supply(unintended hoarding). Evidently, in this view we may have flowequilibrium and stock disequilibrium. But the notion of anequilibrium has clearly been widened to include situations in whichagents themselves are not in equilibrium in the sense that they do notcarry out the transactions most satisfactory to themselves at theruling prices.It is not at all clear that the nomenclature of the literature is agood one, simply because it is not helpful to have the same name todescribe quite different situations. In any case, in this volume thedistinction between stock and flow equilibrium will become relevantonly in the analysis of what, in our d~finition, are disequilibriumsituations.Connected with the distinction we have been discussing is thedevice of \"period analysis.\" This can be helpful in overcomingsome of the conceptual problems raised by continuous time, but itcan also be misleading. For instance, Swedish authors at one timefound it helpful to define the length of the period by the time intervalover which prices could be taken as fixed. Starting with g~ven pricesat the beginning of the period, a flow equilibrium over the period,then, would involve stock disequilibrium at the end of the periodunless the economy was in full equilibrium. They then traced theeconomy from period to period by using certain rules for changingprices. In an economy with many agents, however, it seemsunnatural to suppose that they all not only adjust their preferredaction at discrete intervals, but they do so at the same moment. Ifthat is not so, then such adjustments will be taking place more orless continuously. To this must be added the fact that periodanalysis leads to a formulation in terms of \"difference equations,\"which are capable of producing motions for the system that are notpossible if the formulation is in terms of differential equations, sothat what started as an aid to visualization may finish by beingpretty misleading. In any event, it is noticeable that the discussion of this paragraph quite naturally. ran in terms of what, fromthe agents' point of view, are plainly disequilibrium processes andconfirms the view that these matters are best treated when we cometo consider such processes.\nMARKET EQUILIBRIUM : A FIRST APPROACH\n51\nNotes\nExistence theorems of the general nature ofT.2.2 were first proved byWald [1933-34, 1934-35]; for systematic expositions of severa! interrelated results, see Wald [1936, 1951]. Wald assumed demand functions arising from the household sector together with Cassel's system offixed coefficient relations for production (see Section 1.5). Iffactors areidentified with final goods so that the production of final good i requiresone unit of factor i and nothing else, then Wald's result is the same asT.2.2, though his assumptions were considerably stronger; see Wald[1951' pp. 372-373].McKenzie [1954] established an existence theorem that is moregeneral than Wald's with regard to production assumptions; however,if specialized to the case of exchange, it is identical to Wald's.Both Wald and McKenzie assumed that the demand for a free goodwas infinite, more precisely that z,(pv)-->- + ctJ for any sequence {pv} forwhich pv-->- p0 , where pp = O. As the discussion in Section 2.8 shows,this assumption is not compatible, in general, with utility maximization.Equilibrium in a mo del of no joint production, as discussed in Section2.11, was discussed extensively by Leontief [1941] for the special casein which there are fixed coefficients for the production of each commodity. The crucial role of the productivity assumption, A.2.12(b) inour notation, was first stressed by Hawkins and Simon [1949]. Thegeneralization of these results to the case of variable coefficients is dueindependently to Georgescu-Roegen [1951] and Samuelson [1951].\nJ'\nChapter Three\nPRODUCTION DECISIONS AND THE BOUNDEDNESS OF THE ECONOMY\nPRODUCTION DECISIONS AND THEBOUNDEDNESS OF THE ECONOMYSpecz'alizing is necessary to ejjiciency,which is a form of altruism, andhowever narrow the specialist becomes,we ought to pardon him if he doesgood work.-B. Russell, The Autobiography ofBertrand Russell*\n1. General Principies and lllustrative ExamplesThe three basic elements of the theory of production undercompetitive conditions are its organization through separate firms,the delimitation of the production possibilities of each firm, and thechoice among these possibilities by the principie of profit maximization at given prices. In this section, we will discuss these pointsinformally and comment on sorne revisions and extensions of thesimple concepts of supply and demand functions made necessary bya careful analysis. By illustrations, we will show especially thepossible importance of multi-valued supply and demand relations.First, we will consider the description of a firm's productionpossibilities. In general, a firm will use many inputs to produceseveral outputs; there is no need to confine attention to the singleproduct firm. Any possible state of production of the firm, then, isa statement that outputs of certain commodities in certain amountscan be achieved by inputs of other commodities in other givenamounts. We will agree as a convention that positive quantitieswill represent outputs and negative quantities inputs. Any suchspecification of possible relations between inputs and outputs will betermed an activity; the set of all activities available to the firm will becalled its production possibility S(( t.The word \"possible\" in the preceding paragraph refers to technological knowledge, not to availability of resources; to say that an· activity is possible means only that if the firm possessed the specified\n* Little, Brown and Co., Boston, 1957, p. 246.52\n53\ninputs, the corresponding outputs could be produced. Thus, theproduction possibility set is a description of the state of the firm'sknowledge about the possibilities of transforming commodities.For simplicity in following the discussion in this and the followingtwo chapters, it will be convenient to assume that production and allother economic activity is timeless; inputs and outputs are contemporaneous, and no consideration is given to the future in anyone's decisions. It should be made clear, however, that time can beintroduced into the system by a mere reinterpretation ofthe symbols,so that the model of general competitive equilibrium has a broadapplication.The distinction between pure technological possibility and feasibility, that is, possibility plus the availability of resources, cannotalways be maintained strictly. We will find it convenient to consider sorne commodities as being private to a firm or group of firms(e.g., managerial ability or, in the case of foreign trade, domesticfactor supplies). Theq__,the following two descriptions of reality areequivalent:(1)\n(2)\nincluding the private commodities with all others amongthe components of the activity vectors and adding to thesystem a statement prohibiting the f!ow of these commodities out of the firm or group of firms;deleting the private commodities from the activity vectorsand considering among the set of possible vectors in theremaining components only those vectors whose demandsfor the private commodities can be satisfied with theavailable supplies.\nGiven a set of prices for all commodities, it is possible to calcula tefor each activity its profit, the excess of the values of its outputs o verthe val u e of its inputs; for sorne activities, of cotll'Se, profit m ay benegative. The assumptions of perfect competition imply that, at anyset of prices regarded as given to it, each firm chooses an activitythat yields it at least as much profit as any other possible.Sorne of the possible complexities in a general and rigorous theoryof production decisions can best be brought out through examples.We start with perhaps the simplest possible assumption aboutpossible activities: There is one output that is proportional to thequantity of the one input.\n~\nTPRODUCTION DECISIONS AND THE BOUNDEDNESS OF THE ECONOMY\nGENERAL COMPETITIVE ANALYSIS\n54\nIn accordance with our notational principies, we take the inputy 1 to be negative and the output y 2 to be positive; then we haveassumed that the activities are those of the form(1)\nwhere a is sorne positive constant. If p 1 and p 2 are the prices ofinput and output, respectively, then the profit is\nP1Y1 + P2Y2 = (p2 - ap1)Y2'as seen by substituting from (1). Now the firm's profit-maximizingdecision can easily be calculated. If p 2 < ap 1, then profits arenegative if y 2 > O and O if y 2 = O; thus, the profit-maximizingdecision is to set Y2 = O (and, from (1), also set y 1 = 0), in otherwords, not to engage in production at all. If p 2 = ap1, a morecurious situation arises; profits are O no matter what level is chosenfor y 2 • Hence, any value of y 2 can be regarded as profit-maximizing,provided that the appropriate value of y¡ is chosen at the same time.Equivalently, we can say that any vector satisfying (1) is profitmaximizing. Finally, if p 2 > ap¡, an increase in y 2 always increasesprofits. Strictly speaking, there is no profit-maximizing activity,since for any pair (y 1 ,y 2 ) satisfying (1), there is another, that yieldshigher profits. In ordinary terms, the supply and demand functionsmust be regarded as undefined in this case.We note that the classification of cases depended only on theprice ratio, p 2 fp¡. The case just studied is represented graphicallyin Figure 3-1. In Figure 3-1a, the line OA (assumed indefinitelyOutput\nOutput\nA\na\n------....::!0> I L . - - - Input\n(a)\nFigure 3-1\n(b)\n55\nprolonged) is the set of possible activities. For price vectors withslope less than. a, that is, making an obtuse angle with OA, profitsca~ ~lways be mcreased by a small decrease in scale; hence only theongm can be optimal. A price vector with slope a is perpendicularto OA everywhere; hence no change in scale will change profits soth.at every point of OA is profit maximizing. Finally, a price ve~torWI~h a s~ope grea_t~r than a, making an acute angle with OA at anypomt, ywlds additwnal profits for any .increase in scale and so candefine no profit-maximizing activity. In Figure 3-1 b, the supplycurve for the product implied by Figure 3-Ia is presented. Thequantity supplied depends, of course, only on the price ratio; it iszero for price ratios less than a, it can be any value whatever indifferently at a, and it is undefined above a.This trivial case has been examined in such detail to bring outthree points, stated in increasing order of importance: For sorneprice vectors, the firm may find it most profitable to engage in theactivit~ ~f doin~ ~othing; for sorne price vectors, there is no profitmaximizmg achvity; for sorne price vectors, there is a whole set of~ctivities, each of which is profit maximizing, in the sense that thereIS no other activity that yields a higher profit. Thus, for a generaltheor~, we must relax the assumptions of the last chapter, accordingto wh1ch supply and demand are both defined and single valued foreach price vector.Sorne further examples will be useful. Suppose there are twotypes of activity, of which one is more efficient in the simple senseof more output per unit of input, but can be carried out to a limitedscale, beyond which a less efficient type of activity must be used.(The more efficient activity may require sorne input prívate to thefirm and limited in quantity.) The case is represented in Figure3-2.Clearly, for a price vector with slope less than a, the maximumprofit again is zero, obtainable only at the origin. When the slopeequals. a, all activities on the line OA yield equal (zero) profit, whilethe_ ~r~ce vec~or makes an obtuse angle with all points representingactlvities at h1gher scales, which therefore cannot be optimal, so thatthe profit-maximizing activities are those on OA. If the slope Iiesbetween a and b, the profit must be increasing with scale up to Aan~ decreasing thereafter; hence the profit-maximizing point isumquely A as the output-input price ratio increases from a to b ·supply of the output anci demand for the input are completely price~\n'\n'\n56\nPRODUCTION DECISIONS AND THE BOUNDEDNESS OF THE ECONOMY\nGENERAL COMPETITIVE ANALYSIS\n57\n!;,·;,\nOutput11:\nJ.\nOutput\nOutputb\n~---- ............... -..........\nOutput\nA\n8\nInput\nL -_ __.__ _--+--P2\na(b)\nb\n/¡\n' ,,\n-----------~'-\"-a'~- InputOB(a)\n(b)\na\nFigure 3-2Figure 3-3\ninelastic in this interval. When the price ratio is b, all points fromA on are equally profitable, since the price vector is perpendicular toall ofthem. The amount ofprofit (divided by the price ofthe input)is represented by the intersection B of the perpendicular to the pricevector at any given activity leve! with the input axis; therefore, theprofit is positive as soon as the price ratio rises above a. For priceratios above b, the profit-maximizing activity is undefined again,since any increase in scale is profitable.This is the first example of diminishing retums to scale. The newfeature is the possibility of positive profits, which can be obtainedwhenever the price ratio exceeds a.In Figures 3-3a and 3-3b, we exhibit continuously diminishingreturns to scale. In this case, any given price vector with slopebetween a and b does define a unique profit~maximizing activity,since the price vector can be perpendicular to only one point.Profits are necessarily positive for price ratios greater than a, sincethe intercept of the perpendicular to the price vector (which is alsothe tangent to the production possibility curve) clearly cuts the inputaxis to the right of the origin, as at B. As the price ratio approachesb, the optimum scale approaches infinity; for price ratios at or aboveb, the profit-maximizing activity is undefined. 11Note that the leve] of maximum profits at any given price vector mayapproach either a finite or an infinite limit as the price ratio approaches b.\nFor a final example of considerable general interest, we show inFigures 3-4a and 3-4b a case of increasing returns followed bydiminishing returns. Consider first any price vector with slope lessthan a. It may make an obtuse angle with all possible vectors, sothat none are optimal. Alternatively, it may be the perpendicularto sorne possible activity, such as B; but then the profit, measured byC, is negative, so that B is inferior to the origin. The output-inputprice ratio' a is the smallest value that is perpendicular to the curveof possible production vectors at a point A that yields a zeroprofit at the ratio a. Hence, for that ratio, A and O both representprofit-maximizing activities; for higher values of a, the supply curveConsider, for examples, the following possible input-output relations (recallthat Y1 :S: O):Yo = 1 - Yl - e\"1\n(a)\n(b)\nWith p 1 fixed at 1, the optimum scale of production in both cases approachesinfinity (Yl-+ -oo, y 2 -+ +oo) as J12 approaches 1, but the profits at theoptimum leve! approach 1 for (a) and +oo for (b). Note al~o that when P2rises beyond 1, we can achieve infinite profit even in case <.a), m the sense thata profit as large as prescribed can be obtained by a suffic1ently large scale ofoperations.\nfollows as in Figure 3-3. We note again that the profit-maximizingactivity is multi-valued at the price ratio a.Another way of looking at this case is illuminating. Imagine theoriginal production possibility curve modified by replacing thecurved section OA by the straight line OA. The case is now exactlylike that of Figure 3-2. The s11pply curves are also the same, exceptthat at the price ratio a the profit-maximizing set of activities contains just two points in Figure 3-4, while in Figure 3-2 it contains thesame two points plus all those lying between them. Thus the modi-·fied production possibility curve, obtained by straightening out thehollows, yields a supply curve that is a smoothed version of theoriginal. This smoothing process will be important in discussingthe extent to which the existence of general equilibrium is affected bythe presence of increasing returns (see Chapter 7).Finally, we mention briefty the aggregation of the profit-maximizing decisions of individual firms. First, consider for each firm asingle chosen activity vector. Because ofthe convention about signs-positive for outputs and negative for inputs-the net output of anycommodity by the productive sector can be obtained by simpleaddition ofthe outputs ofthe individual firms; the amount producedby one firm and used by another for further production simplycancels out. The net aggregate \"output\" will turn 'out to benegative for sorne commodities; these are net inputs needed from thehousehold sector, such as labor services.\n1!\n'1:\nPRODUCTION DECISIONS AND THE BOUNDEDNESS OF THE ECONOMY\nGENERAL COMPETITIVE ANALYSIS\n58\n1\nIf at a given set of prices one or more of the firms has more thanone set of profit-maximizing activities, then correspondingly theaggregate supply or demand must be niulti-valued; any aggregateactivity vector that can be forrned by choosing a profit-rnaxirnizingvector for each firm and adding thern up is an aggregate supplyvector for that set of prices.Finally, we note that if ata given set ofprices the profit-maxirnizingvector is undefined for sorne firrn, the aggregate supply vector mustalso be regarded as undefined.\n2. Production Possibility Sets of Individual FirmsDEFiNITION l. The production possibility set for firm J, denoted byY1 , is the set of activity vectors possible to the firrn.The components of an activity vector include all cornmodities;positive cornponents refer to outp\\lt, negative ones to inputs, andzeros to cornrnodities neither purchased nor sold by the firm. Anelernent of Y1 will usually be denoted by y1 .First we introduce two trivial assurnptions about productionpossibilities. The first states that it is always possible for the firmto engage in no activity.ASSUMPTION l.\nOutput\\\nOutput\n'A\\\n/1---+a------p2/p¡(b)\n(a)\nFigure 3-4\n0 E Y1 .\nThe second is more of a convention than an assurnption.AssuMPTION 2.\n' ''\n59\nY 1 is closed.\nThat is, if there are technologically possible activities arbitrarilyclose toa given activity, then we include the given activity arnong thepossible ones. Clearly, little would be lost by sacrificing thisassurnption; for example, instead of there being a profit-maxirnizingactivity for sorne set of prices, there would be a sequencé of possibleactivities approaching a given vector such that the profit derivedfrorn any given activity is less than that derived from any rnernberof the sequence beginning sufticiently far out.A more serious restriction to be irnposed on the productionpossibility sets of individual firrns is that they are convex sets. Theproperty of convexity can be derived from two, more elernentaryhypotheses: divisibility and additivity. Production is said to bedivisible if, whenever y is an activity, .\\y is an activity for O s >. s l.\nGENERAL COMPETITIVE ANALYSIS\n60\nProduction is said to be additive if, whenever y1 and y 2 are activities,y1 + y 2 is an activity. In this notation, production exhibits constantreturns to sea/e if, whenever y is an activity, Ay is an activity for allA ;::: O. The mathematical equivalent to the economic property ofconstant returns to scale is that of being a cone: a set of vectors thatcontains Ax for all A ;::: O if it contains x.LEMMA l. If production is divisible and additive, then thc production possibility set is convex and exhibits constant returns to scale,that is, it is a convex cone.If y1 and y2 are activities, then, by divisibility, Ay 1 and(1 - A)y are activities, for O :::; A :::; 1, and Ay 1 + (1 - A)y 2 is anactivity, by additivity, demonstrating convexity.Proof.\n2\nLet y be an activity, A ;::: O. Let n be the largest integer notexceeding A, v = A - n. Then O :::; v < 1, and vy is an activity by.. 'b'l'Let y1 = y ('1 = 1, ... , n) , yn+l = vy. Th en y1 IS. an1 Ity.d lVISlactivity (i = 1, .... , n + 1), andn+l\n2 yi =Ay.\ni= 1\nFrom additivity it follows by induction that Ay is an activity.The realism ofthe two hypotheses may be discussed briefly. First,consider divisibility, to which the more serious objections can beraised. In principie, we must distinguish between divisibility ofcommodities and divisibility of activities. There are many commodities (water, butter) that come in clearly divisible form and sorne(sugar, sand) for which the indivisible units are so small that theassumption of divisibility is clearly an excellent approximation. Onthe other hand, there are many commodities, particularly instruments of production (shovels, stamping mills) that come in indivisible units. Certainly, if commodities are indivisible, activitiesinvolving them cannot be divisible. lf it is possible to use oneshovel, it does not follow that there is any process in which half ashovel can be used. A more sophisticated example is that of storagecontainers. The usefulness of a storage container is proportionalto the surface area (that is, if the thickness of the walls is constant;it may have to increase somewhat with volume to resist the pressureof the contents). Therefore, the input is proportional to the twothirds power of the output. This case can be regarded formally\nPRODUCTION DECISIONS AND THE BOUNDEDNESS OF THE ECONOMY\n61\nas one of indivisibility; given the geometric shape of the container,containers of different size should be regarded as different commodities, each of which comes only in integer amounts. (This caseis possibly of wide economic importance. To a very considerableextent, the manufacturing of commodities in continuous-processindustries, such as chemicals, is the handling of materials in asequence of containers. It has been observed empirically that thecost of a chemical plant of fixed type rises less than proportionatelyto the capacity and indeed roughly as the 0.6 power.)Even if the divisibility of commodities is accepted, at least as anapproximation, that of divisibility of production activities does notfollow as a logical truth. Rather ít is an empirical generalizationthat, for the great majority of ordinary production processes, auniform reduction in scale preserves feasibility.The assumption of additivity, on the other hand, can always bedefended and indeed made essentially tautologous. The usualcriticism of additivity is that if all inputs are doubled, it still may notbe possible to double outputs because of limiting conditions such asinability to manage larger organizations. This means merely thatsorne relevant input has been omitted. Jf all relevant inputs arelisted, there is no reason why two activities cannot both be carriedon if their inputs are available.Sorne care must be taken, however, in the interpretation of theadditivity assumption in the context of economic equilibrium. Asalready remarked, not all inputs are, in fact, marketed. For themoment, let y be a possible production vector in which all commodities, marketed or not, are included as components, and Jet Ybe the set of possible production vectors (for a particular firm). Ifdivisibility and additivity are assumed, then Y is a convex cone.Suppose that sorne of the components are marketed, while others areprívate to the firm. For any vector y, Jet yM and yP be the vectorsformed by considering only the marketed and private components,respectively. For the firm, assume that the prívate components aregiven: yP = yP. From the viewpoint of the study of markets, onlythe vector y M is relevant; that is, we are interested in the set ofvectors YM = {yM 1 (yM,V) E Y}. It is trivial to observe that theconvexity of Y implies the convexity of YM, but YM need not exhibitconstant returns to scale.From this point on, suppose that the components of y are allmarketed. Then the discussion justifies the tentative assumption:\n62\nGENERAL COMPETITIVE ANALYSIS\nPRODUCTION DECISIONS ANO THE BOUNDEDNESS OF THE ECONOMY\nASSUMPTION 3.\nY¡ is convex.\nRemark. The firms must be assumed distinct, because we are, ineffect, assuming additivity across firms, but not necessarily acrossprocesses within a firm. It is the assumption of possible limitationalfactors to the firm that gives it its individuality.\nAccording to the previous argument, non-convexity arises onlybecause of indivisibility of commodities. Clearly, its economicsignificance is relatively less when the number of units is large.Thus, the difference between one stamping mill and none is important, but if the relevant choice is between 100 and 101 shovels, theassumption of divisibility is unlikely to be seriously misleading.The effects of non-convexity on the existence of equilibrium will bereconsidered along these lines in Chapter 7.\nWe will also refer to the set of possible production allocations thatdefine the production vector for each firm. This is the Cartesian·pr,oduct of the production possibility sets for the individual firms.\nqy = X Y 1 = {y¡, ... , YF 1 Yr E Y¡,\nDEFINITION 3.\nProduction Possibility Set of the Entire Economy\nf\nis a linear mapping of the set of possible production allocations intocommodity space.THEOREM l.\nO E qy; qy is el o sed and convex.\nThis theorem follows trivially from A.3.1-A.3.3.\nCorollary l.Y= LYr\nY=\n1.\nE\nA production vector may be regarded as possible for a set of firmsif it is the sum of vectors, each possible for a different firm of the set.Then, from D.3.2 and A.3.1, it is easy to see that any productionvector possible for a set of firms is possible for society as a whole(i.e., for the set of all firms). Let ft. ... ,j[( be distinct firms, andsupposeYr~E Yh\nL Yr.\nThen, formally,\n{y = t Yr Yr Y¡, allf} = t Y1\nO E Y; Y is convex.\nProof From T.3.1, since Y is the image of qy under the linearmapping\nf\nDEFINITION 2.\nNote that\nLYr\nThe entire production side of the economy is assumed composedof a finite number of (potential or actual) firms. The total production of the economy is the sum of the productions of the individualfirms. Note that if a commodity is an input to one firm and anoutput from another, the net output for society is the differencebetween the two. If y1 is the production vector for firm f, then\nis the production vector for society.Let Y be the social production possibility set.\n(k= 1, ... ,K).\nSet Yr =O ifjis distinct from any ofthe firms.t;,; by A.3.1, Yr E Y1 ,allf By D.3.2,\nf\nit does not follow from A.3.1-A.3.3 alone that Y is closed; thisproperty requires A.3.4 below.If Y1 is unbounded, then at certain p it may be that the firm wouldljke to produce on an infinitely large scale. This possibility, as such,.does not make it impossible to conduct an analysis of marketequilibrium with positive prices; although the firm is taken to supposethat it can sell and bu y whatever quantities it likes at the going prices,the economy, in fact, may be incapable of producing outputs andusing inputs in unlimited amounts. Indeed, if we are interested in. ·a world of scarcity, we ought to exclude the possibility. We willexamine a fairly weak assumption that ensures this.AssuMPTION 4.\nIf y E qy and ¿ Yr ::::: O, then y = O.f\nLYh = LYrE Y.k\nLEMMA 2.\nallf}\nf\nwhere F is the number of firms.3.\n63\nA.3.4 defines the problem of scarcity when\nf\nFor any set of distinct firms, ft. ... , ¡;\" ¿ Y1 e Y.Te\n~\nLYr >O;f\nr1\n64\nGENERAL COMPETITIVE ANALYSIS\nit states that society cannot produce something for nothing by anyorganization of its entire production apparatus. It is important toobserve that this basic property of a social production possibility setcannot be deduced from the corresponding properties of the firmproduction possibility sets. If, in A.3.4, we let y1 = O for all firmsbut one, then we can deduce the corresponding statement for a firm;that is, it cannot be that y1 > O for any possible y1 E Y1 • But theconverse is not true; from this last statement, A.3.4 cannot bededuced. For example, if firm A produces 2 units of commodity 2from 1 unit of commodity 1 and firm B produces 2 units of commodity 1 from 1 unit of commodity 2, then neither firm has outputswithout inputs, but together they can have a net output of 1 unit ofeach commodity with no net inputs.When\nA.3.4 says further that no non-trivial, socially possible productionprocess can be completely undone by another. For the validity ofthis irreversibility postulate, it suffices that there exists at least onenon-produced input that is needed, directly or indirectly, for allproduction; labor provides an obvious example. Alternatively, ifproduction takes time and differently dated commodities are distinguished, then reversa! of a process would require that sorne outputsprecede the corresponding inputs.Assumption A.3.4 implies that the economy must have an initialendowment of resources in order to produce anything. Let theinitial endowment be denoted by x.\nPRODUCTION DECISIONS AND THE BOUNDEDNESS OF THE ECONOMY\n65\nThe set of feasible production allocations is denoted by\nqp =\n@'n{y\\,'f>r + x~o}\nA feasible vector or allocation is one that society is capable ofcarrying out, given the existing resources.For later reference, it is important to add one more assumption,namely that the resources and technology of society together permitthe supply of a positive amount of all goods.AssuM¡:>TION 5.\nFor sorne y E Y, x + y » O.\nNote that if y is the social production possibility vector, y + x is thenet supply, which must be non-negative for feasibility. To insist onthe possibility of strict positivity means something like the following:Divide the commodities into produced and non-produced. Thenon-produced commodities all must be available initially in positiveamounts (a commodity that is neither produced nor availableinitially can surely be disregarded). If the divisibility of productionis assumed, assumption A.3.5 is eé¡uivalent to the surely innocuousproposition that if non-produced goods were available in unlimitedquantities, it would be feasible to produce a positive amount of anygiven produced good. Let P be the set of produced goods, N theset of non-produced goods, and for each i E P, let y 1 be a vector witha positive output of commodity i that would be feasible if there wereno restrictions on the availability of non-produced inputs. That is,\nyi > O\nyj ~ O\nforjE P.\nLet n be the number of produced goods,\nDEFINITION 4. The social production possibility vector y is feasibleif it is possible and\ny+ x ~O.\ny is a convex combination of vectors in Y, so y E Y. Also,all iEP,\nThe set of feasible production possibility vectors is denoted by\nY= Yn {y\n1\ny + x ~ 0}.\nby construction.that\nFor iEN, x1 >O; then choose a, O< a::; 1, so\nDEFINITION 5. The production allocation !) is feasible if y1 ispossible for each f (i.e., if y E W) and if\n2 Yr +:X~ O.f\nall i E N.Since x1 ~O, i EP,all i E P.\n66\nGENERAL COMPETITIVE ANALYSIS\nPRODUCTION DECISIONS AND THE BOUNDEDNESS OF THE ECONOMY\nLet y = ay. Since Y is divisible, y E Y, and by construction,:X + y » O, as assumed in A.3.5.Now it is essential to demonstrate that the set of feasible production allocations is bounded. Por any real number g, let\ng+ = max(g,O)\ng- = max(- g,o),\nis an index of net inputs to society, while L(Jf) and U(!f) are indicesof inputs and outputs, respectively, totalled over firms withoutcancelling inputs of one firm against outputs of another.Let us expand & to include all allocations for 'which the inputssatisfy (3); that is, define\nso that\n(4)\ng- ;:::: o.\ng = g+ - g-\nTo prove qfi bounded, it certainly suffices to show that the larger set,Al so, qy is closed by T.3.1, the set\nPor a vector, x, define upper and lower bounds,\nU(x)\n=.L: x/\n¿x\nL(x) =\nj\n67\nq¡j*, is bounded.\n1-.\nj\nObviously, a set of vectors, S, is bounded if and only if U(x) andL(x) are both bounded from above as x varies over S.\nis closed since it is defined by the continuous function\nTHEOREM 2. If A.3.1-A.3.4 hold, then the set of feasible productionallocations, &, is compact and convex.\nProof.\nPor any lf E qy = X Y1, let y = 2: y1 .f\nand the intersection of closed sets is closed, so that Cfl/* is closed.Prom (2) and the definition of q¡j*·, (4),\nThen\nf\nU(!f) +\nL; (y¡t¡ -y¡¡)= L;Yn = Y1 2 -y¡-,f\nf\nThenU(!f) +\nL(f Yr) 2 L(Jf).\n(5)\nL(f ~Yr) = aL(f Yr) ~ aU(x) ~ U(x),\n(2)\nso that alfE q¡j*.Let\nPor lf E qfi, lf is feasible; that is,\n¿y, 2 -:X,f\nfor !fE q¡j*;\nhence, to prove the boundedness of qij*, it suffices to show that U(!f)is bounded there, for then the boundedness of L(!f) follows by (5).If U(!f) ~ 1, alllf E q¡j*, then there is nothing to pro ve. Supposethat U(!f) > 1, sorne lf E q¡j*. Por any such lf• let a = 1/ U(!f) < l.By divisibility, ay1 E Y¡, allj, so that alfE qy. Also,\nor\nSum over i.\nU(x) 2L(Jf)\nAlso, U(a!f) = aU(!f) = 1, by definition of a.\nq¡j** = q¡j* n{!f 1 U(!f) = 1}.\n'\nIt has just been shown that\nso thatfor lf E&.\n(3)\nL and U may be thought of as indices of inputs and outputs,respectively; then\nif\nU(Jf) > 1\nand\n1a = U(Jf)'\nthen\nalfE Cfl/**.\nTo pro ve the boundedness of qij*, note that it is sufficient to showthat\nL(f Yr) bounded away from zero on qij**.\n(6)\n'/\n68Suppose (6) true.\nPRODUCTION DECISIONS AND TI-lE BOUNDEDNESS OF THE ECONOMY\nGENERAL COMPETITIVE ANALYSIS\nCorollary 2.\nThen for any lf for which U(!f) > 1,\nL(f rxy¡) = rxL(f Yr)\n¿\ne>\nO,\nY is closed.\nProo.f. That x was actually the endowment vector did not enterthe proof of T.3.2; what was shown was that the set\nwn{vj_'f>r + x¿o}\nso that\n1 L(2. Yr)\nu(-)U(!f) = - ::::; _ r _ ::::; ~;\nex\ne\ne\nthus, for !/E qtj*, either U(y) ::::; 1 or U(!J) :i; U(x)je, so that U(!J) iscertainly bounded on qt}*, and qtj* is bounded.It remains to demonstrate (6). The set, qt}**, is clearly closed;since U(y) is bounded on it by definition, (5) implies that qtj** isbounded and therefore compact. Recall that a continuous functionactually assumes a minimum value as the argument varies over acompact set; that is, if f(x) is continuous for x E S, where S iscompact, then, for sorne x E S, f(x) ¿ f(x), all x E S. It followsthat if f(x) > O, for x E S, then f(x) ¿ e > O, all x E S, wheree = f(x). Since\n2 yj = yv.f\nSince yv---+ y 0 , we can certainly find a vector x, with -x « y 0 , suchthatyj + x ¿ Oall v.\n2r\nThen ¡/ belongs to the compact set (7) for al! v. Therefore thereexists a subsequence converging to so me y 0 belonging to '!!/; hence,\nyv =\n2 yj converges to 2 Y7f\nf\n2Yrf\nhas at least one negative component, so thatfor lf E qt}**,as required.Thus, oJJ has been proved bounded. By definition, it is theintersection of closed convex sets and therefore is closed and convex.A closed bounded set is compact, so that T.3.2 has been demonstrated.\n2 Y7\nE\nY.\nf\n4.By A.3.4,\n'\nBut yv---+ y 0 ; henceyo=\nis a continuous function of qy on qt}**, it suffices that\nin order that (6) hold.Since U(O) = O =!= 1, then lf =!= O for lf E qtj**.\n(7)\nis compact for any vector x. Let y0 be a limit point of Y. Thenthere is a sequence, {yv}, yv E Y, yv---+ y0 . By D.3.2, there is, foreach v, a production allocation ij\" such that\nalong the subsequence.\n011 qt}**\n69\nCosts, Profits, an<l Supply\nIn this section, we will show how sorne of the assumptions ofChapter 2 can be derived as propositions in the theory of productionand establish a few results that will be used later in the book. Acomplete study of profit and supply functions is not intended.Suppose first that, in addition to A.3.1-A.3.3, we postulate thatYr is bounded above. Clearly this is not an assumption we shouldwish to retain indefinitely-it excludes, for instance, the case ofconstant returns to scale. When it is made, howover, then for givenpE Sn, the function PYr always attains a maximum on Y1 . Accordingly, we introduceDEFINITION 6.\n7Tr(P) = max py1 ,Y¡ E Y¡\nwhere 7T1(p) is the profit function of firm.f.\n70\nGENERAL COMPETITIVE ANALYSISBy A.3.1 we have 7T¡(p) ;::: O, all pE Sn.\nWe rnay also define\nr\nPRODUCTION DECISIONS AND THE BOUNDEDNESS OF THE ECONOMY\n71\ny1 E Y1} where Y1(p) is\nthat Y 1 admitsfree disposal, in other words, that y1 E Y 1 and y~ ::; y1irnply that y~ E Y1 . A set that adrnits free disposal necessarily hasfull dimensionality.\nOf course, sorne cornponents of rnernbers of Y1(p) will be negative.These denote dernands.W e now pro ve.\nTHEOREM 4. Let Y1 be bounded and strictly convex and adrnit freedisposal. Then (a) 7T¡(p) is a strictly convex function, and (b) Y1(p)has only one elernent for each p and can be written as a fUnction,\nDEFINITION 7. Y1(p) = {y 1 1 py1 = 7T¡(p),the supply correspondence of firrnf\nTHEOREM 3. If Y1 is bounded, then (a) 7T¡(p) is a continuous convexfunction over Sn; (b) Y1(p) is a convex set for each p.Proof (a) Let p, p' E Sn, p(a) = ap' + (1 - a)p, O ::; a ::; 1, andIet y1 E Y1(p), y~ E Y1(p'), y~ E Y1 [p(a)J. Then by D.3.6 and D.3.7,py~ ::; py¡\np'y~ ::; p'y~.\nHence, rnultiplying the first inequality by (1 - a), the second by a,and adding yield\n7T¡[p(a)J ::; (1 - a)7T¡(p) + tx7T¡(p'),so that 7T¡(p) is convex.To dernonstrate continuity, let {pv} be a sequence of price vectorsconverging to p 0 . For each. v, let y[ E Y1(pv). Then, for anyy1 E Y¡, pvyj ;::: pvy1 for all v. Since Y1 is compact, the sequence,{yf}, is bounded. Let y~ be any limit point; then p 0 y~ :2:: P0 Yr forany y1 E Y1 , so that by D.3.6 and D.3.7, Y? E Y1(p 0) and 7T¡(p 0) =poy7. Since y~ was any lirnit point of the bounded sequence {yf} andsince 7T¡(pv) = pvy¡, it has been shown that 7T¡(pv)---'>- 7T¡(p 0 ), andtherefore, 7T¡(p) is a continuous function.(b) Let y 1 , y~ E Y1(p). Then for O ::; a ::; 1, let y¡(a) = ay 1 +(1 - a)YÍ·\npy1(a) = apy1 + (1 - a)py~ = tx7T¡(p) + (1 - a)7T¡(p) = 7T¡(p).But y1(a) E Y 1 by A.3.3 and so belongs to Y1(p) by D.3.4.If one is willing to assurne Yr to be strictly convcx, the results canbe strengthened. (A set is strictly convex if every proper convexcombination of two points of the set belongs to the interior of theset relative to the srnallest linear space containing it. If the set hasfull dimensionality then the relative interior is the interior in theusual sense. A proper convex cornbination of x 1 and x 2 is a pointx = ax 1 + (1 - a)x 2 , for sorne a, O < a < 1.) We also assurne\ny¡(p).Proof Suppose that y 1 and y~ both belong to Y1(p). Then, inthe previous notation and by the rernarks just rnade, y¡(a) belongsto the interior of Y1 if O < a < l. Then there exists y~ » y1(a),y'f E Y1 . But then, since p > O, py'f > py¡(a) = 7T1(p) by T.3.3(b), acontradiction to D.3.6 and D.3.7. It also follows that, forO < a <1, the inequalities used in proving T.3.3(a) are all strict, so that 7T¡(p)rnust be strictly convex.This theorern shows that the discussion in the previous chapter,in particular assurnption A.2.1, was based on the implicit suppositionof diminishing returns to scale. We can also easily prove the otherassurnptions rnade there. Of course, A.2.2, hornogeneity of degreezero, follows imrnediately from the nature of the rnaximizationprocess as far as the production side goes. Walras' law (A.2.3)cannot be discussed without considering the consurnption sector, butcontinuity (A.2.4) can now be demonstrated.\nTHEOREM 5. Let Y1 be bounded and strictly convex and admit freedisposal. Then y1(p) is continuous over Sn.Proof. Let pv---'>- p0 E Sn, and y[ = y(pv). Since Y 1 is cornpact,y[---'>- Y? E Y1 along sorne subsequence. By definition of the supplyfunction, pv[y)! - y1(p 0)] ;::: O, all v, so that, taking limits along theselected subsequence, p 0 [y7 - y1 (p 0 )] ;::: O. ijowever, frorn theu,niqueness of the profit-rnaxirnizing cornrnodity vector for each p,asserted in T.3.4(b), y7 = y1(p 0). Since this holds for any limitpoint, y7, T.3.5 has been established.\nLet us now return to the profit function. Since 7T¡(p) = py1(p), itis certainly continuous. We will show that 7T¡ is, in fact, differentiable and that 8?T1/8p¡ = y1¡(p). This rneans that, to a linearapproximation, the effect on profits of changing a price is thesarne whether inputs and outputs are adjusted optimally or leftunchanged.\ní72\nGENERAL COMPETITIVE ANALYSIS\nBy definition of profits and profit maximization, we have, for anychange h in the price vector,7r¡(p + h) = (p + h)Yr(P + h) ;:;>: (p + h)yr(p) = PYr(P) + hy¡(p)\nPRODUCTION DECISIONS AND THE BOUNDEDNESS OF THE ECONOMY\nLastly, let us consider the special case discussed in Section 2.1 1under the title, the L-economy. Here Y1 is a convex cone and notstrictly convex. Instead we consider the normalized cone,\n= 7r¡(p) + hy¡(p),\nYí = {YÍ YÍ = __!__ Yr,YrrJ\ni¡,,¡\n7r¡(p) = PYr(P) ;:;>: PYr(P + h) = (p + h)yr(P + h) - hyr(P + h)= 7r¡(p + h) - hy¡(p + h).Hence,\n73\nYr E Y¡, Yrr >\no};\nrecall the \"no joint production\" assumption, A.2.10(b ). With thefurther assumption that positive output requires some input, it iseasy to sho;v that Yí is bounded. We can now define:\nh[Yr(P + h) - Yr(P)] > 7rr(P + h) - 7r¡(p) - hyr(P) > OJhJJhl- .\nDEFINITION 8. The unit profit function for a firm having only asingle output and constant returns to scale is defined as\nFrom T.3.4, Yr(P + h) - Yr(P) approaches O as h approaches O;since h/JhJ is certainly bounded, the left-hand member of the aboveinequality approaches O, and therefore,\n7rí(p) = sup PYÍ·\nIim 7r¡(p + h) - 7r¡(p) - hy¡(p) =O·h~oJhJ'by definition, 7r1(p) is differentiable for any p E Sno while, by lettingh = tei, where ei is the ith unit row vector, (0, ... , O, 1,0, ... , 0), with1 in the ith place, we see that 87r1)8p¡ = Y!i·THEOREM 6. lf Yr is bounded and strictly convex and admits freedisposal, then the profit function 7rr(p) is everywhere differentiableand 87rrf8p¡ = Y!i(p).lf it is assumed, in addition, that the profit function is twicedifferentiable, certain very familiar propositions of production theoryemerge. By T.3.6,\nYfEY¡\nThe mínimum unit cost function of Section 2.11, C1(P), then 1sdefined byC1(p) = Pr - 7rí(p).\nIt follows at once from T.3.3 thatTHEOREM 7.\nC1(P) is a continuous concave function over Sn.\nThus the use of the fixed point in establishing the existence of equilibrium in an L-economy (see A.2.13(b)) is justified.Finally, we note a. very simple, but much-used, implication ofprofit maximization.THEOREM 8.\nIf Y7 E Y¡(p1'), k = 1,2, then (p 1 - p2)(y} - yJ) ;:;>: 0.\nIn particular, under the hypotheses of T.3.5,\n(pl _ p2)[y¡(pl) _ y1(p2)] ;::.: o.Proof Profit maximization implies that y} is at least as profitableas YJ at prices p 1 and vice versa.\nBut if 7r¡ is twice continuously differentiable, then the matrix({P7r rf8p¡8p 1) is symmetric; sin ce 7r1 is convex; it is al so positivesemi-definite.\nCorollary 6. 1f Y 1 is bounded and strictly convex and admits freedisposal and if the profit function, 7r¡(p), is twice differentiable, then(a) 8yrdép1 = 8yr 1f8pt for all i and }; (b) the matrix (8y¡;/8p 1) 1spositive semi-definite; and in particular, (e) 8yfif8p¡ ;:;>: O.\nIf these inequalities are added and the terms regrouped, the theoremis established.NotesThe general outlines of production theory in this chapter are commonto the neoclassical tradition and need no special reference. The\n74\nGENERAL COMPETITIVE ANALYSIS\nanalysis of production into activities, which underlies the en tire chapterand which constitutes a synthesis of the earlier \"fixed-coefficient\" and\"production function\" viewpoints, seems to have first appeared in theclassic paper of von Neumann [1937, 1945] on economic growth. Asystematic development of production theory from the activity analysisviewpoint first appeared in Koopmans [1951b]; the crucial importanceof assumptions of the type of A.3.4 in esta·blishing the boundedness ofthe set of feasible production allocations first appeared there.Section 2. For more extended discussion of the possibilities for andmeaning of divisibility in production, see the interchange betweenChamberlin [1948, 1949] and Hahn [1949] and also Menger [1954].Section 3. It has been shown by Debreu [1962] that, in fact, irreversibility is not necessary to the existence theorems to be established inChapter 5, but the proofs appear to become more comp!icated. Inview of the high acceptability of the irreversibility assumption, we ha venot felt it worthwhile to seek the added generality.Section 4. Most of the development of this section is parallel to thecorresponding theorems in consumer demand theory due primarily toSlutzky [1915]. More specifically, the application to the theory of thefirm and particularly Corollary 6 appears in Hotelling [1932]. Themethod of proof follows that of McKenzie [1956-57] for the consumerdemand case; see also Karlin [1959, Vol. I, pp. 265-273].\nGRESEUN\\VERS!rt DE PARIS 1 - PANTHÉON • SORBONNE\n90, ruede To!biac\n75634 PARIS CEDEX 13\nri\n1\nChapter Four\nCONSUMER DECISIONSAND EFFICIENT ALLOCATIONSA levelling rancorous rational sort ofmindThat never looked out of the eye of asaintOr out of a drunkard' s eye.-W. B. Yeats, Seven Sages\nl.\n.\n~\nConsumer Choice\nIt is assumed that there are a finite number of households, indexedby h; X¡, will represent the consumption vector of household h.Each household is also assumed to hold an initial endowment, X¡,, ofgoods; for convenience in exposition, we assume that it sells thisendowment at the going prices and uses the income to purchaseconsumption goods. Thus, all consumption can be regarded asnon-negative.The preferences of the households extend, among other commodities, to choices between labor and leisure and among different kindsof labor. Similarly, among the endowments of the household, themost important in practice are the capacities to perforni differenttypes of labor. To represent labor services, sorne slightly artificialconventions are needed.Let L be the set of labor services. For -a~ lq.Qqf.;:service i EL, letX¡,¡, the endowment, be undefstb6d th' mean tb.e lfWJ.~irnu¡;t1~;tll1.i¡¡mntof that service that household h is oapáble· Df·.supplying undet' anycircumstances. Thus, if i is a slhfl .h<!il(~'l{$s,e~~~d.<-p~ ..~ .xht = O. Ifi is an arduous occupation, it may be physically imposs1ble to supplyit at a very high rate; then xlti will be small. We define the individual's \"demand\" for labor service i, xlti, as the extent to which hissupply of that service falls short of the maximum he is capable ofsupplying; the amount of labor of type i supplied is then X¡,¡ - X¡,¡.Thus, if the individual is capable of teaching for 12 hours a day andalso capable of driving a bus for 12 hours a day and if, in fact, heteaches for eight hours a day and does not drive a bus at all, thenhis demand for \"teaching leisure\" is four hours and that for\n71\n75\n1i\nT!\n76\nGENERAL COMPETITIVE ANALYSIS\n\"bus-driving leisure\" 12 hours.constraints\nThe conventions u sed imply the\n(i EL).If xht < .Xht (i EL), then the individual is supplying labor of type i inthe amount .Xht - Xht· lf Xht > .X\"¡, then the individual is a netdemander of labor of type i in the amount Xht - .Xht; the second casemight arise, for example, for domestic or repair services. In thenotation introduced in Chapter 3, the net supply of labor of type i byhousehold h is (xht - .Xht)-, the net demand is (xht - Xnt) +.The amount of all types of labor that can be supplied is constrainednot merely by capabilities, but also by the scarcity oftime itself. Wehave not specified in what units labor is measured, so let Tht be theamount of time that labor activity i requires per unit. (Ordinarily,we measure labor by time, so that Tht = 1, but it might be measuredin terms of tasks performed, for example.) There is sorne limit Tonthe amount of time in the period under analysis (e.g., 24 hours in aday), so that the total labor supplied cannot exceed T;\n2\nTht(Xht -\n.x,,;)- :::; T.\niEL\nIt is al so true that at least so me types of consumption of goods (otherthan types of leisure) require time. Let Tht be the amount of timerequired to consume a unit of good i (i 1 L); Jet T~t be the amount oftime required to consume the services of a unit of labor of type i.Then the time constraint becomes\nCONSUMER DECISIONS AND EFFICIENT ALLOCATIONS\nAssuMPTION l. The consumption possibility set Xh for individual his closed and convex; xlt :::: O for xlt E Xh.Note that the time constraints are satisfied with strict inequalityif Xht = .Xht (i EL), Xht = O (i 1 L). Then we can choose a, O < a <1, so that the time constraints are satisfied by the vector x\" definedby Xht = a.Xht (i EL), Xht = O (i 1 L). Then certainly\nxhi :::; .xhtX~tt < X~tt\nall i,if Xnt > O.\nThis argument justifies the assumption,AssuMPTION 2.such that\nThere exists a possible consumption vector\nxhi :::; .x,,¡Xnt\n< .X!tt\nx\" X\",E\nall i,if .Xitt >O,\nwhere xlt is the initial endowment for household h.The income. of a household is assumed to derive from two sources:the sale of the initial endowment and the share held by the householdin the profits of firms. lt is assumed that household h owns afraction, dhf, of firmf and shares to that extent in the profits. Ofcourse, d1, 1 must be non-negative, though it may be zero, and foreach firm the total amount of profits is allocated to different households.AssuMPTION 3. For each household h the total income Mh at any setof prices p and any given set of production decisions y1 is given byM\" = px\" +\n2 dh!(PY¡)f\nLater on, the general equilibrium model will be reinterpreted to applyto many time periods simultaneously. The individuals are assumedto make their labor and consumption choices simültaneously for thefuture as well as for the present. Then there is a time constraint foreach period.For subsequent purposes this' detailed description of the consumption possibility set will be used only as informal justification forcertain axioms. The set has been characterized as the set of nonnegative vectors that, in addition, satisfy certain inequalities. It iseasy to verify that the set of vectors x,., which satisfy these inequalities,1s convex.\n77\nwhere dlt 1 :::: O,\n2 dltf = l.h\nAs stated, A.4.3 implies that each firm is a partnership, since thehousehold shares in losses as well as profits. However, sinceO E Y1 , a profit-maximizing firm will always choose y 1 so thatpy1 :::: pO = O; therefore, atan equilibrium in which firms maximizeprofits, it could have been assumed equally well that the firms areincorporated, with limited liability for stockholders.The alm of the household is to choose the most preferred pointamong the commodity vectors available to it at a given set of pricesand a given income. Its preferences are, as usual, assumed to bedefined by an ordering of al! commodity vectors in its consumptionpossibility set. The following assumptions will be made:\n78\nT\nGENERAL COMPETITIVE ANALYSIS\nCONSUMER DECISIONS AND EFFICIENT ALLOCATIONS\nAssUMPTION 4. Por each h, there is a relation, >n (interpreted\"preferred or indifferent \"), for pairs of elements in the consumptionpossibility set, Xn, with the following properties:(a) Transitivity:\nxk >n x~ and x~ >n x~ imply xk >h x~;(b) Connexity:Por all xk and x~ in X~¡, either x~ >h x~ or x~ >n xk;(e) Continuity:\nmust contain xk by definition of a closed set; that is, x~ >h xk,contrary to the assumption xli >-\" x~.The assumption (d) of convexity is, as always, something of astumbling block; it will be seen in Chapter 7 that it can be relaxed.The semi-strictness condition is designed to avoid local satiation, asshown by the following lemma.LEMMA l. (a) Local non-satiation: For every xli E X\" there existsx~ E Xn arbitrarily close to xli for which x~ >-/¡ x~.(b) Convexity: For any x~, the set {x\" 1x\"x~} is convex.\n>\"\n(a) By A.4.4(e), there exists x~ >- x/i. By (d), x~ =(1 - a)x~ + exx/i >-\" x~ forO :::; ex < l. For ex arbitrarily el ose to 1,can be made arbitrarily close to xk.'(b) Let xli and x~ E {x\" 1 x\"x~}, and let x\" = (1 - a)x~ -:0exx~, O :::; ex :::; l. We seek to prove that x\"X¡, for all ex.Th1s IStrivial if ex = O or 1, so assume O < ex < l. From A.4.4(b), assumex~. Choose x;;' so thatwithout loss of generality that xkx* >- x 1 x* arbitrarily el ose to xk. Then x~ >-\" x~ by transitivityhh \"'/¡**and A.4.4(b). Let x;;'* = (1 - ex)x;;' + exx~. By A.4.4(d), x\" >-\"x~, and by transitivity, x;;'* >-h x~, and, in particular, x;;'* E {x\" 1~\";p:\" x~}. Since x; is arbitrarily close to xJi, x;;'* can be chosen arb!trarily close to x\". Hence, x, is a limit point of the set {xh Xn :P:\"x~}; by continuity (A.4.4(c)) Xn belongs to this set.\n1¡\nProof.\nPor any given x~, the sets {xh 1 X~¡ >h x~}and {xh 1 x~ :P:h X~¡} are closed;\nxr\n(d) Semi-strict convexity:\nIf xk >-n x~ andO .:::;; ex < 1, then (1 - ex)xk + exx~ >-h x~;\n>\"\n>\n>\"\n(e) Non-satiation:There is no X~ such that X~ >=h Xn for all X~¡ E xh.The notation >- h used in (d) is defined by\nxk >-h x~ means xk:P:n x~ and not x~ >n xk;that is, xk >- x~ means that xk is preferred to x~.Connexity (b),\n79\nIn view of\nxJi >-h x~ if and only if not x~ >n xk.The assumptions of A.4.4 are fairly stanuard. Parts (a) and (b)state simply that the individual is capable of ranking alternativecommodity vectors in order of preference. Part (e) and the term\"continuity\". attached to it, may be slightly less familiar. Thepreference ordering is assumed to be continuous in the sense that astrict preference between two vectors is not altered if either isaltered by sufficiently small amounts; in symbols, if xJi >-n xn, thenthere are neighborhoods, N 1 and N 2 , of xk and x~, respectively, suchthat X~¡ >- h x~ for all x\" E N 1 and xk >- h Xn for all Xn E N 2 •This statement is equivalent to A.4.4(c). Suppose, for example,there was no such neighborhood, N 1 • Then in every neighborhoodof xli there would exist Xn such that x~ :P:h x\", that is, a member ofthe set {xa 1 x~ :P:\" x,¡}. Since (e) asserts that this set is closed, it\n1\nAnalogous to the choice of production vectors in the profitmaximizing firm, there is a choice of preferred consumption vectorsby the household. We will speak of a preferred vector for a givenset S e X\" as a vector :X,, such that :X\" E S and Xn :P:\" X~¡ for allx\" E S. The demand functions or their generalizations are thepreferred vectors x\" E X\" for the set satisfying the budget constraint,\npx,:::; Mn.As in the case of the firm, no preferred vector need exist; supposethe price of a commodity is zero and the household is never satiatedwith regard to that commodity. Further, it is also possible thatthere is not a unique preferred point; there may be a set of commodity vectors satisfying the budget constraint, indifferent to eachother and preferred to all other bundles in Xn satisfying the budgetconstraint. This possibility requires that the indifference surfacesha ve flat sections, as, for example, when two commodities are perfect\n¡'1'\ni:\n80\n11\nGENERAL COMPETITIVE ANALYSIS\nsubstitutes or when one commodity does not enter into consumptionat all.If p > O, as we shall assume, and py1 ;::: O, all j, thenthe possible consumption vector, X¡¡, whose existence was guaranteedby A.4.2, obviously satisfies the budget constraint. Thus, in any competitive equilibrium, we can as sume that the individual will achieve asatisfaction (in terms of the ordering about to be introduced) at leastas high as that achievable fromx¡¡.\nRemark.\nTo ensure the existence of equilibrium, the demand for commodities should vary continuously with the prices, in sorne appropriate sense of continuity. The hypotheses made do not ensure thisresult. Suppose there are two goods in the economy, and anindividual has an initial stock of good 1, but none of good 2 and noshare of any firm. Hold the price of good 2 constant, and Jet p 1approach O. The budget constraint requires that\n11\nCONSUMER DECISIONS AND EFFICIENT ALLOCATIONS\n81\nLEMMA 2. If x;!' is a preferred vector subject to a budget constraint,px\" :s; M¡¡, x\" E X 1., then x;!' minimizes px\" subject to the constraintx\"x;!'.Proof. Suppose the conclusion is false. Then there existsxk x;!', for which pxk < px;!'. By local non-satiation (Lemma4.1(a)), there exists x~ arbitrarily close to xk, for which x~xk and,therefore, x~xt. By choosing x~ close enough to xk we canguarantee px~ :s; px;!' :s; M¡¡, which contradicts the hypothesis thatx;!' is pref~rred in the budget constraint.\n>\">\"\n>h\n>\"\nThe converse of Lemma 4.2 is valid only if expenditures are abovethe mínimum possible.\n>h\nLEMMA 3. If x;!' minimizes px¡¡ subject to the constraint X¡¡x~and if px;!' > pxk for so me xk E X¡¡, then x;!' is preferred in the budgetconstraint, px¡¡ :s; px;!'.\nProof.\nConsider any x~ E X¡¡ for which px~ :s; px;!'.X¡¡(a) = (1 - a)x~ + axk;\nLet\nthenso that for p 1 > O, X¡¡ 1 :s; X¡¡ 1 . On the other hand, when p 1 = O, theset of commodity vectors compatible with the budget constraint isthe set of all pairs, (X¡¡ 1 ,0), and the chosen value of X¡¡ 1 ' may, beconsiderably Iarger than .X¡¡ 1 • This discontinuity will necessarilyoccur in sorne part of the price space, except in the unrealisticcase in which the household has a positive initial holding ofgoods.On the other hand, there is another optimization problem that isvery similar to choice of the preferred point under a budget constraint, but for which the chosen point varies, in an appropriatesense, continuously with prices. This is the problem of choosing X¡¡to minimize the cost of achieving a given leve! of satisfaction, orformally, minimizing px¡¡ subject to the constraint that X¡¡x~ forsorne prescribed x~. The chosen bundle is usually known in economic Iiterature as the compensated demand function, since realincome (leve! of satisfaction) is held constant, we imagine, byaccompanying each change of price vector with a change of nominalincome so that the commodity vector indifferent to the original onecan be achieved.The uncompensated and compensated demand functions areclosely related.\nall\n>h\n,,,\n'1'\"\n.'¡,,,\n¡/'11\n1''11\n,1¡1\n11,\npx¡¡(a) = (1 - a)px~ + apxk < px;!'\nforO < a :s; l.\n>h\nIf X¡¡(a)x~, then by hypothesis, px; :s; px¡¡(a). Hence, x~ )>¡¡x\"(a) and, therefore, X¡¡( a) E {xh x~ >\"X¡¡}. Since this last set isclosed, it contains lim X¡¡( a) = x~. Since x;!'x~, x;!'x~ for any1\n>h\na->0\n>\"\nx~ for which px~ :s; px;!'.\nIn fact, the failure of the compensated demand functions to agreewith the uncompensated functions on the boundary of the pricedomain is useful, for it can be shown that the compensated demandfunctions are continuous in an appropriate sense. Since thesefunctions may be multi-valued, as we have seen, we need a broaderconcept of continuity. A multi-valued function will be called acorrespondence; we define the correspondence <P(x) to be upper semicontinuous if for any sequences {xv}, {yv}, the conditions xv-+ x,yv-+ y, yv E cp(xv), imply that y E <D(x).Also, defining the compensated demand correspondence, X¡¡(p,x~) ={x~ x~ minimizes px¡¡ subject to X¡¡ E X¡¡, X¡¡>\" x~}.1\nLEMMA 4. · X¡¡(p,x~) is upper semi-continuous in p for fixed x~.\nProof.\nLet {pv} be a sequence with pv-+ p; suppose x); EThen x)'¡x~, all v, and by continuity of\nX\"(pv,x~) and x)'¡-+ X¡¡.\n>h\n,·r-;·¡\n82\n~\n11· .1;\n1\nill\nT\nGENERAL COMPETITIVE ANAL YSIS\npreferences, x, ~\" xW. Take any x~ such that x~ ~\" xW. Then, bydefinition of X,.(pv,xg), pvx¡; ::::; pvx~. In the limit, px,. ::::; px~.\nQ.E.D.\n'•\nWe will not in fact make use of Lemma 4.4 as it stands, but itmotivates the strategy for proving the existence of competitiveequilibrium used in Chapter 5. It is easier to establish the existenceof an equilibrium in a compensated sense because the compensateddemand correspondences are continuous; then it has to be shown(with the aid of an additional assumption) that the compensatedequilibrium assigns each individual an expenditure above theminimal possible, so· that the individual is in fact achieving a preferred point under the budget constraint.\nCONSUMER DECISIONS AND EFFICIENT ALLOCATIONS\nof x, U(x), is taken to be the distance from x 0 to the set of pointspreferred or indifferent to x. (By the distance from a point to a setis meant the smallest distance from the given point to any point ofthe set.)Then letC(x) = {x' J x' ~ x}be the upper contour set through x. By A.4.4(c), this set is closed.Let p(x) = Jx - x 0 J, the distance from x 0 to x. Since p(x') is acontinuous function bounded from below (it is non-negative) andC(x) is closed, p(x') has a mínimum as x' varíes over C(x). WedefineU(x) =\n·1 ,,\n2.\nUtility Functions\nIt turns out that the assumption A.4.4 made on the preferencerelation suffices to permit a continuous numerical representation.\nDEFINITION l. A real-valued function, uh, defined on x,, is autility function if it has the property that xk ~\" x~ if and only ifU11(xk) ;::: U11 (x~).The numerical representation, although it can be d'spehsed with,is extremely useful in simplifying the proofs.Since we are dealing with a single household in this section, wewill omit the subscript h in all uses in order to lighten the notationalburden. Also, for the purpose of establishing the existence of acontinuous utility function, we will not need the full force of A.4.4,only assumptions (a), (b), and (e) (transitivity, connexity, andcontinuity).The two assumptions that play the most important roles indemonstrating the existence of a numerical representation are thecontinuity ofthe ordering (A.4.4(c)) and the convexity of X (actually,the latter could be replaced by the much weaker assumption that anytwo points in X could be connected by a continuous path entirelycontained in X; for a convex set, the line segment joining two givenpoints is such a path)..First, a utility function is constructed for a subset of X. ~pec¡fi­cally an arbitrary element, x 0 E X, is chosen, and a contmuousutilit~ function is constructed for the subset of X for which x ~. ~ 0 •The method is simple: For any x satisfying this condition, the utlhty\n83\nmin p(x),X'EG(X)\n(1)\nand we will show that U(x) is indeed a continuous utility function.The mínimum in (1) is taken on at one or more points of C(x); letM(x) = C(x) n·{x' / p(x') = U(x)}.\n(2)\nSince M(x) e C(x), clearly x' ~ x for all x' E M(x). In fact, itmust be that x' \"' x. Suppose that x' E M(x), x' >- x. There is,by Continuity, a neighborhood of x' such that x\" ~ x for all x\" inthe neighborhood. Choose a > O, but sufficiently small so that(1 - a)x' + ax 0 ~ x; in particular, choose a < l. But\np[(1 - a)x' + ax~] = /(1 - a)x' + ax 0 - x 0 J= (1 - a)Jx' - x 0 J = (1 - a)p(x') = (1 - a)U(x).\nBy definition (1), U(x) ::::; p[(l - a)x' + ax 0 ], so that (1 - a)U(x) ;:::U(x) or U(x) ::::; O. Since U(x) has been defined to be non-negative,U(x) = O. Therefore p(x') = O, or x' = x 0 • Since we are considering only x ~ x 0 , however, the assumption x' >- x has beencontradicted.If x' E M(x),\nthen\nx' \"' x.\n(3)\nTo show that U(x) is a utility function, it suffices by D.4.1 andConnexity, A.4.4(b), to show that x 1 ~ x 2 implies U(x 1 ) ;::: U(x 2 )and that x 1 >- x 2 implies U(x 1 ) > U(x 2 ). The first follows immediately from the definition of U(x), (1), and Transitivity (A.4.4(a));Transitivity implies that C(x 1) e C(x 2), the minimization in (1)occurs over a subset, and hence the mínimum achieved cannot beany lower. Now suppose that x 1 >- x 2 . Then M(x 1) e C(x 1 ) e\n84\nGENERAL COMPETITIVE ANALYSISCONSUMER DECISIONS AND EFFICIENT ALLOCATIONS\nC(x 2). If U(x 1) = U(x 2), then M(x 1) e M(x 2), by (2). If x' EM(x 1), then by (3), x' \"' x 1 and also x' \"' x 2 , so that x 1 \"' x 2 , a contradiction. Since we know that U(x 1) ;;:; U(x 2) and ha ve just shownthat U(x 1 ) #- U(x 2 ), it must be that U(x 1) > U(x 2 ). Therefore U(x)is a utility function for those x E X for which x :p:: x 0 •To demonstrate that U(x) is a continuous function, it suffices toshow that for every real number u, the two sets {x J U(x) ;:::: u} and{x 1 U(x) s u} are closed. Consider the first set. Let {xv} be asequence such that U(xv) ;:::: u, aii v, xv--¿. x. Let x'' be any elementof M(x); by Lemma 4.l(a), we can choose x\" >- x' and arbitrarilyclose. Certainly, U(x\") ::::; p(x\"), by(!). On the other hand, sincex\" :P:: x' and . x' \"' x, by (3), x\" >- x. By Continuity, x\" :p:: xv for aiiv sufficiently large, U(x\") ;:::: U(xv) ;:::: u, so that p(x\") ;:::: u. But x\"can be chosen as el ose as desired to x'; since p(x) is continuous, wecan assert that u ::::; p(x') = U(x), so that the set {x 1 U(x) ;:::: u} hasbeen shown to be closed., Now let {xv} be any sequence such that U(xv) ::::; u, aii v, xv--¿. x.For each v, choose x'v E M(x'). Since p(x'') = U(xv), we have thatp(x'') s u, aii v. Thus, the sequence {x''} is bounded and thereforehas a limit point x', for which p(x') ::::; u. Since x'v \"' xv, by (3) andxv ->- x, it foilows, by restricting attention to the subsequence of{x'v} that converges to x', that x' \"' x, where use is made of theContinuity of preferences. Then by definition of U(x) and the factthat it is a utility function,U(x) = U(x') ::::; p(x') ::::; u,\nso that the set {x 1 U(x) ::::; u} is indeed closed, and therefore, U(x)is a continuous utility function over the set {x 1 x :p:: x 0 }.It remains to extend U(x) in sorne appropriate way to the entireconsumption possibility set, X. If there is a least preferred point,that is, a point x 0 such that x :P:: x 0 for aii x E X, then simply choose0x in the previous construction. Otherwise, for every x E X, thereexists x' E X such that x >- x', and we consider this case. It will beshown next that\nNow Iet X 1 be any compact subset of X and X\" any finite subset ofX'. By Transitivity, we see thatX' n{x' 1 x\" :P:: x'} e X' n{x' 1 x :P:: x'}\nTo see this, consider first any finite subset X\" of X. Then byTransitivity, there certainly exists a least preferred point x\" of X\".\nfor all x E X 1',\nor equivalently,X' n{x' 1 x\" >== x'} =\nn [X' n{x' X>== x'}];1\nXEX\"\nthat is, the set of consumption vectors x' in X' not superior to x\"is the intersection of the sets of consumption vectors not superior tothe various members of X\". Since X 1' belongs to the left-hand set, wesee that the intersection on the right is non-null. The setsX' n{x' 1 x :P:: x'}\nare compact sets. If we consider the entire family of such sets asx varíes over X', it has been shown that the intersection of anyfinite subfamily is non-null. By a well-known theorem of analysis,it follows that the intersection of all such sets is non-null, so that thereexists x* such that,x* E X' n{x' 1 x :p:: X 1}\nfor all x in X',\nand therefore x :P:: x* for aii x E X', x* E X'.In particular, for any fixed positive integer /1-, the set X n{x [lxl ::; P-} is compact; it is non-null for aii 11- sufficiently large.By (4), it has a least preferred point, x 0 ~\". Further, since\nXn {x [lxl : : ; P-} e Xn {x [lxl : : ; 11- + 1},it must be true that x 011 :p:: x 0 •11 + 1 for all 11-·Since we are now assuming that X has no least preferred point, itis true that for every 11- there exists an x E X such that x 0 ~\" >- x. Byconstruction, it must be that /x/ > 11-· For any 11-' ;:::: /x/, x 0 ~\"' <. x,by construction. Now define 11-(v) recursively as follows:11-(l) = min{P-[ Xn {x [ /xl : : ; P-}\nAny compact non-null subset of X containsa least preferred point.\n85\nis non-null},\n11-(v + 1) = min{P- / x 0 u(v) >- x 0 ~\"}.\nBy the previous discussion, 11-(v + 1) ;:::: 11-(v) + 1, so that 11-(v) ;:::: v;and in particular 11-(v) ->- +oo. Define\n1'\n:¡' 111¡¡¡1llu:l!\n'1:,'1\nil\n'U\n87\nGENERAL COMPETITIVE ANALYSIS\nCONSUMER DECISIONS AND EFFICIENT ALLOCATIONS\nthen xv >- xv+ 1. Further, for any x E X, x:;:,: x 0 tt for p, :::-: lxl; therefore, for any x E X, x :;:,: xv for all v sufficiently large.The sequence {xv} has two basic properties: It is strictly decreasingin preference, xv >- xv+ 1 for all v, and every x E X is preferred orindifferent to xv for all v sufficiently large.We can take in turn each xv as the x 0 of our earlier constructionand find a continuous utility function for the set {x 1 x :;:,: xv}. LetU(x;xv) be this utility function. As is well known and obvious, ifU is a utility function and F(u) is a strictly increasing function onthe real numbers, then F[U(x)] is also a utility function in the senseof D.4.l. If F is continuous, then sois F[U(x)]. In particular, ifF(u) = a + bu, b > O, then a + bU(x) is a continuous utility function. Further, by suitable choice of a and b, this utility function canbe made to assume prescribed values at two given points.We will choose arbitrarily the utility values for the points xv.Then, for each v, a utility function will be chosen, by the procedurejust given, to as sume the prescribed val u es at xv - 1 and xv; if v = 1,only the value at x 1 is prescribed. Finally, the utility function isdefined for any given x as the value of the utility function associatedwith xv for the smallest v for which x:;:,: xv.Formally, let {uv} be a strictly decreasing sequence of realnumbers. For each v, define Uv(x) = av + bvU(x;xv) for x:;:,: xv bychoosing av,bv so that Uv(xv- 1) = Uv_ 1, Uv(xv) = Uv. (For v = 1,we require only that U1(x 1) = u1.) Then for each x, there isprecisely one v such that xv- 1 >- x:;:,: xv, or else x:;:,: x 1. LetU(x) = Uv(x). ·The function U(x) is then defined for all x. It remains to show,first, that U(x) is a utility function, and second, that it is continuous.It is obvious that if xa \"' xb, then U(xa) = U(xb). Suppose xa >- xb,There are three possibilities: (a) xa >- xb:;:,: x 1; (b) xv- 1 >xa >- xb:;:,: xv for .some v; (e) xa:;:,: xv >- xb for some v. If (a)holds, then U(xa) = U1(xa), U(xb) = U1(xb); since U1 is a utilityfunction, U(xa) > U(xb). If (b) holds, then similarly, U(xa) =Uv(xa), U(xb) = Uv(xb), and again U(xa) > U(xb). If (e) holds, letv' be the smallest v such that xa:;:,: xv, and v\" the largest v such thatxv >- xb; clearly, v' ;::.: v\", so that Uv• ;::.: Uv\"· Then U(xa) = Uv-(xa) :::-:Uv-(xV') = Uv•, and U(xb) = Uv\"+1(xb) < Uv\"+1(xV\") = Uv\" S Uv• SU(xa). Hence, U(x) is a utility function.It remains to pro ve continuity. If x >- x 1 or xv - 1 >- x :;:,: x• forsome v, then the same relation holds for x' sufficiently close to x, by\nContinuity, so that U(x') = U1(x') or Uv(x') in a neighborhood of x;since the functions Uv(x) are continuous at x, so is U(x).Now suppose x \"' xv for so me v. Let {xP} be a sequence such thatxP ->- x. If xP :;:,: x, all p, then xv - 1 >- xP for p sufficiently large, ifv > 1. Hence, U(xP) = Uv(xP) for p large; by continuity of Uv(x),Uv(xP) ->- Uv(x) = U(x). Similarly, if x >- xP for all p, xP :;:,: xv +1for p sufficiently large, U(xP) = Uv+ 1 (xP) for p large, and U(xP)--¿.Uv+l(x) = Uv+ 1(xv) = Uv = U(x). Finally, if the sequence {xP}contains some members inferior to x and others not inferior, we candivide it into two sequences, for each of which U(xP) converges toU(x).\n86\nTHEOREM l. Every preference ordering satisfying A.4.4(a)-(c) anddefined over a convex set can be represented by a continuous utilityfunction.To state the implications of A.4.4(d) for the utility function,introduce the definitionDEFINITION 2.concave if\nA function f(x) is said to be semi-strictly quasi-\nf(x 1) ;::.: f(x 2 )\nimplies f[ax 1 + (1 - a)x 2 ] :::-: f(x 2 ),\nand\nf(x 1) > f(x 2 )\nimplies f[ax 1 + (1 - a)x 2 ] > f(x 2 ),\nO<asl.\nAs noted earlier, if U(x) is a continuous utility function, then forany b > O, a + bU(x) is also a continuous utility function. Thisfreedom of choice will be used here to set a zero utility level. Withb = 1, we can always ensure that U(x) = O, where x is the possibleconsumption vector named in A.4.2.Then, with the aid of Lemma 4.1, we stateCorollary J. Under A.4.1 and A.4.4, for every household h thereis a continuous semi-strictly quasi-concave utility function, U¡,(x,.),defined on X,., such that for every xh, there exists x~ arbitrarily close,for which Uh(x~) > U¡,(xh), and such that U,.(xh) = O for a commodity vector, xh E xh, such that xh! S Xh¡, all i, Xh¡ < xhl if Xh¡ > o.\nThe airo of the consumer, then, is to maximize Uh(x,.) subject toxh E xh, px S M,., where Mh is defined in A.4.3.\n883.\nGENERAL COMPETITIVE ANAL YSIS\nIndividual- and Market-Excess Demands\nIn the discussion of equilibrium, we are primarily interested inexcess demands on the rnarket, that is, vectors z of the forrnz =\nL x\"- y- x,\nx\" E X\", y E Y.\nh\nCONSUMER DECISIONS AND EFFICIENT ALLOCATIONS\nponent, for then for each commodity aggregate supply, both fromproduction and from initial endowment, exceeds or equals aggregaterequirernents of consurners.DEFINITION 5. An allocation, w, isfeasible ifz(w) ~O.feasible allocations will be denoted by\nHere, because of our conventions as to signs,\nL:x\"h\nis the aggregate vector of demands by households, y the aggregatevector of goods supplied by firrns, and x the aggregate vector ofsupplies initially available before production. The excess-demandvector is a function of the decisions of all units of the economy,households and firms:\n89\nThe set of\nif' = irn{w 1 z(w) ~ 0}.THEOREM 2.convex.\nThe set of feasible allocations, if', is cornpact and\nProof. Frorn D.4.3., A.4.1., and A.3.3, iris a Cartesian productof convex sets and, therefore, convex. Since z(w) is a linearfunction, by D.4.4, the set {to 1 z(w) ~ O} is convex. By D.4.5,if' is the intersection of convex sets and, therefore, convex.Let @''be the projection of if' on I!Y, that is,@' = I!Y n {y 1 z(x,y) ~ O for sorne x E ,q[},\nIn D.3.3 we introduced the notion of a production allocation, whichis a large vector composed of vectors, each of which is a possibleproduction vector for one firm. As noted, it is an element of theCartesian product of the production possibility sets of the differentfirrns, X Y1 . Analogously, we introducerDEFINITION 3.\nand similarly Jet :f be the projection of if' on ,q[,\n:f = ,q[ n{x\nh\nand an allocation, to = (x,y), is a consumption allocation and aproduction allocation, that is, an element of the set\nz(x,y) ~ O for sorne ¿rE I!Y}.\nIf y E @', then\nLr Yr + x;;::: L x\";;::: O,\nA consumption allocation is any element, x, of\n,qr =X x\",\n1\nh\nfor sorne x E ,q[, so that, by D.3.5, @' e @, where qi} is the set offeasible production allocations. Then @ is bounded, as shown inT.3.2., and therefore, so is @<If x E :f, then x ;;::: O and\nir= ,q[ X i!Y.ll!:'lii1\n\"\n·''·i¡'1\n,,.\n1.1,¡:,.'•\n~i\n.\nz(w) =\nL:xh- LYr- x,\"\nr\nwhere\n1\nto = (x,y)Eifí'.11!;.1:.·11\n.!'1\n¡:;,¡' lr1\n,,1'1\n¡,!¡:\n,¡'!\n'!'i,i•L\nfor sorne y E I!Y.\nDEFINITION 4. The excess demand is a linear function over the setof allocations,\nTo say that an allocation is feasible is simply to say that thecorresponding excess-demand vector is non-positive in each com-\nBut then y rnust belong to @', by definition, and therefore, is boundedabove. If x ;::: O,\nL x,. bounded above\"\nfor x E :f,\nthen ic rnust be bounded. If the projections of if' on both ,qr andI!Y are bounded, however, then if' itself must be bounded. Since itis obviously closed, it must be cornpact.\n904.\nGENERAL COMPETITIVE ANALYSISFeasible and Efficient Utility Allocations\nWe will be interested in the possibility that a given householdachieves a certain utility level, and more generally, in the utilitylevels achieved by all households.DEFINITION 6.hold h is\nThe set of U¡¡-possible consumption vectors for house-\nXn(u¡¡) = {xn 1 U¡¡(X¡¡) ::0: uh}.\n,''\n11\nBy a utility allocation, u, we will mean a vector whose hthcomponent, u1, is a possible utility for household h.DEFINITION 7.\nThe set of u-possible consumption allocations is\n1'\n'1'\n1\ni 11'!!¡:li\nil1',\n'\n,,\n¡¡\n1.1'1\n!!\n1\n:\n1\n1\n1\n'\n'\n1\n~;,,\n'¡\nthat is, the Cartesian product of the sets of u1t-possible consumptionvectors for the different households h.DEFINITION 8.\nThe set of u-possible allocations isir(u) = ff(u) x ql/;\nthat is, a u-possible allocation is a u-possible consumption allocationand a possible production allocation.We will be interested in the excess demands corresponding to theu-possible allocations.DEFINITION 9. The set of u-possible excess demands is the image ofir(u) under the linear mapping z(w ), that is,Z(u) = {z 1 z = z(w)\nfor sorne toE \"/Y(u)}.\nAnalogous to the notion of feasibility is that of u-feasibility, theability of the economy to achieve a utility allocation u within thelimits of its resources.DEFINITION 10. The set of u~feasible allocations is the set of u-possible allocations that also are feasible;\"V(u) = \"/f\"(u) n{w 1 z(w) :::; o}.DEFINITION 11. A u~easible excess demand is the excess demandcorresponding toa u-feasible allocation; that is, Z(u) is the image of\"V(u) under the linear mapping z(w ).\nCONSUMER DECISIONS AND EFFICIENT ALLOCATIONS\n91\nTHEOREM 3. For each u, the set of u-feasible allocations 'if'(u) iscompact and convex.T.4.3 is proved exactly the same way as T.4.2, with Xn everywherereplaced by Xh(uh).Corollary 3.\nFor each u, Z(u) is compact and convex.\nProo.f From T.4.3, since Z(u) is the image of 'if'(u) under a linearand therefore continuous mapping.\nAmong the feasible utility allocations, we wish to characterizethose that are efficient in the appropriate sense, that of Pareto.DEFINITION 12. A utility allocation u1 is dominated by u2 if u2 isfeasible and u2 » u1 . A utility allocation, u, is Pareto efficient if itis feasible and not dominated by any other feasible utility allocation.We use the term \"Pareto efficient\" instead of the more common\"Pareto optimal\" beca use the latter term conveys more commendation than the concept should bear, since a Pareto-efficient allocationmight assign extremely low utilities to sorne (indeed, possibly to allbut one) households and thus not be optimal in any sense in whichdistributional ethics are involved., This definition differs somewhatfrom the conventional one, in which the statement u2 dominates u1is interpreted to mean u2 > u1 ; that is, everyone is at least as welloff and one person is better off. In our definition, the concept ofefficiency is somewhat wider than usual; an allocation is efficient ifthere is no·way of making everyone better off. The present definitionleads to simpler results and avoids sorne special, odd cases.The general plan of the analysis is to note that if z is an excessdemand vector for which z « O, it would appear to correspond to adominated allocation, since everyone can be given more of everycommodity; hence, if u is efficient, Z(u) is disjoint from the set{z 1 z « 0}. The two sets are convex and the second has an interior;hence, we can find a separating hyperplane, which can be shown toimply a price system such that the utility allocation u is realizedwhen each firm is maximizing profits and each household is minimizing the cost of achieving its prescribed utility level.LEMMA 5. If z E Z(u), there exist z',u', with z' E Z(u'), z' arbitrarilyclose to z and u' » u.\nGENERAL COMPETITIVE ANALYSIS\n92\nProof.\nCONSUMER DECISIONS AND EFFICIENT ALLOCATIONS\nLet\nz =\nL xh - L y1 - :X,h\nwhere xh E Xh(uh), Yr E Y,.\nf\nBy Corollary 1, x~ can be chosen arbitrarily el ose to xh with Uh(x~) >Uh(xn) = uh. Let\nz' =\nL x~ - L yr - X.h\nf\nThen by D.4.9, z' E Z(u'), where u~ = Uh(x~).LEMMA 6.\nIf u is Pareto efficient, then Z(u) is disjoint from\n{z 1 z « 0}.Proof. Suppose z E Z(u), z « O. By Lemma 4.5 we can findz' « O for which z' E Z(u'), u' » u. But then i(u') is non-null sothat u' is feasible and dominates u, contrary to the definition D.4.12of Pareto efficiency.We now use the well-known separation theorem for convex sets(see T.B.6).LEMMA 7. If A and B are disjoint convex sets in a finite-dimensional space and at least one has an interior, then ther~ exists avector p =1= O and a scalar e such thatpx ;:::: epx :;:; e\nfor all x E A,for all x E B.\nLEMMA 8. If A is a convex set disjoint from the set {x 1 x « 0},then there exists a vector p >O for which px e: O for all x E A.\nProof. Choose p as in Lemma 7, with B = {x x «O}; notethat B has an interior. Let x 0 « O, ei be the vector with 1 in theith component and O elsewhere, and A > O. Then1\nal! A > O,so thatall A > O.Divide through by A and let A approach infinity; then p¡ e: O. Thus,p ;:::: O; sin ce p =1= O, p > O.Also, let e be the vector all of whose components are l. Then- Ee « O, all E > O. Then e ;:::: - Epe; let E approach O, then e e: O.\nh\n!'li\n93\nHence, from px ;:::: e, all x E A, it can be concluded that px ;:::: O, allXEA.We now combine the disjunction assured by Lemma 4.6 with theseparation theorem, Lemma 4.8.\n'i,,,\n1\n·:.¡:\nTHEOREM 4. If u0 is Pareto efficient, there exists a vector p with thefollowing properties:(a)(b)(e)(d)\np > O;pz;::::O,allzEZ(u 0);pz =O, all z E Z(u 0);if (m\\~ 0 ) E i?'(u 0 ), so that the conditions Uh(x~) e: u~,y~ E Y,, and\n('1\n11'1,¡,\n,,1\n'1\nare satisfied, then(i) pxh is minimized over Xh(u~) at x~;(ii) py r is maximized o ver Yr at y~;. (iii) the social budget constraint,\n¿ px~ = ¿n [px¡¡ + ¿r dhf(py~)J,h\nis satisfied.\nProof. Conclusions (a) and (b) are simple consequences ofLemmas 4.6 and 4.8; in other words, Pareto efficiency implies thatZ(u 0) is disjoint from the set of strictly negative vectors, while Lemma4.8 assures the existence of a vector, p > O, for which (b) is true.If z E 2(u 0), then z :;:; O so that, from (a) pz :S: O; then (e) followsfrom (b). Note that, sin ce u0 is feasible, 2(u 0 ) is non-null.Statements (b) and (e) can be rephrased as follows: The mínimumvalue of pz for z E Z(u 0 ) is O and is attained at any z 0 in 2(u 0 ), that is,any z 0 E Z(u 0 ) for which z 0 :;:; O.The hypothesis of (d) is precisely that z 0 :S: O, wherez o = L.,xhL.,YrL.. X¡¡.\"\" o\"\" o\"\"li\nf\nh\nFor any z in Z(u 0), we can, by definition, choose X¡¡ E Xh(u~), Yr E Y,,so that\n:!\n~\n¡1'1;1\n,'1:\n'\n',\n94\nGENERAL COMPETITIVE ANAL YSIS\nCONSUMER DECISIONS AND EFFICIENT ALLOCATIONS\nThen pz ~ pz 0 , or\nP(.Lx\"LYr_Lx\")~ p(_LxgLY~_Lx\")hfhhfhfor all x\" E Xh(ug), y1 E Y1.Add p(~ x,.) to both si des and rewrite slightly:\nL pxh - L PY1 ~ L pxg - L pyg,h\nf\nh\nf\nall x\" E Xh(ug), y1 E Y1.!he va~iables on the left-hand side are independent so that themequahty must hold term-by-term. In more detail let y = y 0 allo1•'f,,f , x\". = x~ for h i= h. Then 1f we cancel all terms in pxg(h i= h')and m py1 from both sides, we havefor all Xh' E Xh'(ug,),which is (i). Statement (ii) follows similar! y; statement (iii) issimply a restatement of (e).T.4.4 is t~e basic e~ciency theorem of welfare economics. AnyPar~t.o-~ffictent allocatwn can be realized as a sort of competitiveeqmhbnum. If an omniscient state wishes to realize a givenPareto-efficient allocation, it computes a price vector, p, satisfyinghypotheses of the theorem. Then it chooses for each individual aninitial endowment, x\", and ownership shares, dhf, in the differentfirms, so that\npxg = px\" + ¿ dhf(PY~)\neach h\nf\nand, óf course,\nThese equations certainly can be sol ved beca use of (d-iii).example, let each individual h have the proportion\nPor\npxg¿pxgh\nof every initially available good and every firm.Then, indeed, at the given prices, each firm will maximize itsprofits at the desired production vector and each household will\n95\nminimize the cost of achieving the given utility leve! at the desiredconsumption vector, at the same time spending exactly the value ofendowment in goods and shares. Thus, in a certain sense, anydesired efficient allocation can be achiev.ed by redistribution of initialassets, followed by the achievement of an equilibriUm. However,there are severa! important qualifications that should be kept inmind.The most obvious and perhaps most important qualification isthat the assumptions made so far have to be satisfied. The mostimportant of these are the convexity of production possibility setsand orderings (the first is much more significant, as the discussionin Chapter 7 will show). Also implicit so far has been the absenceof externalities; preferences and production possibilities are notaffected by the behavior of other economic agents. This problemwill be considered again in Section 6.2.The informational requirements as stated are far beyond thepossible. Methods of successive approximations are needed, butthis, in turn, implies an ability to measure utility levels alreadyachieved.The equilibrium, as defined, is not precisely the competitiveequilibrium in the usual sense. As already noted in Section 4.1, itis rather a compensated equilibrium. The relations between theseconcepts are discussed in detail in Section 5.1.Sorne of the initial endowments reflect labor skills; it is hard toimagine that, in fact, they can be redistributed from one individualto another. The redistribution must take the form of abstractpurchasing power.Por any given distribution of initial assets, the resulting equilibrium might not be unique (see Chapter 9) or stable (see Chapters11-13). Therefore, if the state merely allocates endowments, itcannot always be sure that the market will achieve the desiredPareto-optimal allocation. Of course, if the state also announcesthe price vector, then competitive forces will maintain thát vector.A more extended analysis of the welfare implications of T.4.4 isbeyond the scope of this book, which is concerned with the properties of competitive equilibria; T.4.4 has been proved here as a stepin demonstrating the existence of equilibrium.It has not been implied that the price vector p that will supporta given Pareto-efficient utility allocation is unique. The essential\n,,,,,\n¡1'',\n11\nillll1:!'\n,d',il\ni,,l'1\n.\n1\n111:1\\\nCONSUMER DECISJONS AND EFFICIENT .;\\LLOCATIONS\nGENERAL COMPETITIVE ANALYSIS\n96\nproperties are (a) and (b) of T.4.4; any price satisfying those conditions automatically satisfies (e) and (d). It is obvious that if psatisfies (a) and (b ), then so does ,\\p for any ,\\ > O. This is the usualhomogeneity property of prices. Then, without loss of essentialgenerality, we can restrict ourselves to price vectors p for whichpe = 1, where, it will be recalled, e = (1, ... , 1).Even among these normalized price vectors there may be morethan one satisfying (a) and (b). LetDEFINITION 13.\nU= {u 1 u Pareto efficient} = Pareto frontier.\nDEFINITION 14. P(u) = {p p > 0, pe= 1, pz ::0: 0 for aH Z EZ(u)}.1\nT.4.4 asserts that P(u) is non-m1ll for u E U. We will consider P(u)as a correspondence from U to Sn = {p p > O, pe = 1}, the priceset, the unit simplex for n-dimensional vectors, where n is thenumber of commodities.We conclude this section with some lemmas on domination ofutility allocations to be used in the next chapter.In A.4.2 and Corollary 1, we introduced a possible consumptionvector, xh, for each individual, which was used to define his zeroutility level.1\n1.:11\n1 '1'\nLEMMA 9.\nThe utility aHocation, O, is dominated.\nProof. By A.3.5 there is a vector y in the social productionpossibility set for which\nx +y» O.1\n(6)\nFor any commodity i, either X¡ > O or X¡ = O. In the first case,Xni ::0: O, all h, Xni > O, some h. By A.4.2, then, xhi ::0: xhi• aH h,xhí > xhi• sorne h, so that\nand thereforefor a > O and sufficiently sma11.(Recall that some components of y are negative.) If X¡ = O, thenX¡ = O, and from (6), ji¡ > O so that\nThus,\n97\nz = x - ay - x « O,X = :¿ x, x, E X,(o)'aH h,h\nso that, by Lemma 4.6, O is a dominated utility aHocation.We will confine our attention to non-negative utility aHocations.Then the Pareto-efficient utility allocations will be semi-positive.We noteLEMMA 10. If u and u' are feasible non-negative utility aHocations,u ::;; u', and u, < u;, for any h for which u~ > O, then u is dominated.Proof. Let toE \"F(u), w' E \"F(u'). Since, by Lemma 4.9, O isdominated there is an allocation toa E if'(ua), with ua » O. Nowconsider 'the allocation wb = (1 - a)to' + atoa, O < ex ::;; 1; it iscertainly feasible. We will show that by suitable choice of ex we haveub »u, where u~ = u,(xn. First, consider any h for which u~= O;then u, = O. Either x~ >-, x~ or x~x~. In the first case, bysemi-strict convexity of preferences, A.4.4( d), x~ >-, x~, so thatu~ > U,(x~) ;:o: u~ =O= u,. In the second case, by Lemma 4.1(b),Now consider the households forb > u (xa) > ua > 0 = u.Uh hhh,..which u~ > O; then u~ > u,. Then u~ ;:o: u~ > U¡, for a = O; b_Ycontinuity u~ > U¡, for a > O and sufficiently smaH. Hence, u ISdominated.\n>=,\nRemar k. It is noted, for later reference, that the proof of Lemma4.10 depends only on the validity of Lemma 4.9 and on the semistrict convexity of preferences.\n5.\nSorne Continuity Theorems\nSome of the sets introduced in the preceding sections are functionsof utility 1evels. For the existence of equilibrium we will need toshow that these set-valued functions or correspondences are continuous in appropriate senses. In addition to the concept of uppcrsemi-continuity, already used in Section 4.1, we will need that oflower semi-continuity.\n0\n<D(x) is lower semi-continuous if xv---+ x 0 , y0 E <D(x ) implies that0there exists a sequence {yv} for which yv E <D(xv), yv---+ Y • Acorrespondence <D(x) is said to be continuous if it is both upper andlower semi-continuous.\n,11:!' '1111\n¡;¡1¡,,1!!\n1\n1\n'¡11 :.·.\n';¡\n1\n'f·!1\n98\n1\n1'\nGENERAL COMPETITIVE ANALYSIS\nCONSUMER DECISIONS AND EFFICIENT ALLOCATIONS\nLEMMA 11. The correspondence Xiu\") defined in D.4.6, is convexfor each given u\" and is continuous in u\".\nTo prove lower semi-continuity, let uv _,.. u0 , aJ- 0 E if\"(u 0). Bydefinition, w 0 = (x 0 ,¿l), xg E X\"(ug), :lE 1!!1. Since the correspondence X,.(u\") is lower serni-continuous, we can find a sequence,{xh}, for each h, such that,\nProof Convexity has already been noted. Suppose u); _,.. u~,x); E Xh(u];), x); -¿. X~. By definition, Uh(xh) 2: u;;. Since uh is .continuous, U\"(xg) 2: x~, so that xg E X\"(ug) and X\"(u\") is upperserni-continuous.Now suppose that u);_,.. ug and x~ E X,.( u~). Choose xk so thatU\"(xk) > U,.(xg) 2: u~. Then, for each v, precisely one of the threefollowing possibilities holds:(a)(b)(e)\nu); 2: U,.(xk);\nU,.(~k) > u;; 2: U\"(xg);U\"(x~) > u;;.\nSince u;;_,.. u~, (a) can hold only for finitely rnany v by the definitionof x 1 ; for those v, choose x)'. to be any element of X\"(uh). If (e)holds, let x;; = xg. On this subsequence (if infinite), x)'. ->- x~trivially, and x); E X,.(uh).Now suppose (b) holds. Let x\"(a) = (1 - a)xg + axk, O ::::; a ::::;l. By continuity there exists av, O ::::; av < 1, for which U\"[x,.(av)] =u);. Let x); = x\"(av). Certainly, x); E X\"(uh). It remains to showthat if (b) holds for infinitely many v, then x); _,.. xg along thatsubsequence.The sequence {av} is bounded and, therefore, has a limit point; leta* be any such, and let x~ = x\"(a*) .. Then U\"(x~) = ug, since byassumption, u;;_,.. ug. But since U,. is semi-strictly quasi-concave,U,,[x\"(a)] > U,.(xg) 2: ug for any a > O. Hence, a* = O, and thismust be the only limit point of the sequence {av}. Therefore,x)'. _,.. x~ = xg.THEOREM 5. The correspondence if\"(u) defined in D.4.8 is convexfor each u and continuous in u.\nProof Convexity has already been noted. For upper semicontinuity, suppose uv _,.. u0 , wv _,.. to 0 , wv E if\"(uv). Write10\nv = (xv,yv)\n100\nwhere xv E .:r(uv), yv E 1!!1,\n= (xo,yo).\nThen x); _,.. xg, and by Lemma 4.11, xg E X\"(u~), each h, or x 0 E .:r(u 0).~ince 1!!/ is a closed set, and yv E 1!!1, all v, y 0 E 1!!/; by the definition ofu-possible allocations, '#\"(u), in D.4.8 to 0 E if\"(u 0).\nx); E X,.( u¡;)\nx); _,.. xg.\n(xv,y 0), then wv E if\"(uv), wv _,.. w 0 ,\nIf we let tov =semi-continuity holds.\n99\nso that lower\nCorollary 5. The set of u-feasible allocations, it'(u), is uppersemi-continuous in u.Proof From D.4.10, \"/i'(u) is the intersection of two sets, one ofwhich is upper semi-continuous in u by T.4.5 and the other of whichis independent of u.\nliif,¡,.\n.,\ni]'il!jil¡j1\nCorollary 5'. The set of u-possible excess demands, Z(u), is lowerserni-continuous in u.Proof Let uv _,.. u0 , z 0 E Z(u 0). By D.4.9, z 0 = z(uJ- 0 ) for sorneto E \"/Y(u0). From T.4.5, then, thére exists a sequence {wv} withwv ->- to 0 , wv E if\"(uv). Let zv = z(wv); then zv _,.. z 0, zv E Z(uv), byD.4.9.0\nTHEOREM 6. The set P(u), as defined in D.4.14, is upper semicontinuous in u, compact and convex for each u, and is non-null forUE U.\nProof Convexity and compactness follow trivially from thedefinition of P(u). The non-nullity of the set for u E U is the contentofT.4.4. To see upper semi-continuity, suppose there are sequencesuv _,.. u0 , pv _,.. p0 , pv E P(uv). Since pv > O, pve = 1, it follows thatp0 2: O, p0 e = 1, and therefore, p0 > O. Take any z 0 E Z(u 0 ); byCorollary 5', we can choose a sequen ce {zv}, where zv _,.. z 0, zv E Z(uv),all 11. Since pv E P(uv), it follows by definition that pvzv 2: O, artdhence, by taking limits, p0 z0 2: Q. But then p0 satisfies the definitionof P(u 0).\n6.\nThe Single-Valued Case\nAnalogously to Section 3.4, we will present sorne assumptions thatensure that the excess-demand correspondences of the householdbecome single-valued functions, and we will then discuss sorne oftheir well-known properties.\nli11\nk\n1\n\"!i\n::¡,:¡!i,,l\n.,,¡\n·':i\n'\"\"\"Ir\ni\n100\"\n'\n,, ¡\n~\n~\n:1 '\"\n1\n''1 ;.\n1:'1111''\"\nGENERAL COMPETITIVE ANALYSIS\nCONSUMER DECISIONS AND EFFIC!ENT ALLOCATIONS\nAs in Section 3.4, we assurne that the set of cornrnodities can bepartitioned into two parts, for one of which the household is assurnedto ha ve no utility; that is, we can write the vector, x 11 , as (x~,x~),where U11 (x 11 ) = U11 (x~,xD is, in fact, independent of x~. Analogously to the assurnption that Y1 is strictly convex with respect tothose cornrnodities that appear in it at al!, we strengthen our assurnptions on preferences to strict convexity; that is, if xk :P: x~ andO < a < 1, then ax~ + (1 - a)x~ >- x~ provided xk and x~ differ insorne of the a-cornponents. The dernand for the b-cornrnodities isO for all price levels; it is perrnissible, for sirnplicity, to assurne thatall cornrnodities are a-cornrnodities. (Sorne cornplication may arisefrorn the fact that sorne cornrnodities in the household's endowrnentare b-cornrnodities, not desired for its own consurnption; but we willcarry incorne, M 11 , as a separate variable when needed.)For any given p » O, the set of cornrnodity vectors in Xh thatsatisfy the budget constraint, pxh :s; Mh, is a cornpact set, so thereexists at least one x~, rnaxirnizing Uh(xh) in this set. If xk alsomaxirnized Uh(x~) in this set, then Uh(xh) = Uh(xk). Let x~ be aproper convex cornbination of the two; then it satisfies the budgetconstraint, but by strict quasi-concavity of the utility function, it hasa higher utility than either, which contradicts the choice of x~.\nxh(p 2 ,M~), it must maximize utility subject to the budget constraint,\nTHEOREM 7.. If Uh(x 11 ) is strictly quasi-concave, then for every pthere is, at rnost, one x~ that rnaxirnizes Uh(xh) subject to pxh :S:: Mh,xh E Xh. If p » O, there is one such x~.In view of T.4. 7, it is legitirnate to defineDEFINITION 15. The uncompensated demandfunction xh(p,Mh) is theunique x~ that rnaxirnizes U11 (xh) subject to px11 :S:: Mh, xh E X 11 .In general equilibriurn theory, M 11 is, in turn, a function of p, asdefined by A.4.3.DEFINITION 16. The demand function xh(p) = x 11 [p,M11 (p)], whereMh(p) is defined. by A.4.3.\n'i·¡ i1\n:\nr\n1\n¡\nThen T.4.7 implies that the uncornpensated demand function andthe demand function are both well defined on a domain that includesall strictly positive price vectors. A particular consequence is thewell-known weak assumption of revealed preference. If x~ is avector satisfying the budget constraint p 1 x~ :S:: M~, but x~ i=xh(p\\Mk), then Uh[x 1.(p\\Mk)] > U1.(x~). If in particular, x~ =\n101\np 2 x :S:: M~; therefore it must be that x 11 (p\\MD does not satisfy thatbudget constraint.\nCorollary 7 (Revealed Preference). If p 1 x 11 (p 2 ,M~) :s; M 1~ andxlt(p\\MD i= xh(p 2 ,Mn, then p 2 x 11 (p\\Mk) > M~.From T.4.7, if x 11 (p) is not defined for sorne p, then there is noutility-maximizing x 11 under the budget constraint. The lack ofdefinition comes from the fact that the household is not satiated insorne free goods so its demand is, in sorne appropriate sense, infinite.The example given at the beginning of Section 2.8 shows, however,that sorne care must be taken in defining the sense in which demandsmay be infinite at zero price; even if the household is not satiatedin any comrnodity, demands need not approach infinity as pricesapproach a lirnit in which sotne cornponents are zero. On the otherhand, in the same exarnple it was shown that the su m of the demandsfor all commodities does approach infinity as any set of pricesapproaches O. This is a general result, which will now be dernonstrated, so that assumption A.2.6 can be justified by being derivedfrom utility-maximizing considerations.DEFINITION 17.\nWe define\nin the natural way at any p for which xh(p) is defined and as equalto + oo otherwise.We will show that the function\n2 Xll¡(p),¡\nso defined, is continuous. Continuity for an extended-real-valuedfunction that can take on the value +oo has the usual meaning atany point where the function is finite, while for any sequence {pv}approaching p 0 , where\nwe require that\nT\nr\n1\n!\n102\nCONSUMER.DECISIONS AND EFFICIENT ALLOCATIONS\nGENERAL COMPETITIVE ANALYSJS\n103\nAs v approaches infinity, pvx(p)--+ M(p), M(pv)--+ M(p), and f3vremains bounded.\non the subsequence (if infinite) for which\n¿ X¡¡¡{pv) < +oo.\npx':::; M(p).\ni\nAs the discussion in Section 4.1 (preceding Lemma 4.2) suggests,we are unlikely to achieve continuity in any sense if income is at themínimum possible. It will follow from Lemma 5.1 that M¡¡ is abovethe mínimum possible if and only if M¡¡ > O. We will thereforeassume M¡¡ > Ofor all possible prices-a strong assumption, becauseit means, in effect, that X¡¡ » O, unless the household owns shares ina firm that makes positive profits at any set of prices.THEOREM 8. If the utility function U¡¡(X¡¡) is strictly quasi-concaveand Mh > O for all p, then X¡¡(p) is continuous in its domain ofdefinition, which includes all p » O, and\nSince x' =¡6 x(p), it follows by definition that U(x') < U[x(p)];therefore\nU(x'v) < U[x(p)]for v sufficiently large; from (7), then, U[x(pv)] :::; U(x'v). Also, bycontinuity, we can choose ,\\ > Oso that U(x') < U[,\\x + (1 - ,\\)x(p)],so that\nU(x'v) :::; U[,\\x + (1 - ,\\)x(p)]\nv large,\nand therefore\nU[x(pv)] :::; U[,\\x + (1 - ,\\)x(p)],which implies that\nas extended by D.4.17, is continuous everywhere on the unit simplex,Let v approach infinity.\nSn•Proof\nIn this proof, we will drop the subscript h.\nlx(pv) - x(p)l ;::: E > O\n,\\px + (1 - ,\\)M(p) ;::: M(p),\nSuppose\nx(p) is defined, but not continuous, at sorne price vector p. Thenthere is a sequence {pv}, pv--+ p, and a positive number \" such thatall v.\nLet\nor px ;::: M(p). But as will be seen in Lemma 5.1, this is impossibleif M(p) > O.It remains to show that if x is not defined at p, then for everysequence {pv}, pv--+ p, :¿ X¡(pv)--+ oo. If not, then there is a sequencei\n{pv} converging to p for which {x(pv)} is bounded. Let x' be a limitpoint of the sequence. Since pvx(pv) :::; M(pv), px' :::; M(p). Weshow, in fact, that x' maximizes U(x) subject to px :::; M(p); thenx(p) would be defined equal to x', a contradiction. Consider anyx\" for which U(x\") > U(x'). Then, for sorne ,\\ > O,\nE\nf3v = lx(pv) - x(p)l'\nx'v = f3vx(pv) + (1 - f3v)x(p).Since O < f3v :::; 1, x'v is a convex combination of two members of Xand hence belongs to X. By quasi-concavity,if\nU[x(p)] > U(x'v),\nthen\nU(x'v) ;::: U[x(pv)].\n(7)\nSince lx'v - x(p)l = E, we can choose a subsequence for whichx'v--+ x', where lx' - x(p)l = E. Then x' E X, since X is closed.Since pvx(pv) :::; M(pv),\npVx'V :::; f3vM(pV) + (1 - f3v)pVx(p) = pVX(p) + f3v[M(pv) - pVx(p)].\nU[,\\x + (1 - ,\\)x\"] > U(x'),and therefore\nU[,\\x + (1 - ,\\)x\"] > U[x(pv)],for v sufficiently large along the appropriate subsequence.definition of x(pv), this implies that\npv[,\\x + (1 - ,\\)x\"] > M(pv).\nBy\nT104\nGENERAL COMPETITIVE ANALYSIS\nCONSUMER DECISIONS ANO EFFICIENT ALLOCATIONS\nLet v approach infinity a1ong the appropriate subsequence.\nIf C\" is twice differentiable, then, by (b) of the theorem, theJacobian with elements o2 C1.Jop¡[Jp1 is negative semi-definite andsymmetrk. Thus,\np[.\\x + (1 - .\\)x\"] ;::: M(p).Since M(p) > O, M(p) > px, by Lemma 5.1.\no2 C\"oxh1(p,uh)op 1op 1 =op 1\nHence,\n.\\M(p) + (1 - .\\)px\" > M(p),or px\" > M(p). That is, any x\" preferred to x' must be unavailableat income M(p) and prices p, or equivalently, x' maximizes U(x) topx::::; M(p).Now let us examine sorne well-known properties of compensateddemand for those price vectors p for which M\" > O. Define thefunctionC¡¡(p,u¡¡) = inf{px¡¡ 1 U¡¡(X¡¡) ;::: U¡¡,\n1\n(9)\nand the elements of the Jacobian are the substitution terms oftraditional theory.Now differentiate (8) with respect to p1•\n'ox¡¡(p,uh) = ox¡¡(p,M¡¡) ~ [ox¡¡(p,M¡¡)] (oC¡¡);op1ap1oM¡¡op 1substitution for oC¡¡jop1 from T.4.9(b) yieldsox¡¡(p,U¡¡)ox¡¡(p,M¡¡) + ox¡¡(p,M¡¡).op1=op 1aM\"xhj,\nx\" E X 1.},\nand interpret it as the lowest cost for household h of attaining aprescribed utility leve! U¡¡, given the market prices p. The compensated demand correspondence X¡¡(I), u¡¡) is then defined byX¡¡(p,u¡¡) = {x\" px\" = C1.(p,u¡¡),\n105\nx\" E X¡¡}.\nIf U¡¡(X¡¡) is strictly quasi-concave, X¡¡(p,u\") has only one memberfor each p for which C¡¡(p,u¡¡) > O and, therefore, is a function. Porby Lemma 4.3 and T.4.7, X¡¡(p,u¡¡) is the unique element that maximizes U¡¡(x\") subject to the budget constraint, px¡¡ ::::; C¡¡(p,u¡¡), thatis,\nthe last term is the well-known income effect. Holding all otherprices and money income constant, the effect of a change in oneprice, which is the first term on the right-hand side, can be expressedas the difference between a substitution effect and an income effect.From (9) and T.4.9, we deduceTHEOREM 10. Let U¡¡(X¡¡) be strictly quasi-concave.for which M\" > O,\nThen for all p\n(8)(b)\nthe matrix with typical element,\nThe following theorem is proved in exactly the same way as T.3.4and T.3.6, and we do not repeat the proof here.THEOREM 9. Let U¡¡(x¡¡) be strictly quasi-concave. Then for all pfor which C¡¡(p,u¡¡) = inf{px\" 1 U¡¡( X¡¡) ;::: u,, X¡¡ E X\"} > O,(a)(b)\nox¡¡¡(p,M¡¡) + oX¡¡;(p,M¡¡)a'P joMhX¡¡¡,is negative semi-definite; in particular,\noX¡¡;(p,M¡¡) + OX¡¡¡(p,M¡¡) X < Oop;O'M\"ht •\nX¡¡(p,u,t) is a function,C¡¡(p,u¡¡) is a strictly concave differentiable function of pover Sn for fixed U¡¡, where\nNotes\nFor the most part, the assumptions of this section arestandard in the economic theory of the household. The treatment ofSectiQn J.\nil' 1:\n!' ~\n¡::·i:\n1\n1\n11'\n·1\n•:¡¡[\n1\n1··,,1¡\nl!\nil11\nT1\n106\n,' 1¡,\n·¡:,l'i'1'1'':jill,¡:¡¡:·'1• .li''¡,'1'\n·¡\n1\n.i\n:lf\n1\n'\n,11'\n'·\n'1\nGENERAL COMPETITIVE ANALYSIS\ndifferent kinds of labor as displacements of different kinds of leisure andthe consequent time constraint on types of leisure was introduced byArrow and Debreu [1954, pp. 268-269]. The time constraints onconsumption in general have been stressed by Becker [1965].Section 2. Since the introduction of indifference surfaces by Paretoand Irving Fisher, it has been taken for granted that they could berepresented by a utility function. Wold seems to have been the first tosee the need of specifying assumptions under which the representationby a continuous utility function exists [1943-44, sections 31, 37]. Woldassumed that Xn is the entire non-negative orthant and that preferenceis strictly monotonic in each commodity. In that case, it is easy toverify that each possible consumption vector is indifferent to preciselyone vector of the form p,e, and p, can be used as the utility function. Avery considerable generalization, based on a mathematical paper byEilenberg [1941], was achieved with deeper methods by Debreu [1954];he assumed only the continuity of preferences and the connectedness ofXj, (a property weaker than convexity). The construction of the utilityfunction involves selection of a denumerable subset of Xn everywheredense in it, defining a utility function by placing it inductively into oneto-one correspondence with the rational numbers on the unit interval,and extending this utility function to the entire consumption possibilityset by a limiting process. The proof is straightforward, but lengthy;the result is valid in infinite-dimensional spaces with suitable properties.Further extensions are due to Rader [1963], who gives a simple construction, and to Debreu [1964]; the proof of one of the lemmas in thelast paper has beennotably simplified by Bowen [1968].A more elementary approach in the spirit of Wold's can also besupplied for general convex Xn and continuous preferences. Chooseany strictly positive price vector p0 and define Un(x) to be the cheapestway of buying a commodity vector not inferior to x. Then if x minimizes p 0 x over X¡¡, it is very easy to verify that Un(x) is a continuousutility function over the subset of Xn for which Xn ~ x. However, thisutility function cannot be extended to the entire set Xn without additional assumptions; one set that suffices is to assume that Xn is polyhedral and preferences are convex.The approach used here was suggested to the authors by JamesMirrlees, to whom we are grateful.Section 4. The basic theorem of welfare economics, T.4.4, has awell-known long history. The use of convex set theory to provide arigorous statement is due independently to Arrow [1951] and Debreu[1951].Section 6. Most of the material in this section is too familiar forreference; see also the Notes to Section 3.4. T.4.8 is new; the proofhere is James Mirrlees' simplification of our original proof.\nChapter FiveTHE EXISTENCE OFCOMPETITIVE EQUILIBRIUMAt length 1 saw these lovers full werecomelnto their torture of equilibrium.- John Crowe Ransom,The Equilibrists\nl. Compensated and Competitive Equilibrium: Definitions andInterrelationsAn (uncompensated) competitive equilibrium has the meaningusual in the economic literature: a set of prices and production andconsumption allocations such that each firm maximizes profits atthe given prices, each household maximizes utility at the given pricesand with the income implied by those prices and its initial holdingsof assets and profit shares, and aggregate consumption is feasible innot exceeding the sum of aggregate production and initial endowments. Formally,DEFINITION l.\nA price vector, p*, a consumption allocation, a::*, anda production allocatioh, y*, constítute a competitive equilibrium if(a)(b)\np* >O;L; x;;' ~ L; Y1' + L; x11 ;\n(e)(d)\nyj maximizes p*y1 subject to Yr E Y1 ;x;;' maximizes U¡¡(X¡¡) subject to p*x11 ~ M;;' = p*x1 +¿; dhf(p*yj).\n}¡\nf\nh\nf\nAs already suggested in Section 4.1, it is convenient as an intermedia te step in deriving sufficient conditions for the existence of acompetitive equilibrium to find sufficient conditions for the existenceof another type of equilibrium, which we call a compensated equilibrium. This differs from the competitive equilibrium in theassumptions about consumer behavior; households are assumedto minimize the cost of achieving a given utility level, and it is thenpostulated separately that their income is sufficient to cover thesemínimum costs.\n!1'.:11ji\n1\nil!·¡¡¡1!111 11''1'\n!!¡¡\nil¡!l··i\nti:\n107\n1\n:,\"\nTi\n108\nGENERAL COMPETITIVE ANALYSIS\nTHE EXISTENCE OF COMPETITIVE EQUILIBRIUM\nDEFINITION 2. A price vector, p*, a utility allocation, u*, a consumption allocation, x*, and a production allocation, JI'*, constitutea compensated equilibrium if\nwhich both p 1 > O and x\"1 > O; similarly, p(x,, - x\") > O if andonly if there is at least one component i for which p 1 > O andxhl - x\"1 > O. Hence,\n(a)(b)\np* >O;2: x;i' :;::; ¿ yj + ¿ X.\";h\nf\npx\" > O if and only if p(x\" - x\") > O.\nh\n(e) yj maximizes p*y1 subject to y1 E Y1 ;(d) x;i' minimizes p*x\" subject to Uh(xh) :2:: u;;';(e) p*x;i' =M;;'.As is already evident from Lemmas 4.2 and 4.3, there is a closerelation between the two kinds of equilibria. In one direction therelation is very simple.THEOREM l. If (p* ,x* ,y*) is a competitive equilibrium and u1~ =U\"(x;D for each h, then (p*,u*,x*,y*) is a compensated equilibrium.\n,Proof\nD.5.2(a)-(c) are identical with D.5.I(a)-(c). Lemma 4.2asserts that a consumption vector that maximizes utility subject toa budget constraint also minimizes the cost of achieving that utilityleve!, so that D.5:I(d) implies D.5.2(d). Finally, suppose thatD.5.2(e) does not hold. From D.5.l(d), p*x;i' < M;;'. But then, byCorollary 4. 1, we can choose x~ arbitrarily el ose to x;i' su eh thatU¡¡(x;,) > U\"(x;i'). In particular, x~ can be chosen so that p*x~ :;::;M;;', which is a contradiction to the assumption that x;i' is utilitymaximizing under the budget constraint.Corresponding to Lemma 4.3, a partial converse of T.5.1 is valid.First, we noteLEMMA l.\nlf p > 0 and py r :2:: 0, all j, then\n(a) M\" :2:: O, all h;(b) for any h, M,, > O if and only if M\" > px\".\nProof\n109\nBy definition,\nM\" = px\" + 2: d\"r(PYr).f\nM\" - px\" = p(x~ - x\") + ¿ dhr(PY 1).f\nFrom the hypotheses, obviously, M¡¡ :2:: O, all h. But from A.4.2, itis assumed that :X - x\" :2:: Oand that :X\" has exactly the same positivecomponents (and the same zero components) as :X\" - x\". Sincep > O, px\" > O if and only if there is at least one component i for\nAlso, obviously,\nM\" > O if and only if either px\" > O or\n¿f dh!(PYr) > O;\nM\" - px\" > O if and only if either p(x\" - x\") > O or\n¿ dhf(py¡) > o.f\nThese statements taken together imply the lemma.In particular, Lemma 5.1 implies that if M\" > O, then there issorne= x\") in X\" for which px~ < M\".\nx;, (\nTI-IEOREM 2. If (p* ,u* ,x* ,y*) is a compensated equilibrium andM;;' > O, all h, then (p* ,x* ,y*) is a competitive equilibrium.\nProof D.5.2(a)-(c) are identical with D.5.l(a)-(c). If M;;' > O,then,. by D.5.2(e), p*x;i' = M;;' > p*x~ for some x~ in X\", as justremarked. By Lemma 4.3, it follows from D.5.2(d) that x;i' maximizes U\"(x\") subject to the budget constraint, p*x\" :;::; M;;'.It is not necessarily true that at a compensated equilibrium everyhousehold has positive income. The absence of positive inco,meimplies that there cannot exist a possible consumption vector thatcosts less than total income (since all possible consumption vectorsare non-negative); in view of Lemma 4.3, this raises the possibilitythat utility-maximizing and cost-minimizing behavior do notcoincide. In particular, from the discussion preceding Lemma 4.2,there is a possibility that the uncompensated demand functions arediscontinuous.It can be shown, however, that at least one household has positiveincome.LEMMA 2. If (p*,u*,x*,y-*) is a compensated equilibrium, thenM;;' > O, for some h.\nProof\nIt suffices to prove\n2M;;'> O.h\nT1\n110\nGENERAL COMPETITIVE ANALYSIS\nTHE EXISTENCE OF COMPETITIVE EQUILIBRIUM\nBy definition, however,\n2: M/t = ¿ [p*x\" + ¿ d¡,¡(p*yj)J = ¿ p*x,, + ¿ ¿ dM(p*yj)= 2: p*x\" + ¿ (2: dnr) (p*yj) = ¿ p*x, + ¿ p*yj,h\nf\nh\nf\nh\nh\nh\nh\nsuch that U\"(xk) > u;·, all h.achieving the utility leve] u/t,\nSince x/t minimizes the cost of\np*x/t :::; p*xk\nf\nall h,\nor, in view of D.5.2(e), the balanced budget condition,\nf\nh\nM/t :::; p*xk\nsincefor allfWe have assumed (A.3.5) that the economy is capable of supplyinga positive amount of each good; that is, there exists a sociallypossible production vector, y, such that, x + y » O. Since p* > O,\np*x + p*y = p*(x + y) > o.\nso that\n¿ p*xk > 2 M/t = 2 p*x~z + 2: p*yJ.h\nL YJ is profit maximizing over Y= L Y\n1,\nf\nall h.\nBy Lemma 5.2, there is at least one h for which M/t > O. ByLemma 5.1, p*x/t = M/t > p*x~z for that h, and therefore, x/t is a]soutility maximizing subject to the budget constraint p*x\" :::; M/t, byLemma 4.3. Since U,.(xk) > U~z(x/t) = u/t in this case, it must bethatsorne h,\nSince yj is profit maximizing over Y1 , eachf,\ny* =\n111\nh\n(2)\nf\nh\nOn the other hand, from (1), since p* > O,\n1\n2 p*xk :::; 2 p*x\" + 2 p*y}.\nso that\n¿ p*yJ = p*y* 2 p*y,\nh\nf\nFinally, since YJ is profit maximizing, p*y} :::; p*yJ', all J, so\nf\n2 p*xk :::; 2 p*x\" + 2 p*yJ,\nand therefore,\n¿ M/t = p*x + ¿ p*yJ > o.h\nh\nh\nh\nf\nin contradiction to (2).\nf\nPor our purposes, Lemma 5.2 will be usefullater in establishinga condition under which a compensated equilibrium is also a competitive equilibrium. It is worthwhile, however, to note here that asufficiency theorem for Pareto efficiency can be established at thisstage, although this theorem is not directly relevant to our main aimof proving the existence of equilibrium.\nIt may be worthwhile noting at this point that the theorems andlemmas of this section depend on only a few of the assumptions madein Chapters 3 and 4; in particular, they do not depend on theconvexity assumptions.\nTHEOREM 3. If (p*,u*,x*,y*) is a compensated equilibrium, then u*is a Pareto-efficient utility allocation.\nThe main tool in proving the existence of equilibrium is Kakutani'sfixed-point theorem (see T.C.4). This theorem states that an uppersemi-continuous correspondence that maps points in a compactconvex set into convex subsets of that set has a fixed point; thatis, there is one point that belongs to the subset associated withit by the correspondence. As we will see in the next section, thereis a very natural mapping whose fixed point can be seen to be a\nProof\nSuppose not.\nThen there would exist an allocation\n(xl,y 1), which is feasible,(1)\n2.\nMapping the Pareto Frontier into a Simplex\n1:'11\n~\nT112\ni11\nGENERAL COMPETITIVE ANALYSIS\nTHE EXISTENCE OF COMPETITIVE EQUILIBRIUM\ncompensated equilibrium; but the domain from which the mappingtakes place is, in part, the Pareto frontier (more precise1y, the domainis the Cartesian product of severa! sets, one of which is the set ofnon-negative, Pareto-efficient utility allocations). However, thePareto frontier certainly need not be itself a convex set. Indeed,since the utility functions are defined only up to monotone transformations, convexity, which is a cardinal property, can ha ve no realsignificance.Nevertheless, the non-negative Pareto frontier can be shown to beessentially identical to a convex set, in fact to a simplex, from thetopological point of view. It is sufficient to show that there is asimplex, whose dimensionality is one less than the number of households, which can be mapped in one-to-one, continuous fashion intothe non-negative Pareto frontier.We will first note that the non-negative Pareto frontier can bemapped continuously into a unit simplex and then show that theinverse of this mapping is defined and unique for all elements of thesimplex.Let U' be the non-negative Pareto frontier, that is, the set\nIt is easy to see that if the inverse of v(u) is well defined, it must becontinuous. To show that it is well defined is to say that theequation\nv(u) = vhas a unique so!ution, U, for every V E Sj¡.h\na positive 'scalar, then v(u) = v implies\nh\nuv(u) =(tu\")\n(3)\nFurther, we obviously have\nv(u) ;:o: Oso that v(u) maps U' into a unit simplex, SH, where H is the numberof households.DEFINITION 3.\nThe set of relative utility vectors is defined by\n(4)\nConversely, if (4) holds, then clearly, from (3), v(u) = v. Hence, itsuffices to show that (4) holds for every v E V for a unique ,\\,The functions U,(x\") together define a mapping from the set offeasible consumption allocations to the set of feasible utility allocations. Since the set of feasible consumption allocations is compact,as implied by T.4.2, and the functions U\" are continuous, the set offeasible utility allocations is compact For fixed v, then, the set ofscalars,,\\v\na feasible utility allocation},\n(5)\nis also compact. Since O = Ov is certainly feasible for all v (letx =lf = 0), the set (5) is non-null and hence has a maximum.\n.v,\nX(v) = max{,\\ 1 ,\\v\nThen the mapping\nis well defined and continuous on U'.\nfor some ,\\ > O, u E U'.\nu = ,\\v\n{ ,\\ 1\n¿u,> o.\nIf\n,\\ = 2: u,,\nU' = Un {u 1 u ;:o: O},where U is the set of Pareto-efficient points (see D.4.'13). ByLemma 4.9, O is not Pareto efficient, so every non-negative efficientallocation is semi-positive, and in particular,\n113\na feasible utility allocation}.\nWe will show that ,\\v is efficient if and only if ,\\ = X(v); as previously remarked, this suffices for the existence of an inverse to v(u).If ,\\ > X(v), then, by definition, ,\\v is not feasible and, therefore, notefficient. Now suppose ,\\ = X(v). By definition, X(v)v is feasible.Suppose it were dominated; then, for some feasible u, u » X(v)v (seeD.4.12). But then there exists ,\\ > X(v) for which u ;:o: A.v. Then,\\v is feasible, contrary to the definition of X(v). Hence, X(v)v isundominated and, therefore, efficient.Since, as already remarked, O = Ov is not efficient, it must be thatX(v) > O.Suppose now ,\\ < X(v).,\\v :s; X(v)v,\nThen trivially,\n,\\v\" < X(v)v\" if X(v)v, > O.\nBy Lemma 4.13, then, ,\\vis dominated and, therefore, not efficient.\nT114\nGENERAL COMPETITIVE ANALYSIS\nTHE EXISTENCE OF COMPETITIVE EQUILIBRIUM\nLEMMA 3: Let SH be the simplex of relative utilities. Then thereis a continuous function, u(v), mapping SH into the non-negativePareto frontier, such that Vn = O if and only if un(v) = O.3. . The Existence of Compensated EquilibriumWe are now ready to prove expeditiously the existence of a compensated equilibrium. We introduce two more pieces of notation,sn(p,w) = p[x~~ +\nf\ndhf(py1) -\nx~~J = M 11(p,y) - px11 ,\n(6)\nthe budgetary surplus for household h if prices are p and the allocation is w, andV(p,w) = SH n{v 1 VJ¡ = o if sh(p,w) < 0}.\n·'\n,,''1\n(7)\nWe may think of (7) as an instruction to punish households thatincur budgetary deficits by setting their relative utility, v11 , equal toO, while imposing no conditions on other households. By Lemma5.3, equating a relative utility to O is equivalent to equating theutility of that household to O.The idea of the mapping can be expressed simply. We start witha price vector, p, a relative utility allocation, v, and a feasible commodity allocation, to. These need not be consistent with each other;we assume each arbitrarily chosen from its appropriate domain.The relative utility allocation determines uniquely a non-negativePareto-efficient utility allocation, u = u(v), by Lemma 5.3. Thenthere is a non-mili set of price vectors, P(u), that supports theallocation u, by T.4.4 and D.4.14; by definition of efficiency andfeasibility, there is a set of feasible allocations, if'(u), that permitsthe realization ofthe utility allocation u, by D.4.10 and D.4.12; andthe initial prices and allocation define budgetary surpluses and therewith a new set of relative utilities, by (6) and (7).Since u is a function of v, the sets of prices and of feasible allocations can be written P[u(v)] and if'[u(v)], respectively.The doma~n of the mapping, then, is the Cartesian product,s\" x SH x \"#\"'. s11 and S¡.¡ are simplexes and, therefore, compactconvex sets; by T.4.2, \"F is compact and convex. Hence, thedomain is compact and convex.The correspondence defined on s11 x V x if' is, formally,\nP [u(v)] x V(p,to) x if'[u(v)].\n(8)\n115\nBy the definitions already cited,\nP[u(v)] e P\nV(p,w) e SH\nif'[u(v)] e if',\nso that the correspondence does map the domain into subsets ofitself. By T.4.6, P(u) is compact and convex for fixed u and uppersemi-continuous in u; since u(v) is continuous in v and u is fixed forfixed v, P[u(v)] is compact and convex for fixed v, and upper semicontinuous in v. From Theorem 4.5, Corollary 5, it followssimilarly that if'[u(v)] is compact and convex for fixed v and uppersemi-continuous in v. From (7), for fixed p and w, V(p,to) is theintersection of a compact convex set, SH, with a closed convex setand, therefore, is compact and convex. We wish to prove that it,too, is upper semi-continuous in its variables.Let pv--+ p0 , wv--+ w 0 , vv--+ v0 , vv E V(pv,tt;v). Consider any h forwhich\nSince s11 is a continuous function of p and w, it must be that for vsufficiently large s11(pv,wv) < O. Then, by definition (7), v); = O for allsuch v. Trivially, vg = O. But then we have shown that vg = Owhenever (9) holds. Since vv E V, all v, it is certainly true thatv0 E V; by (7), v0 E V(p 0 ,w0 ), as was to be proved.Thus, all three components of the mapping (8) are compact andconvex for fixed values of p,v,w and, hence, so is the entire mapping.Also, all three components are upper semi-continuous functions ofthese variables and, hence, sois the entire mapping. By Kakutani'sfixed-point theorem (see T.C.4), this mapping has a fixed point; thatis, there is a point (p*,v*,to*) E Sn x SH x if' such that\n(p* ,v* ,w*) E P [u(v*)] x V(p* ,w*) x \"F[u(v*)J.\n(10)\nWe show that this fixed point in fact satisfies all the conditions for acompensated equilibrium, as given in D.5.2. First, let\nu* = u(v*).\n(11)\nThen (10) can be written as the three statements,\np* E P(u*),\n(12)\nv* E V(p*,w*),\n(13)\nw* E if'(u*).\n(14)\n-ll\nli:\nGENERAL COMPETITIVE ANALYSIS\nTHE EXISTENCE OF COMPETITIVE EQUILIBRIUM\nRecall the definitions of P(u) (D.4.14) and il'(u) (D.4.10), and thenuse (12) and (14) in conjunction with the basic theorem on Paretoefficiency, T.4.4. From (12) and part (a) of T.4.4, D.5.2(a) holds.From the definition of il'(u), (14) implies D.5.2(b). From (14) and(12) together, part (d) of the theorem implies D.5.2(c) and (d) andal so\nWe will say that household h' is resource related to household h\"if some increase in those assets held by household h' in so me positiveamounts can be used in a reallocation of the en tire economy so thatno household is worse off and household h\" is strictly better off.Note that the only property of household h' that is relevant to thedefinition is a list of those commodities with which he is endowed insorne positive amount; the only relevant property of household h\" isits utility function. Note too that the manner by which the additional endowments improve the lots of household h\" may be veryindirect. Of course, they may en ter directly into the utility functionof h\"; they may be factors of production used to produce commodities that in crease the utility of h\"; they may be neither of these,but rather, they may enable the production of commodities thatincrease the welfare of some other household, permitting the last togive up some other goods so that its utility leve! does not on balancefall below the initial level, while h\" is made better off by the goodsgiven up.\n116\nwhich, from (6), can be written\n2: sJt(p*,w*) = O.\n(15)\nh\nWe seek to show that D.5.2(e) holds; that is, S¡¡(p*,w*)=O, all h.From (15), it suffices to show that s¡¡(p* ,w*) 2 O, all h. Suppose,then, s\"(p*,to*) < O, some h. From (7) and (13), v~ = O; byLemma 5.3 and (11), u~ = O. By construction, X¡¡ E X\" ist's behaviorwill not suffice to exclude this possibility.\nza\n(25)\nWe now turn to the behavior of the monopolist. At any givenmoment, the monopolists observe current prices and the currentallocation and (individually) décide on their prices. We do not herenecessarily derive their behavior from any hypothesis of profit-orutility-maximization, but 'we do assume that, whatever criterionthey employ, their choices of prices and quantities will de?endcontinuously on observations ofthe rest ofthe market. Under ddferent alternative perceptions of demand conditions, the prices andquantities chosen will differ, but there will be a functional rel.ationon which all the price-quantity choices willlie for given behavwr ofthe rest of the economy. In equilibrium, the actual behavior of themonopolist will be jointly determined by the posited relation an~ ~hetrue demand relation derived from .the behavior of the competitivesector.We shall illustrate the assumptions in the conventional partía!equilibrium analysis of monopoly. The monopol.ist bel~eves thatthe demand curve is given by p = d(y,e), where e 1s a sh1ft parameter. Let R'(y,e) be the corresponding perceived marginal revenuecurve for any e and C'(y) the monopolist's marginal cost curve.Then, for any given e, output and price are determined as the solutions of the pair of equations p = d(y,e), C'(y) = R'(y,e). If weeliminate e in these two relations, we have a single relation betweenp and y, say, y = f(p). This relation might be termed the mono~o­list's supply curve. It is a relation between his price and his quantltythat holds regardless of the demand curves he perceives. Theactual equilibrium of the economy will be determined b~ this relation together with the true demand curve, say, p = d(y). Thefunction d(y) need not coincide with the function d(y,e), for anye, if the monopolist's perceived family of demand curves ~oesnot include the true one. If p*, y* satisfy the two equatwns\nT1\n158\nGENERAL COMPETITIVE ANALYSIS\ny* = f(p*) and p* = d(y*), then the monopolist will perceive the\n·1·:\n!.\ndemand curve as that determined by the value of the shift parameter 8* determined by the relation p* == d(y*, 8*). He must perceivethe correct actual demand, though not necessarily the true demandfunction.Thus, we are assuming a stable relation between the price andquantity decisions of the monopolists, given the observations onprices and quantities in the rest of the economy. If we regard themonopolist's output as the dependent variable, we can think of italso as a function of all prices and quantities; this is not to implythat he takes his price as given, but rather that, given all other pricesand all other quantities, his output decision is functionally relatedto his price decision. Given the monopolized outputs, the choice ofcompetitive inputs to produce them is determined on a cost-minimizing basis. Hence, the total production decision of the monopolyis a function of all prices and quantities. Though we are notassuming profit maximization, it is necessary in a private-enterpriseeconomy to insist on viability; no monopoly can be making anegative profit.\nGENERAL EQUILIBRIUM UNDER ALTERNATIVE ASSUMPTIONS\nWe now repeat the assumptions on consumer behavior discussedin Chapter 4 with a rather technical strengthening of A.4.2.AssuMPTION 17. (a) Assumptions A.4.1, A.4.3, and A.4.4 hold.(b) There exist possible consumption vectors x~ E X\", k = 1, 2,not indifferent to each other, such thatfor k= 1, 2.From (b), we can assume without Ioss of generality thatx~ >-\"xkall h.The utility function, U\"(x\"), can be so chosen that U\"(xk) = O,U\"(x~) = 2, aii h. Then any household can clearly achieve autility of more than 1 regardless of prices. Without loss of generality, then, we restrict ourselves, where appropriate, to allocationsthat achieve a utility of 1 at least for each individual. Define11/'(e) = .%'(e) x I!JJ e x I!JJ M•if'(e) = 11/'(e) n {(x,lf'c•lf'M)Ix S Yc + YM + x},\nW111 (e) is the projection ofif'(e) on I!JJM.\n'1\nAssuMPTION 16. For each monopolistic firm, g, the productionvector is a continuous function, yMg(p,w), of prices and allocationssuch that PYMg(p,w) :2:: O for all p and w.We now turn to the competitive sector, which determines thedemand for monopolized goods. Sorne further notation is needed.For any .fixed monopolistic production allocation, lfM• there is arange _of feasible allocations for the competitive sectors, providedlfM E I!JJ M' namely, those allocations w 0 = (x,1fc) for which\n2 xh S 2 Ycr + X + 2 YMuh\nf\nYcr E Ycr, xh E xh.\ng\nThe productive activity of the monopolistic sector can be treatedas a modification of the initial endowment from the viewpoint of thecompetitive sector. The set of allocations (oc satisfying theseconditions will be denoted by if' c(lf'M).As in Section 4.4, especially D. 4.6-11, we shall be interested infeasible allocations in the competitive sect~r that yield each household at Ieast a prescribed utility leve!. For any vector of utilities,u, we define\nif' c(U,1fM) = if' c(lf'M) n {(x,lf'c)l U\"(x\") :2:: u\", all h}.\n(26)\n159\nAs before, e is the vector all of whose components are 1; in this case,its dimensionality is equal to H, the number of households.The reasoning Ieading to (25) can be repeated with I!JJ M replaced byI!JJ M(e).There exists a continuous function, a(lf'M), with aunique inverse, that maps 1!JJ M( e) into a compact convex\n~A.\n9n\nFor fixed 1/M E <2?1 M(e), we can consider the range of feasible utilityvectors in the competitive sector, that is, the set of vectors u forwhich \"if'(u,lf'M) is non-null. By definition of <2?1 M(e), the vector eis always feasible, so there are always sorne non-negative utilityvectors. We can consider then the range of non-negative Paretoefficient utility aiiocations, U(I!JJ 111). For each u E U(I!JJ M), the set ofPareto-efficient competitive allocations is \"if' u(u,!fM)· By A.6.17,the reasoning leading to T.4.4, the basic theorem of welfare economics, is still valid here, so aiiocations in this set are al! supported bya set of price vectors,\nP0 (U,1fM)·Since e is feasible, O is always dominated.\n(28)Hence Lemma 4.13\n''' ''1''\ni, 1'''1\nil'¡,,\"'11\n160\nGENERAL COMPETITIVE ANALYSIS\n1\nGENERAL EQUILIBRIUM UNDER ALTERNATIVE ASSUMPTIONS\n,1\ni!'!\ni:l\nremains valid (see the Remar k to that Iemma). Hence, the proof ofLemma 5.3 remains valid, so that, for fixed !fM, there is a function,\nu(v,yM),\n1\n1,,i.'J:\n;¡!111,11,\nAssuMPTION 18.\n•11' 1\nmust hold:\n¡'\n,1\n¿ df,(p*y~,) + ¿ d~(p*yttg);f\ng\n(e) ytcr = !fM(p*,w*).The function\n!fM(p,w)in part (e) of this definition is the allocation whose firm componentsare the functionsintroduced in A.6.16.\nSuppose neither (a) nor (b) hold. Then all primary factors arefree, and no competitive firm can make any profit. Then thisassumption simply asserts that at least one monopolistic firm mustbe capable of making positive profits.In defining equilibrium for monopolistic competition, we mustprovide for the distribution of monopolistic profits to households.The income of the household is now given by\nM\" = PXn +\n¿ df?r(PYor) + ¿ d/({;(pyMf\n9 ),\n(29)\ndf(, ;::: o\n¿dí?¡ = 1h\nso that\n¿M\" = px + PYM + PYo·h\n(30)\nDEFINITION 22. A price vector, p*, and an allocation, w* =(x*,y~,ytcr) constitute a monopolistic competitive equilibrium if\np* > O;\n(b) ¿x~ ~\n¿xh + ¿Y~r + ¿ytrg;h\nf\nUnlike the procedure of Chapter 5, we do not explicitly introducea corresponding definition of compensated equilibrium. We shallstill need an assumption of resource relatedness to prove the existence ofmonopolistic competitive equilibrium. We use definitionsD.5.4-5 but relate them to the competitive sector only; monopolisticinputs and outputs are treated as alterations ofthe initial endowment.AssuMPTION 19. Every household is indirectly resource related toevery other through the competitive sector alone for every initialendowment obtained by replacing x by\nx + ¿ YM\n9\nfor sorne . !IM E !fM(e).\ng\ng\nwhere, of course,\nh\n(d) x~ maximizes U\"(x\") subject to\nFor any price vector p, at least one ofthe following\n(a) px > O;(b) for sorne j, PYor > O for sorne Yor E Yor;(e) for any to, PYM9(p,w) > O for sorne g.\n(a)\nY~r maximizes p*y 0 , subject to Yor E Yor;\np*x\" ~ M;t = p*x\" +\nmapping the unit simplex SH into U(yM); the function, u(v,yM), caneasily be seen to be continuous in both variables.We now make an assumption that plays the same role as A.3.5,the ability of the economy to produce a positive amount of everygood. This assumption was used to show that the aggregateincome of the economy must be positive. Here, we simply makethat assumption more directly.\n!¡::,¡11\n(e)\n161\ng\nWe now construct the mapping used to prove the existence ofequilibrium. The basic principie of the mapping of Chapter 5 isretained, but modified to introduce both quantities used in thecompetitive sector and production decisions of monopolists. Themonopolized commodities appear twice in the space in whichthe mapping takes place, but the mapping is so arranged that, atthe fixed point, the two output variables corresponding to the samegood are equa.l. The other variables in the mapping are, as before,prices and relative utilities. The prices in the image will be thosethat sustain an efficient allocation in the competitive sector for givenmonopolistic production decisions. For the image vector ofrelativeutilities, the previous construction is modified in the obvious way.Simply define\n:!,1\n(31)\n'1\n'i1\n,ll il1'¡,11'\nL.t\n'1,\n,,1,,1\nri\n162\nGENERAL COMPETITIVE ANALYSIS\nGENERAL EQUILIBRIUM UNDER ALTERNATIVE ASSUMPTIONS\nwhere w = (x,y 0 ,yM) and Mh is defined in (29),V(p,w) = SH n {vlvh =o if sh(p,w) < 0}.\n(32)\nWe also map the initial situation into the efficient allocation ofcommodities in the competitive sector, conditional on the outputsof the monopolistic sector. For the monopolistic sector, we wouldlike the new value ofthe monopolistic production vector to be on theresponse function postulated in A.6.16. We also want this imageto be in or correspond to a point in A, that is, equivalent to a production vector in qfjM(e), the set that is indexed by A according to (27).The second property will be satisfied at equilibrium if there is one,but not in general for an arbitrary initial p, w. We thereforeconstruct a mapping into A as follows. First, find !fM(p,w), themonopolist's response according to A.6.16. Then map this pointinto @M(e) in such a way that it is unchanged if it is already in thisset. Then map the resulting point into A according to (27). Todo this, choose !1~ to belong to the interior of the neighborhoodspeci:fied in A.6.15. Clearly we can do this in such a way that\nx 0 « yg + y~ + :X for sorne\nx 0 E El'(e), yg E Y0 •\n(33)\nLet p(yM) be the gauge function for the set@ M(e) with center lf~ (seeSection B.2, especially T.B.2). Then !/M E qf)M(e) if and only ifp(yM) ::::; l. Let q(yM) = max[p(bfM), 1]. Then q(yM) = 1 forbfM E WM(e), q(yM) > 1 for Y' M E qf)M(e). Define\n163\nand P0(u,bfM) and 11\"0 (u,bfM) are defined in (28) and (26), respectively.Then Kakutani's theorem guarantees the existence of a :fixed pointfor this correspondence, (p*,v*,w~,a*). Let lf~ be defined bya(y~) =a*\nandu* = u(v*,y~).Sin cep* E P0 (u*,y~)\nw~ E if' 0 (u*,y~),\n(36)\nit follows from T.4.4 that D.6.22 (a)-(c) hold, and alsox~ minimizes p*x~< subject to Uh(xh) :2:: u~.\n(37)\nFrom (31) and (36), it follows, as in Section 5.3, that\n¿ sh(p*,w*) = O.h\nAt the :fixed point, v* E V(p*,w*).follows that\nAgain as m Section 5.3, it\ns¡,(p*,w*) :2:: O\nall h,\nsh(p*,w*) = O\nall h,\nand therefore\n!f~(p,w) =y~ + $fMiP'(~[J~.q bfM ,w\n(34)\na (p,w) = a[y~(p,w)].\n(35)\n(38)\nIn (34), we accept the monopolist's response if it permits a utilityof at least 1 to each household (a utility that can be achieved withouttrade); if not, we move the response toward a given point until itsatis:fies this condition. In (35), we relabel this point to put it in aconvex compact set.We map the setSn X SH X if'& X A\nWe know that (37) and (38) imply that D.6.22(d) (utility maximization) holds if it can be demonstrated that M(: > O(see the proofof T.5.2). Because of A.6.19 (resource relatedness), it suffices toshow that\n1\ninto the correspondencePo(u,yM) x V(p,w) X \"lf' 0 (n,yM) X {a1(p,w )},\nor equivalently,\n¿M(:> O.h\nFrom (33), we know thatp*(yg + y~ + :X) > o.By pro:fit maximization, p*y~ :2:: p*yg and also p*y~ :2:: O.\nwherebfM satisfies the condition a(yM) = a, and u = u(v,yM),\np*(i + y~ + y~) > o\nHence,(39)\n,,11\n,,¡,,,,\n;¡:'11\n'.,\n1\n.11·1)1\n164\nGENERAL EQUILIBRIUM UNDER ALTERNATIVE ASSUMPTIONS\nGENERAL COMPETITIVE ANALYSIS\nand\n165\nSince each household is maximizing utility and since each canachieve a utility of 2 without using the market, it must be that\np*(x + yt) :2: o.\nu~ :2: 2\nFrom A.6.16,\nall h.\nIf yXr were changed to any J/M in its neighborhood, there would still ·exist competitive allocations feasible conditional on the monopolisticallocation J/M• which would achieve a utility strictly greater than 1for each individual. Then yXt must belong to the interior of the set\nP*YMg(p*,w*) :2: Oand, therefore, summing over g,\np*yM(p*,w*) :2: Oso that\n!fY M(e).\nP*[X + Ya* + YM(p*,w*)] :?: O.\n(40)\nBy definition of the gauge function,\nFrom (35), at the fixed point,\np(yft) < l.\nal(p*,w*) = a*,\nBy (34),\nor\np( *) = p(ffM(p*,to*)] < 1J/Mq((JfMp*,w*)),\nykt(p*,w*) = yXt,so. from· over g, we see that y* .. (34) an d summmgbmatwn of yo and( * *..M IS a convex com•MYM P ,w ), With we1ghts 1 _ (ljq*) and ( 1/ *)q ,respectively, where\nTHEOREM 4. Under assumptions A.6.12-19, monopolistic competi.tive equilibrium exists.\nThen, from (39) and ( 40),p*(x + Y~ + yft) :2:: o,\n(41)\nand the strict inequality holds if q* > l.q* = 1, then\nIf, on the contrary,\nyft = YM(p*,w*),and by A.6.16,\np*yft :?: o.Then equality can hoJd in (41) only if simultaneously\np*x = O, p*yt = O, and p*yft = oin contradiction to A 6 18 Th f'in (41) in any case; by.cJO):ere ore, the strict inequaJity hoJds\nh\nand, therefore, D.6.22(d) hoJds.,\nyXr = ¿fM(p*,w*),which is D.6.22(e).\nq* = q[oYM(p*,w*)].\n2M/t >O\nFrom the definitions, this can happen only if q* = 1, that is, if\nRemark l.\nNo explicit mention has been made of productdifferentiation, a central theme of monopolistic competition theory,but note that the model admits the possibility that any rnonopolisticfirm can produce a variety of goods. Suppose that all conceivablegoods are included in the list of commodities; even what are usuallyregarded as varieties of the same good must be distinguished in thislist if they are not perfect substitutes in both production and consumption. In general, a monopolist will find it profitable toproduce a number of varieties. The definition of a monopolyimplies that, for some reason or another, two different monopolistsproduce non-overlapping sets of goods, but of course the goodsproduced by one monopolist may be quite clase substitutes forthose produced by another. The usual idea in product differentiation-that a firm produces just one commodity-is not a convenient assumption for general equilibrium analysis, but it isequally certainly not a good description of the real world.\n;¡\n1\n:,\n1\n¡:\n¡ll¡::11\n1:1\n11\n11\n166\n' i1\nr,,\nGENERAL COMPETITIVE ANALYSIS\nGENERAL EQUILIBRIUM UNDER ALTERNATIVE ASSUMPTIONS\nRemark 2. The notion of free entry, and with it the famousdouble-tangency solution of Chamberlin [1956, pp. 81-100] andRobinson [1933, pp. 93-94], has no role here either. The list ofmonopolists is assumed given, so that in effect there is a scarcityof the appropriate type of entrepreneurship, and there is no reasonfor profits to be wiped out. No doubt if there are severa! firmsproducing producís that are close substitutes in consumption andhave very similar production possibility sets otherwise, they shouldbehave about the same way, and if there are enough of them, it maywell be that each is making very little in the way of profit. But thequestion then is the one raised originally by Kaldor [1935]: Wouldnot the elasticity of demand to the individual firm be essentiallyinfinite, so that the situation is essentially one ofperfect competition?This question has not been fully answered, since a more specificmodel defining close substitutes and their production possibilitieshas not yet been explicitly formulated.\nirrelevant. The problem may be important, however, if his perceptions are accurate only at equilibrium or if there are severa!monopolists; the discontinuity in the behavior of any one affects theperceived demand functions for the others, though, again, if themonopolists are relatively separated in markets and each is relativelysmall on the scale of the economy, then the discontinuities involvedmay be unimportant.\nRemark 3. An open and potentially important research area isthe specification of conditions under which monopolistic behavior,as expressed in the function yM(I),.w) is, in fact, continuous. Theformulation is very general; it is certainly compatible with utilitymaximizing behavior (e.g., preference for size or particular kind ofexpenditure or product) as well as profit-maximizing behavior.The assumption of continuity may be strong nevertheless; in effect,it denies the role of increasing returns as a barrier to entry. Asdemand shifts upward, the firm might pass from zero output (i.e., apurely potential existence) to a minimum positive output. A zerooutput must be interpreted as a price decision at a leve! corresponding to zero demand, but if the demand curve slopes downward,then entry at a positive leve! far removed from zero implies a discontinuous drop in price. The importance of this problem is noteasy to assess. The situation can arise only if the (perceived)marginal revenue curve is, broadly speaking, flatter than the marginalcost curve (otherwise entry would be a continuous phenomenon)but the demand curve must also be relatively flat and therefore theprice discontinuity may be mild even if the output discontinuity islarge. Also, if there were only a single monopolist who correctlyperceived the excess-demand correspondence of the competitivesector, he could choose his most preferred point, which would bethen an equilibrium; the discontinuity of his behavior would be\n167\nRemark 4. It must always be remembered that monopolisticcompetition models of the type discussed here ignore the mutualrecognition of power among firms, the oligopoly problem.Notes\nSection 2. The analysis of this section was developed jointly withDavid Starrett. It is rather hard to make out from the usual literaturewhether it is assumed that competitive equilibrium is compatible withexternalities. Chipman [1970] reviews sorne of the literature. In aparticular case he shows how externalities that give rise to socialincreasing returns, but priva te constant returns, are compatible with theexistence of competitive equilibrium and even, under special circumstances, to Pareto efficiency. Por a good general statement of theusual doctrine of equilibrium with externalities in production, see Bohm[1963, Chapter 2]. Por a rigorous proof of the existence of equilibriumwith externalities in consumption, see McKenzie [1955b].Section 3. The analysis of temporary equilibríum was introducedby Hicks [1939, pp. 130-133]. A more recent methodological discussion can be found in Hicks [1965, Chapter VI]. The possibility ofan existence theorem for temporary equilibrium was indicated bySaito [1961, pp. 233-236]. The results of this section have appeared inslightly different forro in Arrow [1971 ].Section 4. The model presented here is a formalization of Chamberlin's case of monopolistic competition with Iarge numbers [1956, pp.81-100; originally published in 1933]. As Triffin [1940] showed, theessential aspects of monopolistic competition aRpcar as soon as weattempt to introduce sorne monopolies into a system of general competitive equilibrium. . The only previous complete formal model is thatof the brilliant paper of Negishi [1960-61], who proved an existencetheorem for it, the only previous work of this type known to us. Negishiassumed that each monopolist produced only one commodity andmaximized profits according to a perceived demand curve that was afunction of all príces and the entire allocation, but, in particular, waslinear in the price of the commodity. He saw the importance of insisting that at equilibrium the monopolist's perceived demand curveshould at Ieast pass through the observed price-quantity point. In hisformulation, which was originally suggested by Bushaw and Clower\nf.,,,,\n~11\n1\nr\n1'¡, ¡1\n1'1'\ni\n1'1\n!'\n1,¡::¡:11:!11!.'¡\n168\nGENERAL COMPETITIVE ANALYSIS\n[1957, p. 181], the monopolist's price equaled the given one if, at thegiven allocation, supply and demand were equal for that commodity.Also, Negishi restricted attention to the case in which the monopolistshave convex production possibility sets, a severe condition since theoccurrence of monopoly is unlikely under those circumstances, as Negishihimself noted [p. 109, middle]. He raised the possibility of more generalassumptions, similar to A.6.15.A model in tended to represent the ideas of this sectión has already beenpresented in Arrow [1971]. The results given there, however, whilemathematically correct, suffer from considerable difficulties in interpretation. We are greatly indebted to Tatsuro Ichiishi, Keio University,and James Mirrlees, Oxford, for demonstrating to us the need for newthinking on these questions.\nChapter Seven\nMARKETS WITHNON-CONVEX PREFERENCESAND PRODUCTIONA guif profound as that SerbonianBogBetwixt Damiata and mount Casiusold,Where Armies whole have sunk.-John Milton, Paradise Lost\n1. IntroductionThe assumptions of convexity of production (A.3.3) and ofpreferences (A.4.4( d)) ha ve played an essential role in the proof ofexistence of competitive equilibrium. Convexity implies thatresponses of firms and households to changes in prices tend to becontinuous; even when jumps occur (as under constant returns fora firm), every point jn the whole interval between the two extremitiesof the jump is a permissible response so that there are no gaps inwhich an inequality between supply and demand can be fitted. Thispoint can be seen for firms by contrasting Figures 3-1-3-3 withFigure 3-4 (see a1so the accompanying text). In Figure 7-1 wereproduce the production possibility set of Figure 3-4a and add theimplied demand function for the input. Let commodity 1 be inputand commodity 2 output. Then, for p 2 (Jh less than sorne critica!price ratio, a, the firm will make negative profits at any positiveoutput leve! and, therefore, will supply and demand zero. Atp 2 (p 1 = a, the firm will make a zero profit at precisely one non-zeroactivity, (y~,y~) and negative profits at all others. Thus, the profitmaximizing firm is indifferent between (0,0) and (yLyn; the demandby the firm is two-valued, the values being O and -y~. For p 2 /Pl >a, the demand will exceed -y~.Suppose the firm is the only one in the economy, the initial endowment of the economy (summed over all households) is (.X\\,0), andcommodity 1 does not enter anyone's utility function, so that thesale demand for the commodity arises from the firm's productiveactivity. Then if O < .X1 < -y~, it is clear that no equilibriumprice ratio exists. If p 2 (p 1 < a, then supply of commodity 1 exceeds\n169\nT\n¡: i ,\n'1\n170\nGENERAL COMPETITIVE ANALYSIS\nDemand forinput (-y 1 )\nDemand forinput (-y 1 )\n----\n-2y~\nx,\n-y~\n-y~\nx,\n(b)\n'------e------pz/p,\na\n(e)\na\n·¡l¡.\n,1.\n·:il11\n1\nr¡·•\n¡¡,·¡ll11'¡!'1\n¡:.·.\n!j:\nl.i11'.1\n1'1\n11'!¡'1\ni\n.1\n.1\nMARKETS WITH NON-CONVEX PREFERENCES AND PRODUCTION\n(a)\n: ' '1\nT\nFigure 7-1\ndemand. If p 2 /p 1 > a, then demand exceeds supply on that market.lf P2/P 1 = a, there is no behavior of the firm that simultaneouslymaximizes profits and absorbs exactly the available supply.Suppose that Figure 7-la were modified by adding to the production possibility set every production vector on or below the straightline segment OA. Then at the price ratio a all these points wouldyield a zero profit; the demand correspondence for the input wouldinclude the whole vertical segment from Oto -y~. Then the equilibrium input would be .X1 and the equilibrium price ratio a. Thiscomparison brings out more specifically the role of convexity inestablishing the existence of equilibrium.Since existence of equilibrium is not assured in the presence ofnon-convexity, it may be worthwhile to ask how clase to equilibriumthe economy can come, under the assumption that the firm is profit\n171\nmaximizing. Suppose first that O < .X1 ::::; - yV2. Assume theprice ratio is a. Then, if the firm purchases zero, there is an excesssupply .X 1 • If, on the contrary, the firm purchased - y~-an equallyprofitable decision-demand would exceed supply by -y~ - .X 1 ::o:.X 1 . There is, then, a price ratio, a, anda profit-maximizing demand,O, for which the absolute discrepancy between supply and demanddoes not exceed - yV2. If the price ratio were different from a, thediscrepancy could not be smaller. Now, ifwe suppose that -yV2 <.X1 < -y~, the smallest discrepancy between supply and demandoccurs at price ratio a and profit-maximizing demand -y~; this timethere is excess supply, but again the discrepancy does not exceed- yV2 in absolute value.Now, to continue the example, suppose an economy with twoidentical firms, each with the production possibility set defined byFigure 7-la. The aggregate demand for two firms is represented inFigure 7-1c. Then aggregate demand for commodity 1 is zero forp 2 /p 1 < a, and it exceeds - 2y~ for p 2 /p 1 > a. If p2 /p 1 = a, eachfirm will, as befare, demand either zero or -y~. Since neither, one,or both of the two firms may be demanding a positive amount ofcommodity 1, the aggregate demand at p 2 /p 1 = a is tri- valued, thethree possible values being O, -y~, and - 2y~. Now, if .X1 liesbetween O and - 2y~, it is clear that at the price ratio a we canarrange that the discrepancy between supply and demand not exceed- yV2 without violating the assumption that firms maximize profits;all that is needed is to choose that one of three possible magnitudesthat is closest to xl.This conclusion suggests the interesting implication that thepossible discrepancies between supply and demand do not necessarily increase with the number of agents in the economy. Putanother way, the ratio of the possible disequilibrium to the size ofthe economy decreases. The aim of this chapter is to give a generalformulation of this result.The possibility that, at the price ratio a, one firm may be operatingwhile the other is not suggests another implication of non-convexity:At an equilibrium or approximate equilibrium it may be necessarythat identical firms behave very differently.The possibilities for validity or invalidity of the convexityhypothesis have been discussed in Section 3.2. It was argued therethat non-convex production possibility sets could be expected toarise from indivisibilities in production processes .\nT172\nGENERAL COMPETITIVE ANALYSIS\nMARKETS WITH NON-CONVEX PR~FERENCES ANO PRODUCTION\nIt is similarly possible that the preference orderings of householdsdo not satisfy the convexity condition A.4.4(d). Sorne pairs ofcommodities may be antagonistic in consumption. Whiskey andgin form a frequently cited pair of this kind. A more seriousexample is residential location. An individual may be indifferentbetween consuming seven days a week a day of living in Californiaand consuming the same amount of living in Massachusetts, but he\nmay well prefer either to splitting the week between the two. (Onthe other hand, a different choice may be made if the alterna ti ves areLondon and Cambridge.) Evaluations of esthetic satisfaction oftastes, in general, áre al so unlikely to be convex. \"There is noexcellent Beauty that hath not sorne strangenesse in the proportion,\"says Bacon. \"A man cannot tell whether Appelles or AlbertDürer were the more trifler; whereof the one would make a Personage by geometrical proportions; the other, by taking the bestparts out of diverse Faces to make one excellent.\" Nor would aconvex combination of tripe it la mode de Caen and filet de so/eMarguéry be regarded highly by the gourmet (perhaps Chinesecuisine admits more convexity in preferences among its dishes thandoes the French). No doubt the root of any non-convexity inhousehold preference orderings is sorne indivisibility; in any consumption activity, one input is the individual. For our purposes itsuffices to recognize the possibility that preference orderings mayexhibit non-convexities without seeking a deeper explanation.Figure 7-2 illustrates the demands derived from non-convexpreferences, analogous to those derived from non-convex productionpossibility sets in Figure 7-1. It is assumed that the household hasan initial endowment vector, x. Then again the demand correspondence at sorne price ratio will be two valued, but it will have agap.\nXz\n2.(a)\n-'----------------P2fPt(b)\nFigure 7-2\n173\nThe Method of Analysis anda Measure of Non-Convexity\nIn this chapter, we will state a general theorem on the degree towhich an economy not satisfying the convexity assumptions inproduction and consumption nevertheless can possess approximatelya competitive equilibrium; that is, we will show the existence of aprice vector, a consumption vector for each household that minimizes the cost of achieving a given utility leve! and satisfies the budgetconstraint at those prices, and a production vector for each firm thatmaximizes profits at- those prices, such that the social excess demandfor all commodities is bounded in a manner determined by the degreeof non-convexity of the preference orderings and the productionpossibility sets. Further, we can so determine this upper bound onthe discrepancy that it does not increase with the size ofthe economy;hence, the discrepancy divided by sorne measure of the size of theeconomy (e.g., the number of economic agents) approaches zero.This result is stated with greater precision in T. 7.1.\n,\n1\n!\ni11\n174\nGENERAL COMPETITIVE ANAL YSIS\nThe rnethod of analysis is the following. Frorn the given econorny,we construct a new one satisfying all the conditions of the existencetheory of Chapters 3-5. Recall the definition of a convex hull.(See D.B.3, D.B.12, and T.B.7.) A vector x' is said to be the convexcornbination of the vectors in a finite set T if there exists a nonnegative real-valued function, a(x), defined for x E T, such that,\n2; a(x) = 1\n2; a(x)x = x'.\nxeT\nxeT\nWe will say also that the set T spans x'. The convex hui! of a set Sis the set of all vectors, x', that are convex cornbinations of finitesubsets of S. An alternative and equivalent definition is that theconvex hull of S is the intersection of all convex sets of which S is asubset. It is clear that the convex hull of a convex set is the setitself; in general, the convex hull of S is the srnallest convex set thatcontains S.Starting with a given econorny, then, we replace the productionpossibility set of each firrn by its convex hull. Sirnilarly, we replacethe preference ordering of each household by an ordering thatsatisfies the convexity property; this is done by replacing each uppercontour set, that is, {xh 1xh >=h x~} for each possible x~, by its convexhull. We assurne that the convexified econorny so defined satisfiesall the assurnptions of Chapters 3-5. Then it has a competitiveequilibriurn, that is, a price vector, p*' and a feasible allocation,to* = (x*,,Y'*), where x;t' is cost rninirnizing at sorne given level ofthe convexified utility and satisfies the budget constraint and yj isprofit rnaxirnizing in the convexified production possibility set.Each x;t' is a convex cornbination of vectors that belong to the cornpensated dernand correspondence for the original econorny for sorneutility level and the given price vector, p*. It can be shown that wecan choose, for each h, one arnong these vectors, say xl;, in such away that\nis bounded by a rnagnitude that depends on the rnaxirnurn degree ofnon-convexity of the preference orderings. Sirnilarly, we canchoose y}, which is profit rnaxirnizing in the original productionpossibility set at p*, such that the discrepancy\nMARKETS WITH NON-CONVEX PREFERENCES AND PRODUCTION 175is bounded by a rnagnitude that depends on the rnaxirnurn degree ofnon-convexity of the production possibility sets. The price vector,p*, and the allocation a ..t = (xt,y: together constitute an approxirnate equilibriurn in the sense that the discrepancy between supplyand dernand is also bounded (with a rnodification for free goods).No rnatter how large the econorny, the bound is deterrnined by thernaxirnurn degree of non-convexity.For a pure-exchange econorny in the special case where Xh, theconsurnption possibility set, is the entire non-negative orthant, aconsiderably stronger conclusion can be derived; there is a feasibleallocation w** whose distance frorn the allocation tot is boundedsirnilarly to the above. This irnplies that for each individual thedistance between his bundle under the feasible allocation, x;t'*, andhis chosen bundle, xh, approaches zero as the nurnber of participantsin the econorny grows.We have referred vaguely to the \"degree of non-convexity\"; it isnecessary to introduce a specific rneasure. First, we define theradius of a set S, rad(S), as the radius of the srnallest ball (i.e., set ofthe forrn {x llx - x 0 l s R}) containing S. We now define theinner radius r(S) of a set as follows: for every x E2 con S, there is, bydefinition, a finite subset Te S that spans x. For every such x,find the infirnurn of rad(T) as T varíes o ver all such spanning sets;then define r(S) as the suprernurn o ver all x in con S of this infirnurn.Note that if x E S, it is, in particular, spanned by the one-elernentset {x} and therefore inf rad T over all spanning sets Te SisO. Fora convex set, con S = S; hence, r(S) = O if and only if S is convex.Thus, r(S) is a rneasure of non-convexity andbe used as such inthis and the following chapter.1')\nwill\n3.\nApproximation to Market Equilibrium\nIn accordance with the discussion in the previous section, we nowassurne that if each production possibility set is replaced by its convex hull, then all thc assurnptions of Chapter 3 are satisfied.AssuMPTION l.each of thern.\nA.3.1-A.3.4 hold when Y1 is replaced by con Y1 in\nIt is slightly less obvious how we replace a non-convex preferenceordering by a convex one. The original preference orderingdefines (and is defined by) the class of upper contour sets, that is, the\n1\n1\n1\n1\n176\nGENERAL COMPETITIVE ANAL YSJS\nMARKETS WITH NON-CONVEX PREFERENCES AND PRODUCTION\n177\nclass of all sets of the form {xh xh :P:~t x~} as x~ varíes over allelements in Xh. (Of course, many elements x~ may define the sameupper contour set.) Of any two upper contour sets, one must alwaysinclude the other; in particular, they may include each other, inwhich case they are identical. Now, if S 1 and S 2 are sets in the samevector space and S 1 e S 2 , con S 1 e con S 2 • Hence, among theclass of sets that are convex hulls of the upper contour sets, it mustalso be true of any pair of such sets that one includes the other. Itis possible, therefore, to define a new ordering, which we may referto as the convexijication of the original, by the condition that x 1 ispreferred or indifferent to x 2 (in the new ordering) if every convexhull of an upper contour set that contains x 2 also contains x 1 (seeFigure 7-3). In symbols,\nNo doubt, it is possible to specify assumptions on the originalproduction possibility sets and preference orderings from whichA.7.1-A.7.2 could be deduced, but we refrain here.In view of the basic theorem, T. 5.4, we can assert that, under theseassumptions, there exists a compensated equilibrium for the convcxified economy, in other words, that defined by replacing production possibility sets and upper contour sets by their convex hulls.That is, there exists a price vector p* and an allocation .w* = (a:* ,!f*)such that p* > O,\nx~ :P:~t\" x~ is defined to mean that for every x~ forwhich x~ E con{xh 1 xh >=h x~}, it is also true that x~ E con{xh 1 :P:~t x~}.\n1\nAssUMPTION 2.\nDEFINITION l.\nFrom the preceding remarks, the relation >=hlc is certainly connected, while transitivity follows directly from 0.7.1. Hence, :P:~tlcis certainly an ordering. We now assume\nA.4.1-A.4.4 hold when :P:~t is replaced by :P:hlc·\nx* :::;; y* + x,\n(1)\nyj maximizes p*y1 subject to Yr E con Y1 ,\n(2)\nx~ minimizes p*xh subject to xh :P:h1c x~,\n(3)\np*xh* = M*h = P*xh\n+ 'Vd¿, hf (p*y*)r ·\n(4)\nf\nWhen convexity obtains, an equilibrium allocation achieves all ofthe following: feasibility, optimization for each individual atequilibrium prices (profit maximization for firms, cost minimizationfor given utility for households), and satisfaction of the householdbudget constraints. With non-convexity, of course, we cannot hopefor so much. lnstead, we will find a price vector and two allocations,one of which is feasible and the other optimal for each individualand satisfying household budget constraints at the given prices, suchthat in the aggregate the two allocations are close. Formally, weintroduce the following definition.2. A social-approximate compensated equilibrium ofmodulus A is a price vector p* > O and two allocations, <o* =(a:*,y*) and .wt = (a:t,y't), such thatDEFINITION\n(a)(b)(e)(d)(e)LEGEND:\nOriginal indifference curves______ Convexified indifference curves\nFigure 7-3\nx* :::;; y*+ x,\np[ = O if xt < y[ + X;,yj maximizes p*yr for Yr E Y¡,x); minimizes p*xh subject to xh :P:h xi;,p*x); = Mht = p·*-xh + \"d¿, hf (P*Yr·1·) = M*h = P*xh\n+ 2: dh¡(p*yj),(f)\nf\nf\nl(x* -y*) - (x·l· - yt)l :::;; A.\nThen the following theorem will be demonstrated.\nGENERAL COMPETITIVE ANALYSIS\n178\n¡¡¡,,\nMARKETS WITH NON-CONVEX PREFERENCES AND PRODUCTION 179\nTHEOREM l. Under A.7.1 and A.7.2, if Lis such that r(Y1) :::; L, allJ, r({x\" 1 x\" ':?=\" xh}) :::; L, all h, then there exists a social-approximatecompensated equilibrium of modulus LVn,where n is the number of\n(For the last relation, see Lemma B.2.) Sincerad S\" and rad(- Tr)are all uniformly bounded by L, we can apply the Shapley-Folkmantheorem (T.B.9) and assert the existence of\ncommodities.\nztE¿s\" + :LC-Tr)\n1.\nProof\nWe take p* and ro* to be the equilibrium for the convexified economy, so that (1)-(4) are satisfied and, therefore, D.7.2(a)-(b ). Sin ce y'J E con Y1 , y'J is the convex combination of at leastone finite subset of Y 1 . Among al! such subsets, choose the one withthe smallest radius; by the definition of inner radius and the assumption that r( Y1) :::; L, we can find a set, T1 e Y1 , that spans yj andfor which rad(T1) :::; L. By definition, there exists a non-negativevalued function, a(y1), defined for Yr E T1 , such that\nL a(y )y = yj1\nL a(y = l.1)\n1\n~E~\n~E~\nClearly, we can assume a(y 1) > O without loss of generality, forotherwise the corresponding y 1 can be deleted from T 1 withoutaltering either of these relations. Thenp*y'J =\nL a(yr)p*yr;\nf\nh\nfor which lx* - y* - ztl :::; LVn; that is, we can find x\" E S\" andYr E T1 such thatzt =\nL x\" - L Yr·h\nAl! y¡'s in Tr maximize p*yr for Yr E Y1 •\n(5)\nThe set {x\" 1 x\" ':?=\"'' x;i'} is the convex hull of a set of the form{x\" 1 x\" ':?=\" x~}, for sorne x~. By the same argument, then, we canfind a finite subset S\" ofthis set, with rad(S\") :::; L, such that S\" spansx;i' andAll x\"'s in S\" minimize p*x\" for x\" ':?=\" x~;\n(6)\np*xh = p*x;!' for all xh in slt.\n(7)\nFrom (6) it is clear also that we can choose x~ to be any element of\nsh and that all elements of sh are indifferent.By the construction,x* - y* = ¿ x;!' - ¿ yj E ¿ con S\" + ¿ con(- Tr)f\nh\nh\n=con[:¿ S\"+¿ ( -Tr)J.lt\n.f\nf\n1\n¡\nf\n1\nThen, with the aid of (5)-(7), it is clear that D.7.2(c)-(f) hold, andT.7.1 is proved.\nRemark. If the economy increases in size, say by increasel;> in thenumbers of firms and households of roughly similar types, then wemay expect the upper bound, L, on the non-convexities to remainroughly constant; the theorem then assures us that the discrepancybetween supply and demand (for non-free goods) will have the sameupper bound in the aggregate and, therefore, will approach zero asa proportion to total supply or demand.\nY¡ET¡\nbut Yr E Y 1 e con Y 1 foral! Yr E T1 . By (2) (profit maximization),p*yj ;::: p*y1 for all Yr E T1 . With rx(y1) > O, al! Yr E T¡, it is necessary that p*y1 = p*y'J foral! Yr E Tr, and therefore, certainly\n1'\n4.\nApproximation of Equilibrium for Individual Behavior\nIf we restrict ourselves to a pure exchange economy and assumethat for each household the consumption possibility set, X\", is thenon-negative orthant, the approximate equilibrium has a muchstronger property, namely, we can find an allocation with the sametotals as ..v* (therefore also feasible) that is close to the individualoptimal allocation a:;~. The closeness of two allocations is, ofcourse, a much stronger property than the closeness of the markettotals.DEFINITION 3. An individual-approximate compensated equilibriumof modulus A is a price vector, p* > O, and two allocations, w** =(x**,!f**) and to 1' = (xt,yt), such that(a) x** :::; y** + X:,(b) pf = O if xt* < y¡* + X¡,(e) y} maximizes p*yr for Yr E Y¡,(d) x/, minimizes p*x\" for x\" ':?=\" xi,(e) p*x); = M); = M;;',(f) lto** - totl :::; A.\n180\nGENERAL COMPETITIVE ANAL YSIS\nMARKETS WITH NON-CONVEX PREFERENCES AND PRODUCTION 181\nNote that\nlto** - tol =\nSince xj, E X\", x'h1 ;::: O; hence, x;i'¡* ;::: O for i E N if (18) holds.Therefore, condition (16) is redundant.For i E P, xt > O and xf /xt < l. Therefore, if we define\njL lx;i'* - x);l + L IYJ* - yfiZ.2\nf\nh\nHence, if m is the number of agents in the economy and A is aconstant with respect to m, we can see by dividing both sides of (f)by m that the root-mean-square deviation between the bund1eschosen by agents under the two allocations approaches zero.THEOREM 2. In a pure-exchange economy where A.7.2 holds, X, isthe non-negative orthant for each h, and r({x, 1 x, :p., xh}) :s; L forall h, there exists an individual-approximate compensated equilibriumof modulus LVn.\nProof We take p* and xt as in T.7.1.in T. 7.1, and we will find x** such that\nTake also x* as given\n(9)\nx); 1 - x;:'1* is not opposed in sign to xt - xf for all h and i.\nif a> O.Let w\" be arbitrary non-negative with\nN = {i 1 xj - xf :s; 0}.\nDefine\nt + Wh (X¡* - X¡t)Xhi** - Xhi\nh\n(13) holds.\nMultiply by pf and sum over i E N:\nL pf(x;:'¡* - Xh;) = w\" L pf(xf - xt).\niEN\n(12)\n(i E N),\n(13)\nSin ce\n¿ w, = 1,\n(11)\n(i E P),\nfor i E N.\nFrom the definition of N in (1 1), (1 8) certainly holds.\nConditions (8)-(1 O) then can be written\nL.. xhi** -- L..xhl\"'\"'*hh\nif a= O.\nh\n(1 O)\nJf such x** can be found, it is clear from T.7.1 and (8) and (9) thatD.7.3(a)-(e) are satisfied with x;i'* E X\"; it wiii be shown'below thatthat T.7.1 and (10) imply D.7.3(f) with A = Lvn.We first show that (8)-( 1O) can be satisfied. Let\nP = {i 1 xi - xf > O}\n(1 2), (15), and (1 7) will be satisfied. lt remains to show that ( 13),(14), and (18) can be satisfied by choice of x;:'¡* (i E N). From (17),a, ;::: O. Let\n(8)all h,\nfor i E P,\nX¡\nL w\" = 1\nx** = x*,p*x;i'* = p*x'h x;i'* ;::: O\n** = tX¡* x,¡txhl\nieN\nFrom T.7.1 and D.7.2(e), p*x;i' = p*xh, and therefore,\nL pf(xf - xt) = L ieNL pf(x;i'\n1 -\niEN\nh\nx'h 1) ==\nLh iePL pt(x'ht - x;¡'¡)\n=¿ah= a,\"' Pi*(Xht** - xhit ) - \"'t - xhi**) - ah,L..L.. p¡*(xhileNieP\nsay\nh\n(14)in view of (12), so that\nx~¡*;::: O\n(i E P),\n(15)\nX~¡* ;:e: 0\n(i E N),\n(16)\nXh¡- X~¡*;::: 0\n(i E P),\n(17)\nxl;t - X~¡* :s; O\n(i E N).\n(18)\nL pf(x~¡* - x);¡) = w\"a = ah;ieN\nthat is, (14) holds. Hence, (8)-(10) have been shown to hold for asuitable aiiocation .v**.By T.7.1, lx* - xtl :s; LVn, and then, by (8), lx** - x11 :s; Lvñ.\n182\nGENERAL COMPETITIVE ANALYS!S\nBut\nT\nChapter EightTHE CORE OF A MARKET ECONOMY\nand\n(xt* - xt) 2 = [f(x~¡* -\nMy bonds in thee qre all determinate.For how do I hold thee but by thygranting?-William Shakespeare, Sonnet 87\n2\nxf1)J •\nFrom (1 0), the sum in brackets consists of terms all of the same sign;hence,(xf* - xt) 2 ¿(x~1* - x);1) 2 •\n¿h\nIf we now sum over i, we see immediately that\nl.?t** - .?ttl :s; lx** - xtl :s; LVn,as was to be shown.Notes\nTraditional economics texts frequently assumed thc U-shaped costcurve in the context of a discussion of perfect competition; by implication, then, they were asserting something like the results of the presentchapter. As the modern study of the theory of competitive equilibrium emphasized more strongly the importance of the convexityassumption, efforts began to relax it. Farrell [1959] noted first thatnon-convexities of individual economic units correspond to relativelysmall discontinuities in aggregate behavior. His paper gave rise to aconsiderable discussion, by Bator [1961] and especially by Rothenberg[1960], who showed graphically in great thoroughness how with largenumbers of households the effect on aggregate demand is the same as ifthe concavities in the indifference curves were replaced by straight lines.A rigorous general treatment is dueto Starr [1969], on whose work thepresent chapter is entirely based; he made use of sorne mathematicalresults developed by L. S. Shapley and J. H. Folkman, which have notyet been published by them, but which he reported in his paper.An alternative, very bold approach has been taken by Aumann [1966].To begin with, he assumes a continuum of households, each of infinitesimal endowment. Then, by use of sorne deep results in measuretheory, he demonstrates the existence of competitive equilibriumwithout makirfg any assumptions about convexity. This approachworks because the discontinuity in the behitvior of any individual hasinfinitesimal weight in the aggregate, but so far it has been confined toa pure-exchange economy.i,,\n:;1\ni\n·.f'\n:1\n1\nJ\n1.\nEquilibrium in Bargaining\nIn the preceding chapters, and indeed in most of the remainder ofthe book, emphasis has been placed on the allocation of resourcesthrough a price system. All individuals (except monopolists andmonopsonists) behave as though they can huy or sell unlimitedquantities at prices taken as given by_them. They do not take intoaccount any resource Iimitation or tastes of the particular individualwith whom they may be dealing.An entirely different approach is to assume that allocations arearrived at through quantity bargaining. The bargains consideredmay be multilateral as well as bilateral. Thus any set of economicagents are permitted to allocate resources between themselves provided only that their initial endowments and productive capabilitiesare sufficient so that the allocation is feasible without using theresources of other individuals.For simplicity, we first consider a pure exchange economy; production will be introduced in Section 8.5. We have to define sornenotions of equilibrium for bargains. These will take the form ofspecified conditions under which we would expect a bargain not tobe maintained. One is the notion of dominance already introducedin defining Pareto efficiency (see D.4.12). Given a feasible allocation, x, if there is another feasible allocation, x', such that everyhousehold is better off under x' than under m, that is, x~ >-\" x 11 , allh, then we expect that x cannot be the equilibrium of the bargainingprocess. Thus, we assume that equilibria in bargaining must bePareto efficient. Again, an allocation is hardly an acceptable bargain if any individual is better off with his initial endowment thanwith the proposed allocation; thus, x is not a bargaining equilibriumif x1, \"?- 1, x 11 for sorne h.183\nTGENERAL COMPETITIVE ANALYSIS\nTHE CORE OF A MARKET ECONOMY\nThese two principies can be subsumed into a more general one:If any set of households can find an allocation rv' that is feasiblegiven only their endowments and such that each member of the setis better off under m' than under sorne given allocation r:r, it cannotbe that m is a bat'gaining equilibrium. The two preceding principiesare special cases in which the set of households in question consistsof all households or one household, respectively. We now formalizethese considerations by introducing the following definitions.\nTo clarify sorne of these remarks, consider first the thrice-familiarEdgeworth box case-pure exchange, two households, convex indifference maps (the usual restriction to two commodities is no simplification from the analytic viewpoint; it serves only to permitgraphic representation). The core consists of all allocations that arePareto efficient and that do not make either household worse off thanif it were to consume only its endowment. If the endowments aresufficiently different in commodity proportions from each other, then,with suitable indifference maps, the potential gains from trade areIarge. The core contains the allocation that maximizes the utilityof household 1 subject to the constraint that household 2's utility isat least what it receives from its endowment and, similarly, thecorresponding allocation with the two households' roles reversed.For any utility leve! for household 1 between its endowment leve! andthe above' maximum, there will be an unblocked allocation thatyields household 1 that utility leve!.In particular, the competitive equilibrium (or equilibria, if notunique) is Pareto efficient and certainly neither household can beforced below its endowment utility' leve!. Hence, the competitiveequilibria are in the core. However, with two households, the coremight be much larger than the set of competitive equilibria. Suppose now that a third household enters the economy. New possibilities of bargaining and, therefore, of blocking arise from thetwo-member coalitions. Thus, a proposed allocation is blocked notmerely if any one household is driven below its endowment leve!,but also if.any two members can jointly improve their lots by tradesthat do not involve the third. This suggests that in sorne sense therange of unblocked allocations becomes smaller when there are morehouseholds.It turns out that there is a natural way of formalizing the idea thatwith large economies the core tends to be close to the competitiveequilibria. Roughly speaking (see Section 8.3 for details), we consider a sequence of larger and larger economies and, for each one,an unblocked allocation. Then for each economy we can find aprice system such that every coalition in every economy behavesapproximately like a group of price-taking utility maximizers; thatis, the difference between the quantities the coalition receives in thegiven unblocked allocation and the total demands of the same setof households at those prices if they maximize utility under competitive conditions is bounded uniformly in the size of the economy\n184\nDEFINITION l.\nA coalition is a set of households.\nDEFINITION 2.\nAn allocation, rv, is feasible for coalition S if\n2: xh :s; ¿ xh.\nheS\nheS\nRemark. Let V be the coalition composed of all households.Then an allocation that is feasible for V, according to D.8.2, isfeasible in the usual sense (see D.4.5 for the special case in whichthere is no production).DEFINITION 3. An allocation, m, is blocked by coalition S if thereexists another allocation, rv ', that is feasible for coalition S suchthat x~ >- h xh for all h E S.DEFINITION 4. The core of a (pure-exchange) economy is the set ofall allocations that are feasible and not blocked by any coalition.In particular, any allocation in the core is not blocked by thecoalition of all households, and therefore, is Pareto éfficient, nor isit blocked by a coalition consisting of any one household. Theseare properties possessed by the allocation corresponding to anycompetitive equilibrium, for any such is Pareto efficient and ofcourse any household must be at least as well off at the competitiveequilibrium as it would be without trade. This suggests what is, infact, the case-that there is a close connection between allocationsachievable as competitive equilibria and those achievable as a member of the core; but this connection holds only for economies inwhich competitive equilibria exist and cores are non-empty or atleast where these conditions are approximately true. Further, andthis is of great importance, the relation between competitive equilibria and unblocked allocations is especially close when any giveneconomic agent is, in an appropriate sense, small relative to the en tiremarket.\n 185\nT\n'1\n.11,¡1\n¡:\n1•1\n'·\n187\nGENERAL CúMPETITIVE ANALYSIS\nTHE CORE OF A MARKET ECONOMY\nand of the coalition. Thus, for large coalitions, the approximationof the unblocked allocation to a competitive equilibrium is goodrelative to the magnitudes involved.The implications of these conclusions are striking in many ways.They suggest that under appropriate hypotheses, especially convexity and the presence of all markets (absence of externalities),competitive equilibrium is very sturdy. There is no strong incentivefor subgroups to try to coalesce and to achieve,more than they couldin the competitive equilibrium; for any such attempt would beunstable. This is contrary to the view sometimes expressed thatcompetitive equilibrium has an inherent instability in that it wouldpay, for example, the owñers of sorne one commodity to form acartel and exploit their monopoly power. The theorems on therelation between competitive equilibria and the core suggest that anysuch attempt would be broken up by the formation of coalitionsinvolving sorne buyers and sorne sellers of that commodity. Thesellers ultimately can depend for sure only on what they can achieveby trade among themselves, and of course, this may be very littleindeed.In reallife, no doubt, there are many qualifications to these conclusions. Perhaps the most important is the neglect of costs offorming coalitions. Actually, it is probably the fact that the costsof forming coalitions of different kinds of individuals are differentrather than the mere existence of bargaining costs that is of critica!importance. The competitive price system may be expected to prevail when all costs of bargaining are high relative to the costs ofprice-directed markets,. If all costs of bargaining are low, thenagain the theory of the core may be the chief predictive device; thetheorems of this chapter suggest that under appropriate conditions,the outcome will be very similar to that under perfect competition.On the other hand, if the costs of bargaining are not uniform fordifferent coalitions, then indeed quite different results may prevail.Adam Smith suggested in a famous passage that producers of thesame commodity find it easy to communicate with each other; inthat case, the possibility of forming stable cartels to exploit consumers may be enhanced. No real theory of this type has yet beendeveloped, however.There is another qualification arising out of the possible rationalityof seemingly irrational actions, a point that has emerged mostespecially in the discussions of strategy in the context of nuclear\narms (see especially Schelling [1960]). If a coalition with monopolypower somehow makes it credible to all others that its demands willnot be compromised no matter how much it suffers and that none ofits members can be drawn off into side bargains, then it may indeedget its way. This is the value of burning one's bridges behind one.The difficulty with this type of argument is its asymmetry. If onecoalition can threaten in this way, so can the coalition composed ofall others; the result is mutual destruction·, by no means an uncommon occurrence in international politics, but much rarer among thoseplaying for economic advantage only. The asymmetry in expectedbehavior needed for the efficacy of threat strategies is plausible onlywhen based either on differential bargaining costs (so that the countercoalition cannot really form) or on extra-economic motives ofloyalty to and identification with sorne group, such as nation, class,or race.Then, if the economy is large, bargaining costs are low or at leastuniform, and expectations of behavior are symmetric, the theoremson the core imply that departures from perfectly competitivebehavior occur only when there ·are non-convexities or marketfailures of one kind or another.\n186\n2.\nCompetitive Equilibria Are Unblocked\nWe already know that any competitive equilibrium is Paretoefficient (see T.5.3). By definition, any unblocked allocation isPareto efficient. We now show, by using the same reasoning asbefo re,THEORÉM l. In a pure-exchange economy, if (p* ,a:*) is a competitiveequilibrium, then x* belongs to the core.Proof. Suppose a:* is blocked by coalition S (see D.8.1-D.8.4).Then there exists a coalition S and an allocation x' such that\n¿ x;,::; ¿ i\"\nheS\n(1)\nheS\nandall hE S.\n(2)\nFrom the definition of competitive equilibrium (see D.5.1), x~ 1:=\" x,.if p*x\" ::; p*i\" for all h; hence, from (2), p*x~ > p*i1, all hin S, and\n188\nGENERAL COMPETITIVE ANALYSIS\nTHE CORE OF A MARKET ECONOMYdimension n such that r(S) ::;; L for sorne L.F' e F, if\ntherefore,\nS'=Since p* > O, however, it follows by multiplying both sides of (1) byp* that\n189\nFor any finite subfamily\n:¿S,SeF'\nthen for every x E con S', there exists x' E S' such that lx - x'l ::;;\nvvñ.a contradiction.3.\nThe Core Approximates the Competitive Equilibria\nThe near-converse to T.8.1 is much deeper and relies for proof ontheorems due to Shapley and Folkman and to Starr on the extent towhich the vector sum of a large number of sets is approximately aconvex set (see Section B.4). We restate sorne concepts here.First, the radius of any bounded set S, rad(S), is defined to be theradius of the smallest ball that contains S. Then, we define theinner radius of a set S as follows: Any point x in con S (the convexhull of S) is the convex combination of the members of at least onefinite, and hence bounded, subset T of S. For any such x, considerthe infimum of rad(T) for subsets T of S that span x, and then definethe inner radius, r(S), as the supremum over x in con S of theseintima:r(S) = sup\ninf\nxeconS Te S, T spans x\nrad(T).\nNote that if x E S, it is spanned by the one-element set consistingof itself, so that\nThus, no matter how many of the sets S are being added, thedifference between the convex hull of the vector su m and the vectorsum itself is uniformly bounded. In particular, the discrepancybetween the vector average and its convex hull approaches zerowhere the vector average of a family of sets is obtained by dividingeach element of the vector sum by the number of sets in the family.We now state a very general relation between cores and competitive equilibria. In what follows, we shall understand by aneconomy any set of households, where a household is defined by apreference ordering and an endowment.THEOREM 2. Considera class of pairs (E,:X ), where E is an economyand ,¡; is a member of the core of E (assumed non-empty). Foreach household h in any economy E, definex~ = x\" u {x,},\nX \"\" = { x\"\" 1 x,, :2: x,'\ne· X'}10rsorne x,' m\".\nAssume that, for sorne L, r(X~) ::;; L for all h in all economies E inthe class. Then there exists a constant M ( = 2Lv'ñ, where n is thenumber of commodities) and, for each E, a vector p* > O, p*e = 1,such that for any economy E the following statements hold:\n(a)\n,,,1'\ninf\n¡i\nTc.S, Tspansx\ni·;'\nrad(T) = O.\nHence, if S is convex, so that x E: con S only if x E S, r(S) = O, andconversely, r(S) = O only if S is convex. Therefore, r(S) is a measure of the extent to which a set is non-convex.We know that a vector sum of convex sets is convex. It is shownin T.B.l O that the vector su m of any number of sets that are ofuniformly bounded non-convexity (as measured by the inner radius)uniformly approximates its convex hui!. We restate the result here.LEMMA l.\nLet F be a family of sets in a given vector space of\n(b)Before proceeding to the proof, let us first comment on themeaning of the hypotheses and the conclusions. The class ofeconomies is quite arbitrary, but it may be thought of most usefullyas a sequence of economies growing larger and larger in the sense ofconsisting of more and more households. The household characteristics of the different economies are statistically similar in the sensethat the distribution of preference orderings and endowment vectorsamong them are not too remote from each other. Each economy\n~11\n.i;\n•l.,\n¡'1,\nii'' .~\n1\n190\nGENERAL COMPETITIVE ANAtYSIS\nTHE CORE OF A MARKET ECONOMY\nin the cl~ss is assumed to have a non-empty core. This will certainlybe true 1f each possesses a competitive equilibrium, by T.8.1. We~o .not exclude the possibility that households have non-convexmdlfference maps. However, it should be noted that as far aspresent theorems go, the existence of an element in the core isguaran~eed only if preference orderings are convex; hence, it mustbe spec1ally assumed that the core has at least one member.The set 2\" is, for any given household, the upper contour setdefined by the given. allocati.on in the core. If there are any gainsfro.m t~ade at all, th1s set w1ll not contain the original endowmentpomt, X~¡, so that ~~ will consist of an upper contour set (modifiedt~ allow for free d1sposal) ~lus all points to the northeast of x\" (seeFigure 8-1).. In general, :h1s set wdl not be convex even if the uppercontour set 1s, so that r(X \") > O. In Figure 8-1 the point in con X\". set has. maximum radius is a point' like xl, the span-\"w_hose spannm?~m~ set for wh1ch cons1sts of the points x\" and x 2, where x2 is on themd1fference curve through x\". From Figure 8-1a it is clear that anecess~ry condition that r(XZ) be bounded uniformly for all households ~~ all the econo~ies considered is that we are consideringec~nom1es and allocatwns that are sufficiently balanced that the~ar?s from trade for any one household are bounded (so that themd1n:erence curve through x\" is not too far away from x1¡). Figure8-lb dlustra~es a different possible case where r(X~) is Iarge, namely,where there 1s a sequence of households associated with successively\n191\nlarger economies that are more and more nearly satiated withcommodity 2 (relative to commodity 1) at levels only moderatelygreater than the initial endowment. Finally, though not illustrated,r(X~) may become indefinitely large if the non-convexities in theindifference curve through x\" become indefi.nitely large.It thus appears that the assumption that r(X~) is uniformlybounded means that gains from trade do not become unbalanced,that the households in the different economies have stath:;ticallysimilar preference orderings, and that the non-convexities in themare bounded.The conclusions state that, for each pair consisting of an economyand an unblocked allocation for it, we can choose a price vector sothat -allocation approximately satisfies the conditions for a compensated equilibrium. Conclusion (a) asserts that the sum of theabsolute deviations from the budget constraint for the entireeconomy is uniformly bounded over all ecoriomies. This conclusionhas little force for small economies. But if both sides of (a) aredivided by the number of members of the economy E, it is assertedthat the average discrepancy from a budget constraint is bounded bya number that is inversely proportional to the size of the economyand therefore approaches zero for large economies. Conclusion (b)deals with the relation between the given unblocked allocation andthe compensated demand. It asserts that the cost savings totalledover an entire economy in which each household achieves theutility associated with the given allocation in the cheapest possibleway is also bounded uniformly; again, this implies that the unnecessary cost associated with the given allocation averaged over any largeeconomy is very small.\nli\n'ji'.'·¡1¡\n(\n!,,\n¡,,11\n!11\n11:\n'¡,:\n¡,:i\n1\nProof\nFor any economy E, Jet\n1\nX\"= LX~.he E\n(a)\n(b)\nLEGEND:\n~Xí:Figure 8-x\nSince X\" has been defined in terms of an allocation in the core of E,it follows that it must be disjoint from the set of strictly feasiblesocial-demand vectors, that is, those for which\nx « x = LX~¡.he E\n'11\n192\n!\nGENERAL COMPETITIVE ANAL YSIS\nTHE CORE OF A MARKET ECO!')OMY\n193\nFor suppose x\" E X\", x\" « x. From the definitions of x;; and X\"there is a set S of the members of E such thatwhere x~ ;::: x\" for sorne\nXh, X~ ;::>: X1 (3)If S were the null set, x\" ;::: X:, which is impossible if x\" « x. ThisXh E\n¡o\nJ\n;¡\nlast conditíon can be written, from (3),\nand therefore,\nor,xh E\nFigure 8-2\nxh for h S.E\nBy Lemma 8.1, ifx- p,e' E con X\", we can find x\" E X\" such that\nThen, by Lemma 4.l(a), we can choose x;, >-h x\", x~ arbitrarily closeto x\" for each h E S, so that\nIX: - p,e' - x\"l :::; M' = vvñ.\nBut from (4), x\" - X: must have at least one non-negative component.lx - p,e' - x\"l = lp,e' + (x\" - x)l ::::: p, + max(x7 - X¡) ::::: p,,\nand X~ >-h xh ~h xh, all hE S. From D.8.2-D.8.3, the allocationx is blocked by the allocation x', contrary to assumption. Hence,we can assert\nX\" is disjoint from {x 1x « X:}.\nj\nso thatX: - p,e' E con X\"\n(4)\nimplies\np, :::; M'.\n(5)\nSince the set {p, 1 X: - p,e' E con X\"} is bounded, it has a supremum,Then the point X: - p,*e' is necessarily a boundary point ofcon X\". Hence by a well-known theorem in convex set theory (seeCorollary B.5), there is a supporting hyperplane to con X\" at thatpoint, that is, a vector p* =lo O for which\nLet e' be the column vector all of whose components are l. Wewill consider all vectors of the form X: - p,e', p, ;::: O, that belong tocon X\". These points lie on a ray that starts from the socialendowment point and proceeds in a strictly negative direction intothe strictly feasible region as long as the points on the rayare convexcombinations of the points in X\" (see Figure 8-2). Since\np,*.\np*x\" ;::: p*(x - p,*e')\nfor all x\" E con X\".\n(6)\nIn particular, (6) holds for x\" E X\". But by construction, if x\" E X\",then so does x\" + ,\\u for any ,\\ ;::: O, u ;::: O. If we replace x\" byx\" + ,\\u in (6), divide through by ,\\, and let ,\\ approach infinity, weconclude that p*u :::::: O for aii u ;::: O, which implies that p* ::::: O;since p* =jo O, p* > O. From (6), we can assume without loss ofgenerality that p*e' = l. Then we conclude from (6) that\nx = ¿ x\"he E\nand xh E x;; by definition, X: E X\" and, therefore, certainly X: E con X\".Hence, the endowment point, corresponding to p, = O, certainlybelongs to the desired set. The set may or may not contain otherpoints, for which p, > O. We wish to show that the set of suchpoints is bounded uniformly for all economies considered.\np*x\" ::::: p*x - p,*\nfor all x\" E con X\", p* > O, p*e' = l.\n(7)\n'\n1,\n~:¡\n11\n¡;;\n1'\n--1\nT\n1\"11'\n194\nGENERAL COMPETITIVE ANALYSIS\nFor any coalition S, let in particular,\nTI-lE CORE OF A MARKET ECONOMY\n195\np* 2(x11 - x~) ::::; ¡..¡.*.\n(11)\nor\n2x + 2 x\nx\" =\n11 ;\n11\nheS\n/¡\n/leE-S\nsince x 11 E X~, x 11 E X~, x\" E X\" e con X\".recall that\nSubstitute in (7) and\nFrom the definition of S and (9),p*2(x11 - x 11)::::; p*\n2 (x\np*\n2\n(x11 - x 11)::::; ¡..¡.*.\n(12)\n/lEE -S\n/¡\nthen\n1'\nAddition of (11) and (12) yields11 -\nx11 ) ::::; ¡..¡.*.\n2 p*(x\n(8)\nheS\n11 -\nxn ::::; 2¡..¡.* ::::; 2Lv'ñ,\n/¡\nSince (8) holds for any coalition S, it holds with S replaced by\nE\"' S.\nfrom (5), so that (b) of the theorem holds.\n(9)Since the allocation a, is feasible,\n4.\nsince p* > O,p\n*\"\"- *\"\"<p\n~X¡¡_\n~X¡¡,\n/¡\n/¡\nor\nAdd this last result to (8).p*\n2 (x\n11 -\nx 11 ) ::::; ¡..¡.*.\n(10)\nhe E-S\nIn particular, let S = {h 1 p*x11 ;::: p*x11 }.\nThen\np*(x\" - X¡¡) = IP*(X¡¡ - x 11 )1 for hE S, p*(x11 - x 11 ) = IP*(x11 - x 11 )1for hE E \"' S. Then if we add (8) and (10) and use (5), conclusion(a) of the theorem follows.Now let x! minimize p*x11 subject to x\" ~\" x\". Since x! E\nX11 e X~,\n\"\"x*h E X\" '\n,,\n~/¡\nso that, from (7),p*\n2 x! ;::: p*x - *,¡..¡.\nh\nThe Case of Finitely Many Types of Households\nWe now turn to a much studied special case of T.8.2, for which astronger conclusion holds. Let us say that two households are ofthe same type if they have the same preference ordering and the sameendowment vector. Suppose further we consider a sequence ofeconomies with increasing numbers of households in which, however,there are only a fixed finite number of types of households in all theeconomies in the sequence. Suppose finally that the successiveeconomies represent balanced expansions; specifically, assume thatthe numbers of households in the different types are equal for anyone economy. Hence, the size of the economy is indicated by thenumber of households in any one type. The successive economiesmay be thought of as obtained by replication of one .economy.If it is assumed, in addition, that the preference orderings areconvex, then it will be shown that, with a slightly different definitionof blocking, any unblocked allocation must yield the same utility toany two individuals in the same type (since any two such individualshave the same indifference map, such an interpersonal comparisonis meaningful). Thus an unblocked allocation, as far as utilities areconcerned, can be characterized by the utility allocation to types;this has a fixed dimensionality as the size of the economy changes.It is obvious that the competitive equilibria for any economy of thisclass are simply replications of the competitive equilibria for theeconomy with one member per type, and each of these yields a\n•i\n!l\n~ !'' 1\n196\nTHE CORE OF A MARKET ECONOMY\nutility allocation to types that is independent of the size of theeconorny. It turns out, rernarkably, that the converse of this staternent is true; if there is an unblocked allocation for each econornyin the sequence that yields the sarne utility allocation to type~ for allthe econornies, then there is a price vector (the sarne for all econornies) that, together with the given unblocked allocation, is acornpensated equilibriurn for the econorny.W e assurne, then, that there are m types of households; each typehas, say, k rnernbers. We will index households with the doublesubscript ht, for the hth household. of type t (h = 1, ... , k; t =1, ... , m); the preference ordering, utility function, and endowrnentvector of household h,t will have the single subscript t.It is convenient here to use a slightly different definition ofblocking.\nall h and t. Now define for each t the averageU1(x 11) :o; Ut (Xht ) '1bundle received by rnernbers of that type, narne y,\nDEFINITION 5. An allocation, x, is weakly blocked by coalition S ifthere exists another allocation, x', that is feasible for coalition Ssuch that x~x\" for all hE S, x~ >-\" x\" for at least one hE S.\n>\"\nDEFINITION 6. An allocation is strongly unblocked if it is feasibleand not weakly blocked by any coalition S.THEOREM 3. Suppose there are m types of households, where allhoi.Jseholds of each type have the sarne endowrnent and the sarnepreference ordering, and Jet there be k households of each type.ThenThe bundles yielded by any strongly unblocked allocationto two households of the sarne type rnust be indifferent inthe preference ordering for that type.(b) If the nurnber of types and the endowrnents and preferenceorderings defining thern rernain constant, but k, the nurnberof households in each type, varíes, if, for each k, a}\" is astrongly unblocked allocation such that U1(xi;1) = u~ is thesarne for all k (it is independent of h by (a)), and if r(X;) isfinite when k = 1 for all t, then there is a price vector p*such that (p*,u1\",x 1e) is a cornpensated equilibriurn for allk, where ulc is the vector with mk cornponents defined byuftt =u~.\n1<1!=1\n·· U(a) > Ut(x lt ) ' all t ' while. U1(xü >By serni-strict quas1-conc~vlty:t X¡ U (x ) Since x is feas1b1e, 1t follows that1\n11•\nle\n,\n~ Xf = k~ i tit-:1h=1\nXht\n=1\n:o; ~\nm\nm\n¿ ¿ X¡ = ~/t·\nh= 1 t=1\n-\nConsider the coalition that consists o~ all.th~ househ(ol~ t1mrnbere)dh · th1th md1ces 1 t t - , · · · ' m ·1 frorn all the types, t at ts, ose w- 't f llow~ that the allocaSince household 1,t has endow.ment X¡, 1 o rnodit vector xf istion that gives every house,hold m type t t.he com:Own that theby D 8 5feasib1e for this coalition, and therefo~e, 1t h~s. beenTsh..11 b1 ked by th1s coal!tiOn.en. .allocatiOn x ts wea < y och t U ( ) ol8 6 an allocation '\" with the property t at xh'tand D .. 'yd, h' h\" is not strongly unblocked.U(x,)sorne pair 'ft1 for sorne tan1(b) By (a), then, if x is strong1y unb1ocked, xh't \"\"t xh\"t or any 'h', h\". The setsXht = {xht 1 Xht >t X~¡¡}are then the same for all h for any given. t, and, thheref?reX~~e~a;;11rnust b e t rue o f the Sets X\"nt' defined as m T.8.2, t at 1s, ht for all h and t. Now note thatm\n~\nle\ncon ¿\n¿\n1=1 h=1\n(13)\n\"\nx~, 1 = k con ~ X 11·t- 1\n(Recall that for any set of vectors e' fe( means the set obtainedhl' d by't\nfe by the sca1ar k) To see t e va 1 1 yrnultip1ying each e1ernent 0establish that· .'of (13), first note that for any convex set e, 1t ts easy to.r\n¿ e = re.!= 1\n. LB 2 the convex hull of a vector surn,X\" - X\" all h,Second, as shown m ernrna . 'is the vector surn of the convex hulls. Thus, smce nt wle\n¿\nle\n\"\ncon X~t = ¿con X~t =k con X1~>\nh=1\nProof. (a) Let x be a feasible allocation, and suppose that forsorne t, say 1, there are two househo1ds, h' and h\", such that U1 (x~¡, 1 )ol U1 (x\"\" 1). Then for each t Jet the households be nurnbered so thathousehold 1 has the least utility under the given allocation; that is,\nX\nhtxf = \"L.\" y·\n(a)\n[:\n197\nGENERAL COMPETITIVE ANALYSIS\nh=1\nand therefore,m\nm\nk\n1\n'\" X\"lt·\n\"\"\n\"\" k con X Ít = k con t=lL.con ¿m ¿'\" X~t = \"\"L. \"\"L. con X\"\"1 = L.t=l h=l\nt=1 h=l\nt=l\n1\n~ i\n/\n198\n¡i!11,\nGENERAL COMPETITIVE ANALYSIS\nTHE CORE OF A MARKET ECONOMY\nSince a; is strongly unblocked, it certainly belongs to the core, andT.8.2 and its proof can be applied. Let\nThe definitions of blocked allocations and of the core (D.8.3-D.8.4)remain unchanged, provided feasibility is understood in the sense ofD.8.7.An unblocked consumption allocation, ii, then has associatedwith it a production vector, y, which makes it feasible; the pair(:V,y) will be referred to as an unblocked allocation. For any suchallocation, we can define x;; as in the statement of T.8.2. Nowdefine\np,\" = sup{p, 1 k\n'\n.ji\n¡1,,11\nl'·'.'1'1:1\n.',,\nt~ xt - p,e' con t~ \"~ x~JE\nFrom (13), it is obvious that p, 1' = kp, 1 • From the hypothesis, thesets X,t are independent of k, as well as of h; therefore, the same istrue of X~t· Since there are then only finitely many distinct suchsets and since r(X~t) is finite for each such, it follows that r(X~t) isbounded above uniformly over all households in all economies in thesequence formed by letting n increase indefinitely. Therefore, by(5), fk'' is bounded above uniformly in n. But if fk\" = kfk 1 ;:;:: O, thisis possible only if fk 1 = O, and therefore fk'' = O, all k. We can takeM= O in T.8.2. Then, p*x, = p*x, = p*xt, that is, at the pricesp*, x, minimizes the cost of achieving its utility and, at the sametime, that bundle satisfies the budget constraint. Hence, there isexactly a competitive equilibrium.\nz~ = x~-\n199\nz\" = ¿z~.\nY\nhe E\nSince Y is a cone,\n2, Y= yheS1\nfor any coalition S. If we use D.8.7 and the definition of blocking,we can use the same reasoning as in the proof of T.8.2 to show thefollowing extension of (4):\nlt.11:¡:1\n5,\nThe Core of a Productive Economy\nThe preceding two theorems concern only the case of a pureexchange economy. Sorne care must be taken in the introductionof production into the theory of the core. Here we start without aconcept of prices and a fortiori of profits. The model of Chapters3-5, with production taking place in firms separate from householdsand profits then being distributed to the firmsl owners, is inappropriate to the present discussion; it might be said that an adequatetheory of bargaining should explain the formation of firms, notmerely take them for granted.As an alternative, it will be assumed that there is a productionpossibility set associated with each possible coalition. The simplestcase is that in which this is the same, a convex cone Y, for eachcoalition. It will be seen later that, with a suitable redefinition ofthe commodity space, this condition is less restrictive than it mightappear at first.We can now generalize the definitions of feasibility.DEFINITION 7. A consumption allocation, x, is feasible for a coalition, S, if, for sorne y E Y,\n¿ x, s ¿ x, +y./leS\nheS\nZ\" is disjoint from {x 1 X « x}.\n(14)\ni¡\nl!!\nAssume that r(Z~) s L for all h in all economies E for sorne L.We can then parallel the arguments of T.8.2. As there, the set{/k 1 x - p,e'} E con Z\" has a supremum, fk*, not exceeding M=L Vn. Hence, we can find p* so thatfor all z\" E con Z\", p* > O, p*e' = l.\np*z\" ;:;:: p*x - p,*Since Z\" =\n(15)\n¿; X~ - heE¿; Y= X\" - Y, we have, from (15),\nheE\np*x\" ;:;:: p*x - fk* + p*y\nfor all x\" E X\", y E Y.\nClearly, then, p*y is bounded above for y E Y.it must be thatp*y s O\nfor all y E Y.\n(16)\nSince Y is a cone,(17)\nIf we set y = O in (16), we have (7), so that (8) and (9) still hold.Since (:V,y) is a feasible allocation,\n2,x\" s ¿x, +y,11\nh\nand since p* > O,\"' x\"- s p * \"'- + p *-y.p* ~~ x,h\nh\n(18)\n'11\nT\n1,'¡¡\n1\n200\nGENERAL COMPETITIVE ANALYSIS\nTHE CORE OF A MARKET ECONOMY\nIn view of (7), however, (10) still holds, and therefore, T.8.2(a) canbe deduced as befare. From (18) and (8) (with S = E), we can alsodeducep*y 2: -¡.¡,*.(19)\nIt will then be to infinity as the price of anygood goes to zero.When account is taken of production, the assumption of GS doesnot become any more convincing. Even .if differentiability isassumed, there is no good reason to suppose that we may take8y1f8p 1 < Ofor i f= j. Certainly, in the absence of joint production,a ceteris paribus rise, say, in p¡, will cause those producers who use ias an input to reduce (or not increase) their use of that input, so thatwe may argue that the net supply of good j of all producers, otherthan the ith, taken together, will not increase. However, the demandfor good j by the producers of good i may increase sufficiently tocause an increase in the total net supply of goodj. Indeed, there areno satisfactory assumptions, even in the absence of joint production,that imply all goods are gross substitutes in production alone. Thus,the main burden of the GS postulate falls on household demands.To hypothesize, local GS only is weaker, largely beca use we requirerather less of the income term in (10); atan equilibrium, since it is\nstrictly positive, the sum of the terms multiplying r~ is zero. Certainly, then, if A11 > O,j f= i, and the covariance of r~and (.Xn 1 - X~t~)is small, local GS seems reasonable. The smallness ofthe covariancein question could surely be defended also (Section 12.5), but onceagain we require A11 > O and that remains an unhappy postulate.Yet if production considerations are introduced again, we might feelless certain that local GS makes unreasonable demands on ourcredulity. Taking one thing with another, though, there seemsplenty of reason for searching for more agreeable sufficient conditionsfor uniqueness than are provided by GS.\n226\n8. Weak Gross SubstitutesA slight weakening of GS is obtained by dropping the demandthat, for all j f= i, we ha ve s11 < O and replacing it with the requirement that all these terms are non-positive. As we shall see, eventhis slight relaxation of the conditions has considerable consequences for the uniqueness problem. We introduce the followingnomenclature.DEFINITION 6 (WGS). Two goods i andj, i f= j, are said to be weakgross substitutes at p if s 11(p) ,:::; O when s(p) is defined.\nIn view of our preceding discussion, there is no need to emphasizethat the increase in generality obtained by replacing GS by WGS isby no means great. On the principie of Occam's razor, however,we must certainly see whether this relaxation, however slight, stillallows us to deduce sorne of the main results of the previous section.If we are willing to add one more postulate to that of WGS, thenindeed it will not be hard to show that all the theorems proved in theprevious section will continue to hold for this new economy. Weintroduce this extra assumption in the following.DEFINITION 7.\nThe economy will be called connected at p if there isno set of goods 1 such that s1¡(p) = O for all 1 E 1, j ~l.\nSuppose now that an economy has WGS and is connected at p*, anequilibrium. Then it can be left to the reader 1 to show that we can1 By connectedness, s¡¡(p*(i)) < O, sorne j =!= i, otherwise s = O for i E 1 =11{i}, j ~ l. Suppose this is so only for j = h. Then, if s 1(p*(i)) = s1(k(p*(i))),it rnust be that p~ = O. Let p*(i,h) be the vector with p¡* = p: = O and applythe sarne argurnent to s\"(p*(i,h)) = s,(kp*(i,h)). Note that s, 1 < O, sornej =!= i,h, for else we contradict connectedness. Proceeding in this way, wefinish up with either p* = O or s1 = - co, sorne j.\nTHE UNIQUENESS OF COMPETITIVE EQUILIBRIUM\nuse the same method of proof as in T.9.5 to establish that p* » O.Next, consider J(P*). By connectedness, it must be that s1n(P) # O,sorne i. Hence, all the right-hand sides in (8) are non-negative andat least one is positive. Proceeding as in the proof of T.9.7, we nowhave\nWGS and connectedness are weaker than GS, and this is sorneimprovement. Now we must see how far we can go withoutconnectedness.\n2 s~clP*)Pfw1\ni*n\n;::::\nw~c( 2 s,,¡(P*)Pf) ;:::: O.f*n\nIf the first or second inequality is strict, there is nothing more to do,and we proceed as before. The first inequality fails to be strict onlyif, for allj for which s1,¡(P*) < O, we have w1 = w,,. Suppose, then,that s1,\"(P*) < O and w\" = W~c. But then¡;¡¡:\n'\n.!:!1':1\n1111\n1;,\n¡:\n¡,\n1¡\n;\n\"11,\n¡1\n,\"¡¡\n.¡::1\n!\n11\n229\nGENERAL COMPETITIVE ANALYSIS\n228\n? s\"¡(P*)Pfw1 ;:::: w\"(? shi(P*)Pf) ;:::: O.¡*n\n¡*n\nOnce again, if any inequality is strict, we have nothing more to do.Moreover, if the first inequality fails to be strict, then, by connectedness, there must be j # k,h such that s\"¡(P*) < O and w1 = w,,.Proceeding in this way, either all w's are equal-in which case, inview of s1n(P*) < O, sorne i, the second inequality must be strict forsorne k-or the w's are not all equal and the first inequality must bestrict for sorne k. Hence J(P*) has GP. It then follows 'also thatwith WGS replacing GS in Corollary 6 and by adding the connectedness assurnption, the conclusion of the corollary will continue tohold.Next consider T.9.8 with WGS and connectedness instead of GS.Using the sarne notation as ernployed in the proof of that theorem,we note that siP) can only now fail to be positive, if for all jfor which s~c 1 (P) < O, we have v,, = v1• An argurnent exactly analogous to the one we have just used in discussing T.9.7 with the newassurnptions shows that there must be sorne h such that v\" = v,, ands\"(P) > O. Hence one of the goods whose price has risen by nosrnaller proportion from its equilibriurn value than has that of anyother good, rnust now be in excess supply. Since this is the resultwe need for the last crucial inequality ernployed in the proof ofT.9.9, it follows that WGS and connectedness are sufficient to giveP*s(P) < O all P # P*.It should be clear that the assurnption that the economy is connected plays a considerable role in preserving all the results of GSfor the case of WGS. Since a GS economy is certainly connected,\nTHEOREM 10. Suppose for sorne p(i), s1(p(i)) > O. Then S¡(p) >O all pE S. (Recall that p(i) is the vector p with zero in the ithplace.)Proof\n(a) By WGS and H, S¡¡(p) ;:::: O, all pE S, and sos¡{p) ;:::: s1(p(i))\nTherefore, we need to prove only that s1(p(i)) > O, sorne p(i), impliess1(p(i)) > O all p(i) E S.(b) If the theorem is false, there is, by C', so me p'(i) such thats1(p'(i)) = O. _Define p\"(i) so thatp'j(i) = min[p¡(i),p;(i)].\nThen, by WGS,(11)\nS¡(p\"(i)) ;:::: S¡(p(i)) > 0.Now let p(a) = (1 - a)p\"(i) + ap'(i), O ~ a s 1.\nC'\n'\nBy (11) and\nfor a > O and sufficiently srnall.\ns1(p(a)) > O\n(12)\nBy construction, for a > O, p¡(a) > O if and only if pj(i) > O.For all such j, s11(p(a)) =O. Otherwise, by WGS, S¡¡(p(a)) < O;then s1(p(a)) > s1(kp(a)), for k > 1 and sufficiently small, contradicting H. (Note that, by (12), s¡{p(a)) = --oo is irnpossible.) Then,for all j, either s11 (p(a)) = O or p¡(a) is constant at O, so that s,(p(a))is constant. Since p'(i) = p(l),s1(p(a)) = s1(p'(i)) = O\nall a > O,\nin contradiction to (12).Corollary 10. Suppose that for sorne p'(i), s1[p'(i)] = O.s1[p(i)] = O for all p(i).\nThen\nProof If not, then there must be sorne p(i) such that s¡[p(i)] < O,for by T.9.10, there cannot be any p(i) such that S¡[p(i)] > O. Let\npj(i) = rnin[pj(i),p¡(i)].\nThen, by WGS, s1[p\"(i)] ;:::: O.\nBy T.9.10, the inequality is not\n230\nGENERAL COMPETITIVE ANALYSIS\nTHE UNIQUENESS OF COMPETITIVE EQUILIBRIUM\npossible and so0 = S¡(p\"(i)) > s 1[p(i)].Let p(a) = (1 - a)p\"(i) + ap(i).enough,S 1[p(a)]\nThen, for\na > O and srnall\n> S¡[p(i)),\nand p¡(a) > O if and only if p¡(i) > O. Then, by the sarne argurnentas in T.9.10, we obtain s 1[p(1)] = s1[p(i)] > s1[p(i)], a contradiction.\n1'\n:j\nThe theorern and corollary we ha ve just established rnust take theplace of T.9.6 for the GS case. We see that we can no longer clairnthat s 1(p(i)) is undefined, so we can no longer establish p* » O. Ifa rnarket reaches an equilibriurn ata zero price, however, then it cannever be in excess dernand at any set of prices and this is a propertyof the situation that we shall exploit in the following:THEOREM 11. Let p* E E, the set of equilibriurn price vectors.Then, if all goods are WGS at all p, p*s(p) < O, for all p not in E.Before ernbarking on a proof of this theorern we should note thatit is a good deal weaker than T.9.9; if true, it clearly does not enableus to deduce that E has a single rnernber _only. Nonetheless, weshall find that the result will be useful in characterizing the equilibriurn set E. lt will prove useful in later chapters as well.\n1\n1\n1\nProof. (a) Let R = {i 1 pt > O} and R' = {i 1 pt = 0}. Let thesubscript R to a vector denote that it has cornponents in R andsirnilarly for a subscript R'. Then, by WGS,sR(pR,pR') S SR(pR,0).Hence, if we can show that for all (pR,O) not in E, p~sR(pR,O) < O, weshall have proved the theorern.(b) lf i E R, p1 = O, thens¡{pR,O) :S 0.Suppose not, that is, for sorne such i, s1(pR,O) > O. · Then, by T.9.9,s1(p:,o) > O. But pt > O, and so we contradict (p~,O) E E.(e) We propose to show that p*s(p) cannot reach a rnaxirnurn atany p not in E. By the argurnent of (a), we note that the rnaxirnurnrnust occur at sorne (pR,O), where we rnay take PR > O, and so anecessary condition for a rnaxirnurn is\nLpts ,c(pR,O) ;;:::: O,1\n/ER\nall k E R.\n(13)\n231\nClearly (13) holds for PR = p~, and we rnust show that it cannot holdfor any other PR·Suppose (13) holds for PR =¡6 p~, and that the first r elernents ofPR are zero. (Of course, r rnay be zero, i.e., no elernent of PR is zero;the nurnbering is inessential.) Let p~(r) be the vector p~ with itsfirst r elernents set equal to zero. Also let k 1 = p¡fpt and nurnbergoods so thatkr+ 1 ;;:::: kr+ 2 ;;:::: · • ' ;;:::: km,\nwhere we take R as containing all i :S m.Then, by WGS, certainlySr+l(p~,O) :S Sr+l(p~(r),O)),\n(14)\nsince in p~(r) the prices of goods i :S r are lower than they are inBy H,\np~ and no price is higher.\nSr+ 1(p~(r),O) = Sr+l(kr+ 1P~(r),O).\n(15)\nBy the definition of kr+b it rnust be that (r + 1)th cornponent ofkr+ 1 p~(r) is equal to Pr+ 1o while no cornponent of PR can exceed thecorresponding cornponent of kr+ 1 p~(r). But by WGS,Sr+ 1(kr+1P~(r),0) :S Sr+ 1(pR,O),\n(16)\nand so by (14), (15), and (16),Sr+1(p~,0) :S Sr+l(PR,O).\n(17)\nIf in (17) the inequality is strict, we rnay argue as follows: Differentiating W with respect to Pr+ 1 gives\nL p¡SJ,r+l(PR,O) = -Sr+1(pR,0).\n(18)\njER\nFrorn (17) and the fact that (p~,0) is an equilibriurn with P~+ 1 > O,we deduce that the right-hand side of (18) is negative. Yet frorn thedefinition of kr+ 1 and WGS,kr+1\nL PtSJ,r+1(pR,0) :S L p¡SJ,r+l(pR,O),\njER\n}ER\nand so in view of (18)(19)Since (19) contradicts (13), p*s(p) cannot attain a rnaxirnum at(pR,O).\nr\nT\n1'\n1\n1111\n1!\n232\n233\nGENERAL COMPETITIVE ANALYSIS\nTHE UNIQUENESS OF COMPETITIVE EQUILIBRIUM\nSuppose, then, the inequality in (17) is not strict. If kr+ 2 = kr+ 1 ,it is easily checked that we can obtain (17) for Sr+ 2 • Ifthat inequalitywere strict, we would again get (19) for \"r + 2\" with the sameconclusion. So consider kr+ 2 < kr+ 1 • Then every componentkr+ 1P\"t of kr+ 1 p~(r), with i > r + 1, exceeds p 1• Then, sin ce theinequality in (16) is not strict, it must be true, because of WGS, thatSr+ 1jpn,O) = O for j > r + l. Additionally, by H, Sr+ 1,r+ 1 = Oand we conclude\nweaker than those that were establishable with GS, or WGS withconnectedness. Yet for many purposes of economic analysis it iscorrect to say that the convexity of the equilibrium set is as good asuniqueness, and WAR for all comparisons in which one pricebelongs to E is as good as WAR for all comparisons in which oneprice vector is the unique equilibrium one. This will become clearlater in this book. The drawback of the WGS assumption, therefore, is not the weakness of its implications for the equilibrium set,but rather the weak appeal of the assumption itself. It is onlyslightly less ~·estrictive and unappealing than GS and that makes itpretty unpalatable still. There is much incentive to look for ahypothesis that is less disagreeable to common sense.\nallj;::: r + 1 if kr+1 > kr+2and (17) not strict.Now, from (18) and the fact that (17) holds with equality, we have\nL PrSi,r+1(pn,O) =O.\njeR\nBut Sr+ 1,r+ 1(pn,O) = O, so by WGS and the fact that Pi > O, all> r, it must be that\nS;,r+1 =O\nallj>r+l.\nOnce again (17) must hold with sr+ 2 and k,+l replaced by kr+ 2 • Jfthe inequality is strict for this good, we again deduce (19) for\"r + 2\" and, therefore, (13) cannot hold. lf not, we proceed asbefore to r + 3, and so on. lf at no stage we obtain a strictinequality in the appropriate form of (17), then it must be thats;(pn,O) = O for all j > r. But then, sin ce by the argument of (b)s;(pn,O) ~ O, all j ~ r, and since p~ » O and by assumption (Pn,O) isnot an equilibrium, it follows that for some j ~ r, s;(pn,O) < O andso p~sn(Pn,O) < O and p~sn(P) is not maximized at (pn,O). Sincep~sn(P~,O) = O clearly cannot be a minimum of p~sn(p), the theoremis proved.Coro llar y 11. lf all goods are W GS at all p then the set ofequilibrium prices (E) is co~vex.Proof Let p* and p** be two unequal vectors in E and p(a) =ap* + (! - a)p**: O ~ a ~ l. If the corollary is false, then forsome a in the given range, p(a) is not in E. Then p(a)s(p(a)) =(ap* + (1 - a)p**)s(p(a)) = ap*s(p(a)) + (1 - a)p**s(p(a)) < O byT.9.11, and we have a contradiction of W. Hence p(a) EE, for alla in the range.\nThe results we have established for the WGS case are a good deal\n9.\nl.\n!·\nDiagonal Dominance\nSuppose that we wished to investigate the consequences of thehypothesis that the excess demand (supply) of each good is \"moresensitive\" to a change in its own price than it is to a change in theprices of all other goods combined. If this idea is to be madeprecise, it is clear that careful attention will have to be given to theunits in which goods are measured. If we imagine the demandfunction for a good plotted in a multi-dimensional diagram whoseaxes are the different prices, the slope of the resulting demand surfacein any direction will depend on the units in which we have chosen tomeasure the various goods. It is, of course, for this reason that weuse elasticities to measure the responsiveness of demand to changesin price. In formulating our hypothesis precisely, therefore, weshall wish to put it in the form: There is at p so me way of measuringgoods such that for all of them it is true that their excess demandsare more sensitive to a change in their own price than they are to achange in other prices combined. We shall also impose a restrictionon the sign of the term giving the change in the excess demand for agood when its own price changes.DEFINITION\n8 (DD).\nThe economy is said to have Diagonal\nDominance at p with Pn > O if\n(a) s¡¡(p) > O, all i,(b) there is a vector h(p) » O, such that\nh1(p)s¡¡(p) >\n:¿ Js ;(p)Jh¡(p)1\nn>NI\nall i < n.\n_/\nT1\nGENERAL COMPETITIVE ANALYSIS\nTHE UNIQUENESS OF COMPETITIVE EQUILIBRIUM\nPart (a) ofthe definition means that when we cometo stipulate DDfor an economy, we shall be implying that the substitution terms .\\11in Eq. (10) (for j = i), which are known to be negative, are large inabsolute value relative to the income term. If that is not so, wemust rely on a high responsiveness (known to be positive) in thesupply of the ith good to a change in its price. W e can think ofexamples where this is not the case, but far less readily than was thecase for OS, and even less readily when DD is taken to hold locallyonly. By and large, assuming part (a) to hold does not appearabsurd and is in conformity with much of economic theory.Part (b) is in the spirit of our introductory remarks. Note thats11 is the partial of s1 when i and j are measured in any given units;so (h 1/h 1)s11 will be the value of the partial when one new unit of iis now equal to h1 old units and one new unit of j is equal to h1 oldunits of j. Thus (b) says that there are sorne units in which tomeasure goods such that the diagonal term dominates the offdiagonal terms with j < n. lt is reasonable to ask why we shouldhave excluded the nth good.First, it should be clear that the choice of n was arbitrary. IfPs > O, and on excluding the sth good in the same way, but includingthe nth, (a) and (b) are satisfied and we should still say that theeconomy has DD at p. Secondly, let h1, i = 1, ... , n, be any set ofpositive numbers. Let q1 = p¡jh1 and say qr = max q1• Then, usingH,\n(P = (1/pn)p). Suppose there exists v > O, such that TJ(P*)Tv ::5: O.Then, setting w1 = v1/h¡{P*), it must be that TJ+(P*)Tw ::5: O. Let\n234\n,,1\n1\n¡'\n,,\n'\n11\n:¡\n1\n:¡\nand clearly DD is impossible if we include all goods.Lastly, it is worth noting that DD is definitely a weaker requirement than OS for p » O. The latter implies DD, while DD doesnot imply OS. The second part of this statement is obvious. Thefirst foilows at once from H. If we set h;(p) = P;, aii j and p recalls1n > O, we at once verify (b) of the definition; that (a) must holdis obvious. By the same argument, DD is weaker than WOS forp » O and s1n(P) > O, sorne i.lt is easy to establish the following results.THEOREM 12. If for all pE E, the set of equilibrium prices, theeconomy lias DD, and if N holds, then equilibrium is unique.\nProof\n¡¡'l.\\'\nLet J+(P*) have elements h;(P*)s1¡{P*), where p* E E,\n235\ni\n:1\n1\nThen\ntMr(P*)Srr(P*)wr ::5: -\n¿\n¿\ntrrh¡(P*)sr¡(P*)tfiWf ::5: Wrh¡{P*)[srJ(P*)[,i*rf*rwhich contradicts DD. Hence J(P*) has OP, and T.9.2 establishesthe result.Corollary 12. If for all p the economy has DD and N holds, thenequilibrium is unique.By and large, we may rest quite satisfied with the results of thissection. As we have already argued, DD is not an obviously sillyrestriction to impose on the system. Of course, this does not meanthat all actual systems will satisfy DD. What it does mean is thatit will be worthwhile, ata later stage in the book, to further investigatethe properties of such economies.\n1:\n1¡ 1,¡\n1\n10.\nOther Sufficient Conditions for Uniqueness\nIn this section we shall investigate a number of other restrictionson the excess-demand functions that are sufficient to ensure theuniqueness of an equilibrium. These conditions share the disadvantage that it is hard to give them any obvious economic motivation. However, that does not mean that they are without interest,since there is no reason to explain further the actual properties of,say, the Jacobian J(P) of an actual eco no my by more or less commonsense appeals to economic theory.DEFINITION 9. A matrix A is said to be positive definite if for aiinon-zero values of the vector v~ v'Av > O, and A is symmetric. Ais said to be positive quasi-definite if for all non-zero values of thevector v, v'[(A + A')/2]v > O. (A' is the transpose of A.)THEOREM 13. If, for all P* E E, J(P*) is either positive definite orpositive quasi-definite and if N holds, then the economy has aunique equilibrium.\nProof. We establish that J(P*) has OP.(a) Suppose that J(P*) is positive definite, but does not have\n:¡11\nlillii\nr\n1\n1\n236\n1\n'\n1\n~\n''i\n1\ni i'\n1\n1\n'\n::\n:\n1!\nr:IJJ\n1!1\nj¡\n1\nGENERAL COMPETITIVE ANALYSIS\nTHE UNIQUENESS OF COMPETITIVE EQUILIBRIUM\nGP, that is, for sorne T and sorne v > O, TJ(P*)Tv s O. But then(Tv)'J(P*)Tv s O, which contradicts J(P*) positive definite.(b) If J(P *) is positive quasi-definite, the same argument as in(a) holds since'J(P*) V_- V, J(P*) + J(P*)' V.V2But if J(P*) has GP then T.9.2 establishes the theorem.\nTHEOREM 16. Let the Leontief economy satisfy A.2.10-A.2.13.Then equilibrium is unique.\nProof\n237\nLet 7T¡(p) be the unit profit function of the ith sector, that\nis,\n7T¡(p) = p¡ - C¡(p)\ni=1, ... ,n-1\nwhere C1(p) is the mínimum unit cost function of l (see A.2.13).\nIf\nTHEOREM 14. If, for all P* E E, the determinant of every principalsubmatrix of J(P*) is positive and if N holds, then the economy has aunique equilibrium.This is a restatement of Lemma 9.2.\np~ is the equilibrium price of labor, we know (T.2.6) that p~ > O,In addition, if p* is an equilibrium, 1t(p*) = O and, of course,\nIt should be noted that the conditions of T.9.14 are weaker thanany case (except for the Hicksian with sorne zero equilibrium priceswhere no comparison is possible) we have considered so far. This isclear from the single fact that, by T.9.12, DD implies GP, which isequivalent to the condition of T.9.14, but not vice versa. Thesecond part of this statement is obvious as a simple 2 x 2 examplewould illustrate.The following theorem is weaker in sorne respects and stronger inothers than T.9.14.\n7T¡¡(p*)pf +\nTHEOREM 15. If J(P) is non-singular and J - 1 z(P) is continuouslydifferentiable for all P » O, where z(P) is the vector of excessdemands for the non-numeraire commodities, and if\n¿; Z¡(p)\n7r(p*k) = k7T(p*), for k > O.\nHence, by Euler's theorem,\n¿; 7T¡¡(p*)pj = -7T¡n{p*)p~\ni= 1, ... ,n-1,\nn>Ni\n(20)\nwhere 7T¡¡(p*) = 87T¡(p*)/8p1. But we know (T.3.6) that 7T1n(p*) =- a1n, where ain is the input of labor per unit of output of i, so theright-hand side of (20) is positive. Since 7Ttt(P*) > O (see T.3.6) and7T¡¡(p*) s O for j i= i, (20) tells us that the matrix H(p*) = [7r¡¡(p*)],has DD (where H(p*) is (n - 1) x (n - 1)). Hence, by proof ofT.9.12, H(p*) has GP. Since this must be true at every equilibrium,it follows from T.9.2 that there is only one equilibrium.\n12. Economies with No Joint Production but Many Factors\n¡\napproaches +oo whenever p approaches a limit, p 0 with pf = O, sornei, then the economy has a unique, strictly positive equilibrium.This theorem makes global rather than local assumptions aboutthe Jacobian and, in addition, makes strong requirements withrespect to the boundary, though these may be capable of relaxation.On the other hand, only the non-singularity of the Jacobian isassumed; nothing is said about the principal minors.The proof we will give depends on dynamic arguments and ispostponed to Section 12.8.\n11. The Leontief EconomyWe considered this economy in Section 2.11. Here we giveconditions that suffice for it to have a unique equilibrium.'1\"\n\"'\n1\nil\nThe Leontief economy can be generalized by dropping therequirement that there can be only one primary factor. We retainthe assurriptions of constant returns to scale and no joint productionand postulate that any net output requires sorne use of factors.Let y be the vector of produced goods, z the vector of demands forfactor inputs (taken non-negative)_y and L the vector of initial factorholdings. As before, there are no endowments of produced goods.Let p be the vector of prices of produced goods, w the vector offactor prices. Let C(p,w) be the vector of mínimum unit costfunctions. Then, if all goods are produced, equilibrium requiresthat p = C(p,w). There are a number of questions that may beasked of this model; the \"two-sector\" m o del and factor priceequalization discussed below have been much discussed in theliterature.\nr\ni\n11,l\ni\nGENERAL COMPETITIVE ANALYSIS\nTHE UNIQUENESS OF COMPETITIVE EQUILIBRIUM\nDetermination of commodity prices by factor prices. For anygiven factor price vector, w > O, we can regard the factors as acomposite commodity; then all the assumptions of the Leontiefeconomy are satisfied, and from T.9 .16 we can find a unique vectorp that satisfies the conditions of zero profit in each industry. Thenp = p(w) is a function of w; since all the demand and cost functionsare continuous, it can easily be seen that p is a continuous functionof w. Further, as we know, we can choose the activity levels in eachindustry so that supply equals demand on each produced goodsmarket and the total value of demand for factors, at the vector w,equals the value of initial endowment. Assume that producerssupply exactly what is demanded when prices satisfy the zero-profitcondition. Then we hf\\ve defined an excess-supply function,s(p,w) = s[p(w),w] = S(w), say, for the factors, and this must itselfsatisfy W; that is, wS(w) = O, for all w > O. It then follows that w*can be so chosen as to define equilibrium in the factor markets andhence, with p* = p(w*), a general equilibrium.This equilibrium need not be unique, in general, but p is defineduniquely by w. In fact, if we consider different economies with thesame technology, but possibly different factor endowments anddemand functions, we can still say that two equilibria with the samefactor prices must have the same produced goods prices.\nWhat we have just proved clearly holds for any two-goodseconomy, and we sum up this result in the following.\n238\n!11\ni\nThe \"two-sector\" model. Now consider, in particular, theuniqueness of equilibrium in the case of two primary factors. SinceS is certainly homogeneous of degree zero in w, we may normalizeby considering W E S2.We already know that if w* is an equilibrium (here assumed toexist), then w*S(w) < O, all w not proportional to w*, is a sufficientcondition for the uniqueness of the equilibrium. Here it is necessaty. For example, suppose equilibrium is unique. If (0,1) is notan equilibrium, then, with the aid of W, we must have S 1(0,1) < O,S2(0,1) =O, so that w*S(0,1) < O. Similarly, if (1,0) is not anequilibrium, w*S(1,0) < O. Suppose the equation w*S(w) = O hada solution on the unit simplex different from w*, say w'. Thenw*S(w') = O, while, by W, w'S(w') =·O. Since the matrix with rowsw* ,w' is certainly non-singular, it must be that S(w') = O, contraryto the assumption that w* is the unique equilibrium. lf w*S(w) = Oonly for w = w* and w*S(w) < O for sorne w, it must be that for allw =!= w*, w*S(w) < O.\n'L,,'l\n-·~~--·~·--'·--~----·-~-\n239\nTHEOREM 17. Let p be a price vector in the two-dimensional simplex, z(p) a two-dimensional excess-demand vector function. Thena necessary and sufficient condition that p* is the unique equilibriumfor the two-goods economy is that p*z(p) > O for all p for whichp =1= p*. (The two-goods economy is assumed to satisfy all theusual assumptions that we have used to show that at least oneeq uili bri um exists.)We now know that we need conditions that ensure w*S(w) < Ofor all w =1= w* in the simplex. Certainly it is easy to check that thiswill be the case if the economy is \"Hicksian\" in the outputs. Weshall consider instead a situation that has been much discussed in therecent literature on the theory of economic growth.Suppose there are two kinds of households; one kind labeled \"1\"owns all of the input labeled \"1\" and derives utility only from thegood labeled \"1 ,\" while similar! y the kind labeled \"2\" owns all ofthe input with that label and derives utility only from the goodlabeled \"2.\" (This can be translated to the \"classical\" savingsassumption of growth literature.) The househoids ín each groupare Hicksian. From these assumptions we quickly verify, assumingall demands differentiable,OX¡\ni = 1, 2\nPt 8p¡ = -X¡OX¡\nPt ow¡ = L¡\ni = 1, 2,\nwhere L 1 is the amount of the ith input available.Further suppose that the production of each good requires on1yprimary factors; neither good serves as an intermedia te product.If y 1 is the producers' demand for factor i, then,y 1(x,w) =\n¿ aflx\n1\ni = 1, 2,\nj\nwhere a11 is the amount of factor input i per unit of output j; itdepends on w, and from T.3.6, dp 1fdw 1 = a1¡, i, j = 1, 2.Now consideran equilibrium w*. Let Z 1 (= -S1) be the excessdemand for input 1, and write Z 128Z1/8w 2. Using these relationsand the household-demand conditions and taking all derivatives atw*, we have\n=\n-¡-\n11\n1\n240212\nGENERAL COMPETITIVE ANALYSIS\n= BYt ox1 dp1 + By1 (ox2 dp 2 + .ox2) + oy 1ox1 8Pl dw2X1\n-a11a12- P1\nox 2 8p 2 dw 2\now 2\now 2\na22L28Yta21X2- + a 2 1 - +PP28w2\nsince in equilibrium L 1 = x 1 a 12 + x 2a22 . Hence, Z 12 (w*) > O ifa21/P2 > a 11 /p 1 since8Ytfi7w 2 ;:::: O. Since both industries aremaking zero profits, PJ = a¡ 1 W 1 + a¡ 2 w2 , it is easy to verify that thecondition a 21 /p 2 > a 11 /p 1 is equivalent to the same condition withthe subscripts \"1 \" and \"2\" interchanged, so that this conditionensures Z 21 (w) > O. Hence, the two inputs are gross substitutes inevery equilibrium if good i uses inputj (j -1= i) more intensively thangood j does. This means that equilibrium is unique and so, byT.9.17, w*S(w) < O, all w i= w*.There are, of course, other assumptions on household behaviorand the production sets that ensure uniqueness. They all, however,seem to entail the GS property (though we have not made anexhaustive check).This example is instructive for two reasons. First of all, it showsthe need to examine the economics of purely formal uniquenessconditions. Second, it makes clear how special the case of twogoods is (a recurring result, e.g., T.12.I)\". In the present instance,the fact that w*S(w) < O, for w -1= w*, is necessary for uniqueness ishelpful, but this property will not hold for an economy with morethan two inputs.Factor price equalization. We now considera problem arising inthe theory of international trade. In the general model with nojoint production and constant returns, goods prices and factor pricessatisfy the relation p = C(p,w), as we have noted. We now assumethat the number of factors, m, equals the number of goods. Thequestion asked is this: Given p, is there a unique w that sol ves theseequations?lf (C11) is the Jacobian with element (8C¡jow 1), then if this Jacobianhas GP we know that there can be only one w in the simplex that\nTHE UNIQUENESS OF COMPETITIVE EQUILIBRIUM\n241\nsolves these equations. But oCtfow¡ is the intensity with whichindustry i uses input j (T.3.6), so for instance, if there is sorneordering of inputs and sectors such that each sector uses the inputwith the same label more intensively than it does all other inputscombined; that is, if the Jacobian has DD, then it will also ha ve GPand w will uniquely solve the above equations.In this example the economics of our conditions are extremelyunattractive. Pearce [1967] has shown that rather weaker conditions will suffice provided we are willing to extend the domain ofC( ·) to the set of all W· that make C( •) non-negative. Since thisincludes negative factor prices the meaning of such an extension ofthe domain is somewhat obscure.As· our example illustrates, however, the most general uniquenessconditions discussed in this chapter are still extremely restrictive,and we must hope that acceptable weaker conditions will becomeavailable. Even so, a reformulation of the question posed at thebeginning of this example does allow us to give a definite answer.Suppose that the economy has a given endowment vector. Is itpossible to ha ve given p, two values of w for which the economy isin equilibrium, and not only in the sense that unit costs are covered,but also in the sense that all markets are cleared ?Suppose there are two equilibria, (p,w) and (p,w*), with the samevector of goods prices. Let (y,z) be the vector of outputs and inputscorresponding to the first equilibrium, (y* ,z*) to the second. Sincemaximum profits in either case are zero, we must have\npy- w*z :si O\npy* - wz* .:::; O.\n(21)\nBy W, py = wL, py* = w*L. If we add the above inequalities andmake the indicated substitutions, we see that wS* + w*S .:::; O. Bydefinition of equilibrium, however, S* ;:::: O, S ;:::: O, so that equalitymust hold. Hence, we must have py - w*z = O (and also py* wz* = O). If (y1,z1) is the equilibrium input-output vector for theith industry at (p,w), then profit maximization implies that py 1 w*z1 .:::; O, each i; summing over i implies that py - w*z .:::; O; sincewe know the equality holds, it must hold for each i, since a sum ofnon-positive numbers is zero if and only if each one is zero. Byconstant returns, py 1 - wz1 = O for each i, so (w* - w)(z 1 · · · z\"') =O, where (z 1 • • ·z\"') is the matrix with columns z1•Now assume that at the equilibrium (p,w) all goods are producedand the input vectors of the various industries are linearly\n1r\n242\nGENERAL COMPETITIVE ANALYSIS\nindependent. Then the matrix (z 1 • · · zm) is non-singular, so that wmust equal w*; that is, factor prices are uniquely determined bygoods prices.\n13.\nlj!\nConclusion\nAlmost all economists, whether or not they are \"theoretical,\"when asked to evaluate the fairly long-run consequences of a shiftin sorne parameter of an economy, will attempt, certainly in the firststage, a comparison of the equilibrium before and after the change.If equilibrium is not unique this procedure may break down. In thischapter, we have explored· sorne of the sufficient conditions for thismethod to have a ci;lance. Unfortunately, necessary conditions areunlikely to be available. Nonetheless, it can be argued that theconditions we have stated are not, in general, unreasonably demanding, although the last example suggests that in sorne cases they maybecome so. Whether reasonable or not, they are the best availableat this stage to help answer an important question, on which so muchof current analysis depends. Probably the most appealing of thepossible postulates leading to uniqueness is Diagonal Dominance.This condition, if fulfilled in fact, would give a general equilibriumsystem a kind of Mashallian flavor, inasmuch as the properties of thedemand and supply curves in the plane of the price of the good inquestion and the quantity supplied or demanded are in sorne sensethe \"dominating\" properties. lt means that partial analysis maynot make serious mistakes. When the price of a good changes andwe take others as fixed, it is reasonable to suppose in many casesthat, in fact, they are \"almost\" fixed. But then, in view of DD, theanswers we obtain from the \"fixed\" assumption will not be verydifferent from the correct answer. Whatever our intellectual predisposition on the matter of partial versus general equilibriumanalysis may be, we all meet practica! problems by a partial approachfirst, so these are comforting conclusions. Of cotlfSe, it still remainsto see how \"good\" the DD assumption is in fact.\nNotes\nThe study of uniqueness by examining the Jacobian of an appropriatemapping was initiated by Samuelson [1953~54]. He thought a sufficientcondition for uniqueness to be that for one permutation of the rows and\nTHE UNIQUENESS OF COMPETITIVE EQUILIBRIUM\n243\ncolumns of the Jacobian, all its leading principal minors are nonvanishing. This proposition paid insufficient attention to the domainof the mapping and Gale and Nikaidó [1965] showed it to be false bymeans of a counter example. They then established a sufficient condition, here called \"Gale Property,\" which is the foundation of much .ofthis chapter. More recently, Pearce [1967] and Pearce and W1se[unpublished] have sought to find much weaker sufficient conditions.These studies turn on theorems on covering mappings and lead toconditions that require only that over the requisite domain a certainJacobian should not vanish. We have commented briefly on one aspectof this work in Section 9.12. The more recent work of Pearce and Wiseappeared too late to be thoroughly explored here. On one matter,however, comment is appropriate.Pearce and Wise examine the case in which p¡s¡(P) ---+ O as Pt ---+ O.Suppose the economy has an equilibrium P* » O. We may constructa reduced economy by setting p 1 O and noting that W holds for thisreduced economy. (This was discussed in another context by Hahn[1965].) Let the reduced economy have an equilibrium p**, withp¡** = O, of course. Suppose the two economies have non-vanishingJacobians in the neighborhoods of p* and p**, respectively. Then theyshow that it is possible to find a p t p* that is an equilibrium, so thatthe mapping is not univalent. Then the economy cannot have GP, butwe know that GS implies GP. Hence GS must imply p¡s1(p) does notgo to zero as p 1 ~>-O, whence s1(p) must be unbounded below. ThisPearce and Wise consider to be absurd.There are two comments we should like to make on this. First, GSensures that any equilibrium must be in the interior of the simplex andwe need never be concerned with the behavior of excess supplies at, orindeed with suitable assumptions near, the boundaries. Surely theytake \"unbounded demand\" possibilities too literally. It is true thatGS forces this on us as a price goes to zero, but assuming GS over thewhole simplex (including boundaries) is to be taken as an idealization(as recent measure-theoretic approaches to general equilibrium are alsoto be taken), which with care in application simplifies analysis withoutleading us astray. Second, as T.9.3. shows, only assumptions of GP orGS at equilibrium are needed.That both weak revealed preference and GS imply uniqueness wasfirst pointed out by Wald [1936; 1951, pp. 375~376, 385-387]. Arrow,Block, and Hurwicz [1959, p. 90] first showed that if GS holds, weakrevealed preference holds as between an equilibrium price vector andany other. The weak gross substitute extensions are dueto McKenzie[1960], Uzawa [1961], Morishima [1959, unpublished], and Arrow andHurwicz [1960].Much of the discussion of uniqueness in the literature was motivatedby the theory of factor-price equalization in international trade theory.The literature since Samuelson's [1948] paper is large; the results ofSection 9.12 are discussed more fully in McKenzie [1955a].Debreu [1970] has recently reexamined the possibilities for multiple\n=\n¡i1\n••\nil\n1'·\n¡t.!11\ni:ll'\"l1!''1'1\n1'\n1\n11\n1244\nGENERAL COMPETITIVE ANALYSIS\nequilibria. He assumes only that excess-demand functions are differentiable functions of both prices and the distribution of endowments;the absolute value of the excess-demand vector is assumed to approachinfinity as any price approaches zero, so that only strictly positive equilibria are possible. Then it is shown that there is a closed set of measurezero in the space of endowment allocations such that for all otherendowment allocations there are only finitely many equilibria. Thisseems to be the best possible result short of the much more restrictiveassumptions of the type used in this chapter.\nChapter TenCOMPARING EQUILIBRIAThe ald arder changeth, yielding plac1ta the new.-A. Tennyson, Marte d'Arthw\nl. The ProblemIn analyzing the effects of a given change in the parameters of areconomy, say, taste or technology, it is often useful as a first approadto neglect the questions ofadjustment to this change and to compan:the equilibrium that results (if all goes well) with the equilibrium westarted with. One of the questions we shall have to answer is justwhen this approach is in fact likely to prove useful. The method ofcomparing equilibria is often referred to as the method of comparati ve statics or comparative dynamics. The force of the terms\"statics\" and \"dynamics\" is by no means clear. For instance, foreconomies with all possible futures markets it is not easy to saywhether we are dealing with statics, because all contracts are madeat a moment of time, or with dynamics, beca use quantities of goodsproduced and stored may be changing as the future develops. Wetherefore think it best to avoid this terminology.The main problem we set ourselves in this chapter is an inquiryinto the power of general equilibrium models in giving unambiguouspredictions of how the equilibrium of an economy will be affectedby a given parameter change. As we have already argued in theprevious section, this problem must be intimately related to that ofthe uniqueness of an equilibrium and it is pretty clear that we shallnot expect to get very far without stipulating one or the other of theconditions that ensure such uniqueness. Even so, the kind ofparameter changes for which predictiolis become possible is prettylimited.\n2.\nBinary Changes\nWe start our investigation with the simplest case. Suppose thereis a change in the tastes of households so that at a given p » O, they245\n!'\n,..\n~!i\n11\n1\n1:¡\n:!\n'\n246\n'11\n' 1':¡1¡1'1,1\n'\"1¡11\n1\n'\n~~247\nGENERAL COMPETITIVE ANALYSIS\nCOMPARING EQUILIBRIA\ndemand more of a certain good. Then, by W, the demand·for atleast one other good must be affected by the change in taste. Thesimplest of our cases arises when at a given price vector the demandfor two goods only is affected by the change. We shall call such achange a \"binary\" change:\nIf the economy has a unique equilibrium before and after thebi11ary cha11ge, T.IO.l tells us that wi* < wi (and w~* > w~).Thus, if the factor of type 1 is \"capital,\" the equilibrium with morecapital, other thi11gs consta11t, must also have a lower renta! of capital.It is important to understa11d that this prediction depends crucially011 the suppositio11 of u11iqueness.It is 110t hard to see that the lesso11s of this example can be appliedto other situatio11s, for i11stance to the two-country, two-goodneoclassical model of i11ternational trade. Thus suppose that thecou11try experie11cing a once-over increase in the stock of capital wasan exporter of the capital-intensive good. The11, assumi11g theworld equilibrium u11ique, since we know that the equilibrium wagerental ratio must go up a11d since this must mean that the price of thecapital-inte11sive good must fall relatively to that of the other good,we have at once the result that the terms of trade of our countrymust deteriora te. These are all simple co11sequences of T.l 0.1, a11dit must be confessed that they will not generalize to an eco11omy withmore goods, except if the contemplated cha11ge is bi11ary. We shallreturn to this questio11 presently. First, we shall examine what canbe said about binary cha11ges in a world of ma11y goods.\nDEFINITION l. A change in the parameters of an economy at p willbe called a binary change, if, when z'(p) is the excess-demand vectorwhen the parameters have changed, z(p) - z'(p) has only two nol1zero compo11e11ts.\n1\nIt should be noted that this defi11ition stipulates that a change isbinary ata give11 price. Thus a change that satisfies the requirementthat it be bi11ary at p need 11ot ha ve the same effects 011 z at sorne otherprice vector p'. Por co11venie11ce, we shall take z~(p) > z 1 (p) andz~(p) < z 2 (p). (The inequalities must differ, taki11g p 1 > O, p 2 > Ofor the two goods because of W.)The simplest case for this simplest of all parameter changes is thetwo-good eco11omy. Here every parameter change is ipso jactobi11ary. We also get a very simple result.\nTHEOREM l. Let p* be the unique equilibrium before a11d p** theunique equilibrium after the change in parameter. Thenpt* >PI·\nProof In T.9.17 we showed that for a two-good eco11omy thecondition p*s(p) < O for p i= p* was necessary and sufficient foruniqueness. So in the present application,p**s'(p*) < Oand, by W,(p** - p*)s'(p*) < O.By assumption s~(p*) < s 1 (p*), a11d p** and p* E S2 • If the theoremis false, it must be that pi* < PI (since pi* = PI would meanp~* = p~, which is impossible). But then PI > O, so that s 1 (p*) = O,a11d also p~* > p~. Hence, s~(p*) < O :::; s 2 (p*) contrary toassumptio11. Hence pi* > pf.As an application, consider the \"two-sector\" model of 9.12.Suppose there is an exogenous increase in Ll> the amount of thefactor of type 1 available. lt is trivial to show that, in the notationof 9.12, this implies\nTHEOREM 2. Let the parameter change be bi11ary at p*, an equilibrium. Then if (a) the economy is Hicksian for all p and hasp* » O or (b) all goods are GS at all p, there is a new equilibriumprice vector p** with pr* > PI and p~* < pr\nProof If the economy is Hicksian, then by assumption, and ifGS, by Corollary 9.6, p* » O. Therefore, we may choose units forthe goods such that p* = e, the unit vector. By the proof of T.9.4,T.9.9, and W, we have for either type of economy for p i= p**(p - p**)s'(p) > Oand so, in particular,(e - p**)s'(e) > O.\n(1)\nBy the defi11ition of a binary change, s~(e) + s;(e) = O, s~(e) < O ands;(e) =O, all i i= 1,2 (since p* » 0). Hence from (1),\npi* - 1 > p~* - l.\n(2)\nThen there is sorne k > O, such that with p** = kp**,fii* - 1 > O and p~* - 1 < O.By H, p** is an equilibrium.\n(3)\n;.1'\n248\nGENERAL COMPETITIVE ANALYSIS\nCOMPARING EQUILIBRIA\nFor the GS case we can establish a slightly stronger result bydifferent methods.\nof an economy of a switch in government expenditure at p* from onegood to another or of a technical innovation in one sector of theeconomy that has the consequence of reducing, at p*, the demandfor one particular input and increasing the demand for another.But no doubt all these examples are rather artificial. Befare we~ttempt to be more adventurous, however, it will be useful to seewhether the hypotheses of WGS or DD allow us to make straightforward predictions for binary changes.We know from our discussion of the case in Chapter 9 that if onepostulates WGS and connectedness, all the theorems established forGS continue to hold. Thus it is clear that T.! 0.2 and T.! 0.3 withits corollaries continue to be valid for this economy. Accordingly,we concentrate on the case in which connectedness is not stipulated.\nTHEOREM 3. Let the parameter change be binary at p*, an equilibrium. Then, if al! goods are GS for all p and the nth good hasbeen chosen as numeraire (Pn = 1 always), it must be thatp{* > p{,p~* < p~.\nProof By Corollary 9.6, we have p* » O. Again Jet the unitsin which goods are measured be such asto give p* = e. Let p~* ;:::pf*, al! i. Then we claim that k = J. Suppose k =1- l. Then byT.9.8, we ha ve s;c(p*) < s;,(p**). But s;c(p*) = Ofor k =1- 1,2 by thebinary change assumption and s;(p*) > O, by the same assumption.Hence s;c(p**) > O and p** is not an equilibrium contrary to itsdefinition. We conclude that indeed k = l. In the same way weshow that if p~* :S:: pt*; theti it must be that h = 2. Hence thetheorem is proved.\n,,\n,,\ni1i\n11\n¡:¡•\nCorollary 3. Let the economy have GS for all p. Then a binarychange at p*, an equilibrium, will raise the equilibrium price of thegood whose excess demand has increased at p* in greater proportionthan any other equilibrium price is raised and lower the equilibriumprice of the good whose excess demand was decreased ,at p* ingreater proportion than any other equilibrium price.\n,,¡','Jii'\nlil1'1\n;¡,,¡¡1\nii1\ni\n1\n1:\nCorollary 3'. Let the economy have GS at all p. Then a binarychange at p* raises the pr{ces of all goods in terms of the good whoseexcess demand was reduced by the binary change at p*.Proof Choose the second good as numeraire; that is, set p 2 =everywhere. Then if, say, p~* < p~ and p~*jp~ :S:: pf*fpt, all i, thefamiliar argument would lead to s 1/p**) < O; if k =1- 2, then by thebinary change assumption s;,(p**) = s~c(P**) < O and we wouldthus contradict p** as being an equilibrium. This is as it should bein view of GS: p~* = p~, and al! other prices rise relatively to thatof the second good, so that the excess supp1y for the second goodis reduced as needed, since by hypothesis s~(p*) > O.The application of these results to actuál situations is some.whatIimited simply because the supposition that the parameter change isbinary is very limiting. Later we shall be able to illustrate a versionof T.l0.3 for more interesting situations. Here we may find anapplication in the analysis of the consequences for the equilibrium\n249\nTHEOREM.4. Let all goods be WGS and let there be a binary changesuch that for all p* E E, s~(p*) > s 2(p*), s~(p*) < O. Then there isa new set of equilibrium price vectors E' such that if p** E E', thenfor every p* E E, p** can be scaled so that p{* > p{, p~* :S:: p~.\nProof. We note first that if PT > O, for either i = 1 or i = 2,then PT > O, for both i = 1 and i = 2. This follows from W anc\\the postulate that the change is binary. Suppose PT = o fori = 1,2. By T.9.11 and the assumptions that imply that p* is not in ·E', p**s'(p*) < O. For each i #- 1,2, either s¡(p*) = O or s,(p*) > Oand, therefore, PT = O; in the Iatter case, s;(p*) > O, by the assumption of a binary change, and by T.9.10, for all p** E E', pT* =O, sothat in any case p{*s;(p*) = O for i =1- 1,2. Then we have pf*s~(p*)+ p~*s;(p*) < O and so certainly pf* > p{ = O. Since s~(p*) > Oby assumption when p~ = O, T.9.10 ensures that s~(p**) > O,whence= O.1If pf > O for i = 1,2 then we proceed as in T.l0.2.\npr\nWe must now note that this result is not only slightly weaker thanthe corresponding one for GS, but its assumptions are also strongersince we postulate the change in parameters to be of a certain typenot only at a given p, but over a whole set of p's. If this had notbeen postulated, then it might be that E and E' ha ve price vectors incommon, and so we could not have utilized the Weak Axiom in theway we in fact di d. In the case of GS we found (T.l 0.3) that wecould do without the Weak Axiom. Here this avenue is notavailable, for we cannot now argue that if, say, p~* ;::: p'[*, all i,\ni¡\n!¡\n¡\n;j:\n,¡¡1!1!\n!:,,1\n'\nll\nT\n1\n11\n1\n1\n!\n250\nCOMPARING EQUILIBRIA\nGENERAL CO!vJPETITIVE ANALYSIS\ns~(p**) > O for k =1= 1, since it may be that the kth good belongs to\nthe class of goods that is independent of prices, and so we could haveMoreover, should p[ = O for i = 1,2, then if thechange is defined in the usual way to be binary at p* (not over thewhole of E), evidently it is quite possible for p** E E and p[* = Ofor i = 1,2. Thus it would appear that the assumptions of T.10.4are as weak as or weaker than any alternative ones we could imposein order to obtain clearcut results.Unfortunatdy, the assumption that there is Diagonal Dominance,which, we argued in the last chapter, is the most attractive of therestrictions on the forms of the excess.supply functions, is not verypowerful in allowing us to make definite statements when equilibriaare being compared. Let us see what can be done.Consider a binary change at p* such that s~ (p*) - s1 (p*) = -aand s;(p*) - s2 (p*) = b where p'{b - p~a = O. Then, since weshall suppose there to be DD, it follows that there will be a newunique equilibrium, which we may write as p(a). Now let {av} be asequence with é = a, which approaches O, and let pv = p(av). Byan argument exactly similar to that used in proving Lemma 9.3, wecan show thatlim pv = p(lim av) = p(O) = p*,\nds¡[P(a),a] < O implies dP¡(a) > Oda.da - '\n~\n1\nTHEOREM 5. Let s(p,a) be a one·parameter family of excess-supp E.If N is empty, z1(p) :<:::; O, all p and all i, and so W confirms that allpE E.Let us suppose, therefore, that N is not empty and considerM(p) = rnax G¡[z¡(p)J.leN\np¡\nLet PN be the price vector with components in N. It is easy to seethat if PN(O) » O, then PN(t) » O, all t. Suppose not and let t' bethe first time that sorne price, say the ith, i E N, becomes zero. Then,certainly, since no price can have fallen in greater proportionrelatively to its positive equilibriurn price than i has fallen, we have,by WGS,Z¡(p(t')] :?: 0.\n291\n(See T.9.8, which clearly holds in this weak forni.) But, since i E N,the inequality rnust be strict, whence by continuity, there is t* < tsuch thatZ¡[p(t)] > 0\nt* < t < t'.\nFor such t, the adjustment rule ensures jJ¡(t) > O, so that O = p 1(t') >p 1(t *) :2:: O, which is a contradiction.\nNext we note that if pE E, M(p) = O. Conversely, supposeM(p) = O, PN » O, then for all i E N, z1(p) = O, and for all i ~N,z1(p) :<:::; O from our earlier discussion. Then by W, z1(p) < O, i ~Nmust mean p 1 = O, whence p E E.Let\nm= {i\nJ\nM[p(t)] = G1 zt~?]'\niE\nN}·\nThen for all i E m, we have, omitting arguments from functions,\n,.11'\n¡:'\nil¡1!¡,\nThe inequalities follow from\n11\n(a)\nG¡(z1) :<:::; O for j ~N and Zjj :2:: O, j =f i by WGS;\n(b)\nby H and WGS Jz¡¡Jp1 :2::\n(e)\nG1 ;<;;G1,jEN,iEm.\n2, z11p 1 ;\nNi\nNow the right-hand derivative of M(p(t)) isd G¡(Z¡)max--tem dtp¡\nand the left-hand derivative is. d G¡(Z¡)mm---·iem dt p¡\nUsing the above inequalities, we have\ndM[p(t)]+ = G'[dz;/dt _ G1(z¡)] < O1dtPtPtif p(t) ~E, since by A.ll.l, G; >O. We have assumed that thesolution path is bounded and so M(p) is indeed a Lyapounovfunction.\nili.l1,\n':¡',,1\n'11\n292\nGENERAL COMPETITIVE ANALYSIS\nIn particular, if·p*(t) is a limit path of the solution,\nM[p*(t)] = M*\nWe sum up what we have proved or stated.THEOREM 6. Let all goods be WGS and let PN(O) » O. Then A.ll.lis globally stable provided that all solution paths are bounded. Ifthere exists a strictly positive equilibrium, then A.ll.l is alwaysglobally stable.While the analysis of the WGS case is rather more complex thanthat of GS, we see that we do almost as well with the weaker assumption as we did with the stronger. The \"almost\" is dueto the extrafuss to ensure boundedness of the solution paths. The weakeningof the assumptions is to be welcomed, bút they are still pretty strong.4.. Diagonal Dominance\nLet us again start with the simplest case, by supposing DiagonalDominance and the adjustment rule to be of a special kind and theeconomy to be a pure-exchange economy.Let X¡(P) be the demand for good i at the prices (in terms ofnumeraire) P. Then we write e¡J(P) = x 1JCP)P1jx¡(P) as the appropriate elasticities of demand. The special form of DiagonalDominance, which we refer toas D*D*, is this:lett(P)I >\nfor P1 >O.\n1\nall i i= n and P.\n(11)\nIn order to be able to use this rule without complications we furtherstipulate:ASSUMPTION l. For all P, x(P) » 0 and z 1[P(i)] > 0, all i. (P(i)is P with the ith element replaced by zero.) Also, zn[P(n)] > O.This assumption supposes that every good is demanded in positiveamount at every set of prices and that every good is in excess demandwhen its own price is zero. It requires also that the demand for thenumeraire good is large (in excess of the fixed supply) when its pricegoes to zero. We do not claim that all these assumptions have agreat deal to recommend them. In any event, we may now establishTHEOREM 7. If a pure-exchange economy has D*D* and it followsthe tatonnement rule (11), then, provided A.l2.1 and p(O) » O hold,the rule will be globally stable.\nProof By an argument exactly analogous tq that used in theproof of T.12.6 we can show that P(O) » Oimplies that P(t) » O, allt, since z¡(P(i)) > O. Hence, certainly, the solution path is boundedfrom below. By A.l2.1, zn(P) > O for J., Pt sufficiently large, for\nby H, so that setting Pn = 1, zn(P) > O when 2., P1 = +oo and sozn(P) > O for P sufficiently large. By W, 2., P1z1(p) = -zn(P) and(dfdt) 2., P1 = 2., P1z1(P) < O for J., Pt sufficiently large, so that thesolution path is also bounded from above.We now letZ(P) = max lz¡(P)Ii\nand show that it is a Lyapounov function. Let m be the set of ifor which lz¡(P)I = Z(P). Then, for i E m, consider log x¡(P),which, in view of A.ll.l, is well defined. Differentiating withrespect to t and using (11) gives\nall i # n and P;\n,L le J(P)In>Ni\n293\nThe special adjustment form of A.ll.2 is this:\nidentically in t,\nso that every point on p*(t) is an equilibrium.By Corollary 9.11, the set of equilibria is convex when WGS holds,so that the equilibria are not isolated if there are more than one.From T.ll.3 and D.ll.5, therefore, quasi-global stability withoutglobal stability seems possible for this case, although we have notinvestigated this question. However, Arrow and Hurwicz [1962]showed that if we postulate that at least one strictly positive equilibrium exists, the adjustment process is stable. They also gave anexample in which, when this extra assumption (of at least onestrictly positive equilibrium) is not made, the process is quasiglobally stable, but unbounded. In their example, however, G1(0)was not finite. The question whether the process under WGS maybe only quasi-globally stable, but not stable under slightly strongerconditions, is unsettled.\ne¡¡(P) < O\nSTABILITY WITH RECONTRACTING\n'Y(P) zJ·(P) .d[log x 1(P)] -_ L.,eifdtNn\n'F1\nGENERAL COMPETITIVE ANALYSIS\nSTABILITY WITH RECONTRACTING\nIf this expression were non-negative for non-equilibrium P, whenz1 > O, it would have to be that the following is true for i E m:\nIt can be left to the reader to show that this expression has the samesign as z 1 for non-equilibrium P. As before, Z(P) is declining fornon-equilibrium P, and the proof proceeds as before.\n294\nlett(P)IIz1(P)I\n~ L~~~ e¡1(P)z/P)I~\nL; let/P)IIz/P)I ~ lzt(P)I L; le¡¡(P)I.\nn>J;hi\nn>J,Pi\nwhere the last inequality follows from the definition of m. Evidently, the abo ve inequalities contradict D*D*. Similarly, ifz1 < O, d[log x 1(p)]/dt must be positive. Hence, since we are in apure-exchange economy, Z(P) is declining at non-equilibrium P.Since we already know the solution path to be bounded, Z(P) isindeed a Lyapounov function. Since, by T.9.12, the economy musthave a unique equilibrium, the theorem is proved. (Of course, theequilibrium as well as the rule is globally stable.)It is not hard to think of the kind of assumptions we should liketo malee in order to extend these results to an economy in whichthere is also production. We consider only one of these, thesimplest.\nAssuMPTION 2. The numeraire good does not enter into the production of any good nor is it produced. Also, 8y1(P)/8P1 < O for allP » O and j 1= i.The last assumption supposes that, say, a rise in the price of goodj will decrease the economy's output of good i, if that good is\nproduced, or reduce the demand for that good (service) as input ifit is not. As usual, it is easy to think of technologies that wouldfalsify this assumption. If it is made in view of H applied to y(P),however, it follows at once from the supposition that the numerairegood does not enter production in any way, that 8y1(P)/8P1 > O allP » O and all i.THEOREM 8. If an economy has D*D*, follows the rule (II), andsatisfies A.l2.1 and A.12.2, thcn for all P(O) » O, the rule is globallystable.Proof Proceed as in the proof of T.l2.7.writing YiJ(P) = 8y 1(P)/8P1 and using (II),\ndy1(P) = L,\"\"' y ¡(P)P z¡(P).----¡¡¡1\ni\n1\nFor i E m, we find,\n295\nThe result we have just established is worth having if for no otherreason that the Diagonal Dominance hypothesis, when framed interms of elasticities, seems particularly appealing. There is alsoanother, sadder reason. When we return to the more general formof the assumption and also to the more general form of the pricingrule, it is not at present possible to establish global stability. This,if a conjecture may be made, is likely to be due to lack of skill on ourpart, rather than to any global instability in fact. The kind of resultthat we need here is one that would allow us to deduce globalstability from the postulate that the Jacobian of excess supplies haseverywhere DD. No such result is available, but neither are counterexamples. In any event, we are able, at present, to prove only thefollowing, weaker result.THEOREM 9. Let there be units in which goods are measured suchthat if the economy has DD in these units, it has this property at allprices. Then A.ll.2 gives a globally stable rule,Proof. We note formally the assumption of the theorem: Thereis a vector h » O, such that for all i 1= n and all P\n¿ lz ¡(P)Ih\nlztt(P)Ih1 >\n1,\n1\nn>J,Pi\nwhere, of course, Z¡¡(P) < O, all i.We now show thatH(P) = max F¡[Z¡(P)]h¡is a Lyapounov function. Let m be the set of i for whichF1[z1(P)]/h 1 = H(P). Then for i E m,\ndzd~P) =\n¿ Z¡¡(P)FJ[z¡(P)] = ¿; z1 ¡(P)~:F1 [zt(P)],\nThe right-hand side of this expression must be negative for nonequilibrium P. If not, thenZ¡¡(P) 1h¡H(P) ~\n1\n>'-'\"~. :. .:*i:._z_tJ_(P,)_h¡_F_J[z_l_P_)]\n.:..:.:n\nh¡\n~ H(P)\n¿ lzt (P)Ih\nn=NI\n1\n1,\n296\nGENERAL COMPETITIVE ANALYSIS\nSTABILITY WITI-I RECONTRACTING\nwhich would contradict the assumption of the theorem. HenceH(P) is declining in value at every non-equilibrium P and the usualargument proves the theorem.The method of proof we ha ve just used shows why we needed therather special form of Diagonal Dominance. If we had taken h tobe a function ofP, that is, h = h(P), we would have required to knowhow h(P) behaves when P changes, and on this, no useful hypothesisseems available.5,\nLocal Stability\nIn al! the cases we have considered so far, with the exception ofWGS, we know that the equilibrium is unique, and since we haveshown it to be globally stable, it must be that the equilibrium islocally stable also. The question we shall briefly pose is whetherthere are situations for which local, but not global, stability properties can be established. We do not propose, however, to examinelocal stabi!ity problems at al! exhaustively.We shall be considering the numeraire rule of A.ll.2 and conducting our analysis in terms of the norm V(P) = (P - P*)D(P - P*)'when P (taken as a row vector with transposition denoted by aprime) is assumed to lie in an E neighborhood of P*, and ]) is asuitably chosen diagonal matrix. Of cotme, what we are lookingfor are situations for which we can say that the norm is declining foral! non-equilibrium P, for then, on the usual argument, we shall beable to treat it as a Lyapounov function.For a suitable choice of E we may write z1(P) in a Taylor expansion,ignoring non-linear terms, as follows:Z¡(P) = Z¡(P*) +\n¿ Z¡¡{P*)(P¡ - Pj)'.\nIf P* » O, then we know that it must be that z(P*) = O.A.11.2, we may then write\nBy\nF¡ = F; ¿ Z¡¡(P*)(P¡ - Pj).If, as usual, we write J(P*) as the Jacobian of the excess-supplyfunctions and fas the diagonalmatrix with non-zero elements givenby F;, we have, in matrix notation,\nP' = - fJ(P*)(P - P*)'.\n297\nPremultiplying both si des of this expression by (P - P*)¡- 1,\n(P - P*)DP' = - (P - P *)J(P *)(P - P *)'when D = ¡- 1 . The left-hand side of this expression is equal to[dV(P)fdt]/2 and so we would like to be able to say that the righthand side is negative for non-equilibrium P. The reader shouldprove to himself that this is indeed the case for a Hicksian or GSeconomy. It is not necessarily true for DD because V(P) is not asuitable fonn of the Lyapounov function for this case.To proceed, it will be useful to look at the constituents of J(P*).Since s1 = x1 + y1 - X¡, we may write\nJ(P*) = Y(P*) - X(P*),where Y(P*) is the Jacobian of the production term y(P*) andX(P*) the Jacobian of the demand term x(P*) in s(P*). (We hereassume that al! these are differentiable.) From profit maximizationwe know that (P - P*)[(y(P) - y(P*)] ;::: O (see T.3.8). By theTaylor expansion,\ny(P) - y(P*) = Y(P*)(P - P*)'and so\n- (P - P*) Y(P*)(P - P*)' :::; O.It follows from this that if, for sorne cases, we can show\n(P - P*)X(P*)(P - P*)' < Ofor non-equilibrium P, we can then say that for these assumptionsV(P) is indeed a Lyapounov function. Thus the crucial problem isthe behavior of households, not that of producers. We shall simplify matters accordingly from here on by considering only a pureexchange economy.We know that we may write X(P*) as the sum of the matrix ofsubstitution terms, say [au(P*)], and the matrix of income terms, say[[-t1¡{P*)]. The former is known to be negative definite (see T.4.9(b)),so evidently the crux of the pro blem is presented by the income termmatrix as no doubt we expected al! along. From elementary theory,we may write the typical element of that matrix asf-ttiCP*) =\nL sh¡{P*)mh (P*)1\nh\n298\n299\nGENERAL COMPETITIVE ANALYSIS\nSTABILITY WITH RECONTRACTING\nwhere s,¡(P*) is the difference between the amount of the jth goodhousehold h has at P* and the amount it would like to have at P*,household h's excess supply of goodj, and m¡¡,¡(P*) is the household'smarginal propensity to consume good i at P*. Since P* » O, it isof course true that\ncovariance term is small for all P, this does not seem sufficient toestablish a global stability result.Indeed, local stability requires us to show that the real parts ofthe roots of X(P*) are negative. Suppose this to be the case not onlyat P*, but at all P. We might conjecture, then, that provided P(t)is bounded and equilibrium is unique, global stability would follow.This we have not been able to prove.It is not clear how interesting the small covariance case is, since,for instance, a stratified society may well consist of a few kinds ofhouseholds only and. the covariance terms may be large. Indeed,we must recognize that we have here a double-edged weapon, for itwould seem clear that we ought to be able to construct at leasthypothetical examples where the income terms are sufficiently largerelative to the substitution terms to allow us to deduce that V(P) isincreasing for all non-equilibrium P. In that case we shall have notonly a case oflocal instability, but also of course an instance of globalinstability should the equilibrium be unique. We shall considersuch an example now.\nLs,¡(P*) = O.\n¡,.\n\"\nThis enables us to write the typical element of the income termmatrix also as¡.t1¡(P*) =\nLs,¡(P*)[m¡¡,¡(P*) - m (P*)]1\n\"where m (P*) is the average marginal propensity to consume good i1\nfor household as a whole. Evidently, we may interpret the foregoing expression as a covariance. If there is no reason we can thinkof why there should be any systematic relationship between being anet supplier or demander of good j and having a high or low marginal propensity to consume good i, then we would be inclined to saythat this covariance is very close to zero. This inclination would bereinforced if the number of households was large. Of course, if thisis a satisfactory description of the world, then V(P) will indeedqualify as a Lyapounov function, provided the covariance ,(incometerms) is sufficiently small relative to the substitution terms. Herewe get additional help from the fact that the leading diagonal elementsin the substitution matrix of every household must be negative (if thehousehold consumes the good in question). Hence, as far as theseterms are concerned, they are additive when we come to write clownthe substitution matrix for households as a whole. We cannot butthink that this term at least will greatly outweigh the income term inpractice. Of course, this is not enough for the task of provingstability, but it helps.The condition that the covariance must be small ensures localstability, but it does not eritail either that the economy be eitherHicksian or GS or WGS or DD even in a small neighborhood ofP*,let alone everywhere. Moreover, if the demand Jacobian isevaluated at P i= P*,¡.t1¡(P) =\nL s,¡(P)[m (P) - m (P)] + s¡(P)m¡(P).111\n\"\n6.\n1'\nAn Example of Global lnstability\nConsider an economy with three goods, one of which, say thatlabelled \"0,\" can be chosen as numeraire, and we are interested inthe process described by A.ll.2, (1). When examining local stability,that is, the behavior of the system in the neighborhood of an equilibrium Pt, P~, we shall wish to ensure that the real parts of theroots of - DJ(P*) are negative, if there is to be local stability.He re\nwhere D is the diagonal matrix with element k1• However, if R(/.1)is the real part of the ith root, we know that\nL R(/. = LZ¡¡(P*)k and /.1)\n1\n1 /. 2\n= det(- DJ(P*)).\n¡\n1\nThe smallness of the covariance term no longer allows us todeduce desirable properties for the Jacobian. Thus, even if the\nIs there anything in the underlying micro-theory of economic agentsthat ensures that 2 Z¡¡(P*)k 1 < O and det(- DJ(P*)) > O, which isa required necessary condition for local stability?\n11\ní11\n¡¡\n\"'\n300\nGENERAL COMPETITIVE ANALYSIS\nSTABILITY WITH RECONTRACTING\nThe answer is no, as the following example dueto GaJe illustrates.Suppose all households are alike and that they own 12 units of thenumeraire good and nothing of the other two goods. Write thebudget constraint:\nconsume the goods. Here the covariance, which we have alreadyexamined, is not small. Since this has been discussed at so me lengthalready, we shall not pursue it further.\nP1x1(P) + P 2x 2 (P) ;::::; 12.\nLet the utility function be given byU(xt.x 2 ) = :28xl + 28x2 - 2xr - 3x1x?. - 2x~.\n(4)\nThe reader should check that (4) gives convex indifference curves[although they are not strictly convex for all (x 1 ,x 2)]. In theeconomy there are stocks of the two goods given by\nx1 = 6\nx2 = 1.\nThese goods are held by an agent in the economy who is alwayswilling to trade the whole of his stock against numeraire at the goingprices., We find the unique equilibrium prices to be given by P 1 = 1,P 2 = 6. Setting k 1 = k 2 = 1,\n[24 -60]-11\n_ J(P *) = _!_56 10\nand we verify that both roots have positive real parts, so that theeconomy is locally unstable.In this example, good 1 is inferior at the equilibrium prices. Weeasily find the marginal propensity to consume this to be -t.Moreover, this income effect is strong enough to outweigh the substitution effect. This means that the excess demand for this good is,at the equilibrium prices, an increasing function of its own price andthe undesirable consequences follow.Two points may be made. If there is only one good in theeconomy to which the Giffen paradox applies, that is sufficient togive an example of instability for some adjustment speeds. If onediagonal element of -J(P*) is positive, then there is always some Dsuch that the sum of the diagonal elements of - DJ(P*), the trace,is positive, which in turn implies at least one root with positive realpart. Secondly, it should be noted that examples can be constructed, as they have been by Scarf, such that all goods are normalfor every household and yet some diagonal term (or terms) of- DJ(P*) is positive. This is due to differences in endowmentsbetween the households that have different marginal propensities to\n7.\n301\nThe Choice of Numeraire\nIn describing an equilibrium of an economy, it does not matterwhich good with a positive exchange value we choose as numeraire.The question arises whether this is a1so true for the analysis of thepricing process.Certainly, if the economy is Hicksian or if all goods are GS, thechoice of numeraire cannot in any way affect the prediction of globalstability. That this is so follows from the manner in which stabilityfor these cases was established earlier. The DD postulate is not inthe same boat, however, for there is nothing in either the theory ofhousehold choice or the theory of producer choice that rules out thepossibility that a system may ha ve DD for one choice of numeraireand not for another. In that case, we may find ourselves in thesituation in which we can claim the auctioneer's rule to be globallystable for one choice of numeraire and possibly divergent for another.In any event, we may be unable to prove stability for the latter.We know that if the economy has DD for some numeraire, thenit mu:;t have a unique equilibrium. Here the possible lack of DDfor some other numeraire, of course, cannot affect the claim ofuniqueness. Thus, if there is some choice of numeraire that allowsus to show that for no prices in the vicinity of the equilibrium is theequilibriumlocally stable, for that choice of numeraire, we shall alsohave shown that the auctioneer's rules are not globally stable.Suppose there are three goods and the economy has DD when thethird good is chosen as numeraire, but not when the second good isso chosen. In the first case, the Jacobian we require for localanalysis is given byz11 (P*) zdP*))( Z21(P*) Z22(P*)and in the second case, it is given byzll(Q*)( Zsl(Q*)\nzls(Q*))Zss(Q*)\nwhere Q* is the equilibrium price vector in terms of the second good.Since we are not excluding the· possibility that z 33 (Q*) > O, the\n1:\n11\n1\n302\n303\nGENERAL COMPETITIVE ANALYSIS\nSTABILITY WITH RECONTRACTING\nsecond Jacobian may have a positive trace anda positive determinant,and thus both roots may have positive real parts and the secondsystem could not then be locally stable. To clinch the case, wewould need to show by example that this sort of situation can arisefor sorne utility functions and wealth holdings of households. Thisindeed can be done.Since the DD situation is the most interesting of all we haveinvestigated, the sensitivity of the qualitative analysis of the tatonnement to the choice of numeraire must be taken seriously. If weleave, for the moment, the abstract world we have been inhabiting,we would be inclined to argue that insofar as the tatonnement rulesimulates any aspect of reality, there would in practice be no choiceof numeraire at all; prices would be quoted in terms of the mediumof exchange. Therefore, the proper procedure is not to enquirewhether the system has DD for any arbitrary numeraire, but toenquire whether this is the case for this particular one. This argument has sorne force, but it is open to at least two objections, Firstwe must recall that the formal structure of our economy is ill-suitedin its present form to accommodate what we would regard as asensible theory of money. There is no uncertainty, and above all,we ha ve given the economy no time sequence of transactions. Thisobjection, then, is simply one · against the importation of casualempiricism into a construction as abstract as the present one. 1t isan argument for postponing the discussion of the \"choice ofnumeraire\" until we ha ve reached the stage at which we can bringempirical evidence to bear. The second objection, however, isworth noting now. lt is that in a number of actual situations,whatever the power of our model to accommodate them, there is infact a choice of numeraire. Thus, in the theory of the balance ofpayments, there are evidently policy choices such as whether to usea given currency (the dollar) as the .currency in terms of which allothers are quoted on the market for exchange or whether to use goldor sorne fictional unit such as bancors for this role. Thus it maywell be that our laboratory procedure has uncovered a point thatmay yet be of practica! relevance. But the answer to this awaits thestage at which it appears reasonable to draw at least tentativeinference from the theory to the facts.\ntwo rules we have examined will be successful in seeking an equilibrium for the economy. If, for a moment, we think of the auctioneer as a planner who is seeking the equilibrium by trial and errorand forget all about simulating market procedures, it is reasonableto enquire whether there is sorne other rule that would lead to anequilibrium whatever the fine properties of the excess-demandfunctions might be.We shall not attempt to answer this question in its full generality,since it is a little too farfetched to merit detailed attention. We shalldiscuss one interesting example, however.Let P be the price vector in terms of numeraire. Suppose theplanner can observe not only excess-demand vector z(P) for the nonnumeraire goods, but also their Jacobian -J(P). If this Jacobianis non-singular, the planner can calculati~ what the equilibrium pricevector, call it Q, of the economy would be if the excess-demandfunctions were linear with the coefficients J(P); that is, he sol vesz(P) - J(P)(Q - P) = O or (Q - P) = J(P)- 1 z(P),which is Newton's method for solving non-linear equations.Of course, in general, the exces.s-demand functions are not linear.However, the planner follows the rule of raising the price of good iif Q1 > P 1 and lowering it when Q1 < P 1• At each stage of theprocess he must recalculate Q, which depends on P. He mayjustify this procedure simply by the argument that he is alwaysmoving prices in the direction of the only approximation to equilibrium that he is able to calculate.Evidently, this manner of adjusting prices will be possible in thissimple way only if for all P generated, J(P) is non-singular. Thereare other difficulties as well. Certainly, there is no guarantee thatQ will always have non-negative components. 1t may be arguedthat this does not matter so long as P » O, 'Since although theplanner realizes that Q with negative components cannot be anequilibrium price vector, Q1 - P 1 still indicates the direction inwhich P 1 should be changed. Yet if P 1 itself is zero, we certainlycannot let the planner reduce it any further.Suppose thatzt(P)-+ +oo as P 1 -+ O, any i,\n¿j\n8.\nSorne Other Auctioneer's RulesWe have seen that it is by no means true that, in all situations, the\nand take P(O) » O.\n:¡11\n1'\n¡ ¡\n:111\n1\nThe planner follows the ruleP = Q - P = J(P)- 1 z(P)\ni\n'11'\n:1\ne\nl!111\n,11\n304\nGENERAL COMPETITIVE ANALYSIS\nSTABILITY WITH RECONTRACTING\n305\ni:'1\nwhence\n1r [z'(P)z(P)] = -2[z'(P)z(P)] :S Owith equality if and only ifP is an equilibrium. Then, since z'(P)z(P)is never increasing, it follows from our assumption that no P 1 canapproach zero during this process.This argument shows also that [z'(P)z(P)] is a Lyapounov function. Therefore, the planner's procedure, under the given assumptions, willlead to an equilibrium, provided that(a) A. 11.3 is satisfied;(b) the solution path is bounded.Por (a), a Lipschitz condition is sufficient (see Section 11.3 andfootnote). Since z'(P)z(P) is non-increasing, the path remains in acompact set away from the boundaries. Hence, if we assume, as wedid x;i'*,m't;*) and\n** - hm (P**'x-**m-**)mh\"'h\ncomprise another possible set of limiting target demands.U¡¡(x~,m~) =, U1¡{x~*,m~*) = U~and so, by the strict quasi-concavity of U¡¡,\nThen\nall h,\n+ m~ - m~* < O all h.Summing over h leads to a contradiction of :¿; x~ = :¿; :X\" = :¿; x~*,P*(x~ - x~*)\n:¿;m'?; = m = :¿;m'?;*. Hence there is only one limiting set of targetdemands. But x't; = x't;, for if not,\"# O. Hence there is also aunique set of limit endowments: x't;,m't;. Evidently, then, P* is alsothe limit point of the price sequence, and the process is globallystable.It is clear that this result is heavily dependent on the suppositionthat at all moments of time, households are in a position to purchaseifthey so desire. To use Keynesian language, we have assumed thatat least a part of every positive demand for a good can be translated,at all times, into \"effective\" demand. When this is not true, andthere is nothing to ensure that it should be true, then we certainlybreak the thread that links the analy,sis of the process to the behaviorof utilities over time and it is clear that additional assumptions must·be introduced in order to ensure that the process is stable. Evidently,if a household's positive target excess demand fqr sorne good ca:nnotbe translated into a positive active excess demand because of thefinancia! restraint, it is quite possible that the active excess demandfor this good in the economy as a whole is negative. In that case,the arguments of Lemma 1 no longer apply.It is clear that there are other assumptions that could be invokedto allow the exchange process to converge even if we cannot ensurethat households ha ve positive stocks of money at every stage of theprocess. We have pursued this matter far enough to learn the mainlessons, however. In a pure-exchange economy the necessity ofmediation of sorne good in exchange introduces a speculative elementthat, in itself, will not prevent convergence to an equilibrium provided no household is prevented from an act of exchange by lack ofthe medium of exchange. When this is not the case-and a gooddeal of modern analysis suggests that this is the more interestinghypothesis-convergence must be in doubt and, in any case, requiresfurther study. We shall return to this question in our examinationof the Keynesian economy.Lastly, the reader is reminded that the \"monetary theory\" of thissection is extremely rudimentary.\nat\n,l\nT3467.\n'i1\n1\nGENERAL COMPETITIVE ANALYSIS\nConclusions\nThe economy in.vestigated in this chapter is still only a distantrelative of the economy we :know. Nevertheless we may claim tohave learned something. In particular, since A.l3.1 is not unreasonable in its context and since T.13.4 is rather general in content,we must conclude that failure of the market mechanism to establishan equilibrium-if such failures are in fact observable-must be dueto the elements of the actual economy that the economy of Section13.4 neglects. This information is worth having.The most conspicuous neglects in the analysis up to Section 13.5are speculative exchanges, mediation, and production. Of these, wehave· investigated only one. The conclusions that the necessity ofmediation itself introduces a \"speculative\" element into the process of exchange and that general convergence results a la T.13.4seem available only when rather strong special assumptions are madeare perhaps of interest. Speculation of the traditional kind, that is,purchases with a view to resale and vice versa, are best treated in amodel that includes consumption and production. We should notbe surprised if we find, when we briefiy turn to this matter in Chapter14, that stability may become problematical. In particular, theabsence of production in our analysis so far is significanL If werecall the \"stock-fiow\" problems associated with the existence ofdurable purchases we may conjecture that we shall find it muchharder to ensure a \"well-behaved\" market mechanism in aproduction economy.NotesThe first study of a process without recontract was reported byNegishi [1961]. He allowed endowments of households to vary out ofequilibrium in a continuous way and stipulated GS. The process ofSection 13.1 was first studied by Uzawa [1962] and, in a somewhatdifferent form, by Hahn [1962]. The assumption that the signs ofprivate and aggregate excess demands for each good were always thesame was first investigated by Hahn and Negishi [1962] and furtherextended to include adaptive expectations by Negishi [1964]. Thediscussion on the modification of the analysis when a medium ofexchange is present owes its point of departure to Clower [1965].\nji1\nChapter Fourteen\nTHE KEYNESIAN MODEL\ni!·1\nThings fall apart, the center does nothold.-W. 'B. Yeats, The Second Coming\nl. IntroductionKeynes was concerned with what we have called temporaryequilibrium (Sections 2.10 and 6.3). However, our previousanalysis requires sorne modification before it can be applied to theKeynesian case. This is so for two reasons. In Section 6.3 wesupposed that at the moment an equilibrium was to be shown toexist, economic agents had no cominitments left from the past, andsecondly, the economy discussed was not explicitly a monetary one.One of the questions we shall study in this chapter is whether theappropriate, required modifications may lead us to modify theproposition that a temporary equilibrium always exists. This is amatter of interest because Keynes has often been interpreted asclaiming that, in fact, a temporary equilibrium (as we have definedit) may not exist.There is another, less formal possible interpretation of theGeneral Theory. In this view, Keynes was more concerned withdemonstrating a \"failure\" of the price mechanism than arguing thatthere exist no prices that make equilibrium possible. Consideringthe amount of attention he gave to matters such as expectations andspeculation, this is a very plausible interpretation. The out-ofequilibrium behavior of an economy in which transactions take placeat all prices we know to be hard to analyze. We shall do no morethan consider a number of rather general problems raised by suchan undertaking.This chapter as a whole, of course, is not concerned with either afull exposition of Keynes or a detailed analysis of all the problemsraised. We are solely concerned with relating certain features ofthis model to what has gone before in this book.347\ni¡;.l\n1''\nli!\nT1\n!\n3482.\nGENERAL COMPETITIVE ANAL YSIS\nSorne Preliminaries\nWe cannot here attempt a detailed and full analysis of a monetaryeconomy. However, there are certain features that it is useful todiscuss before we proceed.Money. So far in this book, except in ehapter 8 and briefly inehapter 13, the existence of markets has been taken for granted.Once economic agents know market prices they take it that they cantransact to any extent on these terrns. The process of exchange isentirely anonymous-no bargain need be struck between any twoagents. It is pretty clear that this would be entirely unrealistic in aneconomy with no medium of exchange. eonsider three individuals,A, B, and e, where A has quantities of goods X and Y and derivesno utility from good Z, B has quantities of goods Y and Z andderives no utility from good X, and e has quantities of Z and X andderives no utility from Y. It is perfectly clear that there are noterms on which any two of the agents could beneficially trade witheach other, although there may be available, at sorne terms ofexchange, triangular trades that are Pareto superior to the presentallocation. To make sure that the equilibriurn of this economy isPareto efficient we would have to assume that all possible triangulartrades have been explored by the three households. It is easy toconstruct exarnples in which chains of arbitrarily many links wouldhave to be taken as explored by each agent before the resultingequilibrium could be shown to be Pareto efficient.·Such explorations ha ve two fea tu res: They are costly, and sincethey may involve a household in an exchange that, as such, is not\"beneficia!,\" but is undertaken for the expectation of another thatis, they may involve speculation. Of course, one of the advantagesof a rnonetary econorny is that it rnakes it possible to have anonymous rnarkets such that every agent need rnake, at most, two separa tetransactions if he desires to exchange a given \"non-money\" good foranother. We have seen (ehapter 13) that this does not entirelyremove the speculative element from transactions, but it grcatlyeconornizes in the nurnber of such transactions. In particular,only one transaction is needed in the exchange of money for anygood.While a monetary econorny greatly econornizes in the number oftransactions it does not make them costless; we still ha ve wholesalers,retailers, and brokers, whose function it is to reduce the costs of\nTHE KEYNESIAN MODEL\n349\ntransactions such as the search for information, but who themselves do not perform costlessly. Moreover, most transactions taketime and perhaps sorne effort, such as traveling.From these considerations alone it is possible to construct anexplanation of why an economic agent should hold part of his wealthin a medium of exchange with zero rate of return even when thereare other assets yielding a positive rate of return. Of course, insofaras money is held (and here money is supposed to be intrinsicallyworthless), it is held for future transactions. This would not occurif there were in existence al! the futures markets discussed in Section2.9. The cost of organizing all these markets is one reason we donot have them and, thus, one reason we use money. eosts also areresponsible for the fact that sales and purchases do not alwayscoincide in time. Thus, for instance, if a household sells services toa firm, the latter will ha vean incentive to economize in the frequencyof payment, that is, in the number of transactions. On the-otherhand, should the household buy only after it has actually sold (beenpaid), it would be involved in storage costs.Jt will be noted that so far we have not made the point that thefuture is uncertain and that in the absence of the requisite numberof contingent futures markets, well-known propositions in the theoryof choice under uncertainty can be invoked to explain why agentsshould include money in their portfolio of assets. In this view, therate of return foregone in holding money is a kind of insurancepremium against the possibility that, in fact, the rate of return onother assets may turn out to be negative. Of course, if the \"bestguess\" is that the return on other assets will be negative, no furtherexplanation for the holding of money is required. We shall notpursue the uncertainty problern here.We can formalize sorne of the above arguments in the spirit ofSection 6.3, but it should be ernphasized that only the most primitivemonetary ideas are treated here.Let the subscript \"m\" stand for rnoney that we now regard as thenon-interest-paying debt of sorne agency outside our formal systern,say the government. Household h, as in Section 6.3, has an anticipated volurne of receipts given by xhb· (For the moment we ignorepast debts.) Receipts are measured in unit of account, but notnecessarily in terms of money. In addition, the household has astock of rnoney, Xhm· The anticipated receipts of period 2 do notinclude the money stock transferred from period 1 to period 2. The\n350\nGENERAL COMPETITIVE ANAL YSIS\ntwo budget constraints read:P Xk + Pb(xhb - Xhb) + Pm(Xhm - Xhm) :S: p X1\n1\n1\n+\nL dh1(py1)\n+ L (d¡,1 - dh!)K1,\n(1)\nf\nP~X~ :S: Xhb + P~mXhm·\n1·\n1\n(2)\nIn addition to these budget constraints, the household is constrained by transaction costs, which depend on the money stocks itholds, prices, and the transactions it propases to carry out. Recallthe time constraint on the amount of labor services supplied that wasintroduced in Section 3.1. We shall now write\n(3)The left-hand side indicates the necessity of supplying some labortime for transactions in period 2. The amount required declineswith the money stock and increases with the value of transactions.We take J( ) to be continuous in its arguments.Evidently, (3) is a pretty crude device to capture some of theproblems discussed in this section, but for our purposes it will serve.Now, if X¡¡ = (xk,xhb,Xhm), the first-period derived utility function,D.6.18, is given bys.t. (2) and (3).2\nNote that the .\" true\" utility function, Uk ( ), depends only on consumption of goods and leisure, but that the derived function dependson the money stock chosen for transfer to period (2). It is likelythat more sophisticated versions of the demand for money alsowould allow the construction of a derived utility function of whichthe money stock is an argument.In Section 6.3 we showed that our consumption assumptionsallowed us to deduce that U¡¡(X¡¡) was semi-strictly quasi-concave,where xh did not include money. Here we may assumeAssUMPTION ·¡,\nJ(x~,p~,p~mXhm) is, for given p~, P~mXhm,\na convex\nfunction of x~.This assumption can \\:)e justified by arguing that there are íncreasing time costs of transactions with a given stock of money. (Strictlyspeaking, a transaction takes place only when X~¡ =1 X~¡. We havenot thought it worthwhile to introduce the extra elaboration\n!1\n,¡\nrequired.)If A.l4.1 holds, the proof of p.l44 can be used toestablish that Uh(xh) is semi-strictly quasi-concave when xh =(xk,xhb,Xhm)· We need note only thatas there defined, satisfiesthe constraint (3).Lastly, it is easy to see that if J( ) becomes large enough asPnmxhm becomes small forp~ given, the household will alwaystransfer some money from period 1 to period 2.\nxn,\nf\n. i\n351\nTHE KEYNESIAN MODEL\nxn,\nThe Past. In Section 6.3 all households started period 1 with nocommitments from the past. This plainly is not .realistic since weare not considering period 1 to be the beginning of the world.Indeed, in the present context, history may have peculiar significance.To examine the matter further we need a rather more elaboratestructure than that of Section 6.3.Let there be three time intervals: O, 1, and 2. If the agent is viewedas acting in period O, then 1 is an interva1 ofthe future and 2 is theremaining future. If the agent is acting in period 1, then O is thepast and 2 is the future. We give a variable the superscript \"OF\"to denote the expectation that was formed in O of the values to betaken on by that variable from period 1 on, that is, in periods 1 and2. We give a superscript \"ij,\" j =1 F, to denote the expectationformed in i of the values of the variable in j. A single superscript\"i\" denotes that we are dealing with the actual variable value in i.In this notation, for instance, p~Fx~F is what the agent h believes inperiodO will be the present value of his endowment in period 1, that is,p~Fj~F = p~lj~l\n+ p~l(p~2j~2).\nSimilarly, p~FyJF is the present value of the profits in period 1 offirm f on the expectations formed in period O.Let us now view period 1 as the present. We assume that thebonds issued by firm fin period O are repaid in pericid 1, but that, asbefore, the firm issues a quantity of new bonds, p} 2y} 2, equal to theprofits it expects in 1 to make in 2. (The reader should note thaty} 2 now has quite a different meaning from that given it in Section6.3). We write xkb as the actual value of receipts in period 1 plusthe present value of receipts expected then for period 2. By theassumptions of Section 6.3,\nxkb = plxk + p~(pkzxkz) +\n¿ dk¡[ply} + p&(p}2y}2) - pJFyJFJf\n+ p~\nLdk [max(pk2yj2) - p} y}2\n1\nf\nh\n2\n]\n(4)\n~·j-\n352\n353\nGENERAL COMPETITIVE ANAL YSIS\nTHE KEYNESIAN MODEL\nThe first two terms are straightforward; they give the receiptsfrom current endowment sale and the present expected value fromfuture endowment sale. The first square bracket, for any j, gives thenet payment of fto shareholders after repayment of the bonds issuedin O. The second square bracket gives the profit expected by themost optimistic household in period 2 after repayment of the bondsissued in period l. As before dkr = O if h is not the most optimistichousehold.If we write K} as the capital val ue of firm fin period 1, then it isgiven by the first square bracket plus p& times the second squarebracket for .f That is,\nThe resources at the disposal of the household at the beginning ofperiod 1 are\n(5)This should be compared with D.6. 15 and D.6. 16. Sin ce theeconomy now has a history, the firm has past commitments, thatmust be taken into account in the valuation placed on it in period 1.1t is plain that we now cannot assume K} ?: O. lf K} < O, then thehousehold with a share dgr in the firm is responsible for dgK} of thenet debt and cannot escape this obligation:ASSUMPTION 2.\n-1Xnb\n[p 1xk + p&(pk 2 xk 2) -\n:¿ dkrK}.\n(4')\nWe refer to (7) as the wealth of h at the beginning of period 1 andwrite it as wk. lf dkr = d~} = d~r' as we could take to be the caseif all expectations are fulfilled and no one buys \"short\" in period O,and if indeed all expectations are correct, then wk = x~b + p~x~m'which is. exactly (except for the monetary component) what wededuced to be the form of the wealth transferred to the \"future\" inSection 6.3.Since households and firms ha ve different expectations in periodO,it cannot be that all expectations are fulfilled in period l. Thus, ingeneral:\n(b)\nBut\n:¿ dg}K9 + :¿ (dgr - dg})KJ1\nf\n1.\n(6)\nf\nHere K9 1 is the capital value of firm fin period 1 as expected inperiod O. Also, d~} are the planned holdings of h for period 1 ofthe shares of firm .f Note that\nKJl = [max (pgFyJF) _ pJFyJF]h\n= max(pg1yJ1 + pg1(p~zy~z) _ pJFyJF]h\nso that, by the assumptions of Section 6.3, KJ 1 ¿ O.\n,.1•\nlj\nl~-~ -- ~----- ------ -\nf (dkrK} - d~}KJ 1)J1\nTo (4') we add the net repayment of bonds to the household,(xgb - xg~), and the money stocks transferred to period one,\nxg~ = pJFx~F +\npJFx~F] + [f\nf\nP~X~m-\n+ PmXnm1 o\n- :¿ (d~r - dgl)KJ + x~b + p~X~m· (7)\nNow we may write (4) also as\nxkb = p1 xk + p&(pk 2 xk 2 ) +\n-oF)·Xhb\nor, using (4) and (6),\n(a)\nK} < 0 implies dkr = d~r·\n+ ( Xnbo -\n(e)\nThe value of the endowment of a household in 1 will differfrom what was expected at O (the first square bracket in(7)). If it is less, then the first term in (7) is negative.K} may be negative (and differ from K~ 1 ) because the valueof the firm's production plan in 1 is less than it wasexpected to be in O. This may be so for three relatedreasons: First-period prices may be different than they hadbeen expected to be; the price expected in period 1 to rulein period 2 may be different than period 2 prices wereexpected to be in period O; the production plan of the firmin period 1 may differ from what was expected in periodO.The actual share, dkr, in firmfmay differ from its plannedvalue for all the reasons already given.\nNow severa! situations that did not arise in our previous work arepossible. As before, let p = (p\\pD.(a) Suppose p such that p 1y} + p&pj2y} 2 - pJFyJF < O. Thenthe firm f cannot repay the debt of the previous period. We couldsay that the firm is bankrupt. Since there may be shareholders moreoptimistic than the firm, however, we might wish to assume that they\n354\n355\nGENERAL COMPETITIVE ANALYSIS\nTHE KEYNESIAN MODEL\nwill repay the short-fall on the firm's debt as long as they are notinvolved in loss. From this reasoning (b) follows.(b) The firm is bankrupt when at sorne p, Kj < O. As long asthe present value ofprofits ofthe firm is positive, however, it evidentlypays to continue operating.(e) If at p, K} is sufficiently negative to cause wk < O, the bankruptcy point of household h has been passed. We must supposethat, in fact, the household hands over to its creditors all its assets,including the present val u e of its wages and its share in the firm. Thecreditors may value the future profits of the firm, the debtor's shareof which they claim, quite differently than the debtor did, sothey (the creditors) might experience a discontinuous change in wealth.(d) To be even remotely realistic, we must add that the management of the firm and thus 'its production plans may change at anystage in (a), (b), or (e). In (a) the shareholders may install newmanagement, in (b) the creditors may demanda change, and in (e)the creditors own a fraction of the firm. Any such change in theidentity of the management, since it will be accompanied by a changein the expectations, will generally lead to a discontinuous change ofproduction plans.Clearly, the actual bankruptcy procedure is at least partly amatter oflaw, but it seems plain that the history ofthe economy maymake it impossible to guarantee the continuity properties of thevarious functions and correspondences and this is bad for existenceproofs. It is to this, one of our main concerns in this chapter, thatwe now turn.\nwith a zero real wage. This is not the only desideratum, however.Keynes was concerned with a monetary economy, and in any casewe ha ve agreed that all of our constructions presuppose the absenceof barter. It is rather essential, then, that once money has beenintroduced explicitly as the means of effecting exchanges, we shouldnot finish up with an equilibrium in which money has zero exchangevalue, that is, one in which p~ = O, in the notation of the previoussection. In other words, we must show the existence of an equilibrium restrained furtlier by the requirement that p~ > O.Our procedure will be to assume first that if an equilibrium existsit will satisfy p~ > O. This allows us to take money as thenumeraire. Later we shall re-examine this matter.From what we have .learned already we know that we must beable to establish the appropriate continuity properties of thebehavioral function or correspondences and of those constructedfrom them in order to demonstrate that an equilibrium exists. Thepossibility that at sorne point in the price space the entire resourcesof one agent become the property of other agents, in the presentcontext, is associated in general with a discontinuity, so the existenceproof is endangered.Suppose that household e is the so le creditor of firm/from periodO and that household h owns all the shares of firm f Then household e includes among the resources available to it in period 1p~Fy~F, the repayment of its loan to firm/, made in periodO. If atp, however, household h has wk = O, then it cannot borrow andtransfers all its resources to c. As far as h is concerned they are justequal in value to its debt of p~Fy?F. But household h expected toreceive pk 2 y} 2 in period 2, while household e expects p; 2 y} 2 and thetwo amounts may differ. Al so, of course, the future \"earningpower\" of h from its own resources was pk 2 x~, while household evalues them at p~ 2 x~. Hence, at the bankruptcy point, e may experience a discontinuous change in wealth.To this must be added the equally important difficulty causedby a change in managemcnt resulting from the bankruptcy of thefirm.In addition to all this another problem arises. It will be recalledthat the strategy of our existence proofs was to establish the existenceof a compensated equilibrium and then to show that it was, in fact,a competitive equilibrium. For this last step we needed to ensurethat in the compensated equilibrium every household disposed of a\n3.\nThe Existence of Keynesian Temporary Equilibrium\nThere are two, rather distinct questions that we must investigate.The first, straightforward question is whether it can be argued thatKeynes discovered features of an economy that lead to the failure ofone or the other of our assumptions of Section 6.3 and thus make itimpossible to establish the existence of a temporary equilibrium.(It should be emphasized that for our purposes temporary equilibrium implies the clearing of all markets including that for labor.The next section looks at a different kind of equilibrium.) Thesecond question is whether such an equilibrium, even if it can beshown to exist, is \"sensible.\"By \"sensible,\" of course, we can mean all sorts of things. Certainly, though, we should not be much interested in an equilibrium\n1,1 ¡!111\n' '11.\n'~ 1\"\n11\n¡ll],,\ni\n356\nv.alue of resources that exceeded the value of its minimum consumptwn vector. It is plain that this last step may not be possible noweven: if the existence of a compensated equilibrium could be demon~st.rated. In a compensated equilibrium, if a household is bankrupt itd1sposes of no resources, and we cannot use our assumption ofresource relatedness to reach the desired conclusion. The fact thatsorne household has an \"effective\" demand for the resources of thebankrupt household does not help the latter to any \"disposable\"resources.In his Chapter 19, \"Changes in Money-Wages,\" Keynes reallyaddressed himself to the problems of this section, although he wasnot concerned with a formal existence analysis. He argued thatlower money wages might not reduce unemployment. He adducedvarious well-known reasons, including one not yet mentioned here,namely the possibility that expected prices may not be continuousfunctions of current price. This is not unimportant if we consider,for instance, the likelihood that the bankruptcy of firms and households is information separate from current price information, whichmay influence agents' views of the future. But Keynes also wrote,\"Indeed if the fall in wages and prices goes far, the embarrassmentof those entrepreneurs who are heavily indebted may soon reach thepoint of insolvency-with severely adverse effects on Investment \"(p. 264).'This Ieads us to another point of sorne importance: The problemof bankruptcy is not unrelated to the good or goods in terms ofwhich debts are contracted. Keynes realistically took it that theywere contracted in terms of money. We have hitherto taken themas contracted in abstract unit of account. Consider again thecr~ditor household c. If it has a contract to receive money, then itwlll receive p~(pJFyJF)p~1 , and this is the amount of money the debtorhousehold also is contracted to deliver. Evidently then, the set ofP at which wk = O when debt is fixed in unit of account will notcoincide, in general, with the set of p at which wk = O when debt ispresent in terms of money. The terms in which contracts are madematter. In particular, if money is the good in terms of whichcontracts are made, then the prices of goods in terms of money areof special significance. This is not the case if we consider aneconomy without a past and without a future. Keynes wrote that\"the importance of money essentially flows from it being a linkbetween the present and the future,\" to which we may add that it is\n357\nTI-lE KEYNESIAN MODEL\nGENERAL COMPETITIVE ANALYSIS\nimportant also because it is a link between the past and the present.If a serious monetary theory comes to be written, the fact thatcontracts are indeed made in terms of money will be of considerableimportance.We now have a great deal of evidence that establishing the existence of a temporary equilibrium for the economy we are nowconsidering m ay not be smooth sailing. Of course, general \"nonexistence\" theorems are not to be sought. Therefore it may behelpful to sketch an example.To avoid aggregation problems, Jet us suppose that the economyis capable of producing a single good. For the purpose of thisexample only, we write yt as the output ofthe good at time t (not to beconfused with the vector y 1)'. The good may be consumed or usedin subsequent production. Let S1 be the amount of the goodavailable at the end of period t for production at t + 1 and Jet Lt bethe amount of the single kind of labor service used in productionat t. Then the production function is\ny 1 = Sf_ 1 Lr\na> 0,(3 >O, a+ (3 <l.\n(8)\nNote tha:t there are diminishing returns to scale and that onlystocks set aside in the previous period are availab1e for production.It will be convenient to take units such that\nSo = l.Let p be the actual price of the good in period 1 (i.e., we omit thesuperscript), pJ the price expected by the firm for period 2. SimiIarly w is the current wage and WJ the wage expected by the firm forperiod 2. All prices are measured in terms of rnoney. Then,assuming that the present value of profits are maximized, routinecalculations giveTT¡\n= p(ar)a(l -\na) + pb(pJ) 11 bb(l - a)(arJ)u ( ~ )\n- fi/b(l- a)\n(9)\nwhere Trr is the present value of profits as seen by the firm and\nr = !!..,w\nPJpry = w¡'q = ~,\na =_a_, b = 1 - (a+ (3),\n1-a\nAl so\n1-a\na\nu=-·b\n(10)\n!:.!!:\n' ',111\n11\n358\nGENERAL COMPETITIVE ANALYSIS\nNext let us consider households. We shall assume that theyhave identical utility functions, although they may have differentexpectations. For reasons we will not examine, a household willalways deliver one unit of labor in each period. (This assumptionmakes the example easier, but is in no way essential.) The maximum amount of leisure it can have in each period is also one unit.Part of the leisure, however, may have to be used in transactions(see (3)). To make this precise, Jet e!, be the amount of the goodbought by h in period t and Jet mi,- 1 be the amount of money transferred from period (t - 1) to period t. Then, if Al. is the leisureconsumed by hin period t, we postulate\nAl.= min(1, m~~)·p eh1\n(ll)\nTHE KEYNESIAN MODEL\n359\n2, mk = iñ,\n(16)\n",
      "topic": "econometrics"
    }
  },
  "verification": {
    "has_empty_values": false,
    "issues": []
  }
}