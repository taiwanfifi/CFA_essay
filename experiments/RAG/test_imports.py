"""
æµ‹è¯•æ‰€æœ‰ RAG è„šæœ¬çš„å¯¼å…¥å’ŒåŸºæœ¬ç»“æ„
"""
import sys
import os

def test_imports():
    """æµ‹è¯•æ‰€æœ‰å¿…è¦çš„å¯¼å…¥"""
    print("ğŸ” æµ‹è¯•å¯¼å…¥...")
    
    errors = []
    
    # æµ‹è¯•åŸºç¡€åº“
    try:
        import json
        import itertools
        from typing import List, Dict, Any, Set, TypedDict
        print("âœ… åŸºç¡€åº“å¯¼å…¥æˆåŠŸ")
    except Exception as e:
        errors.append(f"åŸºç¡€åº“: {e}")
    
    # æµ‹è¯• dotenv
    try:
        from dotenv import load_dotenv
        print("âœ… dotenv å¯¼å…¥æˆåŠŸ")
    except Exception as e:
        errors.append(f"dotenv: {e}")
    
    # æµ‹è¯• LangChain
    try:
        from langchain_core.documents import Document
        from langchain_openai import ChatOpenAI, OpenAIEmbeddings
        from langchain_core.prompts import PromptTemplate
        from langchain_core.output_parsers import JsonOutputParser, StrOutputParser
        print("âœ… LangChain æ ¸å¿ƒåº“å¯¼å…¥æˆåŠŸ")
    except Exception as e:
        errors.append(f"LangChain æ ¸å¿ƒ: {e}")
    
    try:
        from langchain_milvus import Milvus
        print("âœ… langchain_milvus å¯¼å…¥æˆåŠŸ")
    except Exception as e:
        errors.append(f"langchain_milvus: {e}")
    
    try:
        from langchain_community.retrievers import BM25Retriever
        from langchain.retrievers import EnsembleRetriever
        print("âœ… LangChain æ£€ç´¢å™¨å¯¼å…¥æˆåŠŸ")
    except Exception as e:
        errors.append(f"LangChain æ£€ç´¢å™¨: {e}")
    
    # æµ‹è¯• LangGraph
    try:
        from langgraph.graph import StateGraph, END
        print("âœ… LangGraph å¯¼å…¥æˆåŠŸ")
    except Exception as e:
        errors.append(f"LangGraph: {e}")
    
    # æµ‹è¯• LlamaIndex
    try:
        from llama_index.core import VectorStoreIndex, Document, Settings
        print("âœ… LlamaIndex æ ¸å¿ƒå¯¼å…¥æˆåŠŸ")
    except Exception as e:
        errors.append(f"LlamaIndex æ ¸å¿ƒ: {e}")
    
    try:
        from llama_index.embeddings.openai import OpenAIEmbedding
        from llama_index.llms.openai import OpenAI
        print("âœ… LlamaIndex OpenAI å¯¼å…¥æˆåŠŸ")
    except Exception as e:
        errors.append(f"LlamaIndex OpenAI: {e}")
    
    # æµ‹è¯• Pydantic
    try:
        from pydantic import BaseModel, Field, ConfigDict
        print("âœ… Pydantic å¯¼å…¥æˆåŠŸ")
    except Exception as e:
        errors.append(f"Pydantic: {e}")
    
    # æµ‹è¯•å…¶ä»–
    try:
        import numpy as np
        from tqdm import tqdm
        print("âœ… NumPy, tqdm å¯¼å…¥æˆåŠŸ")
    except Exception as e:
        errors.append(f"NumPy/tqdm: {e}")
    
    if errors:
        print("\nâŒ å¯¼å…¥é”™è¯¯:")
        for err in errors:
            print(f"   - {err}")
        return False
    else:
        print("\nâœ… æ‰€æœ‰å¯¼å…¥æµ‹è¯•é€šè¿‡ï¼")
        return True


def test_data_loader():
    """æµ‹è¯•æ•°æ®åŠ è½½å™¨"""
    print("\nğŸ” æµ‹è¯•æ•°æ®åŠ è½½å™¨...")
    try:
        from data_loader import load_thelma2_dataset
        questions, docs = load_thelma2_dataset()
        print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ: {len(questions)} ä¸ªé—®é¢˜, {len(docs)} ä¸ªæ–‡æ¡£")
        return True
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return False


def test_script_syntax():
    """æµ‹è¯•è„šæœ¬è¯­æ³•ï¼ˆä¸å®é™…è¿è¡Œï¼‰"""
    print("\nğŸ” æµ‹è¯•è„šæœ¬è¯­æ³•...")
    scripts = [
        "rag_agent_pragmatist.py",
        "rag_langchain_advanced.py",
        "rag_llama_index.py",
        "rag_llama_index_vector.py"
    ]
    
    all_ok = True
    for script in scripts:
        try:
            with open(script, 'r', encoding='utf-8') as f:
                code = f.read()
            compile(code, script, 'exec')
            print(f"âœ… {script} è¯­æ³•æ­£ç¡®")
        except SyntaxError as e:
            print(f"âŒ {script} è¯­æ³•é”™è¯¯: {e}")
            all_ok = False
        except Exception as e:
            print(f"âš ï¸ {script} æ£€æŸ¥æ—¶å‡ºé”™: {e}")
    
    return all_ok


if __name__ == "__main__":
    print("=" * 50)
    print("RAG è„šæœ¬æµ‹è¯•")
    print("=" * 50)
    
    result1 = test_imports()
    result2 = test_data_loader()
    result3 = test_script_syntax()
    
    print("\n" + "=" * 50)
    if result1 and result2 and result3:
        print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        print("\næ³¨æ„: å®é™…è¿è¡Œéœ€è¦è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯")
    print("=" * 50)

