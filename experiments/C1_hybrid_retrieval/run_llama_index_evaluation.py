import os
import json
from tqdm import tqdm
from typing import List, Dict, Any

from dotenv import load_dotenv

from llama_index.core import (
    VectorStoreIndex,
    SimpleDirectoryReader,
    Settings,
    Document,
    StorageContext,
    load_index_from_storage,
)
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.llms.openai import OpenAI

print("--- ğŸš€ LlamaIndex è©•ä¼°åŸ·è¡Œå™¨ (OpenAI ç‰ˆ) ---")

# ========================
# 0. ç’°å¢ƒæª¢æŸ¥
# ========================
load_dotenv()
if not os.getenv("OPENAI_API_KEY"):
    raise RuntimeError("ğŸ›‘ è«‹å…ˆè¨­å®šç’°å¢ƒè®Šæ•¸ OPENAI_API_KEY")

# ========================
# 1. è¨­å®š LLM & Embedding
# ========================
Settings.llm = OpenAI(model="gpt-4o-mini", request_timeout=120.0)
Settings.embed_model = OpenAIEmbedding(model="text-embedding-3-large")

print("âœ… å·²è¨­å®š LlamaIndex ä½¿ç”¨ OpenAI")
print(f"   - LLM: gpt-4o-mini")
print(f"   - Embedding: text-embedding-3-large\n")

# ========================
# 2. è³‡æ–™èˆ‡è¼¸å‡ºè·¯å¾‘
# ========================
DATA_FILE_PATH = "./data/ultimate_rag_challenge_questions.json"
OUTPUT_FILE_PATH = "./llama_index_retrieval_results.json"
KB_PERSIST_DIR = "./llama_index_kb_storage"

# ========================
# 3. æº–å‚™çŸ¥è­˜åº«
# ========================
if not os.path.exists(KB_PERSIST_DIR):
    print("ğŸ“‚ æœªæ‰¾åˆ°ç´¢å¼•ï¼Œå»ºç«‹æ–°ç´¢å¼•ä¸­...")
    with open(DATA_FILE_PATH, "r", encoding="utf-8") as f:
        eval_data = json.load(f)

    unique_evidence: Dict[str, str] = {}
    for item in eval_data:
        for ev in item.get("gold_evidence", []):
            did = ev.get("doc_id")
            txt = ev.get("text_snippet")
            if did and isinstance(txt, str):
                unique_evidence[did] = txt

    docs = [Document(text=txt, metadata={"doc_id": did}) for did, txt in unique_evidence.items()]
    print(f"   - æ‰¾åˆ° {len(docs)} ä»½æ–‡ä»¶ï¼Œæ­£åœ¨å»ºç«‹ç´¢å¼•...")

    index = VectorStoreIndex.from_documents(docs, show_progress=True)
    os.makedirs(KB_PERSIST_DIR, exist_ok=True)
    index.storage_context.persist(persist_dir=KB_PERSIST_DIR)
else:
    print("âœ… å¾æ—¢æœ‰ç´¢å¼•è¼‰å…¥")
    storage_context = StorageContext.from_defaults(persist_dir=KB_PERSIST_DIR)
    index = load_index_from_storage(storage_context)

query_engine = index.as_query_engine(similarity_top_k=5)

# ========================
# 4. é€é¡Œæª¢ç´¢
# ========================
print("\n--- é–‹å§‹è™•ç†è©•ä¼°å•é¡Œ ---")
with open(DATA_FILE_PATH, "r", encoding="utf-8") as f:
    eval_data_for_questions = json.load(f)

results_map: Dict[str, List[Dict[str, Any]]] = {}

for qa_pair in tqdm(eval_data_for_questions, desc="è©•ä¼°é€²åº¦"):
    q_id = qa_pair.get("question_id")
    question = qa_pair.get("question")
    if not q_id or not question:
        continue

    try:
        response = query_engine.query(question)
        retrieved_nodes = response.source_nodes or []

        bundle: List[Dict[str, Any]] = []
        for sn in retrieved_nodes:
            node = sn.node
            did = node.metadata.get("doc_id")
            if did:
                bundle.append({
                    "page_content": node.get_content(),
                    "metadata": {"doc_id": did},
                })
        results_map[q_id] = bundle

    except Exception as e:
        results_map[q_id] = []
        print(f"\nâš ï¸ å•é¡Œ {q_id} ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

# ========================
# 5. è¼¸å‡º
# ========================
with open(OUTPUT_FILE_PATH, "w", encoding="utf-8") as f:
    json.dump(results_map, f, ensure_ascii=False, indent=4)

print(f"\nğŸ‰ å®Œæˆï¼æª¢ç´¢çµæœå·²è¼¸å‡ºè‡³ {OUTPUT_FILE_PATH}")
print("ä¸‹ä¸€æ­¥ï¼šåŸ·è¡Œ `python evaluate.py` æŸ¥çœ‹å®Œæ•´å ±å‘Šã€‚")
