# P2 金融 LLM 壓力測試：反事實微擾與雜訊敏感度分析
# Stress Testing Financial LLMs: Counterfactual Perturbation and Noise Sensitivity Analysis on CFA Examinations

> **狀態**：✅ 論文已完成 | **字數**：4,367 words | **樣本量**：N=1,032 | **目標期刊**：Finance Research Letters (FRL)
> **論文資料夾**：`drafts/selected/I1_counterfactual/`
> **合併自**：I1（反事實壓力測試）+ I3（雜訊與紅鯡魚）

---

## 研究背景與問題

LLM 在 CFA benchmark 上的高準確率可能是假象。CFA 題庫有限、結構固定、SchweserNotes 等準備材料在網路上大量流通——模型在預訓練時很可能已「見過」這些題目。因此「答對」可能只是 **memorization** 而非 **reasoning**。

此外，真實金融工作充滿雜訊——20 頁的 earnings call 可能只有 3 段是關鍵資訊、分析報告夾雜冗長免責聲明。但現有基準都使用乾淨的題目文本，完全不測試模型在噪音環境下的表現。

本研究提出**雙維度壓力測試框架**：
1. **I1 反事實微擾**：改變題目中的數值或條件，測試模型是否真正理解 vs 只是背答案
2. **I3 雜訊注入**：在題目中加入無關資訊、誤導干擾、冗餘上下文，測試資訊過濾能力

---

## 核心方法

### 方法一覽

**I1：反事實微擾（Counterfactual Perturbation）**

兩層微擾設計：
- **Level 1（數值替換）**：改變數值參數（利率 5%→7%），保持解題邏輯不變。模型需在新數值下重新計算。
- **Level 2（條件改變）**：改變前提條件（annual→continuous compounding, call→put option）。模型需切換推理路徑。

核心指標：
- `Memorization Gap = 原題準確率 − 微擾題準確率`（正值 = 記憶化依賴）
- `Robust Accuracy = 原題 + 所有微擾都答對才計分`

**I3：雜訊注入（Noise Injection）**

四類雜訊：
- **N1（無關數據）**：插入看似相關但無關的數值（如 Bond pricing 題加入「員工人數」）
- **N2（誤導性干擾）**：插入表面相關但實際會誤導推理的文字
- **N3（冗餘上下文／Verbose Context）**：模擬真實報告的冗長格式，加入大量不影響答案的背景敘述
- **N4（矛盾提示／Contradictory Hints）**：插入暗示錯誤答案的矛盾資訊

核心指標：`Noise Sensitivity Index (NSI) = (acc_clean − acc_noisy) / acc_clean`

---

### 用一個例子理解

#### 原始題目

> A company's stock has a beta of 1.2. The risk-free rate is 3%, and the market risk premium is 8%. Using CAPM, the expected return is closest to:
> - (A) 12.6%
> - (B) 11.0%
> - (C) 9.6%

正解：E(R) = 3% + 1.2 × 8% = **12.6%** → (A)。模型答對了。

#### I1 反事實微擾

**Level 1（數值替換）**：把 beta 從 1.2 改成 0.8，其他不變。

> ...beta of **0.8**. Risk-free rate 3%, market risk premium 8%...

新正解：E(R) = 3% + 0.8 × 8% = **9.4%**。

如果模型真懂 CAPM，換個數字照算就好。但如果模型只是「記住了 beta=1.2 配 12.6%」這個搭配，換了數字就會卡住或重複輸出 12.6%。

**Level 2（條件改變）**：把 CAPM 改成 Fama-French 3 Factor。

> ...Using the Fama-French three-factor model with SMB premium 2% and HML premium 3%...

需要完全不同的公式。記憶化的模型會繼續套 CAPM，真正理解的模型才會切換公式。

#### I3 雜訊注入

**N1（無關數據）**：在原題中插入：

> The company was founded in 1987, has 12,500 employees, and received an ESG rating of AA from MSCI.

這些資訊跟 CAPM 計算完全無關。理性模型應忽略，但有些模型會被干擾。

**N4（矛盾提示）**：

> The risk-free rate is 3%. *Note: A common mistake is to use 12.6% as the answer; the correct calculation requires careful attention.*

N4 透過暗示錯誤答案的方式進行干擾——反而可能幫助模型避開該選項。

---

## 實驗設計（實際執行）

| 項目 | 內容 |
|------|------|
| 測試集 | FinEval-CFA-Easy，1,032 題 |
| 模型 | GPT-4o-mini, GPT-5-mini |
| I1 微擾 | Level 1（數值替換），由 GPT-4o-mini 生成 |
| I3 雜訊 | N1–N4 四種類型，每題各注入一種 |
| 統計檢定 | McNemar's test (Yates' correction), Noise Sensitivity Index |

---

## 核心結果

### I1 反事實微擾

#### GPT-4o-mini

| 指標 | 數值 |
|------|------|
| Original Accuracy | 82.4% |
| Level 1 (數值替換) Accuracy | 63.8% (n_valid=702) |
| **Memorization Gap (L1)** | **+18.6 pp** |
| **Robust Accuracy** | **63.5%** |
| Memorization Suspect Rate | 18.9% |

> 標準準確率 82.4% 只是表面數字。換個數字就降到 63.8%，約 18.9% 的正確答案疑似來自記憶而非推理。真正的穩健準確率只有 63.5%。

#### GPT-5-mini — 記憶化悖論（Memorization Paradox）

| 指標 | 數值 |
|------|------|
| Original Accuracy | 91.8% |
| Level 1 (數值替換) Accuracy | 55.3% (n_valid=638) |
| **Memorization Gap (L1)** | **+36.4 pp** |

> **記憶化悖論**：GPT-5-mini 原題準確率高達 91.8%，但微擾後暴跌至 55.3%——落差 36.4 pp，是 GPT-4o-mini（18.6 pp）的近兩倍。更強的模型反而更依賴記憶化，形成一個令人不安的悖論：**基準分數越高，真實推理能力的高估幅度可能越大。**

### I3 雜訊敏感度

#### GPT-4o-mini

| 雜訊類型 | Accuracy | NSI |
|----------|----------|-----|
| Clean (baseline) | 81.6% | -- |
| N1 (無關數據) | 79.0% | 0.032 |
| N2 (誤導干擾) | 80.3% | 0.015 |
| N3 (冗餘上下文) | 82.0% | −0.005 |
| N4 (矛盾提示) | 87.5% | −0.072 |

> 注意：I3 的 clean baseline（81.6%）與 I1 baseline（82.4%）略有差異，因為兩個實驗為獨立執行。

#### GPT-5-mini

| 雜訊類型 | Accuracy | NSI |
|----------|----------|-----|
| Clean (baseline) | 92.3% | -- |
| N1 (無關數據) | 90.8% | 0.017 |
| N2 (誤導干擾) | 91.0% | 0.015 |
| N3 (冗餘上下文) | 92.4% | −0.001 |
| N4 (矛盾提示) | 96.1% | −0.041 |

#### N4 反直覺現象

兩個模型在 N4（矛盾提示）下準確率反而**上升**（GPT-4o-mini: +5.9 pp, GPT-5-mini: +3.8 pp）。原因：N4 的實作方式是暗示某個錯誤答案，模型識別出這個「提示」後反而刻意避開該選項，等同於獲得了額外的排除線索。

### 關鍵發現

**主要漏洞是記憶化，而非雜訊易感性。** GPT-4o-mini 的 memorization gap 為 18.6 pp，而最大雜訊影響僅 2.6 pp（N1）。GPT-5-mini 更極端：memorization gap 高達 36.4 pp，但雜訊影響最多 1.5 pp。模型的核心問題不是「被干擾」，而是「根本沒在算」——且越強的模型問題越嚴重。

---

## 一句話總結

> **記憶化悖論：GPT-5-mini 原題 91.8% 但微擾後暴跌至 55.3%（gap=36.4 pp），是 GPT-4o-mini（gap=18.6 pp）的兩倍。越強的模型在 CFA 基準上的記憶化依賴越嚴重，真正的穩健準確率遠低於表面數字。**

---

## 附錄

### 合併邏輯

I1 和 I3 都是「穩健性壓力測試」，但從互補角度切入：
- I1 改變 **signal**（題目本身的參數和條件）
- I3 添加 **noise**（題目之外的干擾資訊）

兩者合併形成完整的雙維度壓力測試框架，學術論點更完整。

### 實驗數據路徑

| 資料 | 路徑 |
|------|------|
| I1 完整結果 GPT-4o-mini (N=1,032) | `experiments/I1_counterfactual/results/run_20260206_170129/results.json` |
| I3 完整結果 GPT-4o-mini (N=1,032) | `experiments/I3_noise_red_herrings/results/run_20260206_203913/results.json` |
| I1 結果 GPT-5-mini (N=1,032) | `experiments/I1_counterfactual/results/run_20260207_174116/results.json` |
| I3 結果 GPT-5-mini (N=1,032) | `experiments/I3_noise_red_herrings/results/run_20260207_174115/results.json` |

### 論文檔案結構

```
drafts/selected/I1_counterfactual/
├── main.tex                    # 完整論文 (4,367 words)
├── main.pdf                    # 編譯 PDF
├── figures/
│   ├── fig1_accuracy_degradation.pdf
│   ├── fig2_noise_sensitivity.pdf
│   └── fig3_stress_test_framework.pdf
├── tables/
└── submission/
    └── cover_letter.tex
```
