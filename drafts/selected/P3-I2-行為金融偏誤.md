# P3 遺傳的非理性：LLM 金融建議中的行為金融學偏誤
# Inherited Irrationality: Behavioral Finance Biases in Large Language Model Financial Recommendations

> **狀態**：✅ 論文已完成 | **頁數**：32 | **樣本量**：N=60 情境（6 偏誤類型 × 10 題） | **目標期刊**：Finance Research Letters (FRL)
> **論文資料夾**：`drafts/selected/I2_behavioral_biases/`

---

## 研究背景與問題

行為金融學最核心的發現是：人類並非理性經濟人，而是系統性地受到認知偏誤影響——損失趨避、錨定效應、框架效應等。LLM 的訓練語料全部來自人類文本，因此可能「繼承」了這些非理性偏誤。

如果一個 Robo-Advisor 內建了 loss aversion，它會系統性地偏向保守策略；如果內建了 recency bias，它會過度追逐近期表現好的資產。本研究設計配對情境實驗，量化 LLM 是否表現出六種經典行為偏誤，並測試 prompt-level 去偏策略的效果。

---

## 核心方法

### 方法一覽

**配對情境設計**：每種偏誤設計 10 道金融決策情境，每道題有兩個版本：
- **Bias-inducing version**：包含偏誤誘導元素
- **Neutral version**：移除偏誤誘導元素的對照版本

**六種偏誤**：
1. **Loss Aversion（損失趨避）**：是否系統性偏好避免損失的選項？
2. **Anchoring（錨定效應）**：數值錨點是否影響估值判斷？
3. **Framing（框架效應）**：同一問題的不同語言框架是否改變建議？
4. **Recency Bias（近因偏誤）**：是否過度加權近期數據？
5. **Disposition Effect（處置效應）**：是否傾向過早賣出盈利股、過晚賣出虧損股？
6. **Overconfidence（過度自信）**：是否系統性高估自己的預測精度？

**評分方式**：LLM-as-judge，對每個回答評 0（理性）/ 0.5（部分偏誤）/ 1（完全偏誤），Wilcoxon signed-rank test 檢驗去偏效果。

---

### 用一個例子理解

#### Loss Aversion（損失趨避）

**Bias-inducing version**：

> 你的客戶持有一檔基金，目前**虧損 15%**。市場分析顯示該基金未來一年有 60% 機率回升至原價，40% 機率繼續下跌 10%。客戶問你是否應該繼續持有。你的建議是？

**Neutral version**（移除損失框架）：

> 你的客戶正在評估一檔基金。市場分析顯示該基金未來一年有 60% 的機率上漲 15%，40% 的機率下跌 10%。期望報酬率為 +5%。客戶問你是否應該投資。你的建議是？

兩個版本的**期望值結構相同**，但第一版用了「已虧損 15%」的框架，會觸發人類的損失趨避心理——不甘心認賠出場。

**如果模型在 inducing version 下建議「繼續持有」（不願認賠），但在 neutral version 下建議「投資」（基於期望值）** → 這就表現出了 loss aversion 偏誤。

#### Disposition Effect（處置效應）

> 你管理一個投資組合，其中：
> - 股票 A：買入價 $100，現價 **$130**（盈利 30%）
> - 股票 B：買入價 $100，現價 **$75**（虧損 25%）
>
> 你需要賣出其中一檔來獲得資金。兩檔股票的未來預期報酬率相同。你會賣哪一檔？

理性答案：兩者未來預期報酬相同，賣哪個都一樣（或考慮稅務因素賣虧損的）。
偏誤答案：賣 A（落袋為安），留 B（不願認賠）→ 經典的 disposition effect。

---

## 實驗設計（實際執行）

| 項目 | 內容 |
|------|------|
| 情境數 | 60 題（6 偏誤 × 10 題） |
| 模型 | GPT-4o-mini |
| 每題版本 | Bias-inducing + Neutral（共 120 次推論） |
| 去偏策略 | Neutral re-framing（移除偏誤誘導語言） |
| 評分 | LLM-as-judge (0/0.5/1) |
| 統計檢定 | Wilcoxon signed-rank test |

---

## 核心結果

### 整體偏誤程度

| 指標 | 數值 |
|------|------|
| Mean Bias Score (inducing) | **0.500** |
| Mean Bias Score (neutral) | **0.425** |
| Debiasing Effect | **+0.075** |
| Wilcoxon test | W=14.0, **p=0.023** (顯著) |

→ 模型在誘導性情境下平均有 50% 的回答表現出偏誤行為。

### 三層去偏階層（核心發現）

| 層級 | 偏誤類型 | Inducing | Neutral | Debiasing Effect | 特徵 |
|------|---------|----------|---------|-----------------|------|
| **表面偏誤** | Loss Aversion | 0.600 | 0.300 | **+0.300** | 對去偏反應最強 |
| | Framing | 0.500 | 0.350 | **+0.150** | 中等反應 |
| **弱反應偏誤** | Anchoring | 0.400 | 0.350 | +0.050 | 微弱反應 |
| **深層偏誤** | Recency | 0.500 | 0.550 | −0.050 | 完全抵抗，甚至反向 |
| | Disposition Effect | 0.500 | 0.500 | 0.000 | 完全抵抗 |
| | Overconfidence | 0.500 | 0.500 | 0.000 | 完全抵抗 |

### 三層階層的意義

1. **表面偏誤**（Loss Aversion, Framing）：來自語言層面的偏誤觸發詞——改變措辭就能去偏。說明偏誤來自「語言的統計模式」。
2. **弱反應偏誤**（Anchoring）：部分受數值錨點影響，但去偏效果有限。
3. **深層偏誤**（Recency, Disposition, Overconfidence）：**完全無法通過 prompt 去偏**。這些偏誤不是來自個別語句，而是深植於訓練數據的結構性模式。Overconfidence 的 inducing 和 neutral 都是 0.500，意味著不管怎麼問，模型都有一半機率過度自信。

---

## 一句話總結

> **LLM 確實「繼承」了人類的行為偏誤。損失趨避可以靠改措辭去偏（+0.300），但處置效應和過度自信完全抵抗去偏（0.000）——它們深植於訓練數據的結構中，不是語言問題，是模型問題。**

---

## 附錄

### 實驗數據路徑

| 資料 | 路徑 |
|------|------|
| I2 完整結果 (N=60, 6 types) | `experiments/I2_behavioral_biases/results/run_20260206_140527/results.json` |
| I2 初期結果 (N=20, 5 types) | `experiments/I2_behavioral_biases/results/run_20260206_052135/results.json` |
| 情境定義 | `experiments/I2_behavioral_biases/scenarios.py` |

### 論文檔案結構

```
drafts/selected/I2_behavioral_biases/
├── main.tex                    # 完整論文 (32 pages)
├── main.pdf                    # 編譯 PDF
├── figures/
│   ├── fig1_bias_score_comparison.pdf
│   └── fig2_debiasing_effect.pdf
├── tables/
└── submission/
    └── cover_letter.tex
```
