# 給繆老師的信 — 研究進度報告與會面邀約

> **寄件人**：程煒倫（博士班學生）
> **收件人**：繆維中 教授（指導教授）
> **副本**：張光第 副教授（共同指導教授）
> **日期**：2026 年 2 月

---

## 信件草稿

繆老師您好，

好久沒跟老師報告進度了，非常抱歉。這段時間我一直在進行 LLM（大型語言模型）應用於金融推理的實證研究，目前已經完成了 **7 篇可投稿論文**的初稿，全部瞄準 **Finance Research Letters (FRL)** 等級的期刊。

因為研究進展到了需要跟老師討論的階段，想跟老師約個時間當面聊聊，主要想討論：

1. **研究方向與論文內容**：7 篇論文各自在做什麼、學術貢獻在哪裡
2. **發表規劃**：投稿順序、目標期刊、時程安排
3. **資格考**：以論文發表過資格考的可行性與時間點
4. **鴻海研究院合作掛名**：我目前在鴻海研究院工作，想討論是否合適在論文中加入鴻海研究院的 affiliation 或致謝

不知道老師 **下週二（2/10）或週三（2/11）** 是否方便撥個時間？大約需要 30–40 分鐘。以下先附上研究概要，讓老師先有個 big picture。

煒倫 敬上

---

## 研究概要：LLM 金融推理能力的系統性評估

### 一句話總結

> 我用 CFA（特許金融分析師）考題作為標準化測試平台，從 **7 個不同角度** 系統性地拆解 LLM 在金融推理上的能力與缺陷，產出 7 篇獨立但互補的實證論文。

### 為什麼這個研究重要？

金融業正大規模導入 LLM（GPT-4o、GPT-5 等）輔助投資決策、風險評估、合規審查。但學術界對 LLM 金融推理能力的評估存在三個根本問題：

1. **評估方法有偏差**：現有基準幾乎全用選擇題（MCQ），但選項本身會洩漏線索，導致分數虛高
2. **穩健性未經檢驗**：把題目稍微改寫、加點干擾，準確率就可能暴跌——這對實際部署是致命的
3. **失敗模式不明**：我們知道 LLM 會犯錯，但不知道「錯在哪」「為什麼錯」「能不能修」

我的 7 篇論文分別從不同面向回答這些問題。

---

### 七篇論文一覽

| # | 簡稱 | 核心問題 | 方法學創新 |
|---|------|---------|-----------|
| P1 | 選項偏差 | 選擇題格式讓 LLM 分數灌了多少水？ | 配對實驗 + McNemar 統計檢定 |
| P2 | 壓力測試 | 把題目改寫後 LLM 還答得對嗎？ | 反事實微擾 + 雜訊注入 |
| P3 | 行為偏誤 | LLM 會像人一樣有損失趨避、錨定效應嗎？ | 6 種認知偏誤的控制實驗 |
| P4 | 道德韌性 | 施加情緒/利益壓力，LLM 的道德判斷會動搖嗎？ | 5 種對抗式壓力情境 |
| P5 | 錯誤圖譜 | LLM 金融推理的「錯誤地圖」長什麼樣？ | 三維錯誤分類法 + 黃金上下文注入 |
| P6 | 信心校準 | LLM 說「我 90% 確定」的時候，真的有 90% 準嗎？ | ECE 校準曲線 + 高信心錯誤風險分析 |
| P7 | 訊號理論 | 當 AI 能考過 CFA，CFA 證照的「訊號價值」會怎樣？ | 修改版 Spence 訊號模型 |

---

### 各篇論文詳細說明

#### P1：選項偏差與開放式評估（A1+A5）
**Beyond Multiple Choice: How Answer Options Inflate LLM Financial Reasoning Scores**

- **問題**：CFA 選擇題的選項會洩漏答案方向（例如三個選項都在 $900–$1,100 之間），LLM 不需要真正計算就能猜到合理範圍
- **方法**：同一組 1,032 題 CFA 題目，分別以「有選項」和「無選項」兩種格式測試同一模型，用 McNemar's test 檢定配對差異
- **關鍵發現**：
  - GPT-4o-mini：有選項 82.6% → 無選項 80.6%，差距僅 +1.9pp（p=0.251，不顯著）
  - **GPT-5-mini：有選項 92.8% → 無選項 83.2%，差距 +9.6pp（p<0.001，高度顯著）**
  - 這證明選項偏差不是固定的格式屬性，而是**模型依賴的**——更強的模型反而更依賴選項線索
- **學術意義**：挑戰了金融 AI 基準評估的有效性。如果高分只是因為選項在「提示」答案，那現有排行榜的意義就要重新審視

#### P2：反事實壓力測試與雜訊敏感度（I1+I3）
**Stress Testing Financial LLMs: Counterfactual Perturbation and Noise Sensitivity Analysis**

- **問題**：LLM 答對一道 CFA 題，是真的「理解」還是只是「記住」了訓練資料裡的答案？
- **方法**：
  - **反事實微擾（I1）**：修改題目的關鍵數值（如利率從 5% 改成 7%），看模型能否跟著調整答案
  - **雜訊注入（I3）**：在題目中加入 4 種干擾（冗餘資訊、矛盾暗示等），測試抗噪能力
- **關鍵發現**：
  - GPT-4o-mini：原題 82.4% → 微擾後 63.8%，記憶落差 18.6pp
  - **GPT-5-mini：原題 91.8% → 微擾後 55.3%，記憶落差 36.4pp（「記憶悖論」）**
  - 更強的模型在原題表現更好，但微擾後反而跌得更慘——暗示它更依賴記憶而非推理
- **學術意義**：提出「Memorization Paradox」概念，對 LLM 金融推理的可靠性提出根本質疑。監管機構在審批 AI 投資顧問時需要考慮這種脆弱性

#### P3：行為金融偏誤（I2）
**Inherited Irrationality: Behavioral Finance Biases in LLM Financial Recommendations**

- **問題**：行為金融學發現人類有各種認知偏誤（損失趨避、錨定效應等），LLM 是否也「繼承」了這些偏誤？
- **方法**：設計 60 個金融情境（6 種偏誤 × 10 題），每題設計「理性答案」和「偏誤答案」，測試 LLM 的選擇傾向。然後用三層去偏（zero-shot → few-shot → structured）測試偏誤的可消除性
- **關鍵發現**：
  - 平均偏誤分數 0.500（1.0 = 完全偏誤，0.0 = 完全理性），顯著高於理性基線
  - **損失趨避（0.700）和錨定效應（0.633）最頑固**，即使用最強的結構化去偏也降不了太多
  - 去偏效果整體顯著（Wilcoxon p=0.023, r=0.284），但效果分層：有些偏誤容易消除，有些根深蒂固
- **學術意義**：首次系統性證明 LLM 從訓練資料中「繼承」了人類的認知偏誤。這對 robo-advisory（智能投顧）的監管設計有直接影響

#### P4：對抗式道德測試（D6）
**Under Pressure: Adversarial Stress Testing of LLM Ethical Judgment in Financial Decision-Making**

- **問題**：LLM 在金融情境中的道德判斷，能否承受刻意施加的壓力？
- **方法**：從 CFA 道德與職業標準題中篩選 47 題，設計 5 種壓力情境（利益誘惑、情緒操控、道德兩難、框架重述、權威壓力），測試模型是否會改變原本正確的答案
- **關鍵發現**：
  - GPT-4o-mini：14 次道德翻轉（14/235 = 6.0%），情緒操控和框架重述最有效
  - **GPT-5-mini：0 次翻轉，完全免疫，且壓力情境下準確率反而微幅上升（ERS > 1.0）**
  - 呈現明顯的世代差異：新一代模型的道德對齊（alignment）有質的飛躍
- **學術意義**：為金融 AI 的道德韌性提供量化評估框架。GPT-5-mini 的「完全免疫」結果對 AI 治理和合規設計是重要參考。我們已在論文中主動討論了「零翻轉是否太完美——是否為資料洩露」的質疑，提供三項反駁論點（對抗式 prompt 是全新的、ERS>1.0 與單純記憶不一致、標準準確率非 100%）

#### P5：錯誤圖譜（E1）
**The CFA Error Atlas: Mapping Failure Modes of LLMs in Financial Reasoning**

- **問題**：LLM 在 CFA 題目上犯的 557 個錯誤，能不能系統性地分類？錯誤是「知識不足」還是「推理能力不足」？
- **方法**：建立三維錯誤分類法（8 種錯誤類型 × 10 個 CFA 主題 × 5 個認知階段），再用 **Golden Context Injection (GCI)**——把正確的金融概念直接餵給模型，看錯誤能不能修復
- **關鍵發現**：
  - 概念性錯誤佔 68.8%，遠超計算錯誤（1.4%）——模型的問題是「不知道該用哪個公式」而非「算錯」
  - GCI 修復率：GPT-4o-mini 82.4%、GPT-5-mini 88.3%
  - **大多數錯誤是「知識缺口」而非「推理能力缺陷」**——給對的前提，模型就能推對
- **學術意義**：提出可操作的錯誤診斷框架。GCI 的高修復率暗示 RAG（檢索增強生成）在金融領域有巨大潛力。同時從金融理論角度連結 **效率市場假說 (EMH)**：當 AI 顧問系統成為邊際定價者，這些系統性（非隨機）的概念錯誤將威脅半強式市場效率

#### P6：信心校準與過度自信風險（D1+D4）
**When AI Is Confidently Wrong: Calibration and Risk Analysis of LLMs in Financial Decision-Making**

- **問題**：LLM 表達的信心程度跟實際準確率有多大落差？「高信心但答錯」的情況有多危險？
- **方法**：讓模型對每個答案附上 0–100% 的信心分數，繪製校準曲線（calibration curve），計算 ECE（Expected Calibration Error），重點分析信心 ≥ 80% 但答錯的「過度自信」案例
- **關鍵發現**：
  - GPT-4o-mini ECE = 0.315（嚴重偏離完美校準），系統性高估自身準確率 22–32%
  - **信心 ≥ 80% 的回答中，30.0% 是錯的**；反過來，所有錯誤中 66.4% 帶有高信心
  - 跨模型比較（Qwen3:32b）顯示過度自信是 LLM 的普遍問題，非單一模型特性
- **學術意義**：直接回應監管機構的核心關切——如果 AI 給出自信滿滿但錯誤的投資建議，後果遠比「我不確定」嚴重。為 AI 金融產品的風險披露提供實證基礎

#### P7：訊號理論 — CFA 證照的價值會被 AI 侵蝕嗎？（G2）
**The Certification Signal Erosion Hypothesis: A Modified Spence Model for AI-Disrupted Professional Credentialing**

- **問題**：如果 AI 能輕鬆通過 CFA 考試，那 CFA 證照作為「專業能力信號」的價值會怎樣？
- **方法**：修改 Spence (1973) 的經典勞動市場訊號模型，引入 AI 作為第三類參與者，推導均衡條件。用 P1 的 A5 實驗數據作為實證支撐
- **關鍵發現**：
  - 定義 Signal Retention Ratio R = （無選項準確率）/（有選項準確率），R < 1 代表訊號被侵蝕
  - GPT-4o-mini R = 0.976（接近 1，訊號幾乎未受影響）
  - **GPT-5-mini R = 0.897（訊號開始明顯侵蝕）**
  - AI 在 CFA 中的能力是分層的：程序性知識（公式套用）→ 已被取代；判斷性知識（情境分析）→ 部分保留
- **學術意義**：用 40 年歷史的訊號理論框架回應當前 AI 對專業證照體系的衝擊，理論與實證結合。對 CFA Institute 和金融監管機構的考試制度設計有直接政策意涵

---

### 研究的整體學術貢獻

1. **方法論創新**：提出多套可重複使用的 LLM 金融能力評估框架（反事實微擾、GCI 診斷、對抗式壓力測試等），其他研究者可以直接套用到不同模型或不同金融考試
2. **實證規模**：以 CFA-Easy 1,032 題為主要測試集，搭配 GPT-4o-mini 和 GPT-5-mini 兩代模型，兼顧統計效力與跨模型泛化
3. **政策相關性**：每篇論文都直接回應金融監管和 AI 治理的實際問題（AI 投顧的可靠性、過度自信風險、道德韌性、證照制度的未來）
4. **互補性**：7 篇論文涵蓋「能力」「穩健性」「偏誤」「道德」「校準」「錯誤診斷」「制度影響」7 個維度，合在一起構成對 LLM 金融推理能力最全面的評估

---

### 模擬審稿結果

我們用 LLM 模擬了一輪 peer review，以提前找出論文的弱點並修正。結果摘要：

| 論文 | 模擬評分 | 模擬決定 | 主要意見 | 回應 |
|------|---------|---------|---------|------|
| P7 訊號理論 | 92 | Accept | 理論貢獻卓越 | 無需修改 |
| P2 壓力測試 | 88 | Accept | 方法論嚴謹 | 無需修改 |
| P1 選項偏差 | 85 | Minor Revisions | 需更多機制解釋 | ✅ 已補充排除法機制 |
| P6 信心校準 | 75 | R&R | 樣本量不足 | 已回覆：CFA-Challenge 的選用有方法論理由 |
| P5 錯誤圖譜 | 70 | Transfer | 缺金融理論 | ✅ 已補充 EMH 連結 |
| P3 行為偏誤 | 65 | R&R | 樣本量不足 | 已回覆：效果量 r=0.284 具統計檢定力 |
| P4 道德韌性 | 60 | Reject | N=47 + 零翻轉過完美 | ✅ 已補充 data contamination 討論 |

根據模擬結果，P7、P2、P1 是最具投稿競爭力的三篇。P4–P6 的弱點已盡可能在文本中補強，但可能需要跟老師討論是否值得擴充實驗。

---

### 待討論事項

1. **投稿順序**：根據模擬審稿評分，建議先投 **P7（92 分，訊號理論，理論貢獻最深）** 和 **P2（88 分，壓力測試，Memorization Paradox 最新穎）**，然後是 P1（85 分，選項偏差 p<0.001 統計最強）
2. **鴻海研究院**：
   - 方案 A：在 affiliation 中加入鴻海研究院作為第二機構
   - 方案 B：僅在 acknowledgment 中致謝鴻海研究院提供算力或研究支持
   - 需要老師判斷哪個方案比較合適，以及是否需要鴻海那邊的正式同意
3. **資格考**：目前 7 篇論文若能發表 2–3 篇，是否足以申請以論文過資格考？時間點如何規劃？
4. **共同作者排序**：目前設定為 Wei-Lun Cheng（第一作者）、Daniel Wei-Chung Miao（通訊作者）、Guang-Di Chang（共同指導），老師覺得是否合適？

---

### 技術細節（供老師參考）

- **資料集**：CFA-Easy（1,032 題），來源為 Salesforce AI Research 的 FinDAP 資料集（EMNLP 2025 Oral），非 CFA Institute 官方考題
- **模型**：主要用 GPT-4o-mini（OpenAI）和 GPT-5-mini（OpenAI 最新推理模型），部分實驗含 Qwen3:32b（阿里雲開源模型）
- **統計方法**：McNemar's test（配對分類比較）、Wilcoxon signed-rank test（非參數檢定）、Expected Calibration Error（校準度量）、Noise Sensitivity Index（自定義指標）
- **目標期刊**：Finance Research Letters（SSCI Q1，IF ≈ 10.4，FRL 接受 short papers 約 3,500–4,500 字）
- **程式碼與數據**：全部實驗程式碼與原始輸出已整理完成，可重現所有結果
