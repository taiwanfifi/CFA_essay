% Finance Research Letters â€” Elsevier Template
% E1: CFA Error Pattern Atlas
\documentclass[preprint,12pt]{elsarticle}

\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{multirow}
\usepackage{threeparttable}
\usepackage{float}

\journal{Finance Research Letters}

\begin{document}

\begin{frontmatter}

\title{The CFA Error Atlas: Mapping Failure Modes of Large Language Models in Financial Reasoning}

\author[ntust]{Wei-Lun Cheng}
\ead{d11018003@mail.ntust.edu.tw}

\author[ntust]{Daniel Wei-Chung Miao\corref{cor1}}
\ead{miao@mail.ntust.edu.tw}
\cortext[cor1]{Corresponding author}

\author[ntust]{Guang-Di Chang}
\ead{gchang@mail.ntust.edu.tw}

\affiliation[ntust]{organization={Graduate Institute of Finance, National Taiwan University of Science and Technology},
            city={Taipei},
            postcode={10607},
            country={Taiwan}}

\begin{abstract}
When Large Language Models (LLMs) fail on financial reasoning tasks, these failures are not random---they exhibit systematic patterns that reflect specific cognitive limitations. We present the \textit{CFA Error Atlas}, a taxonomy of LLM errors derived from 557 incorrect responses out of 1,032 CFA (Chartered Financial Analyst) examination questions answered in open-ended format. Using a three-level grading rubric (exact match, directionally correct, incorrect), we find that GPT-4o-mini achieves only 24.5\% exact accuracy while 54.0\% of responses are outright incorrect. Error classification of the 557 failures reveals that \textbf{conceptual errors} dominate overwhelmingly (68.8\%), followed by incomplete reasoning (10.8\%) and assumption errors (10.6\%), while pure calculation errors account for a mere 1.4\%. A \textit{Golden Context Injection} (GCI) experiment---re-prompting the model with correct financial concepts---reveals that 82.4\% of errors respond to concept hints (knowledge gaps amenable to retrieval augmentation), while 17.6\% persist even with correct context (true reasoning gaps requiring fine-tuning). A cross-model GCI replication with GPT-5-mini demonstrates that the reasoning model nearly doubles the full recovery rate (\textbf{50.4\%} vs.\ 25.5\%) and reduces the true reasoning gap to \textbf{11.7\%}, suggesting that extended chain-of-thought reasoning substantially improves concept \textit{execution} once the correct concept is provided. These findings challenge the narrative that financial AI needs ``better math'' and redirect attention to the more fundamental challenge of concept selection and problem framing.
\end{abstract}

\begin{keyword}
Large Language Models \sep Error Analysis \sep Financial Reasoning \sep CFA Examination \sep Error Taxonomy \sep Failure Modes
\end{keyword}

\end{frontmatter}

%% ============================================
%% 1. INTRODUCTION
%% ============================================
\section{Introduction}
\label{sec:intro}

The growing deployment of Large Language Models (LLMs) in financial applications has motivated extensive benchmarking on professional examinations \citep{callanan2023gpt, ke2025findap}. These evaluations universally report \textit{accuracy}: the fraction of questions answered correctly. However, accuracy tells us nothing about \textit{how} models fail---and in financial applications, the nature of failure matters as much as its frequency.

Consider two models, both achieving 60\% accuracy on CFA questions. Model A's errors are predominantly arithmetic mistakes (correct formula, wrong calculation), while Model B's errors are predominantly conceptual misunderstandings (wrong financial model applied). Model A's errors are more amenable to computational tool augmentation; Model B requires fundamental knowledge improvement. Current benchmark reporting obscures this distinction entirely.

This paper presents the \textit{CFA Error Atlas}: a systematic taxonomy of LLM failure modes on financial reasoning tasks. We evaluate GPT-4o-mini on 1,032 CFA-Easy questions in open-ended (non-MCQ) format, applying a three-level grading rubric (Level~A: exact match, Level~B: directionally correct, Level~C: incorrect). Of the 557 Level~C responses, each error is classified along three dimensions:
\begin{enumerate}
    \item \textbf{Error type}: What kind of mistake? (7 categories)
    \item \textbf{CFA topic}: Which financial domain? (8 knowledge areas)
    \item \textbf{Cognitive stage}: At which point in the reasoning process? (5 stages)
\end{enumerate}

Our contributions are fourfold:
\begin{enumerate}
    \item We provide the first systematic error taxonomy for financial LLMs at scale ($N = 1{,}032$), revealing that conceptual errors (68.8\%) dominate over calculation errors (1.4\%).
    \item We demonstrate dramatic topic-dependent error profiles: Ethics failures are reasoning-based while Derivatives failures are computation-based.
    \item We introduce \textit{Golden Context Injection} to distinguish knowledge gaps (82.4\% of errors, amenable to RAG) from reasoning gaps (17.6\%, requiring fine-tuning).
    \item We identify concept identification as the primary cognitive bottleneck, reframing financial AI improvement from ``better arithmetic'' to ``better concept selection.''
\end{enumerate}

%% ============================================
%% 2. METHODOLOGY
%% ============================================
\section{Methodology}
\label{sec:method}

\subsection{Data Collection}

We use all 1,032 questions from the CFA-Easy dataset \citep{ke2025findap}. Each question is converted from multiple-choice to open-ended format by removing answer options, forcing GPT-4o-mini to generate a free-form response with full reasoning traces. Responses are graded on a three-level rubric:
\begin{itemize}
    \item \textbf{Level A (Exact)}: Answer matches within numerical tolerance ($\pm2\%$) or exact semantic match---253 responses (24.5\%).
    \item \textbf{Level B (Directional)}: Correct direction or approach but different assumptions or magnitude---222 responses (21.5\%).
    \item \textbf{Level C (Incorrect)}: Wrong answer---557 responses (54.0\%).
\end{itemize}
All 557 Level~C responses are collected with full reasoning traces for error classification.

\subsection{Three-Dimensional Error Taxonomy}

\textbf{Dimension 1 --- Error Type (7 categories):}
\begin{itemize}
    \item \texttt{conceptual\_error}: Misunderstands the financial concept being tested
    \item \texttt{incomplete\_reasoning}: Correct approach but stops before reaching the final answer
    \item \texttt{assumption\_error}: Wrong assumptions about compounding, timing, or other parameters
    \item \texttt{reading\_error}: Misreads the question stem or key numerical values
    \item \texttt{arithmetic\_error}: Correct formula but computational mistake
    \item \texttt{formula\_error}: Selected the wrong formula or financial model
    \item \texttt{unknown}: Error cannot be reliably classified
\end{itemize}

\textbf{Dimension 2 --- CFA Topic:} Ethics, Fixed Income, Economics, Portfolio Management, Wealth Planning, Derivatives, Alternative Investments, Equity.

\textbf{Dimension 3 --- Cognitive Stage:} Identify (concept recognition), Recall (formula/rule retrieval), Calculate (numerical computation), Verify (answer checking), Unknown.

\subsection{Automated Classification}

GPT-4o-mini serves as the error classifier, receiving the question, the model's incorrect response (with full reasoning trace), and the correct answer, then outputting the three-dimensional classification.

%% ============================================
%% 3. RESULTS
%% ============================================
\section{Results}
\label{sec:results}

\subsection{Three-Level Grading Distribution}

Before analyzing errors, Table~\ref{tab:grading} reports the overall grading distribution across all 1,032 questions.

\begin{table}[htbp]
\centering
\caption{Three-Level Grading Distribution ($N = 1{,}032$)}
\label{tab:grading}
\begin{tabular}{llrr}
\toprule
\textbf{Level} & \textbf{Description} & \textbf{Count} & \textbf{\%} \\
\midrule
Level A & Exact match & 253 & 24.5\% \\
Level B & Directionally correct & 222 & 21.5\% \\
Level C & Incorrect & 557 & 54.0\% \\
\bottomrule
\end{tabular}
\end{table}

Over half of GPT-4o-mini's responses are outright incorrect when the multiple-choice scaffold is removed. Only one in four answers achieves exact numerical or semantic match, highlighting the substantial gap between MCQ performance (where option recognition can substitute for genuine reasoning) and open-ended competence.

\subsection{Error Type Distribution}

Table~\ref{tab:errortype} presents the error type distribution across all 557 Level~C errors.

\begin{table}[htbp]
\centering
\caption{Error Type Distribution ($N = 557$)}
\label{tab:errortype}
\begin{tabular}{lrrl}
\toprule
\textbf{Error Type} & \textbf{Count} & \textbf{\%} & \textbf{Category} \\
\midrule
Conceptual error & 383 & 68.8\% & Reasoning \\
Incomplete reasoning & 60 & 10.8\% & Reasoning \\
Assumption error & 59 & 10.6\% & Reasoning \\
Unknown & 35 & 6.3\% & --- \\
Reading error & 12 & 2.2\% & Extraction \\
Arithmetic error & 7 & 1.3\% & Calculation \\
Formula error & 1 & 0.2\% & Calculation \\
\midrule
\multicolumn{4}{l}{\textbf{Aggregated:} Reasoning 90.1\%, Extraction 2.2\%, Calculation 1.4\%, Unknown 6.3\%} \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.85\textwidth]{figures/fig1_error_type_distribution.pdf}
\caption{Distribution of 557 LLM errors across seven error types, color-coded by aggregate category (Reasoning, Calculation, Extraction). Conceptual errors alone account for over two-thirds of all failures, underscoring that fundamental misunderstanding of financial concepts---rather than computational mistakes---is the dominant failure mode.}
\label{fig:errortype}
\end{figure}

\textbf{Key finding}: As visualized in Figure~\ref{fig:errortype}, reasoning errors dominate overwhelmingly (90.1\%), dwarfing calculation errors (1.4\%). The primary failure mode is not ``can't compute'' but ``doesn't understand the concept.'' Conceptual errors alone (68.8\%) exceed all other categories combined. This has direct implications for remediation: calculator tools and formula retrieval won't help when the fundamental financial concept is misunderstood.

\subsection{Topic-Level Error Profiles}

To examine whether error profiles differ across financial domains, we further classify each of the 557 errors by CFA knowledge area. Table~\ref{tab:topicerror} presents the distribution from a pilot subsample ($n = 229$) annotated across all three dimensions.\footnote{Topic-level annotation for the full $N = 557$ sample is ongoing. The pilot subsample was drawn from 90 CFA-Challenge questions evaluated across five reasoning methods; see Section~\ref{sec:discussion} for discussion of generalizability.}

\begin{table}[htbp]
\centering
\caption{Error Distribution by CFA Topic (Pilot Subsample, $n = 229$)}
\label{tab:topicerror}
\begin{threeparttable}
\begin{tabular}{lrccc}
\toprule
\textbf{Topic} & \textbf{n} & \textbf{Reasoning\%} & \textbf{Calculation\%} & \textbf{Other\%} \\
\midrule
Ethics & 70 & 87.1\% & 0.0\% & 12.9\% \\
Portfolio Mgmt & 45 & 62.2\% & 17.8\% & 20.0\% \\
Fixed Income & 35 & 34.3\% & 25.7\% & 40.0\% \\
Wealth Planning & 27 & 81.5\% & 3.7\% & 14.8\% \\
Derivatives & 24 & 41.7\% & 37.5\% & 20.8\% \\
Economics & 17 & 35.3\% & 5.9\% & 58.8\% \\
Alternatives & 7 & 100.0\% & 0.0\% & 0.0\% \\
Equity & 4 & 25.0\% & 25.0\% & 50.0\% \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item Reasoning = conceptual + assumption + incomplete reasoning; Calculation = formula + arithmetic; Other = reading, unknown, and selection errors.
\end{tablenotes}
\end{threeparttable}
\end{table}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.85\textwidth]{figures/fig2_topic_error_profile.pdf}
\caption{Grouped bar chart comparing the proportion of Reasoning, Calculation, and Other errors across eight CFA knowledge domains. The stark contrast between Ethics (87.1\% reasoning) and Derivatives (37.5\% calculation) demonstrates that error profiles are topic-dependent, implying that different financial domains require fundamentally different remediation strategies.}
\label{fig:topicerror}
\end{figure}

Even in the pilot subsample, the error profiles are strikingly different:
\begin{itemize}
    \item \textbf{Ethics} (87.1\% reasoning errors): The model fails by starting from wrong ethical premises---misidentifying which CFA Standard applies or misinterpreting the ethical dilemma. Calculation is irrelevant for Ethics.
    \item \textbf{Derivatives} (37.5\% calculation errors): The highest calculation error rate among all topics, reflecting the mathematical complexity of options pricing and hedging calculations.
    \item \textbf{Economics} (58.8\% other errors): Dominated by reading and selection-type errors, suggesting the model understands broad concepts but struggles to extract the correct parameters or differentiate between similar outcomes.
    \item \textbf{Fixed Income} (balanced): A near-even split between reasoning, calculation, and other errors, reflecting the topic's blend of conceptual understanding and quantitative computation.
\end{itemize}

\subsection{Cognitive Stage Analysis}

The error type distribution from the full-scale study directly implies which cognitive stage fails. Mapping the 557 errors to cognitive stages via the correspondence between error types and processing stages (conceptual errors $\to$ Identify; assumption and incomplete reasoning $\to$ Recall/Verify; reading errors $\to$ Extract; arithmetic and formula errors $\to$ Calculate), we estimate the stage-level breakdown in Table~\ref{tab:cognitive}.

\begin{table}[htbp]
\centering
\caption{Estimated Cognitive Stage Distribution ($N = 557$)}
\label{tab:cognitive}
\begin{tabular}{lrr}
\toprule
\textbf{Cognitive Stage} & \textbf{Count} & \textbf{\%} \\
\midrule
Identify (concept recognition) & 383 & 68.8\% \\
Recall / Verify (reasoning chain) & 119 & 21.4\% \\
Extract (reading comprehension) & 12 & 2.2\% \\
Calculate (computation) & 8 & 1.4\% \\
Unknown & 35 & 6.3\% \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.85\textwidth]{figures/fig3_cognitive_stages.pdf}
\caption{Estimated error distribution across cognitive processing stages ($N = 557$). The Identify stage (concept recognition) accounts for 68.8\% of all errors, revealing that the primary bottleneck in LLM financial reasoning occurs at the earliest stage of problem solving---selecting the appropriate financial concept or framework---rather than at downstream computation or verification stages.}
\label{fig:cognitive}
\end{figure}

\textbf{Key finding}: As shown in Figure~\ref{fig:cognitive}, the Identify stage---where the model must recognize which financial concept, formula, or framework applies to the given problem---accounts for over two-thirds of all errors. This is the ``upstream'' stage: if concept identification fails, all subsequent reasoning is built on a wrong foundation. The Calculate stage accounts for only 1.4\% of errors, confirming that modern LLMs are reasonably competent at arithmetic when given the right formula.

\subsection{Golden Context Injection: Knowledge Gap vs. Reasoning Gap}

To determine whether errors represent \textit{knowledge gaps} (fixable via retrieval augmentation) or \textit{reasoning gaps} (requiring architectural improvement), we apply \textit{Golden Context Injection} (GCI): for each of the 557 Level~C errors, we re-prompt the model with the correct financial concept or formula as an explicit hint, then evaluate whether the model recovers the correct answer.

\begin{table}[htbp]
\centering
\caption{Golden Context Injection Results ($N = 557$ errors)}
\label{tab:gci}
\begin{tabular}{lrr}
\toprule
\textbf{Recovery Level} & \textbf{Count} & \textbf{\%} \\
\midrule
Full recovery (Level A) & 142 & 25.5\% \\
Partial recovery (Level B) & 317 & 56.9\% \\
Still wrong (Level C) & 98 & 17.6\% \\
\midrule
\textbf{Any recovery (A+B)} & \textbf{459} & \textbf{82.4\%} \\
\bottomrule
\end{tabular}
\end{table}

Table~\ref{tab:gci} reveals that 82.4\% of errors respond to golden context injection, suggesting that the majority of failures are \textit{knowledge gaps}---the model fails because it selects the wrong concept, not because it cannot reason. However, only 25.5\% achieve full recovery; most improvements are partial (56.9\%), indicating that even with the correct concept provided, the model often struggles with precise execution.

\begin{table}[htbp]
\centering
\caption{GCI Recovery by Error Category}
\label{tab:gci_category}
\begin{tabular}{lrccc}
\toprule
\textbf{Error Type} & \textbf{$n$} & \textbf{Full\%} & \textbf{Partial\%} & \textbf{None\%} \\
\midrule
Conceptual & 383 & 26.1\% & 58.2\% & 15.7\% \\
Incomplete reasoning & 60 & 20.0\% & 56.7\% & 23.3\% \\
Assumption & 59 & 20.3\% & 61.0\% & 18.6\% \\
Arithmetic & 7 & 57.1\% & 14.3\% & 28.6\% \\
Reading & 12 & 16.7\% & 58.3\% & 25.0\% \\
\bottomrule
\end{tabular}
\end{table}

Table~\ref{tab:gci_category} disaggregates recovery by error type. Arithmetic errors show the highest full recovery rate (57.1\%)---when given the right formula, the model can usually compute correctly. Conceptual errors, despite dominating in volume, recover at 84.3\% (any level), confirming that concept selection is the primary bottleneck: provide the right concept, and the model can often reason from there. Incomplete reasoning errors are the most resistant to full recovery (20.0\%), suggesting that truncated reasoning chains reflect a deeper processing limitation rather than a simple knowledge deficit. Figure~\ref{fig:gci} visualizes the recovery profile across error categories.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.85\textwidth]{figures/fig4_gci_recovery.pdf}
\caption{Golden Context Injection recovery rates by error category ($N = 557$ errors). Stacked bars show full recovery (correct answer), partial recovery (directionally correct), and still wrong. Arithmetic errors have the highest full recovery rate (57.1\%), while conceptual errors---the dominant error type---show the highest overall recovery (84.3\%), confirming that most failures are knowledge gaps rather than reasoning gaps.}
\label{fig:gci}
\end{figure}

These findings have direct implications for remediation strategy. The 82.4\% recovery rate establishes a ceiling for retrieval-augmented generation (RAG) interventions: a well-designed RAG system that reliably retrieves the correct financial concept could potentially recover most errors. However, the 17.6\% residual rate---the \textit{true reasoning gap}---requires training-time interventions such as fine-tuning on step-by-step financial reasoning traces.

\subsection{Cross-Model GCI: Extended Reasoning Amplifies Recovery}
\label{sec:crossmodel_gci}

To assess whether the knowledge-gap vs.\ reasoning-gap distinction is model-dependent, we replicated the GCI experiment using GPT-5-mini, a next-generation reasoning model that employs extended chain-of-thought (``thinking tokens'') before generating its answer. GPT-5-mini was prompted with identical golden context hints on the same 557 errors originally produced by GPT-4o-mini.\footnote{We deliberately test GPT-5-mini's ability to recover GPT-4o-mini's errors, rather than GPT-5-mini's own errors, to hold the error set constant across models. This cross-model GCI design tests whether a more capable model can recover errors that a weaker model cannot, given the same conceptual hint.}

\begin{table}[htbp]
\centering
\caption{Cross-Model GCI Recovery Comparison ($N = 557$ GPT-4o-mini errors)}
\label{tab:gci_cross}
\begin{tabular}{lccccc}
\toprule
& \multicolumn{2}{c}{\textbf{GPT-4o-mini}} & \multicolumn{2}{c}{\textbf{GPT-5-mini}} & \textbf{$\Delta$} \\
\cmidrule(lr){2-3} \cmidrule(lr){4-5}
\textbf{Recovery Level} & Count & \% & Count & \% & pp \\
\midrule
Full recovery (A) & 142 & 25.5\% & 281 & 50.4\% & +24.9 \\
Partial recovery (B) & 317 & 56.9\% & 211 & 37.9\% & $-$19.0 \\
Still wrong (C) & 98 & 17.6\% & 65 & 11.7\% & $-$5.9 \\
\midrule
\textbf{Any recovery (A+B)} & 459 & \textbf{82.4\%} & 492 & \textbf{88.3\%} & +5.9 \\
\bottomrule
\end{tabular}
\end{table}

Figure~\ref{fig:gci_cross} and Table~\ref{tab:gci_cross} reveal a striking pattern: GPT-5-mini nearly doubles the full recovery rate (50.4\% vs.\ 25.5\%) while the partial recovery rate decreases (37.9\% vs.\ 56.9\%).

\begin{figure}[htbp]
\centering
\includegraphics[width=0.85\textwidth]{figures/fig5_cross_model_gci.pdf}
\caption{Cross-model Golden Context Injection recovery ($N = 557$ errors). GPT-5-mini nearly doubles the full recovery rate (50.4\% vs.\ 25.5\%) while reducing the true reasoning gap from 17.6\% to 11.7\%. Extended chain-of-thought reasoning improves concept \textit{execution}, not just concept \textit{recognition}.}
\label{fig:gci_cross}
\end{figure} The total recovery rate improves modestly (88.3\% vs.\ 82.4\%). This means GPT-5-mini's primary advantage is not recovering \textit{more} errors but recovering them \textit{more completely}---converting partial recoveries into full recoveries through more precise execution. The extended chain-of-thought reasoning enables the model to follow through on the provided concept with fewer computational missteps.

The true reasoning gap narrows from 17.6\% to 11.7\%, suggesting that some errors classified as ``reasoning gaps'' for GPT-4o-mini are actually \textit{execution gaps} that more capable reasoning can overcome. Nevertheless, 65 errors (11.7\%) persist even with golden context and extended reasoning, representing a hard core of genuine reasoning limitations that neither concept provision nor enhanced inference can address.

%% ============================================
%% 4. DISCUSSION
%% ============================================
\section{Discussion}
\label{sec:discussion}

\subsection{Economic Significance: Targeted Remediation}

The Error Atlas enables \textit{precision remediation}---addressing specific failure modes rather than generic improvement:

\begin{itemize}
    \item \textbf{Ethics remediation}: The model needs better ethical framework recognition, not better calculation. Fine-tuning on CFA Standards case studies (with diverse scenarios) is more effective than general knowledge augmentation.
    \item \textbf{Derivatives remediation}: The model needs computational tool augmentation (external calculator, symbolic math) to reduce arithmetic errors. Conceptual understanding is relatively intact.
    \item \textbf{Economics remediation}: The model needs better option discrimination training---it understands the general concept but cannot reliably distinguish between similar answer choices.
\end{itemize}

This targeted approach is potentially more efficient than generic fine-tuning, as it focuses training resources on the specific failure modes most prevalent in each domain.

\subsection{Implications for Market Efficiency and Advisory Reliability}

The structured nature of LLM errors has direct implications for financial market theory. Under the Efficient Market Hypothesis \citep{fama1970efficient}, market prices reflect available information processed by rational agents. When AI advisory systems become marginal price-setters---as algorithmic trading and robo-advisory adoption grows---the systematic, \textit{non-random} error patterns documented here threaten semi-strong market efficiency: conceptual misapplication in Ethics (87.1\% reasoning errors) could generate systematic compliance violations in advisory recommendations, while Derivatives pricing failures (37.5\% calculation errors) could produce correlated hedging errors across AI-assisted portfolios. Unlike random noise, which averages out, structured errors create directional bias in aggregate market behavior.

From an investor protection perspective, the 68.8\% conceptual error rate reveals that current LLMs fail at the \textit{identification} stage of financial reasoning---they misrecognize which analytical framework applies before any computation begins. This is precisely the type of error that is invisible to end users, who receive a confidently stated but fundamentally misdirected analysis. The Golden Context Injection results (82.4\% partial recovery) suggest that retrieval-augmented architectures can mitigate this risk, effectively providing the ``concept recognition'' layer that current models lack. This has direct implications for the design of AI-assisted financial advisory systems: concept verification should precede any downstream computation or recommendation.

\subsection{Risk-Weighted Error Assessment}

Not all errors are equally costly. A reasoning premise error in Derivatives pricing can cause catastrophic hedging failures; a selection near-miss in Economics may have minor consequences. We propose a risk-weighted accuracy metric:
\begin{equation}
    \text{Risk-Weighted Acc} = \frac{\sum_{i} \text{correct}_i \times w_{\text{topic},i}}{\sum_{i} w_{\text{topic},i}}
\end{equation}
where risk weights reflect the financial consequences of errors in each domain (e.g., Derivatives $>$ Ethics in immediate monetary impact).

\subsection{Implications for Human-AI Collaboration}

The Atlas reveals where human oversight is most needed:
\begin{itemize}
    \item \textbf{High reasoning error rate} topics (Ethics, Wealth Planning): Require human judgment review---the AI's problem framing may be fundamentally wrong.
    \item \textbf{High calculation error rate} topics (Derivatives): Can be improved with tool augmentation---verify computations with external calculators.
    \item \textbf{High selection error rate} topics (Economics): May benefit from retrieval augmentation---provide additional context to help discriminate between similar options.
\end{itemize}

\subsection{Limitations}

Several limitations deserve note. First, the automated error classification uses GPT-4o-mini as the classifier, which may introduce systematic biases; a human annotation validation study is planned. Second, the topic-level error profiles (Table~\ref{tab:topicerror}) are drawn from a pilot subsample ($n = 229$) on CFA-Challenge questions; full-scale topic annotation is in progress. Third, while the cross-model GCI experiment (Section~\ref{sec:crossmodel_gci}) addresses the single-model limitation for recovery testing, the error taxonomy itself is derived from GPT-4o-mini's failures; GPT-5-mini may produce a different error distribution that warrants separate analysis. Finally, the open-ended format removes MCQ scaffolding, which inflates the error rate relative to standard MCQ evaluations; this design choice is deliberate, as it isolates genuine reasoning from option-recognition heuristics.

%% ============================================
%% 5. CONCLUSION
%% ============================================
\section{Conclusion}
\label{sec:conclusion}

The CFA Error Atlas, based on 557 incorrect responses from 1,032 CFA questions answered in open-ended format, reveals that LLM financial reasoning failures are highly structured, not random. Conceptual errors---not calculation mistakes---are the dominant failure mode (68.8\% vs.\ 1.4\%), and error profiles vary dramatically across financial domains. Golden Context Injection demonstrates that 82.4\% of errors are at least partially recoverable when the correct concept is provided, establishing a ceiling for retrieval-augmented remediation. Cross-model GCI with GPT-5-mini narrows the true reasoning gap from 17.6\% to 11.7\% and nearly doubles the full recovery rate (50.4\% vs.\ 25.5\%), revealing that extended chain-of-thought reasoning substantially improves concept execution once the correct concept is provided.

\textbf{The question is not how accurately AI computes, but whether it knows which computation to perform---and our cross-model evidence shows that while providing the right concept is usually sufficient, the completeness of recovery depends critically on the model's reasoning depth.}

\section*{Data Availability}
The experimental data and analysis code are available from the corresponding author upon reasonable request.

\section*{Declaration of Competing Interest}
The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.

\section*{CRediT Author Contributions}
\textbf{Wei-Lun Cheng}: Conceptualization, Methodology, Software, Formal Analysis, Data Curation, Writing -- Original Draft, Visualization.
\textbf{Daniel Wei-Chung Miao}: Supervision, Writing -- Review \& Editing.
\textbf{Guang-Di Chang}: Supervision, Writing -- Review \& Editing.

\section*{Acknowledgments}
Computational resources were provided by National Taiwan University of Science and Technology (NTUST).

%% ============================================
%% REFERENCES
%% ============================================
\begin{thebibliography}{10}

\bibitem[Callanan et al.(2023)]{callanan2023gpt}
Callanan, E., Mbae, A., Selle, S., Gupta, V., \& Houlihan, R. (2023).
\newblock Can GPT-4 pass the CFA exam?
\newblock \textit{arXiv preprint arXiv:2310.09542}.

\bibitem[Fama(1970)]{fama1970efficient}
Fama, E. F. (1970).
\newblock Efficient capital markets: A review of theory and empirical work.
\newblock \textit{The Journal of Finance}, 25(2), 383--417.

\bibitem[Ke et al.(2025)]{ke2025findap}
Ke, Z., Ming, Y., Nguyen, X. P., Xiong, C., \& Joty, S. (2025).
\newblock Demystifying domain-adaptive post-training for financial LLMs.
\newblock In \textit{Proceedings of EMNLP 2025}.

\end{thebibliography}

\end{document}
