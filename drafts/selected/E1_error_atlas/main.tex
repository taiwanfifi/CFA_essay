% Finance Research Letters â€” Elsevier Template
% E1: CFA Error Pattern Atlas
\documentclass[preprint,12pt]{elsarticle}

\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{multirow}
\usepackage{threeparttable}
\usepackage{float}

\journal{Finance Research Letters}

\begin{document}

\begin{frontmatter}

\title{The CFA Error Atlas: Mapping Failure Modes of Large Language Models in Financial Reasoning}

\author[sinica]{Wei-Lun Cheng}
\ead{wlcheng@iis.sinica.edu.tw}

\author[nccu]{Wei-Chung Miao\corref{cor1}}
\ead{wcmiao@nccu.edu.tw}
\cortext[cor1]{Corresponding author}

\affiliation[sinica]{organization={Institute of Information Science, Academia Sinica},
            city={Taipei},
            country={Taiwan}}

\affiliation[nccu]{organization={Department of Finance, National Chengchi University},
            city={Taipei},
            country={Taiwan}}

\begin{abstract}
When Large Language Models (LLMs) fail on financial reasoning tasks, these failures are not random---they exhibit systematic patterns that reflect specific cognitive limitations. We present the \textit{CFA Error Atlas}, a three-dimensional taxonomy of LLM errors on 229 incorrect responses to CFA (Chartered Financial Analyst) examination questions across five reasoning methods. Our taxonomy classifies errors along three dimensions: error type (8 categories from reasoning premise errors to calculation mistakes), CFA topic (8 knowledge domains), and cognitive stage (5 stages from concept identification to verification). We find that \textbf{reasoning premise errors} dominate overall (49.3\%), but the error profile varies dramatically by topic: Ethics errors are overwhelmingly reasoning-based (87.1\%), while Derivatives errors are computation-heavy (37.5\% arithmetic/formula errors). The cognitive stage analysis reveals that \textbf{concept identification} is the primary bottleneck (53.7\%), contradicting the common assumption that LLMs primarily struggle with arithmetic. These findings enable targeted remediation: different financial domains require different intervention strategies, and institutions can use the Atlas to identify where human oversight is most critical.
\end{abstract}

\begin{keyword}
Large Language Models \sep Error Analysis \sep Financial Reasoning \sep CFA Examination \sep Error Taxonomy \sep Failure Modes
\end{keyword}

\end{frontmatter}

%% ============================================
%% 1. INTRODUCTION
%% ============================================
\section{Introduction}
\label{sec:intro}

The growing deployment of Large Language Models (LLMs) in financial applications has motivated extensive benchmarking on professional examinations \citep{callanan2023gpt, ke2025findap}. These evaluations universally report \textit{accuracy}: the fraction of questions answered correctly. However, accuracy tells us nothing about \textit{how} models fail---and in financial applications, the nature of failure matters as much as its frequency.

Consider two models, both achieving 60\% accuracy on CFA questions. Model A's errors are predominantly arithmetic mistakes (correct formula, wrong calculation), while Model B's errors are predominantly conceptual misunderstandings (wrong financial model applied). Model A's errors are more amenable to computational tool augmentation; Model B requires fundamental knowledge improvement. Current benchmark reporting obscures this distinction entirely.

This paper presents the \textit{CFA Error Atlas}: a systematic, three-dimensional taxonomy of LLM failure modes on financial reasoning tasks. We analyze 229 incorrect responses from GPT-4o-mini across five reasoning methods on 90 CFA Level III questions, classifying each error along three dimensions:
\begin{enumerate}
    \item \textbf{Error type}: What kind of mistake? (8 categories)
    \item \textbf{CFA topic}: Which financial domain? (8 knowledge areas)
    \item \textbf{Cognitive stage}: At which point in the reasoning process? (5 stages)
\end{enumerate}

Our contributions are threefold:
\begin{enumerate}
    \item We provide the first systematic error taxonomy for financial LLMs, revealing that reasoning premise errors (49.3\%) dominate over calculation errors (12.7\%), contradicting the popular narrative that LLMs ``can't do math.''
    \item We demonstrate dramatic topic-dependent error profiles: Ethics failures are reasoning-based while Derivatives failures are computation-based, implying that different financial domains require fundamentally different remediation strategies.
    \item We identify concept identification (53.7\%) as the primary cognitive bottleneck, reframing the challenge of financial AI from ``better arithmetic'' to ``better financial concept selection.''
\end{enumerate}

%% ============================================
%% 2. METHODOLOGY
%% ============================================
\section{Methodology}
\label{sec:method}

\subsection{Data Collection}

We use 90 CFA Level III questions from the CFA-Challenge dataset \citep{ke2025findap}. GPT-4o-mini is evaluated using five reasoning methods: zero-shot, chain-of-thought (CoT), CoT with step-by-step verification \citep{lightman2023lets}, structured reasoning, and naive agent. All incorrect responses (229 total) are collected with full reasoning traces.

\subsection{Three-Dimensional Error Taxonomy}

\textbf{Dimension 1 --- Error Type (8 categories):}
\begin{itemize}
    \item \texttt{reasoning\_premise\_error}: Incorrect initial assumption or problem framing
    \item \texttt{reasoning\_chain\_break}: Correct start but logical break in reasoning chain
    \item \texttt{calc\_formula\_error}: Selected wrong formula or financial model
    \item \texttt{calc\_arithmetic\_error}: Correct formula but computational mistake
    \item \texttt{concept\_misunderstanding}: Fundamental misunderstanding of financial concept
    \item \texttt{concept\_incomplete}: Partial but incomplete understanding
    \item \texttt{selection\_near\_miss}: Close to correct answer but chose wrong option
    \item \texttt{selection\_random}: No discernible reasoning, appears random
\end{itemize}

\textbf{Dimension 2 --- CFA Topic:} Ethics, Fixed Income, Economics, Portfolio Management, Wealth Planning, Derivatives, Alternative Investments, Equity.

\textbf{Dimension 3 --- Cognitive Stage:} Identify (concept recognition), Recall (formula/rule retrieval), Calculate (numerical computation), Verify (answer checking), Unknown.

\subsection{Automated Classification}

GPT-4o-mini serves as the error classifier, receiving the question, the model's incorrect response (with full reasoning trace), and the correct answer, then outputting the three-dimensional classification.

%% ============================================
%% 3. RESULTS
%% ============================================
\section{Results}
\label{sec:results}

\subsection{Overall Error Distribution}

Table~\ref{tab:errortype} presents the error type distribution across all 229 errors.

\begin{table}[htbp]
\centering
\caption{Error Type Distribution ($N = 229$)}
\label{tab:errortype}
\begin{tabular}{lrrl}
\toprule
\textbf{Error Type} & \textbf{Count} & \textbf{\%} & \textbf{Category} \\
\midrule
Reasoning premise error & 113 & 49.3\% & Reasoning \\
Reasoning chain break & 34 & 14.8\% & Reasoning \\
Selection random & 22 & 9.6\% & Selection \\
Calc arithmetic error & 20 & 8.7\% & Calculation \\
Selection near miss & 16 & 7.0\% & Selection \\
Concept misunderstanding & 10 & 4.4\% & Knowledge \\
Calc formula error & 9 & 3.9\% & Calculation \\
Concept incomplete & 5 & 2.2\% & Knowledge \\
\midrule
\multicolumn{4}{l}{\textbf{Aggregated:} Reasoning 64.2\%, Selection 16.6\%, Calculation 12.7\%, Knowledge 6.6\%} \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.85\textwidth]{figures/fig1_error_type_distribution.pdf}
\caption{Distribution of 229 LLM errors across eight error types, color-coded by aggregate category (Reasoning, Calculation, Selection, Knowledge). Reasoning premise errors alone account for nearly half of all failures, underscoring that incorrect problem framing---rather than computational mistakes---is the dominant failure mode.}
\label{fig:errortype}
\end{figure}

\textbf{Key finding}: As visualized in Figure~\ref{fig:errortype}, reasoning errors dominate (64.2\%), not calculation errors (12.7\%). The primary failure mode is not ``can't compute'' but ``starts from wrong premise.'' This has direct implications for remediation: calculator tools won't help when the fundamental problem framing is wrong.

\subsection{Topic-Level Error Profiles}

Table~\ref{tab:topicerror} reveals dramatically different error profiles across CFA knowledge domains.

\begin{table}[htbp]
\centering
\caption{Error Distribution by CFA Topic}
\label{tab:topicerror}
\begin{threeparttable}
\begin{tabular}{lrccc}
\toprule
\textbf{Topic} & \textbf{N} & \textbf{Reasoning\%} & \textbf{Calculation\%} & \textbf{Selection\%} \\
\midrule
Ethics & 70 & 87.1\% & 0.0\% & 0.0\% \\
Portfolio Mgmt & 45 & 62.2\% & 17.8\% & 15.6\% \\
Fixed Income & 35 & 34.3\% & 25.7\% & 34.3\% \\
Wealth Planning & 27 & 81.5\% & 3.7\% & 14.8\% \\
Derivatives & 24 & 41.7\% & 37.5\% & 16.7\% \\
Economics & 17 & 35.3\% & 5.9\% & 52.9\% \\
Alternatives & 7 & 100.0\% & 0.0\% & 0.0\% \\
Equity & 4 & 25.0\% & 25.0\% & 50.0\% \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item Reasoning = premise error + chain break; Calculation = formula + arithmetic; Selection = near miss + random. Knowledge errors omitted for space.
\end{tablenotes}
\end{threeparttable}
\end{table}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.85\textwidth]{figures/fig2_topic_error_profile.pdf}
\caption{Grouped bar chart comparing the proportion of Reasoning, Calculation, and Selection errors across eight CFA knowledge domains. The stark contrast between Ethics (87.1\% reasoning) and Derivatives (37.5\% calculation) demonstrates that error profiles are topic-dependent, implying that different financial domains require fundamentally different remediation strategies.}
\label{fig:topicerror}
\end{figure}

As Figure~\ref{fig:topicerror} illustrates, the error profiles are strikingly different:
\begin{itemize}
    \item \textbf{Ethics} (87.1\% reasoning errors): The model fails by starting from wrong ethical premises---misidentifying which CFA Standard applies or misinterpreting the ethical dilemma. Calculation is irrelevant for Ethics.
    \item \textbf{Derivatives} (37.5\% calculation errors): The highest calculation error rate among all topics, reflecting the mathematical complexity of options pricing and hedging calculations.
    \item \textbf{Economics} (52.9\% selection errors): Dominated by near-miss and random selection errors, suggesting the model understands broad concepts but struggles to differentiate between similar options.
    \item \textbf{Fixed Income} (balanced): An even split between reasoning, calculation, and selection errors, reflecting the topic's blend of conceptual understanding and quantitative computation.
\end{itemize}

\subsection{Cognitive Stage Analysis}

Table~\ref{tab:cognitive} shows the distribution of errors across cognitive processing stages.

\begin{table}[htbp]
\centering
\caption{Error Distribution by Cognitive Stage}
\label{tab:cognitive}
\begin{tabular}{lrr}
\toprule
\textbf{Cognitive Stage} & \textbf{Count} & \textbf{\%} \\
\midrule
Identify (concept recognition) & 123 & 53.7\% \\
Verify (answer checking) & 50 & 21.8\% \\
Calculate (computation) & 20 & 8.7\% \\
Recall (formula/rule retrieval) & 14 & 6.1\% \\
Unknown & 22 & 9.6\% \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.85\textwidth]{figures/fig3_cognitive_stages.pdf}
\caption{Error distribution across five cognitive processing stages. The Identify stage (concept recognition) accounts for 53.7\% of all errors, revealing that the primary bottleneck in LLM financial reasoning occurs at the earliest stage of problem solving---selecting the appropriate financial concept or framework---rather than at downstream computation or verification stages.}
\label{fig:cognitive}
\end{figure}

\textbf{Key finding}: As shown in Figure~\ref{fig:cognitive}, the Identify stage---where the model must recognize which financial concept, formula, or framework applies to the given problem---accounts for over half of all errors. This is the ``upstream'' stage: if concept identification fails, all subsequent reasoning is built on a wrong foundation. The Calculate stage accounts for only 8.7\% of errors, confirming that modern LLMs are reasonably competent at arithmetic when given the right formula.

%% ============================================
%% 4. DISCUSSION
%% ============================================
\section{Discussion}
\label{sec:discussion}

\subsection{Economic Significance: Targeted Remediation}

The Error Atlas enables \textit{precision remediation}---addressing specific failure modes rather than generic improvement:

\begin{itemize}
    \item \textbf{Ethics remediation}: The model needs better ethical framework recognition, not better calculation. Fine-tuning on CFA Standards case studies (with diverse scenarios) is more effective than general knowledge augmentation.
    \item \textbf{Derivatives remediation}: The model needs computational tool augmentation (external calculator, symbolic math) to reduce arithmetic errors. Conceptual understanding is relatively intact.
    \item \textbf{Economics remediation}: The model needs better option discrimination training---it understands the general concept but cannot reliably distinguish between similar answer choices.
\end{itemize}

This targeted approach is potentially more efficient than generic fine-tuning, as it focuses training resources on the specific failure modes most prevalent in each domain.

\subsection{Risk-Weighted Error Assessment}

Not all errors are equally costly. A reasoning premise error in Derivatives pricing can cause catastrophic hedging failures; a selection near-miss in Economics may have minor consequences. We propose a risk-weighted accuracy metric:
\begin{equation}
    \text{Risk-Weighted Acc} = \frac{\sum_{i} \text{correct}_i \times w_{\text{topic},i}}{\sum_{i} w_{\text{topic},i}}
\end{equation}
where risk weights reflect the financial consequences of errors in each domain (e.g., Derivatives $>$ Ethics in immediate monetary impact).

\subsection{Implications for Human-AI Collaboration}

The Atlas reveals where human oversight is most needed:
\begin{itemize}
    \item \textbf{High reasoning error rate} topics (Ethics, Wealth Planning): Require human judgment review---the AI's problem framing may be fundamentally wrong.
    \item \textbf{High calculation error rate} topics (Derivatives): Can be improved with tool augmentation---verify computations with external calculators.
    \item \textbf{High selection error rate} topics (Economics): May benefit from retrieval augmentation---provide additional context to help discriminate between similar options.
\end{itemize}

\subsection{Limitations}

The classification uses GPT-4o-mini as an automated error classifier, which may introduce systematic biases. A 200-question human annotation validation is planned. The current data is from a single model (GPT-4o-mini); cross-model comparison would reveal whether error patterns are model-specific or universal.

%% ============================================
%% 5. CONCLUSION
%% ============================================
\section{Conclusion}
\label{sec:conclusion}

The CFA Error Atlas reveals that LLM financial reasoning failures are highly structured, not random. Reasoning premise errors---not calculation mistakes---are the dominant failure mode (49.3\%), and error profiles vary dramatically across financial domains. These findings challenge the narrative that financial AI needs ``better math'' and redirect attention to the more fundamental challenge of ``better financial concept selection.''

\textbf{The question is not how accurately AI computes, but whether it knows which computation to perform.}

\section*{Data Availability}
The experimental data and analysis code are available at \url{https://github.com/[anonymized]} upon publication.

\section*{Declaration of Competing Interest}
The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.

\section*{CRediT Author Contributions}
\textbf{Wei-Lun Cheng}: Conceptualization, Methodology, Software, Formal Analysis, Data Curation, Writing -- Original Draft, Visualization.
\textbf{Wei-Chung Miao}: Supervision, Writing -- Review \& Editing.

\section*{Acknowledgments}
The authors thank the anonymous reviewers for their constructive feedback. Computational resources were provided by Academia Sinica.

%% ============================================
%% REFERENCES
%% ============================================
\begin{thebibliography}{10}

\bibitem[Callanan et al.(2023)]{callanan2023gpt}
Callanan, E., Mbae, A., Selle, S., Gupta, V., \& Houlihan, R. (2023).
\newblock Can GPT-4 pass the CFA exam?
\newblock \textit{arXiv preprint arXiv:2310.09542}.

\bibitem[Ke et al.(2025)]{ke2025findap}
Ke, Z., Ming, Y., Nguyen, X. P., Xiong, C., \& Joty, S. (2025).
\newblock Demystifying domain-adaptive post-training for financial LLMs.
\newblock In \textit{Proceedings of EMNLP 2025}.

\bibitem[Lightman et al.(2023)]{lightman2023lets}
Lightman, H., Kosaraju, V., Burda, Y., et al. (2023).
\newblock Let's verify step by step.
\newblock \textit{arXiv preprint arXiv:2305.20050}.

\bibitem[Wu et al.(2023)]{wu2023bloomberggpt}
Wu, S., Irsoy, O., Lu, S., et al. (2023).
\newblock BloombergGPT: A large language model for finance.
\newblock \textit{arXiv preprint arXiv:2303.17564}.

\end{thebibliography}

\end{document}
