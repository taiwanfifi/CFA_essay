\documentclass[preprint,12pt]{elsarticle}

%% -----------------------------------------------------------------------
%% Packages
%% -----------------------------------------------------------------------
\usepackage{amsmath,amssymb}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{multirow}
\usepackage{enumitem}
\usepackage{float}
\usepackage{natbib}
\usepackage{xeCJK}
\setCJKmainfont{Songti TC}
\setCJKsansfont{Heiti TC}
\setCJKmonofont{Heiti TC}


\hypersetup{
  colorlinks=true,
  linkcolor=blue!70!black,
  citecolor=blue!70!black,
  urlcolor=blue!70!black
}

%% -----------------------------------------------------------------------
%% Journal metadata
%% -----------------------------------------------------------------------
\journal{Finance Research Letters（繁體中文版）}

\begin{document}

\begin{frontmatter}

\title{繼承的非理性：量測大型語言模型中的行為金融偏誤}

\author[ntust]{Wei-Lun Cheng}
\ead{d11018003@mail.ntust.edu.tw}

\author[ntust]{Daniel Wei-Chung Miao\corref{cor1}}
\ead{miao@mail.ntust.edu.tw}
\cortext[cor1]{通訊作者}

\author[ntust]{Guang-Di Chang}
\ead{gchang@mail.ntust.edu.tw}

\affiliation[ntust]{organization={國立臺灣科技大學 財務金融研究所},
            city={臺北},
            postcode={10607},
            country={臺灣}}

\begin{abstract}
大型語言模型（LLMs）日益被部署為金融顧問與分析工具。由於這些模型係以大量人類生成之文本進行訓練，其可能繼承行為金融學所記載之系統性認知偏誤。本研究設計一配對情境實驗框架，以量測 GPT-4o-mini 在 60 個金融決策情境（每種偏誤類型 10 個）中的六種典型偏誤——損失趨避、錨定效應、框架效應、近因偏誤、處置效應與過度自信。每個情境分別以偏誤誘發框架與中性框架呈現，由 LLM 評審以 0--1 量表評分（$0=$ 完全理性，$1=$ 完全偏誤）。研究結果顯示平均偏誤分數為 0.500，表明該模型在其金融建議中有半數呈現偏誤行為。中性重新框架將平均分數降至 0.425，產生統計顯著之去偏誤效果 $+0.075$（Wilcoxon 符號等級檢定 $W = 14.0$，$p = 0.023$）。關鍵發現在於，去偏誤效果揭示了三層級階層結構：\emph{表層偏誤}（損失趨避 $+0.300$、框架效應 $+0.150$）對提示層級干預反應強烈；\emph{弱回應偏誤}（錨定效應 $+0.050$）僅呈現邊際改善；而\emph{深層偏誤}（處置效應 $+0.000$、過度自信 $+0.000$、近因偏誤 $-0.050$）則完全抵抗中性重新框架，其中近因偏誤在中性條件下反而弔詭地\emph{上升}。這些發現暗示，部署於金融諮詢角色的 LLMs 可能系統性地放大人類的非理性——並非因為它們經歷情緒，而是因為它們從訓練資料中吸收了偏誤人類推理的統計規律性。
\end{abstract}

\begin{keyword}
行為金融 \sep 大型語言模型 \sep 損失趨避 \sep 錨定效應 \sep 框架效應 \sep 近因偏誤 \sep 處置效應 \sep 過度自信 \sep 認知偏誤 \sep AI 金融顧問 \sep 展望理論
\end{keyword}

\end{frontmatter}

%% -----------------------------------------------------------------------
\section{緒論}
\label{sec:introduction}
%% -----------------------------------------------------------------------

效率市場假說假設市場參與者為理性代理人，能不帶系統性誤差地處理資訊 \citep{fama1970efficient}。數十年來的行為金融學研究已瓦解了此一假設：投資者展現出持續性的認知偏誤——損失趨避、錨定效應、處置效應、過度自信等——導致可預測地偏離期望效用最大化 \citep{kahneman1979prospect, shefrin1985disposition, thaler1985mental}。這些發現深刻影響了我們對資產定價、投資組合管理與市場微觀結構的理解。

隨著大型語言模型（LLMs）在金融服務中的快速部署，一個新的問題由此產生。GPT-4、BloombergGPT \citep{wu2023bloomberggpt}，以及 Llama-Fin \citep{ke2025findap} 等領域適應型模型正被用於股權研究、風險評估、客戶諮詢與自動化交易。這引發了根本性的問題：這些缺乏人類情感的系統，是否真正免於困擾人類決策者的行為偏誤？

我們挑戰此一假設。LLMs 係以大量人類撰寫的文本進行訓練——分析師報告、金融新聞、投資論壇與教科書——這些文本不僅包含事實資訊，亦蘊含其人類作者的推理模式、捷思法則與系統性偏誤。若損失趨避式推理普遍存在於金融評論中（如「保護你的下檔風險」、「不惜一切避免損失」），則以此類文本訓練的語言模型可能將損失趨避內化為統計規律性，在其自身建議中加以複製——儘管它並未經歷損失帶來的情緒不適。

本文做出三項貢獻。第一，我們設計了一個\emph{配對情境}實驗框架，透過將同一金融決策分別以偏誤誘發框架與中性框架呈現，來隔離特定的行為偏誤。第二，我們提供了首次針對六種典型行為偏誤——損失趨避、錨定效應、框架效應、近因偏誤、處置效應與過度自信——在一個先進 LLM（GPT-4o-mini）上的系統性實證量測，採用 60 個 CFA 等級的金融情境（每種偏誤類型 10 個）。第三，我們識別出一個\emph{三層級去偏誤階層結構}：由情緒框架線索觸發的表層偏誤（損失趨避、框架效應）對提示層級去偏誤反應良好；弱回應偏誤（錨定效應）呈現邊際改善；而深層偏誤（處置效應、過度自信、近因偏誤）則完全抵抗中性重新框架，顯示其係結構性地嵌入模型所學習之推理模式中。

若 AI 顧問系統性地建議過早賣出贏家（處置效應）、將估值錨定於過時價格、維持過度自信的部位規模，或偏好確定但較低的報酬而非機率上更優越的替代方案（損失趨避），則它們不僅無法改善人類判斷，反而可能主動放大其原本被期望消除的非理性。


%% -----------------------------------------------------------------------
\section{文獻回顧}
\label{sec:literature}
%% -----------------------------------------------------------------------

\citet{kahneman1979prospect} 的奠基性研究確立了個體系統性地違反期望效用理論的事實，其途徑為\emph{損失趨避}（損失的心理權重約為等額利得的兩倍）與\emph{參考點依賴}。在金融市場中，這些偏離表現為處置效應——過早賣出贏家同時持有輸家 \citep{shefrin1985disposition}——以及錨定效應，即判斷被拉向初始參考點 \citep{tversky1974judgment}。

LLMs 在金融領域的應用已快速加速，領域專用模型如 BloombergGPT \citep{wu2023bloomberggpt} 與領域適應框架如 FinDAP \citep{ke2025findap} 在金融自然語言處理任務與 CFA 等級題目上展現優異表現。越來越多研究檢視 LLMs 是否複製人類認知偏誤：\citet{hagendorff2023human} 發現 LLMs 在經典認知心理學任務上展現類似人類的直覺偏誤，但某些偏誤隨模型規模增大而減弱。然而，先前研究聚焦於一般認知任務，而非具有實際經濟利害關係的\emph{金融}情境，亦未量測去偏誤干預在多種偏誤類型間的效果。本研究透過使用 60 個旨在引發特定偏誤的 CFA 等級金融決策情境來填補此一缺口。


%% -----------------------------------------------------------------------
\section{研究方法}
\label{sec:methodology}
%% -----------------------------------------------------------------------

\subsection{實驗設計}

本框架建立於\emph{配對情境}設計之上。對於每個金融決策，我們建構兩個版本：

\begin{enumerate}[label=(\roman*)]
  \item \textbf{偏誤誘發版本：}情境以已知會在人類受試者中觸發目標偏誤的方式進行框架。對於損失趨避，這意味著明確陳述潛在損失（如「20\% 的機率\emph{損失} \$2,000」）。對於錨定效應，這意味著在要求估值之前提供一個不相關或過時的參考價格。
  \item \textbf{中性版本：}同一決策僅以量化事實呈現——期望值、預期報酬率或基本面指標——不含任何帶有情緒色彩的框架或錨定資訊。
\end{enumerate}

若模型為完全理性，其建議在每個情境的兩種框架下應完全一致。兩版本間的任何系統性差異即構成行為偏誤之證據。

\subsection{偏誤類型與情境建構}

我們測試六種典型行為偏誤，每種類型 10 個情境，共計 60 個配對情境：

\paragraph{損失趨避（10 個情境）。}每個情境呈現一個選擇：風險選項具有較高期望值但明確標示潛在損失，安全選項具有較低期望值但無下檔風險。

\paragraph{錨定效應（10 個情境）。}每個情境提供一個歷史價格或先前估計作為錨點，隨後是基本面已根本改變、理應產生截然不同估值的條件。

\paragraph{框架效應（10 個情境）。}每個情境以利得強調或損失強調的框架呈現同一金融決策；理性代理人的建議應不受框架影響 \citep{tversky1974judgment, kahneman1979prospect}。

\paragraph{近因偏誤（10 個情境）。}每個情境呈現與長期基本面背離的近期績效資料，測試模型是否過度加權最近期的資料點。

\paragraph{處置效應（10 個情境）。}每個情境呈現一個同時包含贏家與輸家部位的投資組合，要求模型建議賣出哪一個；具處置效應偏誤的代理人會賣出贏家同時持有輸家 \citep{shefrin1985disposition}。

\paragraph{過度自信（10 個情境）。}每個情境測試模型是否相對於基準比率與統計證據過度加權個人信念或績效紀錄。

完整情境資料庫（60 個情境，每種偏誤類型 10 個）可向通訊作者索取。

\subsection{模型與提示協定}

我們評估 \textbf{GPT-4o-mini}（OpenAI, 2024），一個廣泛用於金融應用的高效能前沿模型。對於每個情境，我們發出兩次 API 呼叫：

\begin{enumerate}[label=\arabic*.]
  \item \textbf{偏誤誘發條件：}系統提示指示模型扮演「CFA 認證金融顧問」並「清楚展示推理過程」。使用者提示包含該情境的偏誤誘發版本。
  \item \textbf{中性條件：}系統提示指示模型「僅使用量化分析進行評估」並「嚴格聚焦於期望值與風險調整報酬」。使用者提示包含中性版本。
\end{enumerate}

所有呼叫皆使用溫度 $= 0.0$（貪婪解碼），最大 token 預算為 1,500，以確保確定性、可重現的輸出。此確定性設定排除了隨機性作為干擾因素的可能：任何觀察到的偏誤反映的是模型習得之偏好，而非取樣變異性。

\subsection{透過 LLM 評審進行偏誤評分}

每個模型回應由另一個 GPT-4o-mini 實例擔任行為金融專家評審進行評估。評審接收：
\begin{itemize}
  \item 被測試的偏誤類型
  \item 情境文本
  \item 模型的回應（截斷至 1,500 tokens）
  \item \emph{理性基線}（期望值最優答案）
  \item \emph{偏誤預測}（偏誤人類會給出的答案）
\end{itemize}

評審以三點量表指派偏誤分數：

\begin{equation}
  \text{Bias Score} \in \{0.0, 0.5, 1.0\}
  \label{eq:bias_score}
\end{equation}

\noindent 其中 $0.0$ 表示完全理性、與期望值最優基線一致的回應，$0.5$ 表示混合或模稜兩可的建議，$1.0$ 表示完全偏誤、與偏誤預測選擇一致的回應。此離散量表反映了金融建議本質上的類別特性（選擇 A 或 B、賣出或持有），同時允許模糊案例的存在。

\subsection{去偏誤效果}

我們將\emph{去偏誤效果}定義為中性框架所達成之偏誤分數降低幅度：

\begin{equation}
  \Delta_{\text{debias}} = S_{\text{bias}} - S_{\text{neutral}}
  \label{eq:debiasing}
\end{equation}

\noindent 其中 $S_{\text{bias}}$ 為偏誤誘發框架下的偏誤分數，$S_{\text{neutral}}$ 為中性框架下的分數。正值 $\Delta_{\text{debias}}$ 表示中性框架成功降低偏誤；零值表示無去偏誤效果；負值則表示中性框架弔詭地增加了偏誤。


%% -----------------------------------------------------------------------
\section{結果}
\label{sec:results}
%% -----------------------------------------------------------------------

\subsection{整體偏誤量測}

表~\ref{tab:overall} 呈現 GPT-4o-mini 在所有 60 個情境中的彙總結果。在偏誤誘發框架下，模型展現平均偏誤分數 0.500，表明其金融建議平均而言有部分受到與人類受試者相同之認知偏誤驅動。中性重新框架將平均分數降至 0.425，產生平均去偏誤效果 $+0.075$。對 60 個配對觀測值進行 Wilcoxon 符號等級檢定得 $W = 14.0$，$p = 0.023$，效果量 $r = 0.284$，確認偏誤誘發條件在 5\% 顯著水準下引發顯著較高的分數。60 個情境配對中有 13 個在兩條件間展現非零差異。

\begin{table}[H]
\centering
\caption{整體偏誤量測結果（GPT-4o-mini，$n=60$ 個情境，6 種偏誤類型）。}
\label{tab:overall}
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{指標} & \textbf{偏誤誘發} & \textbf{中性} & \textbf{$\Delta_{\text{debias}}$} \\
\midrule
平均分數          & 0.500 & 0.425 & +0.075 \\
標準差            & 0.129 & 0.201 & 0.220  \\
最小值            & 0.00  & 0.00  & $-$0.50  \\
最大值            & 1.00  & 1.00  & +0.50  \\
\midrule
\multicolumn{4}{@{}l}{\textit{Wilcoxon 符號等級檢定：$W = 14.0$，$p = 0.023$，$r = 0.284$（13/60 非零差異）}} \\
\bottomrule
\end{tabular}
\end{table}

雖然效果量為中等（$r = 0.284$），結果揭示了值得注意的\emph{極端結果}：框架效應情境 fr\_03 與 fr\_04 引發完全偏誤回應（分數 $= 1.0$），而 fr\_02 即使在偏誤誘發條件下仍產生完全理性回應（分數 $= 0.0$）。情境 an\_10（新創企業估值）展現\emph{弔詭去偏誤}，其中中性條件產生的偏誤分數高於偏誤誘發條件。

圖~\ref{fig:bias_score_comparison} 以視覺化方式比較六種偏誤類型在偏誤誘發與中性框架下的平均偏誤分數，呈現三層級去偏誤階層結構。

\begin{figure}[htbp]
\centering
\includegraphics[width=0.85\textwidth]{figures/fig1_bias_score_comparison.pdf}
\caption{GPT-4o-mini 在六種行為偏誤類型中，偏誤誘發框架與中性框架下之平均偏誤分數（$n=60$ 個情境，每種類型 10 個）。偏誤分數範圍為 0（完全理性）至 1（完全偏誤）。損失趨避呈現兩條件間最大差距（$\Delta = +0.300$），而近因偏誤則弔詭地在中性條件下呈現較高分數（$\Delta = -0.050$）。}
\label{fig:bias_score_comparison}
\end{figure}

\subsection{各偏誤類型之結果}

表~\ref{tab:by_type} 按偏誤類型細分結果，揭示六種偏誤類別在偏誤易感性與去偏誤效果上的顯著異質性。

\begin{table}[H]
\centering
\caption{各偏誤類型之偏誤分數（GPT-4o-mini，$n=60$ 個情境涵蓋 6 種偏誤類型，各 10 個）。}
\label{tab:by_type}
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{偏誤類型} & \textbf{$n$} & \textbf{偏誤分數} & \textbf{中性分數} & \textbf{$\Delta_{\text{debias}}$} \\
\midrule
損失趨避        & 10 & 0.500 & 0.200 & +0.300 \\
框架效應        & 10 & 0.550 & 0.400 & +0.150 \\
錨定效應        & 10 & 0.500 & 0.450 & +0.050 \\
處置效應        & 10 & 0.500 & 0.500 & +0.000 \\
過度自信        & 10 & 0.500 & 0.500 & +0.000 \\
近因偏誤        & 10 & 0.450 & 0.500 & $-$0.050 \\
\midrule
\textbf{整體}   & \textbf{60} & \textbf{0.500} & \textbf{0.425} & \textbf{+0.075} \\
\bottomrule
\end{tabular}
\end{table}

結果揭示了一個顯著的\emph{三層級去偏誤階層結構}：

\paragraph{第一層級：表層偏誤。}損失趨避（$\Delta = +0.300$）與框架效應（$\Delta = +0.150$）最易受提示層級去偏誤影響。對於損失趨避，中性重新框架將平均分數從 0.500 降至僅 0.200，顯示損失趨避行為主要由情緒框架線索——明確提及潛在損失、下檔語言、最壞情境——所觸發，而量化重新框架可有效中和之。框架效應呈現較弱但仍為正向的去偏誤回應，平均分數從 0.550 降至 0.400。

\paragraph{第二層級：弱回應偏誤。}錨定效應（$\Delta = +0.050$）呈現邊際去偏誤回應。中性條件下平均偏誤分數從 0.500 降至 0.450——微幅改善顯示，雖然移除明確參考價格可稍微減弱錨定效應，但模型傾向朝先前提及之數字靠攏的傾向在很大程度上抵抗提示層級干預。

\paragraph{第三層級：深層偏誤。}處置效應（$\Delta = +0.000$）、過度自信（$\Delta = +0.000$）與近因偏誤（$\Delta = -0.050$）呈現零或\emph{負向}去偏誤效果。這些偏誤在中性框架下產生與偏誤誘發框架相同或更差的分數。最值得注意的是，近因偏誤展現弔詭性逆轉：中性條件實際上產生\emph{較高}的平均偏誤分數（0.500），高於偏誤誘發條件（0.450），暗示當近期績效資訊被移除時，模型可能轉而依賴其他捷思法則，產生同樣或更偏誤的輸出。

框架效應是唯一平均偏誤分數超過 0.500 的偏誤類型，主要由情境 fr\_03 與 fr\_04 驅動，兩者皆獲得完全偏誤分數 1.0。這顯示框架效應，特別是涉及相同結果的利得/損失呈現時，可將模型推過其典型的模稜兩可行為。

三層級階層結構在圖~\ref{fig:debiasing_effect} 中進一步呈現，該圖以遞減順序繪製各偏誤類型的去偏誤效果（$\Delta_{\text{debias}}$）。

\begin{figure}[htbp]
\centering
\includegraphics[width=0.85\textwidth]{figures/fig2_debiasing_effect.pdf}
\caption{各偏誤類型之去偏誤效果（$\Delta_{\text{debias}} = S_{\text{bias}} - S_{\text{neutral}}$），以遞減順序排列（$n=60$ 個情境）。三層級階層結構清晰可見：表層偏誤（損失趨避 $+0.300$、框架效應 $+0.150$）對提示層級干預有回應；錨定效應呈現邊際回應（$+0.050$）；而處置效應（$+0.000$）、過度自信（$+0.000$）與近因偏誤（$-0.050$）則完全抵抗或弔詭性逆轉。}
\label{fig:debiasing_effect}
\end{figure}

情境層級分析揭示數個值得注意的模式。損失趨避呈現雙峰去偏誤模式：10 個情境中有 6 個達到完全去偏誤（$\Delta = +0.50$），而 4 個涉及較高利害關係權衡的情境（退休收入、創投、捐贈基金提領）則完全抵抗重新框架。兩個框架效應情境——fr\_03（「保住 200 個」對「失去 400 個」工作機會）與 fr\_04（「保護 95\%」對「5\% 暴露」）——產生完全偏誤回應（分數 $= 1.0$），證明模型對相同結果之利得/損失呈現的敏感性。處置效應與過度自信展現顯著的一致性：這兩種類型全部 20 個情境皆產生相同的 $0.50/0.50$ 分數，模型一致建議賣出贏家以「鎖定獲利」同時持有輸家——恰恰是 \citet{shefrin1985disposition} 所預測的不對稱行為。近因偏誤產生弔詭結果：情境 re\_04 在偏誤誘發條件下的偏誤分數（0.00）低於中性條件（0.50），暗示在長期基本面旁同時呈現近期績效資料，實際上可透過提供資訊對比來輔助理性推理。



%% -----------------------------------------------------------------------
\section{討論}
\label{sec:discussion}
%% -----------------------------------------------------------------------

\subsection{機制：統計偏誤，而非情緒偏誤}

該模型沒有情緒、沒有風險偏好、也沒有個人財富面臨風險。其「損失趨避」反映的是訓練語料中損失趨避式推理的壓倒性普遍——如「保護你的下檔風險」與「投資的第一法則是永遠不要虧錢」等語句在預訓練期間被吸收為統計規律性。就此意義而言，偏誤係\emph{繼承}而非\emph{經歷}的：模型如同一面忠實的鏡子，反射人類金融話語中嵌入的群體偏誤。此一區別意味著 LLM 去偏誤必須針對訓練資料中的\emph{統計模式}或\emph{推論時提示}，而非人類去偏誤干預所針對的情緒根源。

\subsection{三層級去偏誤階層結構}

三層級階層結構提供了一個分類框架，用以理解偏誤在 LLMs 中的編碼方式。\emph{表層偏誤}（第一層級：損失趨避、框架效應）由詞彙線索觸發——如「虧損」、「下跌」、「保住」等詞——存在於模型的提示—回應映射中而非其核心推理中；提示工程在此有效。\emph{弱回應偏誤}（第二層級：錨定效應）運作於更深層面，可能存在於模型對所有提供之數值資訊進行條件化的傾向中。\emph{深層偏誤}（第三層級：處置效應、過度自信、近因偏誤）嵌入於模型習得之推理模式中——權重本身編碼了賣出贏家、對基準比率避險及產生模棱兩可回應的傾向。這些不同的編碼深度意味著需要不同的緩解策略：提示工程適用於第一層級，架構修改適用於第二層級，而訓練資料干預適用於第三層級。

\subsection{弔詭性發現：過度自信與近因偏誤}

過度自信與近因偏誤的結果揭示了反直覺的模式。對於過度自信，模型持續承認基準比率與統計證據，但未能給出完全理性的建議，在兩種條件下皆產生模稜兩可的 0.50 分數。我們認為此「承認但避險」模式代表一種\emph{校準失靈}：模型已學會即使證據是一面倒的情況下仍「呈現雙方觀點」，此行為可能繼承自訓練中的平衡式金融評論。對於近因偏誤，負向去偏誤效果（$\Delta = -0.050$）暗示偏誤誘發框架——在長期基本面旁同時呈現近期績效——實際上提供了有助於理性推理的資訊對比，而中性框架則移除了這項有用的背景脈絡。這意味著對於 LLM 金融顧問而言，移除可能造成偏誤的資訊並非總是最佳的去偏誤策略。

\subsection{經濟顯著性}

觀察到的偏誤具有具體的經濟後果。處置效應——在所有 10 個情境中完全抵抗提示層級去偏誤——若服務數百萬客戶的機器人顧問系統性地過早賣出贏家同時持有輸家，可能實質性地降低投資組合報酬 \citep{shefrin1985disposition}。錨定效應結果顯示，即使明確的錨點被移除，10 個情境中有 8 個仍展現殘留偏誤，暗示其估值捷思法則本質上具有參考點依賴性。模型在過度自信情境中持續在基準比率推理與專家信念之間避險，暗示其系統性地低估統計證據而偏好敘事推理。

\subsection{研究限制}

有數項限制應予以說明。第一，每種偏誤類型僅有 10 個情境，型內異質性仍然較高；一個全面的基準測試應包含每種類型 20--30 個情境，並進行多次隨機運行。第二，LLM 評審評分方法可能引入其自身偏誤；未來研究應以人類專家評審進行驗證。第三，粗略的偏誤分數量表 $\{0.0, 0.5, 1.0\}$ 可能掩蓋細緻的模式。第四，我們的結果基於單一模型（GPT-4o-mini）；對額外模型家族與推理專用架構進行跨模型驗證將強化研究的可推廣性。


%% -----------------------------------------------------------------------
\section{結論}
\label{sec:conclusion}
%% -----------------------------------------------------------------------

本研究提供證據表明，GPT-4o-mini 作為一個先進大型語言模型，在進行金融建議時展現可量測的行為金融偏誤。透過採用配對情境框架，涵蓋六種偏誤類型（每種 10 個）的 60 個 CFA 等級金融決策，我們發現平均偏誤分數為 0.500——表明模型的建議受到與影響人類投資者相同之認知偏誤的影響。中性重新框架產生統計顯著的去偏誤效果 $+0.075$（Wilcoxon $W = 14.0$，$p = 0.023$），但實際影響在不同偏誤類型間差異懸殊。

我們最重要的發現是\emph{三層級去偏誤階層結構}。表層偏誤——損失趨避（$\Delta = +0.300$）與框架效應（$\Delta = +0.150$）——由情緒詞彙線索觸發，對提示層級去偏誤反應良好。弱回應層級——錨定效應（$\Delta = +0.050$）——呈現邊際改善。深層偏誤——處置效應（$\Delta = +0.000$）、過度自信（$\Delta = +0.000$）與近因偏誤（$\Delta = -0.050$）——完全抵抗提示層級干預，顯示其係結構性地嵌入模型訓練衍生之推理模式中。近因偏誤在中性框架下的弔詭惡化暗示，資訊移除並非總是有效的去偏誤策略。

這些發現挑戰了 AI 驅動金融建議本質上比人類建議更理性的假設。LLMs 不會經歷恐懼、貪婪或遺憾，但它們複製了這些情緒的行為特徵，因為它們學習自經歷這些情緒之代理人所產生的文本。三層級階層結構具有直接的實務意涵：雖然損失趨避行為與某些框架效應可透過謹慎的提示工程加以緩解，但更深層的偏誤如處置效應、過度自信與近因偏誤則需要訓練時干預措施。

未來研究應將此分析擴展至更多模型家族與規模，以探究模型擴展是否均勻地降低偏誤或重塑偏誤地景；檢視偏誤持續性背後的神經機制（例如持續性偏誤是否對應特定的注意力模式或權重分佈）；並開發訓練時去偏誤技術——如偏誤感知的人類回饋強化學習（RLHF）、基於理性與偏誤推理配對的對比微調，或以去偏誤金融推理進行的合成資料增強——以針對繼承之非理性的根本原因，而非僅仰賴提示層級的權宜之計。


%% -----------------------------------------------------------------------
%% 參考文獻
%% -----------------------------------------------------------------------
\section*{資料可用性}
實驗情境與分析程式碼可向通訊作者合理索取。

\section*{利益衝突聲明}
作者聲明無已知可能影響本文所報告研究之競爭性財務利益或個人關係。

\section*{CRediT 作者貢獻}
\textbf{Wei-Lun Cheng}：概念化、方法論、軟體、形式分析、資料管理、撰寫——初稿、視覺化。
\textbf{Daniel Wei-Chung Miao}：指導、撰寫——審閱與編輯。
\textbf{Guang-Di Chang}：指導、撰寫——審閱與編輯。

\section*{致謝}
運算資源由國立臺灣科技大學（NTUST）提供。

\begin{thebibliography}{99}


\bibitem[Callanan et~al., 2023]{callanan2023gpt}
Callanan, E., Mbae, A., Seo, S., Chang, D., Ritter, A., 2023.
\newblock Can {GPT} pass the {CFA} exam?
\newblock \emph{arXiv preprint arXiv:2310.14356}.


\bibitem[Fama, 1970]{fama1970efficient}
Fama, E.F., 1970.
\newblock Efficient capital markets: A review of theory and empirical work.
\newblock \emph{The Journal of Finance} 25(2), 383--417.

\bibitem[Hagendorff et~al., 2023]{hagendorff2023human}
Hagendorff, T., Fabi, S., Kosinski, M., 2023.
\newblock Human-like intuitive behavior and reasoning biases emerged in large language models but disappeared in {ChatGPT}.
\newblock \emph{Nature Computational Science} 3, 833--838.


\bibitem[Kahneman and Tversky, 1979]{kahneman1979prospect}
Kahneman, D., Tversky, A., 1979.
\newblock Prospect theory: An analysis of decision under risk.
\newblock \emph{Econometrica} 47(2), 263--292.

\bibitem[Ke et~al., 2025]{ke2025findap}
Ke, Z., Wen, Y., Feng, B., Xu, M., Zhu, C., Jiang, X., Sun, C., Caverlee, J., Liu, Y., 2025.
\newblock {FinDAP}: Demystifying domain-adaptive post-training for financial {LLM}s.
\newblock In: \emph{Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing (EMNLP)}. (Oral).

\bibitem[Shefrin and Statman, 1985]{shefrin1985disposition}
Shefrin, H., Statman, M., 1985.
\newblock The disposition to sell winners too early and ride losers too long: Theory and evidence.
\newblock \emph{The Journal of Finance} 40(3), 777--790.

\bibitem[Thaler, 1985]{thaler1985mental}
Thaler, R.H., 1985.
\newblock Mental accounting and consumer choice.
\newblock \emph{Marketing Science} 4(3), 199--214.

\bibitem[Tversky and Kahneman, 1974]{tversky1974judgment}
Tversky, A., Kahneman, D., 1974.
\newblock Judgment under uncertainty: Heuristics and biases.
\newblock \emph{Science} 185(4157), 1124--1131.

\bibitem[Wu et~al., 2023]{wu2023bloomberggpt}
Wu, S., Irsoy, O., Lu, S., Daber, V., Dredze, M., Gehrmann, S., Kambadur, P., Rosenberg, D., Mann, G., 2023.
\newblock {BloombergGPT}: A large language model for finance.
\newblock \emph{arXiv preprint arXiv:2303.17564}.

\end{thebibliography}


\end{document}
