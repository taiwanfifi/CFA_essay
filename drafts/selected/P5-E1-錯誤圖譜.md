# P5 CFA 錯誤圖譜：LLM 金融推理失敗模式的系統性映射
# The CFA Error Atlas: Mapping Failure Modes of Large Language Models in Financial Reasoning

> **狀態**：✅ 論文已完成 | **字數**：2,627 | **頁數**：11 | **樣本量**：N=557 筆錯誤（來自 1,032 題 CFA-Easy 全量測試） | **目標期刊**：Finance Research Letters (FRL) / J. Financial Data Science
> **論文資料夾**：`drafts/selected/E1_error_atlas/`

---

## 研究背景與問題

當 LLM 在 CFA 題目上犯錯時，錯誤並非同質的。「不知道公式」和「知道公式但算錯」是完全不同的失敗模式，需要截然不同的修復手段。然而現有研究只報告整體 accuracy，從未系統性地分類與量化錯誤。

本研究的目標：建構一個**三維度的 CFA Error Pattern Atlas**，讓每一種失敗模式都被精確定位、計數、視覺化。**圖譜本身即為核心學術貢獻**——這是一篇 data/resource contribution paper。

---

## 核心方法

### 方法一覽

**三維度錯誤分類體系 (Error Taxonomy)**：8 types × 10 topics × 5 cognitive stages

**Dimension 1 — Error Type（8 種錯誤類型）**
- Reasoning Premise Error、Concept Confusion、Formula Misapplication、Calculation Error、Data Extraction Error、Incomplete Analysis、Logical Fallacy、Misinterpretation

**Dimension 2 — CFA Topic（10 個學科領域）**
- Ethics, Quantitative Methods, Economics, Financial Reporting, Corporate Finance, Equity, Fixed Income, Derivatives, Alternative Investments, Portfolio Management

**Dimension 3 — Cognitive Stage（5 個認知階段）**
- Concept Identification → Formula Recall → Data Extraction → Calculation → Verification

使用 GPT-4o-mini 作為 automatic error classifier：輸入題目 + 模型錯誤回答（含 reasoning trace）+ 正確答案，輸出三個維度的分類標籤。

---

### 用一個例子理解

#### 一道 Derivatives 題目

> A European call option has S=$50, K=$55, r=5%, T=1 year. Using the put-call parity, if the put price is $8, the call price is:

**正確解法**：
Put-call parity: C = P + S − PV(K)
PV(K) = 55 / (1.05) = $52.38
C = 8 + 50 − 52.38 = **$5.62**

**模型的錯誤回答**：$13.62

**Error Attribution 過程**：

GPT-4o judge 分析模型的推理過程，發現模型寫了：
> C = P + S − K = 8 + 50 − 55 = $3... wait, let me recalculate.
> C = P + K − S = 8 + 55 − 50 = $13

→ 模型**先用錯了公式**（C = P + S − K 是對的，但中途自己「修正」成 C = P + K − S），然後在錯誤公式上計算正確。

**三維分類**：
| 維度 | 分類 |
|------|------|
| Error Type | **Formula Misapplication**（公式用反了） |
| CFA Topic | **Derivatives** |
| Cognitive Stage | **Formula Recall**（在回想公式時出錯） |

#### 對比：另一種錯誤

同一道題，另一個模型的錯誤回答：$5.72

分析推理過程：公式正確（C = P + S − PV(K)），但 PV(K) = 55/1.05 算成 52.28 而不是 52.38。

**三維分類**：
| 維度 | 分類 |
|------|------|
| Error Type | **Calculation Error**（算術出錯） |
| CFA Topic | **Derivatives** |
| Cognitive Stage | **Calculation**（在計算步驟出錯） |

→ 同一道題、同樣是錯，但錯因完全不同。前者是「不知道公式」，後者是「知道但算不準」。修復策略也不同：前者需要加強知識，後者需要加強計算精度。

---

## 實驗設計（實際執行）

| 項目 | 內容 |
|------|------|
| 資料來源 | A1 open-ended 全量測試中 GPT-4o-mini 的所有錯誤答案 |
| 測試集 | CFA-Easy 1,032 題（全量） |
| 錯誤數 | **557 筆** |
| 分類器 | GPT-4o-mini |
| 分類體系 | 8 error types × 10 CFA topics × 5 cognitive stages |

---

## 核心結果

### 顛覆性發現：「LLM 不會算」是迷思

| 錯誤類型 | 佔比 | 傳統印象 |
|----------|------|---------|
| **Reasoning Premise Error** | **46.0%** | 被低估 |
| Concept Confusion | 15.3% | -- |
| Formula Misapplication | 10.5% | -- |
| **Calculation Error** | **12.7%** | 被高估 |
| 其他 | 15.5% | -- |

→ 近一半的錯誤（46.0%）是**推理前提就錯了**——模型從一開始就理解錯了題意或概念。只有 12.7% 是真正的計算錯誤。**「LLM 不會算」是迷思，真正的瓶頸是「理解」。**

### 主題級錯誤剖面

| CFA 主題 | 推理類錯誤 | 計算類錯誤 | 特徵 |
|----------|-----------|-----------|------|
| **Ethics** | **87.1%** | 0% | 幾乎全是推理問題 |
| Economics | 72.3% | 8.1% | 以概念理解為主 |
| **Derivatives** | 52.5% | **37.5%** | 計算需求最高的主題 |
| Fixed Income | 61.8% | 21.4% | 公式密集 |

→ 不同 CFA 主題有截然不同的「錯誤簽名」(error signature)。

### 認知階段瓶頸

| 認知階段 | 在該階段出錯的比例 |
|---------|-------------------|
| **Concept Identification** | **50.3%** |
| Formula Recall | 18.3% |
| Data Extraction | 9.6% |
| Calculation | 12.7% |
| Verification | 9.1% |

→ 超過一半的錯誤發生在最初的「概念識別」階段。模型還沒開始算，就已經走歪了。

### Golden Context Injection (GCI) 實驗

GCI 是對 Error Atlas 的修復驗證：給模型提供正確的「黃金上下文」（相關公式、概念定義、解題步驟提示），看能否修復錯誤。

#### GPT-4o-mini GCI 結果（N=557 errors）

| 修復程度 | 比例 |
|---------|------|
| **Full Recovery（完全修復）** | 25.5% |
| **Partial Recovery（部分修復）** | 56.9% |
| No Recovery（無法修復） | 17.6% |
| **Total Recovery Rate** | **82.4%** |

- Conceptual errors recovery: 84.3%（383 errors）
- Arithmetic errors recovery: 71.4%（7 errors, 57.1% full recovery）

#### GPT-5-mini GCI 結果（跨模型驗證）

| 修復程度 | 比例 |
|---------|------|
| **Full Recovery（完全修復）** | 50.4% |
| **Partial Recovery（部分修復）** | 37.9% |
| No Recovery（無法修復） | 11.7% |
| **Total Recovery Rate** | **88.3%** |

→ GPT-5-mini 在 GCI 下展現更強的修復能力：完全修復率從 25.5% 躍升至 50.4%（+24.9 pp），總修復率從 82.4% 提升至 88.3%（+5.9 pp）。這表明更強的模型能更有效地利用正確上下文修復推理錯誤。

---

## 一句話總結

> **LLM 的金融推理瓶頸不在「算不準」（12.7%），而在「理解錯了」（46.0%）。一半以上的錯誤在「概念識別」階段就已發生（50.3%）。Golden Context Injection 可修復 82.4-88.3% 的錯誤，證明瓶頸是知識取用而非能力缺失。**

---

## 附錄

### 實驗數據路徑

| 資料 | 路徑 |
|------|------|
| 錯誤分析 (N=557, full-scale) | `experiments/E1_error_analysis/results/error_analysis_all_methods_20260203_230751.json` |
| A1 全量結果 (N=1,032) | `experiments/A1_open_ended/results/run_20260206_173445/` |
| GCI GPT-4o-mini | `experiments/E1_error_analysis/results/golden_context_gpt-4o-mini_20260207_032341.json` |
| GCI GPT-5-mini | `experiments/E1_error_analysis/results/golden_context_gpt-5-mini_20260207_220440.json` |

### 論文檔案結構

```
drafts/selected/E1_error_atlas/
├── main.tex                    # 完整論文 (11 pages)
├── main.pdf                    # 編譯 PDF
├── figures/
│   ├── fig1_error_type_distribution.pdf
│   ├── fig2_topic_error_profile.pdf
│   ├── fig3_cognitive_stages.pdf
│   ├── fig4_gci_recovery.pdf
│   └── fig5_cross_model_gci.png
├── tables/
└── submission/
    └── cover_letter.tex
```
