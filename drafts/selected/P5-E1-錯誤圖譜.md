# P5 CFA 錯誤圖譜：LLM 金融推理失敗模式的系統性映射
# The CFA Error Atlas: Mapping Failure Modes of Large Language Models in Financial Reasoning

> **狀態**：✅ 論文已完成 | **頁數**：11 | **樣本量**：N=229 筆錯誤 | **目標期刊**：Finance Research Letters (FRL) / J. Financial Data Science
> **論文資料夾**：`drafts/selected/E1_error_atlas/`

---

## 研究背景與問題

當 LLM 在 CFA 題目上犯錯時，錯誤並非同質的。「不知道公式」和「知道公式但算錯」是完全不同的失敗模式，需要截然不同的修復手段。然而現有研究只報告整體 accuracy，從未系統性地分類與量化錯誤。

本研究的目標：建構一個**三維度的 CFA Error Pattern Atlas**，讓每一種失敗模式都被精確定位、計數、視覺化。**圖譜本身即為核心學術貢獻**——這是一篇 data/resource contribution paper。

---

## 核心方法

### 方法一覽

**三維度錯誤分類體系 (Error Taxonomy)**：

**Dimension 1 — Error Type（8 種錯誤類型）**
- Reasoning Premise Error、Concept Confusion、Formula Misapplication、Calculation Error 等

**Dimension 2 — CFA Topic（8 個學科領域）**
- Ethics, Quantitative Methods, Economics, Financial Reporting, Fixed Income, Derivatives, Portfolio Management 等

**Dimension 3 — Cognitive Stage（5 個認知階段）**
- Concept Identification → Formula Recall → Data Extraction → Calculation → Verification

使用 GPT-4o-mini 作為 automatic error classifier：輸入題目 + 模型錯誤回答（含 reasoning trace）+ 正確答案，輸出三個維度的分類標籤。

---

### 用一個例子理解

#### 一道 Derivatives 題目

> A European call option has S=$50, K=$55, r=5%, T=1 year. Using the put-call parity, if the put price is $8, the call price is:

**正確解法**：
Put-call parity: C = P + S − PV(K)
PV(K) = 55 / (1.05) = $52.38
C = 8 + 50 − 52.38 = **$5.62**

**模型的錯誤回答**：$13.62

**Error Attribution 過程**：

GPT-4o judge 分析模型的推理過程，發現模型寫了：
> C = P + S − K = 8 + 50 − 55 = $3... wait, let me recalculate.
> C = P + K − S = 8 + 55 − 50 = $13

→ 模型**先用錯了公式**（C = P + S − K 是對的，但中途自己「修正」成 C = P + K − S），然後在錯誤公式上計算正確。

**三維分類**：
| 維度 | 分類 |
|------|------|
| Error Type | **Formula Misapplication**（公式用反了） |
| CFA Topic | **Derivatives** |
| Cognitive Stage | **Formula Recall**（在回想公式時出錯） |

#### 對比：另一種錯誤

同一道題，另一個模型的錯誤回答：$5.72

分析推理過程：公式正確（C = P + S − PV(K)），但 PV(K) = 55/1.05 算成 52.28 而不是 52.38。

**三維分類**：
| 維度 | 分類 |
|------|------|
| Error Type | **Calculation Error**（算術出錯） |
| CFA Topic | **Derivatives** |
| Cognitive Stage | **Calculation**（在計算步驟出錯） |

→ 同一道題、同樣是錯，但錯因完全不同。前者是「不知道公式」，後者是「知道但算不準」。修復策略也不同：前者需要加強知識，後者需要加強計算精度。

---

## 實驗設計（實際執行）

| 項目 | 內容 |
|------|------|
| 資料來源 | D1 calibration 實驗中 GPT-4o-mini 的所有錯誤答案 |
| 推理方法 | 5 種：Zero-Shot, CoT, CoT+Verification, Self-Consistency, Combined |
| 題目數 | 90 題 CFA-Challenge |
| 錯誤數 | 229 筆 |
| 分類器 | GPT-4o-mini |

---

## 核心結果

### 顛覆性發現：「LLM 不會算」是迷思

| 錯誤類型 | 佔比 | 傳統印象 |
|----------|------|---------|
| **Reasoning Premise Error** | **49.3%** | 被低估 |
| Concept Confusion | 15.3% | -- |
| Formula Misapplication | 10.5% | -- |
| **Calculation Error** | **12.7%** | 被高估 |
| 其他 | 12.2% | -- |

→ 近一半的錯誤（49.3%）是**推理前提就錯了**——模型從一開始就理解錯了題意或概念。只有 12.7% 是真正的計算錯誤。**「LLM 不會算」是迷思，真正的瓶頸是「理解」。**

### 主題級錯誤剖面

| CFA 主題 | 推理類錯誤 | 計算類錯誤 | 特徵 |
|----------|-----------|-----------|------|
| **Ethics** | **87.1%** | 0% | 幾乎全是推理問題 |
| Economics | 72.3% | 8.1% | 以概念理解為主 |
| **Derivatives** | 52.5% | **37.5%** | 計算需求最高的主題 |
| Fixed Income | 61.8% | 21.4% | 公式密集 |

→ 不同 CFA 主題有截然不同的「錯誤簽名」(error signature)。

### 認知階段瓶頸

| 認知階段 | 在該階段出錯的比例 |
|---------|-------------------|
| **Concept Identification** | **53.7%** |
| Formula Recall | 18.3% |
| Data Extraction | 9.6% |
| Calculation | 12.7% |
| Verification | 5.7% |

→ 超過一半的錯誤發生在最初的「概念識別」階段。模型還沒開始算，就已經走歪了。

---

## 一句話總結

> **LLM 的金融推理瓶頸不在「算不準」（12.7%），而在「理解錯了」（49.3%）。一半以上的錯誤在「概念識別」階段就已發生——模型還沒開始算，就走歪了。**

---

## 附錄

### 實驗數據路徑

| 資料 | 路徑 |
|------|------|
| 錯誤分析 (全部方法) | `experiments/E1_error_analysis/results/error_analysis_all_methods_20260203_230751.json` |
| 錯誤分析 (CoT only) | `experiments/E1_error_analysis/results/error_analysis_cot_20260203_211957.json` |
| 原始 D1 數據 | `experiments/D1_confidence_calibration/results/run_20260202_034237/results.json` |

### 論文檔案結構

```
drafts/selected/E1_error_atlas/
├── main.tex                    # 完整論文 (11 pages)
├── main.pdf                    # 編譯 PDF
├── figures/
│   ├── fig1_error_type_distribution.pdf
│   ├── fig2_topic_error_profile.pdf
│   └── fig3_cognitive_stages.pdf
├── tables/
└── submission/
    └── cover_letter.tex
```
