# Paper A 能力的假象：壓力測試、錯誤分類與信心校準
# The Illusion of Financial Competence: Stress Testing, Error Taxonomy, and Calibration Analysis

> **目標期刊**：International Review of Financial Analysis (IRFA, IF 9.8) | **字數**：~3,675 words | **樣本量**：N=1,032 + N=557 + N=257
> **論文資料夾**：`paper_A_risk/`
> **合併自**：P2 (壓力測試) + P5 (錯誤圖譜) + P6 (信心校準)

---

## 這篇在講什麼？（30 秒版）

AI 考過 CFA 的新聞滿天飛，但我們發現：**它的高分是假的**。

1. 把題目的數字改一改，它的準確率就從 82% 掉到 64%——因為它是**背答案**，不是真的在推理。
2. 它答錯的時候，68.8% 是搞錯金融概念，不是算錯數——它是「不懂」，不是「手殘」。
3. 它答錯的時候，還表現得非常自信（信心 85%，實際只對 52%）——你根本無法從它的語氣判斷它是對是錯。

**一句話：AI 的 CFA 成績單，像是一個背了考古題、搞不清觀念、又死不承認自己不會的考生。**

---

## 研究背景

現在所有的 AI 金融基準測試（benchmark）都只報一個數字：**準確率**。

> GPT-4 通過了 CFA Level I！準確率 82%！

但這個數字回答不了三個關鍵問題：

1. **它是真的會，還是背出來的？**（Robustness）
2. **它答錯的時候，是怎麼錯的？**（Error Structure）
3. **它知道自己什麼時候是錯的嗎？**（Calibration）

本研究用三個維度拆解這個「準確率的假象」。

---

## 三個維度的方法

### 維度一：壓力測試（它是不是在背答案？）

**反事實擾動（Counterfactual Perturbation）**

把題目的數字改掉（例如利率從 5% 改成 7%），但解題步驟完全不變。如果模型真的「會」這題，改數字不應該影響答案——就像你真的懂 PV 公式，換個利率你還是會算。

> **例子**：原題問「5% 利率下的債券價格」→ 改成「7% 利率下的債券價格」
> 如果模型原本答對、改了數字就答錯 → 它可能是背了「這題答案是 $964」

**雜訊注入（Noise Injection）**

在題目裡加入四種干擾：
- N1：無關的額外數字（例如多給一個不需要的匯率）
- N2：看似相關但其實不相關的金融描述
- N3：廢話連篇的冗長敘述
- N4：暗示常見錯誤答案的矛盾提示

### 維度二：錯誤圖譜（它怎麼錯的？）

把 1,032 題的選項拿掉，讓模型自己寫答案。對所有錯誤答案（557 個）做三維分類：
- **錯誤類型**：概念錯誤？推理不完整？假設錯誤？算術錯誤？
- **CFA 主題**：哪個主題最容易錯？
- **認知階段**：是在「辨認概念」就錯了，還是「計算」的時候才錯？

然後做 **Golden Context Injection (GCI)**：告訴模型正確的金融概念，看它能不能修正答案 → 區分「不知道」vs「知道但沒想到」。

### 維度三：信心校準（它知道自己錯了嗎？）

用兩種方法測量模型的「自信程度」：
- **語言化信心**：直接問模型「你有多確定？」
- **自我一致性**：同一題問 10 次，看答案一致率

然後比較信心和準確率的差距，計算 **Confidence-at-Risk (CaR)**：類似金融的 VaR，問「有沒有一個信心門檻，能讓錯誤率低於 5%？」

---

## 用一個故事理解

想像你在面試一個分析師候選人：

| 場景 | 意義 |
|------|------|
| 你問他一個標準的 DCF 估值問題，他算對了 | 這就是「準確率 82%」—— 看起來很厲害 |
| 你把現金流的數字改了，他突然算不出來 | 這就是「記憶化缺口」——他可能是背了例題 |
| 你看他的算錯的題目，發現他用錯了 WACC 公式 | 這就是「概念錯誤 68.8%」——他不是計算機壞了，是觀念不清 |
| 你問他「你確定嗎？」他每次都說「我 85% 確定」，不管對不對 | 這就是「固定信心暫存器」——他的信心跟對錯完全脫鉤 |

這就是目前 AI 在金融推理上的真實狀態。

---

## 核心結果

### 壓力測試

| 指標 | GPT-4o-mini | GPT-5-mini |
|------|------------|------------|
| 標準準確率 | 82.4% | 91.8% |
| 擾動後準確率 | 63.8% | 55.3% |
| **記憶化缺口** | **18.6 pp** | **36.4 pp** |
| 穩健準確率 | 63.5% | 67.2% |

**記憶化悖論**：更強的模型（GPT-5-mini）記憶化缺口反而更大！它的進步大部分來自「更會背」而不是「更會想」。

### 雜訊敏感度

| 雜訊類型 | 準確率 | NSI | 解讀 |
|---------|--------|-----|------|
| 乾淨版 | 81.6% | --- | 基準 |
| N1 無關數據 | 79.0% | 0.032 | 微弱影響 |
| N2 誤導性描述 | 80.3% | 0.015 | 極微影響 |
| N3 冗長廢話 | 82.0% | -0.005 | 無影響 |
| N4 矛盾提示 | 87.5% | -0.072 | 反而幫助！ |

N4（告訴模型「常見錯誤答案是 X」）反而讓準確率提升 → 模型可能藉此排除錯誤選項。

### 錯誤分類

| 錯誤類型 | 比例 | 說明 |
|---------|------|------|
| 概念錯誤 | 68.8% | 用錯公式、搞混概念 |
| 推理不完整 | 10.8% | 少算一步 |
| 假設錯誤 | 10.6% | 假設條件不對 |
| 閱讀錯誤 | 2.2% | 看錯題目 |
| 計算錯誤 | 1.4% | 真正的「算錯」 |

**90.1% 的錯誤都是推理類**。給它計算機沒有用——它不是算不了，是搞不懂要算什麼。

### 黃金上下文注入 (GCI)

| 恢復程度 | GPT-4o-mini | GPT-5-mini |
|---------|------------|------------|
| 完全恢復 | 25.5% | 50.4% |
| 部分恢復 | 56.9% | 37.9% |
| 仍然錯誤 | 17.6% | 11.7% |
| 任何改善 | 82.4% | 88.3% |

82.4% 的錯誤在給了正確概念後能改善 → 大部分是「知識缺口」，RAG 系統有幫助。但 17.6% 無法修復 → 這是真正的推理缺陷。

### 信心校準

| 指標 | CFA-Challenge (N=90) | CFA-Easy (N=1,032) |
|------|---------------------|-------------------|
| 準確率 | 52.6% | 81.7% |
| 平均信心 | 84.1% | 86.0% |
| ECE | 0.315 | 0.073 |
| 過度自信缺口 | +31.5 pp | +4.3 pp |
| 高信心錯誤率 | 40.0% | 15.1% |

模型永遠說自己「85% 確定」——不管題目難不難。這是一個**固定信心暫存器**，沒有真正的元認知能力。

**CaR(5%) = 未定義**：沒有任何信心門檻能把錯誤率壓到 5% 以下。即使模型說「我 100% 確定」，錯誤率仍有 32.4%（放寬到信心 ≥ 90% 則為 41.7%）。

---

## 一句話總結

> **AI 的 82.4% CFA 準確率是一場假象：其中 18.6% 是背出來的（壓力測試），答錯時 90% 是概念搞不懂（錯誤圖譜），而且它完全不知道自己什麼時候是錯的（信心校準 CaR 未定義）。更糟的是，更強的模型（GPT-5-mini）更會背答案，記憶化缺口幾乎翻倍。**

---

## 實務意義

**對金融機構**：不能只看 AI 的準確率就放心部署。要同時測試「穩健準確率」、「錯誤結構」和「信心校準品質」。我們提出的 CaR 指標類似金融界的 VaR，是一個監管可用的風險量化工具。

**對 AI 監管**：我們建議分級部署標準：
- Tier 1（客戶諮詢級）：ECE < 0.15，記憶化缺口 < 10%
- Tier 2（研究級）：ECE < 0.25，記憶化缺口 < 20%
- Tier 3（內部使用）：ECE < 0.35，需附加免責聲明

目前沒有任何測試模型達到 Tier 1 或 Tier 2 標準。

---

## 附錄

### 合併邏輯

三篇原始論文回答同一個核心問題的不同面向：
- P2 問「它的高分是真的嗎？」→ 壓力測試
- P5 問「它錯的時候怎麼錯？」→ 錯誤圖譜
- P6 問「它知道自己錯嗎？」→ 信心校準

三者合併成一個「三維評估框架」，比單獨看任何一個維度都更有說服力。

### 實驗數據路徑

| 資料 | 路徑 |
|------|------|
| I1 反事實擾動 GPT-4o-mini | `experiments/I1_counterfactual/results/run_20260206_170129/` |
| I1 反事實擾動 GPT-5-mini | `experiments/I1_counterfactual/results/run_20260207_174116/` |
| I3 雜訊注入 GPT-4o-mini (N=1,032) | `experiments/I3_noise_red_herrings/results/run_20260206_203913/` |
| I3 雜訊注入 GPT-5-mini (N=1,032) | `experiments/I3_noise_red_herrings/results/run_20260207_174115/` |
| E1 錯誤分析 GPT-4o-mini | `experiments/E1_error_analysis/results/error_analysis_all_methods_20260203_230751.json` |
| E1 GCI GPT-4o-mini | `experiments/E1_error_analysis/results/golden_context_gpt-4o-mini_20260207_032341.json` |
| E1 GCI GPT-5-mini | `experiments/E1_error_analysis/results/golden_context_gpt-5-mini_20260207_220440.json` |
| D1 信心校準 CFA-Challenge | `experiments/D1_confidence_calibration/results/run_20260202_034237/` |
| D1 信心校準 CFA-Easy | `experiments/D1_confidence_calibration/results/run_20260210_152709/` |
