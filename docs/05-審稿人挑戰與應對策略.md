# 審稿人挑戰與應對策略

## 前言

本文件針對基於本研究資料庫（CFA+LLM）所撰寫之論文，預先整理審稿人可能提出的質疑，
並準備嚴謹、具體且有數據支撐的回應策略。每項挑戰皆包含：問題描述、預期審稿人立場、
以及 3-5 個具體防禦論點（含量化佐證）。

本文件假設讀者已閱讀 `博士論文研究指南.md` 及 `CFA數據集完整分析.md`，
對本研究之數據集結構與研究框架有基本了解。

---

## Challenge 1: 為什麼不使用 CFA Institute 官方真題？

### 問題描述

審稿人可能質疑：「為何不使用 CFA Institute 官方考試題目？使用第三方教材編製的題目
是否能真正反映 LLM 在專業金融考試上的能力？」

### 預期審稿人立場

審稿人可能認為僅有官方真題才能代表真實考試難度與知識覆蓋範圍，
使用非官方題目會降低研究結論的可信度與外部效度（external validity）。

### 防禦策略

1. **官方真題受嚴格版權保護，學術研究不可能合法取得。**
   CFA Institute 對考試題目實施極為嚴格的保密措施，所有考生須簽署保密協議，
   從未公開釋出任何歷年真題。全球所有 CFA+LLM 研究均面臨相同限制，
   這並非本研究之特有缺陷。

2. **SchweserNotes 是業界最受認可的第三方 CFA 備考教材。**
   Kaplan SchweserNotes 由持有 CFA Charter 的專業人士編寫，題目設計
   嚴格對齊 CFA Institute 公佈的 Learning Outcome Statements (LOS)，
   覆蓋全部 10 個主題領域，難度與格式（item-set format for Level II）
   忠實模擬真實考試。

3. **頂級會議已有使用同源數據的先例。**
   FinDAP（Ke et al., 2025）獲得 EMNLP 2025 Oral 接受，其訓練數據
   （cfa_exercise, 2946 題）即來自 SchweserNotes。此先例證明頂級 NLP 會議
   認可此類數據來源的學術價值。

4. **不公開數據的研究更缺乏科學價值。**
   arXiv:2509.04468 聲稱使用 1,560 道「CFA 官方模擬考題」，但未公開數據集、
   未釋出程式碼，完全不可重現（non-reproducible）。相比之下，本研究所有數據集
   均公開於 HuggingFace，可重現性（reproducibility）是科學研究的基石。

5. **所有評測數據完全公開可存取。**
   FinEval-CFA-Challenge（90 題）、FinEval-CFA-Easy（1032 題）、
   CRA-Bigdata（1472 題），總計 2594 道評測題目，
   全部由 Salesforce 發布於 HuggingFace。

---

## Challenge 2: 數據量是否足夠？

### 問題描述

CFA-Challenge 僅有 90 題。審稿人可能質疑樣本量是否足以支撐統計上有意義的結論，
訓練數據量是否足以實現有效的 domain adaptation。

### 預期審稿人立場

審稿人可能援引統計檢定力（statistical power）不足的論點，
認為小樣本下的準確率差異不具有統計顯著性。

### 防禦策略

1. **嚴格的統計顯著性計算。**
   對於 CFA-Challenge（n=90）：
   若 p=0.60，95% CI = 0.60 +/- 1.96*sqrt(0.60*0.40/90) = 0.60 +/- 0.101
   若 p=0.70，95% CI = 0.70 +/- 1.96*sqrt(0.70*0.30/90) = 0.70 +/- 0.095
   即約 +/-10%，兩模型差異超過 20% 即具有統計顯著性。
   對於 CFA-Easy（n=1032）：
   CI = 0.70 +/- 1.96*sqrt(0.70*0.30/1032) = 0.70 +/- 0.028，即約 +/-3%，
   足以檢測 6% 以上的準確率差異。

2. **多數據集交叉驗證。**

   | 數據集 | 題數 | 95% CI 寬度 | 用途 |
   |--------|------|-------------|------|
   | CFA-Challenge | 90 | +/-10% | 高難度壓力測試 |
   | CFA-Easy | 1032 | +/-3% | 主要統計驗證 |
   | CRA-Bigdata | 1472 | +/-2.5% | 大規模穩健性驗證 |
   | **合計** | **2594** | **+/-1.9%** | **綜合評估** |

   三個數據集結論一致則大幅提升可信度；若不一致則差異本身是有價值的分析素材
   （例如：難度敏感性分析）。

3. **訓練數據量與同類研究相當。**
   可用 domain-specific 訓練數據：
   - cfa_exercise: 2946 題（FinDAP 官方訓練集）
   - CFA_Extracted-sft: 2946 題（SFT 格式）
   - chunk_0: 1124 題（額外訓練數據）
   - 合計約 7000 筆 domain-specific 訓練樣本

   FinDAP（EMNLP 2025 Oral）使用相似規模數據。Med-PaLM 使用約 3000 筆
   醫學 QA 進行 instruction tuning，規模亦相當。

4. **數據質量優於數據數量。**
   所有訓練數據均為專業金融人士（CFA Charterholder）編撰，對齊官方課綱（LOS），
   包含完整題幹、選項與詳細解析，格式統一且經品質檢查。
   高品質 domain-specific 數據的效果遠優於大量但品質參差的通用數據。

5. **與 FinDAP 的數據規模一致。**
   FinDAP 使用類似規模數據並獲 EMNLP 2025 Oral 接受。我們的數據規模與其一致，
   且在評測端提供更多維度的分析（calibration、error taxonomy），
   進一步強化結論的穩健性。

---

## Challenge 3: 為什麼主要只有 Level II 數據？

### 問題描述

CFA 考試分三個級別（Level I、II、III），本研究核心數據主要來自 Level II。
審稿人可能質疑研究結果能否推廣至其他級別。

### 預期審稿人立場

審稿人可能認為僅覆蓋一個級別缺乏通用性（generalizability），
無法得出關於「LLM 在 CFA 考試上表現」的一般性結論。

### 防禦策略

1. **範圍限定是標準學術實踐。**
   明確定位為「Level II domain adaptation 研究」，頂級會議論文經常聚焦於特定子問題。

2. **Level II 的 item-set format 對 LLM 構成最大挑戰。**
   Level II 採用 vignette-based item set 格式（情境描述 + 4 道關聯題），
   同時要求長文本理解、多步推理與跨題一致性。三級中的格式挑戰度排序：
   - Level II: item-set format，需情境理解與多步推理
   - Level III: MCQ 部分與 Level I 類似（另含 essay 題）
   - Level I: 獨立單選題，無需跨題推理
   若模型在 Level II 表現良好，可合理推論 Level I 表現更佳。

3. **Level II 完整覆蓋 CFA 全部 10 個主題領域。**
   包括：Ethical and Professional Standards、Quantitative Methods、Economics、
   Financial Statement Analysis、Corporate Issuers、Equity Valuation、
   Fixed Income、Derivatives、Alternative Investments、Portfolio Management。
   雖僅聚焦 Level II，但知識覆蓋範圍完整。

4. **提供初步跨級別比較。**
   CFA_Level_III 數據集（90 道 MCQ）可作為 Level II vs Level III
   表現差異的初步參照，為 future work 提供方向。

5. **Future work 明確規劃擴展路徑。**
   論文 Future Work 部分列出：
   - 擴展至 Level I（獨立 MCQ 格式）
   - 擴展至 Level III（essay + MCQ 混合格式）
   - 跨級別遷移學習（cross-level transfer learning）研究

---

## Challenge 4: Multi-Agent / Reasoning Strategies 是否必要？

### 問題描述

審稿人可能質疑：「為什麼需要 multi-agent 系統？單一 LLM 搭配適當 prompting
是否就能達到類似效果？增加的系統複雜度是否合理？」

### 預期審稿人立場

審稿人可能傾向奧卡姆剃刀（Occam's Razor），認為在效果相當的情況下
應偏好更簡單的方法。

### 防禦策略

1. **必須提供完整的 ablation study。**
   論文必須包含以下對比實驗：

   | 配置 | CFA-Challenge | CFA-Easy | CRA-Bigdata | 計算成本 |
   |------|--------------|----------|-------------|----------|
   | Single Agent (zero-shot) | baseline | baseline | baseline | 1x |
   | Single Agent + CoT | +a% | +b% | +c% | ~1.5x |
   | Single Agent + 5-Stage Pipeline | +d% | +e% | +f% | ~2x |
   | Multi-Agent (specialist ensemble) | +g% | +h% | +i% | ~Nx |

   只要 ablation 顯示統計上顯著的準確率提升，質疑即可有效回應。

2. **CFA 考試的多領域特性天然適合 specialist agents。**
   10 個主題領域需要截然不同的專業知識：
   - Ethics: 需要法規知識與道德推理
   - Quantitative Methods: 需要數學計算與統計推理
   - Financial Statement Analysis: 需要會計知識與報表解讀
   - Fixed Income: 需要利率模型與債券定價
   - Derivatives: 需要衍生品定價公式與風險分析
   specialist agents 各自專注特定領域再由 meta-agent 整合，直覺上合理。

3. **成本效益分析（cost-benefit analysis）。**
   論文必須報告每種策略的 token 消耗量、API 調用次數、推理延遲，
   以及「準確率提升 / 額外成本」比值。
   例如：若 multi-agent 將準確率從 65% 提升至 75%（+10%），
   計算成本增加 3 倍，則每 1% 提升的成本為 0.3x 原始成本。

4. **必要性是實證問題，讓數據說話。**
   論文中應聲明：「We do not claim that multi-agent systems are always
   necessary. Instead, we provide empirical evidence showing under what
   conditions and for which topic areas multi-agent approaches provide
   significant benefits.」
   這種謙遜且數據驅動的論述方式遠比強硬宣稱更有說服力。

5. **不同主題受益於不同策略。**
   分主題分析可揭示：Quantitative Methods 受益於 tool-augmented reasoning、
   Ethics 受益於 multi-perspective deliberation、Financial Statement Analysis
   受益於 structured extraction。這種精細化分析本身就是研究貢獻。

---

## Challenge 5: CoT 等技術是否缺乏新穎性？

### 問題描述

審稿人可能指出：Chain-of-Thought (CoT)、ReAct、RAG 均為成熟技術，
將其應用於 CFA 題目並無技術創新。

### 預期審稿人立場

審稿人可能認為本研究僅是「舊技術 + 新數據集」的簡單組合，
缺乏足夠的方法論創新（methodological novelty）。

### 防禦策略

1. **創新在於領域特定的認知流程設計（cognitive pipeline）。**
   五階段流程：
   (i) 題目解析（Question Parsing）：識別題型、主題領域、關鍵概念
   (ii) 知識檢索（Knowledge Retrieval）：定位 CFA 課程相關知識點
   (iii) 計算執行（Computation）：調用金融計算工具（TVM, bond pricing 等）
   (iv) 推理驗證（Reasoning Verification）：交叉檢查計算結果與推理邏輯
   (v) 答案校準（Answer Calibration）：基於置信度進行答案選擇
   這是領域特定設計，非通用 CoT 的簡單套用。

2. **金融計算工具整合是領域特定創新。**
   CFA 涉及大量精確數值計算（TVM, Modified Duration, Black-Scholes,
   WACC, DDM, DCF），LLM 在純數值計算上存在已知弱點。
   LLM + Calculator 的整合方式是針對金融考試場景的創新設計。

3. **首次在專業金融考試上進行 calibration 研究。**
   系統性測量 Expected Calibration Error (ECE)、AUROC for selective prediction、
   Reliability diagram。在金融應用中，錯誤的高信心預測可能造成嚴重後果，
   calibration 分析尤為重要。

4. **金融推理錯誤分類法（Error Taxonomy）是原創貢獻。**
   建立的錯誤分類包含：
   - 知識缺失（Knowledge Gap）：模型缺乏特定金融概念的知識
   - 計算錯誤（Computation Error）：數值計算失誤
   - 推理鏈斷裂（Reasoning Chain Break）：推理過程中的邏輯跳躍
   - 概念混淆（Concept Confusion）：將相似但不同的金融概念混為一談
   - 情境誤讀（Context Misinterpretation）：對 vignette 中的資訊理解錯誤
   這為理解 LLM 金融推理弱點提供系統化洞察，且具實際教學應用價值。

5. **系統性比較本身是 systems paper 的貢獻。**
   在標準化金融基準上比較多種推理策略，揭示哪些主題受益於哪種策略。
   Systems/benchmark paper 在 ACL、EMNLP 中是被認可的貢獻類型。

---

## Challenge 6: 評估指標是否全面？

### 問題描述

審稿人可能質疑：「僅使用準確率（accuracy）作為評估指標是否足夠？
這無法反映模型推理過程的品質。」

### 預期審稿人立場

審稿人期望看到多維度的評估框架，而非僅依賴單一指標。

### 防禦策略

1. **多維度評估框架，五大類指標。**
   - **Accuracy Metrics**: 整體準確率、分主題準確率（10 個 CFA 主題）、
     分難度準確率（Easy vs Challenge）
   - **Calibration Metrics**: ECE、AUROC for Selective Prediction、Brier Score
   - **Reasoning Quality Metrics**: 推理步驟正確率、邏輯一致性、計算正確率
   - **Computational Cost Metrics**: 推理延遲、API 調用次數、token 消耗量
   - **Error Analysis Metrics**: 錯誤類型分布、分主題錯誤模式、錯誤嚴重度分級

2. **分主題細粒度分析。**
   10 個 CFA 主題分別報告，揭示模型的知識分布特徵：
   哪些主題表現優異（如 Ethics 因規則明確）、
   哪些表現不佳（如 Derivatives 因計算複雜），
   以及不同策略對不同主題的效果差異。

3. **難度分層分析。**
   利用 CFA-Easy 與 CFA-Challenge 進行難度敏感性分析：
   模型是否在簡單題目接近人類水準但在困難題目急劇下降？
   不同策略在不同難度上效果是否一致？

4. **人類基準比較。**
   CFA Institute 公佈的歷史通過率提供人類基準：
   - Level I: 約 35-45% 通過率（近年趨勢）
   - Level II: 約 40-50% 通過率
   - Level III: 約 48-56% 通過率
   通過分數（minimum passing score）業界估計約 60-70%。
   這些數據提供 contextualizing 模型表現的有意義參照。

5. **統計顯著性檢驗。**
   - McNemar's test: 比較兩個模型在相同題目上的表現差異
   - Bootstrap confidence intervals: 提供穩健區間估計
   - Bonferroni correction: 多重比較時的顯著性校正
   - Effect size（Cohen's h）: 報告效果量，而非僅報告 p-value

---

## 額外準備：常見技術質疑

### Q1: 如何確保 evaluation 沒有 data leakage？

- 訓練數據（FinTrain）與評測數據（FinEval）由 Salesforce 官方分離，
  分別發布於不同 HuggingFace 資料集
- 執行系統性 overlap detection：exact match 比對 + fuzzy matching
  （Jaccard similarity > 0.8），確認零重疊
- 評測數據集僅用於最終報告，不用於超參數調優
- 承認 base model（Llama-3-8B）預訓練數據可能包含金融文本，
  這是所有 LLM 研究的共同限制

### Q2: 結果是否可重現？

- 所有數據集公開於 HuggingFace（Salesforce 命名空間的 FinEval/FinTrain、
  ZixuanKe/ 命名空間的 pre-tokenized 數據）
- 程式碼完整開源，評測使用標準化 lm-evaluation-harness（EleutherAI）
- 固定隨機種子、完整超參數文件（YAML/JSON 格式）、硬體規格記錄
- 報告 prompt template 完整內容及 decoding 參數（temperature, top_p, max_tokens）

### Q3: 與 FinDAP 的關係？

- 建立在 FinDAP 基礎上：使用其數據集（FinTrain, FinEval）、
  訓練框架（posttrain.py）、模型（Llama-Fin-8B）作為基線
- 貢獻方向正交（orthogonal）：FinDAP 聚焦 domain-adaptive post-training，
  我們聚焦 reasoning strategies、calibration、error taxonomy
- FinDAP 回答「如何訓練好的金融 LLM」，
  我們回答「如何讓金融 LLM 更好地推理」——互補而非競爭
- 論文中明確引用 FinDAP 並在 Related Work 中詳細討論

### Q4: 為什麼選擇 Llama-3-8B 而非更大或更新的模型？

- 與 FinDAP 對齊，確保結果可直接比較
- 8B 參數量使完整 ablation study 在合理計算預算內可行
- 研究焦點是 reasoning strategies 效果，非模型規模效應
- 在更大模型（70B+）和更新模型（Llama-3.1, Qwen-2.5）上的驗證列為 future work

### Q5: 如何處理 LLM 的隨機性（stochasticity）？

- 所有實驗至少運行 3 次（不同隨機種子），報告平均值與標準差
- 評測使用 temperature=0（greedy decoding）確保確定性
- 使用 paired tests（McNemar's test）在相同題目上比較不同模型/策略
- 所有數值附帶 95% 信賴區間

---

## 應對策略總結

### 核心原則

1. **數據驅動**: 所有主張必須有實驗數據支撐，避免空泛論述
2. **承認限制**: 主動承認研究限制（scope, data size），展現學術誠信
3. **量化論證**: 提供具體數字（CI 寬度、p-value、effect size）
4. **先例引用**: 引用頂級會議論文作為方法論先例
5. **正交定位**: 明確區分本研究與相關工作的貢獻方向

### 論文撰寫檢查清單

在提交前，確保論文包含以下內容：

- [ ] 完整的 ablation study 表格
- [ ] 所有比較的統計顯著性檢驗結果
- [ ] 95% 信賴區間（所有報告的數值）
- [ ] 分主題細粒度結果（10 個 CFA 主題）
- [ ] 分難度結果（Easy vs Challenge）
- [ ] Calibration 分析（ECE, AUROC, reliability diagram）
- [ ] Error taxonomy 與案例分析
- [ ] 計算成本報告（latency, token usage）
- [ ] Data leakage 檢查聲明
- [ ] 可重現性聲明（程式碼、數據、超參數）
- [ ] Limitation 段落（主動承認限制）
- [ ] Future work 段落（明確後續研究方向）
- [ ] 適當引用 FinDAP 及相關工作

### 各挑戰的最強防禦論點

| 挑戰 | 最強防禦 | 關鍵數據 |
|------|---------|---------|
| 非官方題目 | 可重現性 > 官方但不公開的數據 | arXiv:2509.04468 無法重現 |
| 數據量不足 | 多數據集交叉驗證 | 2594 題評測, CI +/-1.9% |
| 僅 Level II | 範圍限定 + Level II 最具挑戰性 | 10 個主題完整覆蓋 |
| Multi-Agent 必要性 | Ablation study | 量化準確率提升與計算成本 |
| 技術新穎性不足 | 領域特定設計 + Calibration + Error Taxonomy | 五階段認知流程 |
| 評估指標不全 | 多維度評估框架 | 5 大類指標 |

---

## 附錄：相關文獻快速索引

以下文獻在回應審稿人時可能需要引用：

1. **FinDAP** (Ke et al., 2025) -- EMNLP 2025 Oral, domain-adaptive post-training
2. **arXiv:2509.04468** -- CFA benchmark study, 未公開數據集
3. **arXiv:2507.02954** -- CFA Level III 評測, 23 個 LLM
4. **lm-evaluation-harness** (Gao et al., 2024) -- 標準化評測框架
5. **Med-PaLM** (Singhal et al., 2023) -- 醫學領域 domain adaptation 先例
6. **Chain-of-Thought** (Wei et al., 2022) -- CoT prompting 原始論文
7. **ReAct** (Yao et al., 2023) -- Reasoning + Acting 框架
8. **Calibration of LLMs** (Kadavath et al., 2022) -- LLM 校準度研究

---

*本文件最後更新：2026-01-30*
*建議搭配 `博士論文研究指南.md` 及 `CFA+AI研究深度分析與機會.md` 一併閱讀*
