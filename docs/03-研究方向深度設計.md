# 研究方向深度設計：CFA + LLM 博士研究藍圖

## 前言

本文件綜合了先前對現有研究文獻的全面梳理（包括 FinDAP / EMNLP 2025、CFA Level III 大規模評估、FinanceMath 基準測試等）、對本倉庫十三個資料集的深度分析，以及對當前金融 LLM 領域研究空白的系統性識別，提出七個具體的博士研究方向。每個方向均包含明確的新穎貢獻（Novel Contribution）、可操作的實驗設計、資料需求分析，以及目標發表場所。這七個方向並非互斥，而是形成一個可相互支撐的研究生態系統，使研究者能夠依照時間線與資源狀況，靈活拆分為四至五篇獨立論文。

本文件的設計原則如下：

1. **可操作性優先**：每個方向都附有具體的實驗步驟，而非僅停留在概念層面。
2. **資源現實主義**：明確標註是否需要 GPU 訓練、資料是否已就緒，以及預估的產出時間。
3. **學術嚴謹性**：每個方向的新穎貢獻均經過與現有文獻的差異分析，確保不與已發表工作重疊。
4. **技術連貫性**：七個方向之間存在技術銜接，後續方向可以復用前期方向的實驗基礎設施與分析結果。

---

## 方向 1：Structured Financial Reasoning Decomposition

### 1.1 研究問題

當 LLM 回答一道 CFA 題目時，其失敗究竟發生在認知過程的哪個環節？是無法辨識題目涉及的金融概念？是遺忘了正確的公式或原則？是從題幹中提取數值與條件時出錯？是計算過程本身有誤？還是未能對最終結果進行合理性驗證？現有研究（包括 arXiv 2507.02954 的 CFA Level III 評估與 arXiv 2509.04468 的跨 Level 基準研究）均僅報告最終答案的正確率，而未能定位失敗的精確環節，這使得改進方向不明確。

### 1.2 技術方法

設計一個五階段認知管道（Cognitive Pipeline），模擬 CFA 考生的解題過程：

```
Stage 1: Concept Identification
  -- 輸入：完整題目
  -- 輸出：涉及的金融概念列表（如 Duration, Convexity, Immunization）
  -- 評估：與 ground truth 概念集合的 precision/recall

Stage 2: Formula / Principle Recall
  -- 輸入：Stage 1 辨識出的概念
  -- 輸出：應適用的公式或原則
  -- 評估：公式正確性（精確匹配 + 語義等價判斷）

Stage 3: Numerical / Condition Extraction
  -- 輸入：題幹文本（含 exhibit / scenario）
  -- 輸出：結構化的數值與條件（JSON 格式）
  -- 評估：與人工標註的數值集合比對

Stage 4: Calculation Execution
  -- 輸入：Stage 2 的公式 + Stage 3 的數值
  -- 輸出：計算結果
  -- 評估：與正確答案的數值比較（容許合理精度誤差）

Stage 5: Reasonableness Verification
  -- 輸入：Stage 4 的結果 + 原始題目情境
  -- 輸出：合理性判斷（結果是否在合理範圍內）
  -- 評估：是否能偵測到自身計算錯誤
```

每個 Stage 獨立評估準確率，並計算各 Stage 對最終錯誤的貢獻比例。

### 1.3 實驗設計

**實驗 1：Stage-wise Accuracy Profiling**

- 使用 FinEval-CFA-Challenge（90 題）與 FinEval-CFA-Easy（1,032 題）作為測試集
- 對每道題目，分別在五個 Stage 強制中斷並評估該 Stage 的輸出
- 測試模型：GPT-4o, Claude Opus, Llama-Fin-8b, Llama-3-8B-Instruct（基線）
- 報告：每個 Stage 的準確率、各 Stage 的錯誤累積曲線

**實驗 2：Error Attribution Analysis**

- 對所有最終回答錯誤的題目，回溯標記首個出錯的 Stage
- 建立 Error Attribution Matrix：行為 CFA 主題（Ethics, Quantitative Methods, Fixed Income 等），列為五個 Stage
- 統計分析：哪些主題在哪個 Stage 最容易出錯

**實驗 3：與現有推理策略的嚴格對比**

- Baseline 1：Zero-shot Direct Answer
- Baseline 2：Few-shot (3-shot, 5-shot)
- Baseline 3：Vanilla Chain-of-Thought
- Baseline 4：Self-Consistency (k=5, 10)
- Proposed：Structured 5-Stage Pipeline
- 評估指標：Accuracy, Stage-wise Error Rate, Error Attribution Distribution

**實驗 4：教育診斷應用**

- 基於 Error Attribution Matrix，為每個 CFA 主題產生「學習建議報告」
- 與 CFA 教育專家合作評估報告的實用性（如果可行）

### 1.4 資料需求

- **主要測試資料**：FinEval-CFA-Challenge（90 題）+ FinEval-CFA-Easy（1,032 題），均已就緒
- **Stage Ground Truth 建構**：利用 CFA_Extracted-chunk_0 的 material、scenario、exhibit、gpt4_answer_justification 欄位，可半自動建構各 Stage 的 ground truth
  - material 欄位 → Stage 1 的概念列表
  - gpt4_answer_justification 欄位 → Stage 2 的公式、Stage 4 的計算過程
  - scenario / exhibit 欄位 → Stage 3 的數值提取
- **人工標註**：需要約 200 題的完整五階段人工標註作為 gold standard，預計需要具備 CFA 知識的標註者 40-60 小時工作量
- **無需額外訓練資料**：本方向為推論分析型研究

### 1.5 預期結果

- 揭示 LLM 在 CFA 推理中的「瓶頸環節」，預期 Stage 3（數值提取）與 Stage 4（計算執行）為主要失敗點
- 建立首個 CFA 領域的 Stage-wise Error Profile，為後續的針對性改進提供精確路線圖
- 預期 Structured Pipeline 相較於 Vanilla CoT 在準確率上提升 3-8%

### 1.6 新穎貢獻

- **領域認知科學與 NLP 的交叉研究**：首次將認知心理學中的問題解決階段理論應用於金融 LLM 的錯誤分析
- **Stage-wise Error Attribution**：超越「黑箱式」的最終準確率報告，提供可操作的診斷資訊
- **金融教育應用**：直接產出對 CFA 考生與教育者有價值的學習診斷工具
- **方法論的通用性**：Structured Reasoning Decomposition 的框架可以遷移至醫學執照考試（USMLE）、法律考試（Bar Exam）等其他專業領域

### 1.7 目標發表場所

- **首選**：ACL 2026 / EMNLP 2026（主會議）
- **次選**：AAAI 2027
- **期刊備選**：Artificial Intelligence in Education (AIED)

---

## 方向 2：Calibration & Selective Prediction for Financial LLMs

### 2.1 研究問題

LLM 在回答 CFA 題目時，其表達的信心程度是否與實際正確率一致？當模型「非常有信心」但實際答錯時，這種 overconfidence 在哪些 CFA 主題上最為嚴重？能否設計一個 abstention 機制，讓模型在不確定時選擇放棄回答，從而在回答的題目上達到更高的準確率？這些問題對於金融監管（Financial Regulation）具有直接的政策含義：若 LLM 被用於金融決策輔助，其 calibration 品質直接關係到系統性風險。

### 2.2 技術方法

**Calibration 度量**

- Expected Calibration Error (ECE)：將預測概率分為 M 個 bin，計算每個 bin 內的平均信心與實際準確率的加權差距
- Maximum Calibration Error (MCE)：所有 bin 中最大的校準誤差
- Brier Score：同時衡量校準與鑑別力的綜合指標

**信心估計方法（四種對比）**

```
Method 1: Logit-based Confidence
  -- 使用模型輸出 logits 中正確選項的 softmax 概率
  -- 僅適用於開放權重模型（Llama-Fin-8b, Llama-3-8B）

Method 2: Verbalized Confidence
  -- 要求模型在回答後自我評估信心（0-100%）
  -- 適用於所有模型（包括 API-only 模型）

Method 3: Ensemble Disagreement
  -- 使用多個模型（或同一模型不同 temperature）的答案分歧程度
  -- 高分歧 = 低信心

Method 4: Self-Consistency Variance
  -- 同一題目採樣 k 次（k=10,20），計算答案的一致性比例
  -- 一致性越低 = 信心越低
```

**Selective Prediction 機制**

- 設定信心閾值 theta，僅回答信心 >= theta 的題目
- 繪製 Coverage-Accuracy Trade-off 曲線
- 計算 AUROC（Area Under Receiver Operating Characteristic）：衡量信心分數區分正確/錯誤回答的能力
- 計算 AUPRC（Area Under Precision-Recall Curve）：在類別不平衡情況下的補充指標

### 2.3 實驗設計

**實驗 1：全面 Calibration 分析**

- 測試模型：GPT-4o, Claude Opus, Gemini 2.5 Pro, Llama-Fin-8b, Llama-3-8B-Instruct
- 測試資料：FinEval-CFA-Challenge + FinEval-CFA-Easy + flare-cfa（交叉驗證）
- 四種信心估計方法的 ECE / MCE / Brier Score 計算
- 繪製 Reliability Diagram（橫軸：信心，縱軸：實際準確率）

**實驗 2：Topic-wise Overconfidence Analysis**

- 按 CFA 主題分類所有題目（Ethics, Quantitative Methods, Economics, Financial Reporting, Corporate Issuers, Equity, Fixed Income, Derivatives, Alternative Investments, Portfolio Management）
- 對每個主題單獨計算 ECE
- 識別「最危險主題」：模型最 overconfident 的主題
- 分析原因：是否與主題的知識密集程度或計算複雜度有關

**實驗 3：Selective Prediction Trade-off**

- 對每個信心估計方法，繪製 Coverage-Accuracy 曲線
- 計算不同 coverage 水平（100%, 90%, 80%, 70%, 60%, 50%）下的準確率
- 實際場景模擬：若 LLM 被用作 CFA 備考助教，在什麼 coverage 水平下準確率可達 95%？

**實驗 4：Calibration 與模型規模 / 訓練方法的關係**

- 比較 Llama-3-8B-Instruct（基礎）vs Llama-Fin-8b（FinDAP 訓練後）的 calibration 變化
- 分析問題：Domain-adaptive post-training 是否改善了 calibration？或者反而造成了新的 overconfidence？
- 此分析直接與 FinDAP 論文對話

### 2.4 資料需求

- **測試資料**：FinEval-CFA-Challenge（90 題）+ FinEval-CFA-Easy（1,032 題）+ flare-cfa（1,032 題用於交叉驗證），均已就緒
- **主題標註**：需要為每道題目標註 CFA 主題分類，可利用 CFA_Extracted 的 material 欄位半自動分類，預計需要 10-15 小時人工校驗
- **計算資源**：
  - 開放權重模型（Llama 系列）：需要單張 A100 或等效 GPU 進行推論，約 2-4 小時
  - API 模型（GPT-4o, Claude, Gemini）：僅需 API 費用，預估 200-400 美元
- **無需 GPU 訓練**：本方向為純推論 + 統計分析研究

### 2.5 預期結果

- 預期發現：所有主流 LLM 在 CFA 領域均存在顯著的 overconfidence（ECE > 0.10）
- 預期 Verbalized Confidence 的 calibration 品質最差（模型傾向於誇大自信）
- 預期 Self-Consistency Variance 為最佳信心估計方法
- 預期在 coverage = 70% 時，最佳模型的準確率可從約 78% 提升至約 90%
- 預期 Derivatives 與 Quantitative Methods 為最 overconfident 的主題

### 2.6 新穎貢獻

- **首個專業金融考試的 LLM Calibration 研究**：現有 calibration 研究集中於通用問答（TriviaQA, MMLU），本研究首次聚焦於高風險的專業金融場景
- **金融監管政策含義**：Calibration 品質直接關係到 LLM 在金融決策輔助中的可信度，研究結果對金融科技監管（如 SEC 對 AI 使用的指引）具有實質性參考價值
- **Domain-adaptive Training 對 Calibration 的影響**：首次分析 FinDAP 風格的領域適應訓練是否改善或惡化了模型的 calibration
- **最快產出路徑**：無需 GPU 訓練，僅需推論與統計分析，預估 2-3 個月可產出完整結果

### 2.7 目標發表場所

- **首選**：ACL 2026 / EMNLP 2026（NLP 頂會，關注 LLM reliability）
- **高影響力備選**：Management Science（管理科學頂刊，Technology Track 歡迎 AI 信任度研究）
- **金融科技**：Journal of Financial Technology / Journal of Finance（Technology Track）
- **交叉領域**：AAAI 2027（AI Safety & Trustworthiness Track）

---

## 方向 3：CFA Knowledge Graph Augmented Generation (KG-RAG)

### 3.1 研究問題

傳統 RAG 系統基於語義相似度檢索文本片段，但 CFA 考試中的許多題目需要多跳推理（multi-hop reasoning）：例如，理解 immunization strategy 需要先理解 duration，而 duration 又依賴於 yield curve 的知識。這種知識間的前置依賴（prerequisite dependencies）、應用關係（applied_in）、衝突關係（conflicts_with）無法被純粹的語義相似度捕捉。構建一個 CFA Knowledge Graph（KG）並基於此進行 Graph-Augmented Retrieval，是否能顯著優於傳統 chunk-based RAG？

### 3.2 技術方法

**CFA Knowledge Graph 設計**

```
節點類型（Node Types）:
  - Concept:    Duration, Convexity, Yield Curve, CAPM, Efficient Frontier ...
  - Formula:    Macaulay Duration = ..., Modified Duration = ..., Black-Scholes = ...
  - Principle:  No-Arbitrage Principle, Law of One Price, Modigliani-Miller ...
  - Regulation: GIPS Standards, Code of Ethics, Standard I-VII ...

邊類型（Edge Types）:
  - prerequisite:    Convexity --prerequisite--> Duration
  - applied_in:      Duration --applied_in--> Bond Immunization
  - conflicts_with:  CAPM --conflicts_with--> Fama-French Three Factor
  - refines:         Modified Duration --refines--> Macaulay Duration
  - regulated_by:    Portfolio Management --regulated_by--> GIPS Standards
  - quantified_by:   Credit Risk --quantified_by--> Credit Spread Formula
```

**KG 半自動建構流程**

1. 從 CFA_Extracted-chunk_0 的 material 欄位提取概念與關係（使用 GPT-4 進行 relation extraction）
2. 人工校驗與補充（重點校驗 prerequisite 與 conflicts_with 邊）
3. 預估 KG 規模：約 500-800 個節點，2,000-5,000 條邊

**Graph-Augmented Retrieval 機制**

```
Step 1: Question -> Concept Identification (提取題目涉及的概念)
Step 2: Graph Traversal (從識別出的概念出發，沿 prerequisite/applied_in 邊擴展)
Step 3: Subgraph Extraction (提取相關子圖，包含節點屬性與邊資訊)
Step 4: Linearization (將子圖轉化為結構化文本，作為 context 注入 LLM)
Step 5: Answer Generation (LLM 基於 graph context 生成回答)
```

### 3.3 實驗設計

**實驗 1：KG-RAG vs Standard RAG vs No-RAG**

- Standard RAG：使用 CFA_Extracted-chunk_0 的 material 欄位作為知識庫，基於 embedding 相似度檢索 top-k chunks
- KG-RAG：使用上述 Knowledge Graph 進行 graph-augmented retrieval
- No-RAG：純模型推論，無外部知識
- 測試集：FinEval-CFA-Challenge + FinEval-CFA-Easy
- 評估指標：Accuracy, Retrieval Relevance（人工評估 retrieved context 的相關性）

**實驗 2：Multi-hop Reasoning Benchmark**

- 從測試集中篩選出需要多跳推理的題目（人工標註）
- 在多跳推理子集上，KG-RAG 的優勢預期最為顯著
- 分析：Standard RAG 失敗但 KG-RAG 成功的案例，展示 graph structure 的價值

**實驗 3：KG Coverage & Quality 分析**

- 分析 KG 的覆蓋率：測試集中有多少題目涉及的概念被 KG 覆蓋
- KG 品質評估：隨機抽取 100 條邊，人工評估正確率
- 消融實驗：不同邊類型的貢獻（移除 prerequisite 邊 / 移除 conflicts_with 邊的效果）

**實驗 4：KG 建構成本分析**

- 報告半自動建構的人工時間與 API 成本
- 分析 KG 的可擴展性：新增主題的邊際成本

### 3.4 資料需求

- **KG 建構來源**：CFA_Extracted-chunk_0 的 material 欄位（1,124 條記錄），已就緒
- **KG 建構工具**：GPT-4 API 用於 relation extraction（預估成本 100-200 美元）
- **人工校驗**：需要 CFA 知識背景的人員進行校驗，預計 30-50 小時
- **測試資料**：FinEval-CFA-Challenge + FinEval-CFA-Easy，已就緒
- **RAG 基礎設施**：需要 vector database（如 FAISS / Chroma）與 graph database（如 Neo4j / NetworkX）
- **推論 GPU**：單張 A100 用於開放權重模型推論

### 3.5 預期結果

- KG-RAG 在整體準確率上優於 Standard RAG 2-5%
- 在多跳推理題目子集上，KG-RAG 的優勢更為顯著（5-10% 提升）
- 揭示哪些邊類型（prerequisite vs applied_in vs conflicts_with）對推理的貢獻最大
- 建構出可公開釋出的 CFA Knowledge Graph 資源

### 3.6 新穎貢獻

- **結構化知識優於非結構化檢索**：在專業領域推理任務中，首次實證展示 graph-structured knowledge 相對於 chunk-based retrieval 的系統性優勢
- **CFA Knowledge Graph 公共資源**：建構並釋出首個 CFA 領域的 Knowledge Graph，為後續研究提供基礎設施
- **Multi-hop Financial Reasoning**：首次在金融專業考試情境中系統性分析多跳推理的需求與挑戰
- **可遷移的方法論**：KG-RAG 框架可直接遷移至醫學（USMLE KG）、法律（Bar Exam KG）等專業領域

### 3.7 目標發表場所

- **首選**：ACL 2026 / EMNLP 2026（Knowledge Graph + NLP 交叉）
- **次選**：AAAI 2027（Knowledge Representation + Reasoning Track）
- **期刊備選**：TACL (Transactions of the ACL)

---

## 方向 4：Preference Learning for Financial Reasoning Quality

### 4.1 研究問題

在 CFA 題目解答中，「答案正確但推理過程有瑕疵」與「推理嚴謹但計算出錯」是兩種截然不同的錯誤模式。然而，現有的訓練方法（包括 FinDAP 的 RPO Stage 3）主要以最終答案的正確性作為獎勵訊號。能否設計一套偏好學習機制，使模型更偏好「高品質推理過程」，即使這意味著在某些情況下犧牲少量的最終準確率？這對於 LLM 在高風險金融決策中的可信度具有根本性的意義。

### 4.2 技術方法

**推理品質多維度評分框架**

```
Dimension 1: Step Correctness（每個推理步驟是否正確）
  -- 評分：0/1 per step, 平均得到 step accuracy

Dimension 2: Logical Coherence（步驟之間的邏輯連貫性）
  -- 評分：1-5 scale
  -- 關注：是否有邏輯跳躍、是否有自相矛盾

Dimension 3: Formula Usage Appropriateness（公式使用的恰當性）
  -- 評分：1-5 scale
  -- 關注：是否選用了正確的公式、是否正確代入參數

Dimension 4: Financial Reasoning Depth（金融推理的深度）
  -- 評分：1-5 scale
  -- 關注：是否考慮了邊界情況、是否辨識了 distractor 的干擾
```

**偏好對建構流程**

1. 使用 Llama-Fin-8b 對每道 CFA 題目進行多次採樣（k=10），產生多個回答
2. 使用 GPT-4 對每個回答進行四維度評分
3. 建構偏好對（preference pairs）：
   - Type A：正確答案 + 高品質推理 > 正確答案 + 低品質推理
   - Type B：錯誤答案 + 高品質推理 > 正確答案 + 低品質推理（關鍵創新點）
   - Type C：高品質推理 > 低品質推理（不論答案正確性）
4. 使用 DPO 或 RPO 進行偏好學習

**與 FinDAP Stage 3 的技術銜接**

- FinDAP 的 RPO（Robust Policy Optimization）已經實現了 outcome signal + process signal 的雙信號學習
- 本方向在此基礎上進一步：
  - 細化 process signal 為四個維度（而非單一過程獎勵）
  - 引入 Type B 偏好對（挑戰「正確答案即為好答案」的假設）
  - 使用 CFA 領域特定的評分維度（Formula Usage, Financial Reasoning Depth）

### 4.3 實驗設計

**實驗 1：偏好對建構與品質分析**

- 使用 FinTrain-cfa_exercise（2,946 題）作為採樣基礎
- 每題採樣 10 個回答，共計約 29,460 個回答
- GPT-4 四維度評分，建構偏好對
- 分析：不同偏好對類型（Type A / B / C）的分布與品質

**實驗 2：Preference Learning 訓練**

- 基礎模型：Llama-Fin-8b（FinDAP 訓練後的模型，作為 starting point）
- 訓練方法：DPO / RPO（使用 FinDAP 的現有訓練框架，即 datasets/FinDap/FinDAP/ 中的 posttrain.py）
- 消融實驗：
  - 僅使用 Type A 偏好對（傳統方法）
  - 僅使用 Type B 偏好對（本方向的關鍵創新）
  - 使用 Type A + B + C 全部偏好對
  - 使用不同評分維度子集

**實驗 3：推理品質評估**

- 測試集：FinEval-CFA-Challenge + FinEval-CFA-Easy
- 評估指標：
  - 最終答案準確率（Accuracy）
  - 推理品質分數（Reasoning Quality Score，四維度加權平均）
  - 人工評估：隨機抽取 100 個回答，由 CFA 知識背景的評估者進行盲審
- 與基線模型的對比：Llama-Fin-8b (before preference learning) vs after preference learning

**實驗 4：推理品質的下游影響**

- 高品質推理是否使得錯誤更容易被偵測與修正？
- 設計 self-correction 實驗：讓模型審視自己的推理過程並嘗試修正
- 假說：經過 preference learning 的模型，其 self-correction 成功率更高

### 4.4 資料需求

- **採樣基礎**：FinTrain-cfa_exercise（2,946 題），已就緒
- **GPT-4 評分**：約 29,460 個回答需要評分，預估 API 成本 300-500 美元
- **起始標註**：CFA_Extracted 的 gpt4_answer_justification 欄位可作為推理品質標註的起始點
- **訓練基礎設施**：FinDAP 的訓練框架（posttrain.py + RPO trainer），已在本倉庫中
- **GPU 需求**：需要多張 A100（FinDAP 腳本預設 16-GPU FSDP 配置），但可使用 LoRA 降低至 2-4 張 A100
- **人工評估**：100 個回答的盲審，預計需要 20-30 小時

### 4.5 預期結果

- 經過 preference learning 的模型在推理品質分數上顯著提升（預期 15-25%）
- 最終答案準確率維持不變或小幅提升（0-3%）
- Type B 偏好對（錯誤答案但高品質推理）的加入顯著改善推理過程的嚴謹性
- Self-correction 成功率提升（預期 10-15%）

### 4.6 新穎貢獻

- **推理過程品質 > 答案正確性**：挑戰現有偏好學習中以最終答案為唯一獎勵訊號的範式
- **多維度推理品質評分框架**：超越單一的「好/壞」標籤，提供可解釋的品質診斷
- **Type B 偏好對的創新**：首次在金融推理領域引入「錯誤答案但高品質推理 > 正確答案但低品質推理」的偏好訊號
- **與 FinDAP 的技術延續**：直接建立在 EMNLP 2025 oral paper 的基礎上，形成自然的學術脈絡
- **金融決策可信度**：對於 LLM 在金融決策輔助中的部署，推理品質比答案正確性更為重要（因為用戶需要理解 LLM 的推理過程才能做出決策）

### 4.7 目標發表場所

- **首選**：NeurIPS 2026（偏好學習 / RLHF 方向的頂級場所）
- **次選**：EMNLP 2026（與 FinDAP 的自然延續）
- **期刊備選**：JMLR (Journal of Machine Learning Research)

---

## 方向 5：Financial Reasoning with Calculator Tool Augmentation

### 5.1 研究問題

CFA 考試允許且鼓勵使用 HP-12C 或 Texas Instruments BA II Plus 金融計算器，這意味著 CFA 考試的設計預設了考生可以精確計算的能力。然而 LLM 的數學計算是已知弱點：FinanceMath 基準測試中，即使 GPT-4o 加上 CoT 也僅達 60.9%，與人類專家的 92% 之間存在 31.1% 的差距。能否為 LLM 配備領域特定的金融計算器工具（而非通用的 Python interpreter），使其在需要計算的題目上達到接近人類的準確率？

### 5.2 技術方法

**金融計算器 API 設計**

```
Tool 1: TVM Calculator (Time Value of Money)
  -- PV, FV, PMT, N, I/Y 的互算
  -- 支持 annuity due / ordinary annuity
  -- 範例：PV(rate=0.05, nper=10, pmt=100, fv=1000) = ?

Tool 2: Bond Calculator
  -- Bond price, YTM, current yield, duration, convexity
  -- 支持 semi-annual / annual coupon
  -- 範例：BondPrice(face=1000, coupon=0.06, ytm=0.07, years=10, freq=2)

Tool 3: Statistics Calculator
  -- Mean, variance, standard deviation, covariance, correlation
  -- Portfolio return and risk calculation
  -- Sharpe ratio, Treynor ratio, Jensen's alpha

Tool 4: Derivatives Calculator
  -- Black-Scholes option pricing
  -- Put-call parity
  -- Swap valuation (interest rate swap, currency swap)

Tool 5: Financial Ratio Calculator
  -- ROE decomposition (DuPont analysis)
  -- Liquidity ratios, solvency ratios, profitability ratios
  -- EV/EBITDA, P/E, P/B calculation
```

**ReAct-style 推理框架**

```
Thought: 題目要求計算 10 年期債券的價格，票面利率 6%，YTM 7%，半年付息。
Action: BondPrice(face=1000, coupon=0.06, ytm=0.07, years=10, freq=2)
Observation: 929.76
Thought: 債券價格為 929.76，低於面值，因為 YTM > coupon rate，合理。
Answer: C. $929.76
```

LLM 負責理解題意、選擇工具、提取參數、解讀結果，而精確計算交由工具執行。

### 5.3 實驗設計

**實驗 1：三方比較**

- Condition 1：Pure LLM（無任何工具）
- Condition 2：LLM + Generic Calculator（Python interpreter，LLM 自行撰寫計算代碼）
- Condition 3：LLM + Financial Calculator（上述五個領域特定工具）
- 測試集：FinEval-CFA-Challenge + FinEval-CFA-Easy
- 報告：整體準確率、按題目類型（計算題 vs 概念題 vs 分析題）分析

**實驗 2：Tool Selection Accuracy**

- 評估 LLM 是否能正確選擇適當的工具
- 評估 LLM 是否能正確提取並傳入工具參數
- 錯誤分析：Tool Selection Error vs Parameter Extraction Error vs Tool Unnecessary（概念題不需要工具但模型嘗試使用）

**實驗 3：與 Stage Pipeline 的結合**

- 將 Financial Calculator Tools 整合進方向 1 的 Stage 4（Calculation Execution）
- 評估整合後的端到端效果
- 這展示了方向之間的技術協同

**實驗 4：Tool Augmentation 的泛化性**

- 測試 Financial Calculator 在 FinanceMath 基準上的效果
- 比較：是否能縮小 LLM 與人類專家的 31% 差距

### 5.4 資料需求

- **測試資料**：FinEval-CFA-Challenge + FinEval-CFA-Easy，已就緒
- **題目分類標註**：需標註每道題目是否為計算題，預計 15-20 小時
- **工具實現**：五個金融計算器工具的 Python 實現，預計 40-60 小時開發時間
- **ReAct 框架**：可使用 LangChain 或自行實現，基礎設施成熟
- **GPU 需求**：僅需推論，單張 A100 或等效 GPU

### 5.5 預期結果

- LLM + Financial Calculator 在計算題上的準確率顯著高於 Pure LLM（預期提升 15-25%）
- LLM + Financial Calculator 略優於 LLM + Generic Calculator（因為減少了 LLM 撰寫代碼的錯誤）
- Tool Selection Accuracy 預期約 85-90%（主要錯誤來自參數提取）
- 在概念題上，三個 Condition 的表現相近（工具不影響概念理解）

### 5.6 新穎貢獻

- **領域特定工具增強**：超越通用的 code interpreter，設計金融領域專用的工具集
- **模擬真實考試環境**：CFA 考試允許使用金融計算器，本方向使 LLM 的評估條件更接近人類考生
- **Tool Selection 的錯誤分析**：揭示 LLM 在「何時使用工具」與「如何使用工具」上的決策品質
- **與方向 1 的協同**：Financial Calculator 直接插入 Structured Pipeline 的 Stage 4，展示模組化設計的優勢

### 5.7 目標發表場所

- **首選**：EMNLP 2026（Tool-augmented LLM 為當前熱門方向）
- **次選**：ACL 2026 Findings
- **期刊備選**：TACL

---

## 方向 6：Error Pattern Mining and Targeted Remediation

### 6.1 研究問題

當 LLM 在 CFA 題目上犯錯時，不同類型的錯誤需要截然不同的修復策略：Knowledge Gap 需要 RAG 補充知識，Misapplication 需要 few-shot 示範，Calculation Error 需要計算器工具，Distractor Confusion 需要選項分析技術。能否建構一個自動化的錯誤分類系統，並為每種錯誤類型設計對應的修復策略，形成一個「錯誤診斷 -- 針對性修復」的閉環系統？

### 6.2 技術方法

**多維度錯誤分類體系**

```
Level 1: Error Category (四大類)
  ├── Knowledge Gap:      模型缺乏必要的金融知識
  ├── Misapplication:     具備知識但錯誤地應用（如用錯公式、概念混淆）
  ├── Calculation Error:  知識與應用正確但計算出錯
  └── Distractor Confusion: 被題目選項中的干擾項誤導

Level 2: Error Subcategory (細分)
  ├── Knowledge Gap
  │   ├── Concept Unknown:     完全不認識某概念
  │   ├── Concept Incomplete:  對概念理解不完整
  │   └── Regulation Outdated: 使用過時的規則或標準
  ├── Misapplication
  │   ├── Wrong Formula:       選用了錯誤的公式
  │   ├── Wrong Condition:     未正確辨識適用條件
  │   └── Concept Confusion:   混淆了相似概念
  ├── Calculation Error
  │   ├── Arithmetic Error:    基本算術錯誤
  │   ├── Unit Error:          單位換算錯誤
  │   └── Precision Error:     精度或捨入錯誤
  └── Distractor Confusion
      ├── Partial Truth:       選項部分正確但不完整
      ├── Common Misconception: 選項利用常見誤解
      └── Similar Value:       選項數值接近正確答案
```

**自動錯誤分類器**

- 輸入：題目 + 模型的錯誤回答（含推理過程）+ 正確答案
- 輸出：Error Category + Error Subcategory + 錯誤發生的具體位置
- 實現方式：使用 GPT-4 作為 judge，設計詳細的分類 prompt
- 校驗：與人工標註的 200 題比對，計算 Cohen's Kappa

**錯誤類型對應的修復策略**

```
Knowledge Gap       --> RAG（檢索相關知識片段後重新回答）
Misapplication      --> Few-shot（提供正確應用的示範案例）
Calculation Error   --> Calculator Tool（使用方向 5 的金融計算器）
Distractor Confusion --> Option Analysis（逐項分析每個選項的正確性與錯誤性）
```

### 6.3 實驗設計

**實驗 1：Error Pattern Profiling**

- 對所有測試集上的錯誤回答進行自動分類
- 建立 CFA Error Pattern Atlas：按 CFA 主題 x 錯誤類型的二維熱力圖
- 統計分析：不同模型的錯誤模式是否相似？不同主題的錯誤模式是否有規律？

**實驗 2：Targeted Remediation Effectiveness**

- 對每個錯誤類型，套用對應的修復策略
- 計算每種策略的修復成功率（Fix Rate）
- 對比：Targeted Remediation vs Uniform Remediation（對所有錯誤都用同一策略）

**實驗 3：Cascaded Remediation Pipeline**

- 設計串聯修復管道：首先嘗試最低成本的策略，若失敗再嘗試更高成本的策略
- 評估：在相同的計算預算下，Cascaded Pipeline vs Single Strategy 的總修復率

**實驗 4：Cross-model Error Pattern Transfer**

- 在 Model A 上挖掘的錯誤模式，是否能預測 Model B 的錯誤？
- 若是，則 Error Pattern Atlas 具有跨模型的通用性

### 6.4 資料需求

- **測試資料**：FinEval-CFA-Challenge + FinEval-CFA-Easy + flare-cfa，已就緒
- **錯誤回答收集**：需要先對多個模型進行推論，收集所有錯誤回答及其推理過程
- **自動分類**：GPT-4 API 用於錯誤分類，預估成本 200-300 美元
- **人工校驗**：200 題的人工錯誤分類標註，需要 CFA 知識背景，預計 30-40 小時
- **修復策略基礎設施**：RAG 系統（方向 3）、Calculator Tools（方向 5）、Few-shot 庫建構
- **GPU 需求**：僅需推論

### 6.5 預期結果

- Knowledge Gap 為最常見的錯誤類型（預期佔 35-45%），與現有研究一致
- Targeted Remediation 的修復成功率顯著高於 Uniform Remediation（預期 60-70% vs 30-40%）
- CFA Error Pattern Atlas 可視化將揭示有趣的模式：例如 Derivatives 主題以 Calculation Error 為主，而 Ethics 主題以 Distractor Confusion 為主
- 不同模型的錯誤模式具有中度相似性（預期 Cohen's Kappa 0.4-0.6）

### 6.6 新穎貢獻

- **自動化錯誤診斷系統**：首次為金融 LLM 建構系統化的錯誤分類與診斷工具
- **CFA Error Pattern Atlas**：可公開釋出的錯誤模式圖譜，為後續研究與 LLM 改進提供路線圖
- **Targeted Remediation**：超越「一體適用」的改進策略，展示針對性修復的顯著優勢
- **「錯誤診斷 -- 針對性修復」閉環**：建構完整的錯誤處理管道，具有工程化的實用價值
- **與方向 3 和方向 5 的協同**：RAG 與 Calculator Tool 作為修復策略的組件被整合

### 6.7 目標發表場所

- **首選**：EMNLP 2026（Error Analysis + NLP）
- **次選**：ACL 2026
- **應用場所**：ACL 2026 System Demonstrations Track

---

## 方向 7：Dual-Process Financial Reasoning (System 1 / System 2)

### 7.1 研究問題

受 Daniel Kahneman 的 Dual-Process Theory（System 1 快速直覺 / System 2 慢速深思）啟發，能否設計一個自適應計算的金融推理系統？對於簡單的概念題，System 1（快速直覺回答）即可獲得正確結果；對於複雜的計算題或多概念整合題，則觸發 System 2（RAG + CoT + 逐步驗證的完整管道）。這種設計在準確率與計算成本之間取得最佳平衡。

### 7.2 技術方法

**System 1：Fast Intuition**

```
-- 直接使用 LLM 進行 zero-shot 回答
-- 同時輸出信心分數（使用方向 2 的 Self-Consistency Variance）
-- 若信心 >= 閾值 theta_high -> 直接輸出答案
-- 若信心 < theta_high -> 觸發 System 2
```

**System 2：Deliberate Reasoning**

```
-- Step 1: RAG 知識檢索（使用方向 3 的 KG-RAG 或 Standard RAG）
-- Step 2: Chain-of-Thought 逐步推理
-- Step 3: Financial Calculator Tool 輔助計算（使用方向 5 的工具）
-- Step 4: Reasoning Chain Verification（三維度驗證）
```

**Reasoning Chain Verifier（三維度驗證）**

```
Dimension 1: Concept Verification
  -- 推理中使用的金融概念是否正確？
  -- 使用 Knowledge Graph 交叉驗證

Dimension 2: Logic Verification
  -- 推理步驟之間的邏輯是否連貫？
  -- 是否存在邏輯跳躍或矛盾？

Dimension 3: Calculation Verification
  -- 計算結果是否正確？
  -- 使用 Financial Calculator 獨立驗算
```

**自適應閾值調整**

- theta_high 的設定影響 System 1 / System 2 的分配比例
- 使用驗證集（validation set）上的 Coverage-Accuracy 曲線來最佳化 theta_high
- 目標：在總計算成本最低的情況下，達到目標準確率

### 7.3 實驗設計

**實驗 1：System 1 vs System 2 vs Dual-Process**

- System 1 Only：所有題目都用 zero-shot
- System 2 Only：所有題目都用完整管道
- Dual-Process：自適應分配
- 評估：Accuracy, Total Inference Cost (API calls / GPU time), Accuracy-per-Dollar

**實驗 2：閾值敏感度分析**

- 掃描 theta_high 從 0.5 到 0.95
- 分析：不同 theta_high 下的 System 1 分配比例、整體準確率、計算成本
- 找到 Pareto 最優點

**實驗 3：Reasoning Chain Verifier 效果**

- 消融實驗：移除三個驗證維度中的任何一個
- 分析：哪個驗證維度貢獻最大
- Verifier 的 False Positive Rate 與 False Negative Rate

**實驗 4：與人類認知的對比分析**

- 收集人類 CFA 考生的解題行為資料（如果可行）
- 分析：人類在哪些題目上使用「快思考」vs「慢思考」
- 比較：Dual-Process LLM 的分配是否與人類相似

### 7.4 資料需求

- **測試資料**：FinEval-CFA-Challenge + FinEval-CFA-Easy，已就緒
- **方向 2 的信心估計基礎設施**：Self-Consistency Variance 的實現，可直接復用
- **方向 3 的 KG-RAG 系統**：作為 System 2 的知識檢索組件
- **方向 5 的 Financial Calculator**：作為 System 2 的計算組件
- **驗證集**：從 FinEval-CFA-Easy 中劃出 20% 作為閾值最佳化的驗證集
- **GPU 需求**：與方向 3 和方向 5 相同，僅需推論

### 7.5 預期結果

- Dual-Process 系統在準確率上接近 System 2 Only（差距 < 2%）
- 計算成本降低 40-60%（因為大量簡單題目由 System 1 快速處理）
- Accuracy-per-Dollar 指標顯著優於 System 2 Only
- Reasoning Chain Verifier 能偵測並修正 5-10% 的 System 2 錯誤
- 預期約 50-60% 的 CFA 題目可由 System 1 正確回答

### 7.6 新穎貢獻

- **認知科學啟發的 LLM 架構**：首次將 Kahneman 的 Dual-Process Theory 系統性地應用於金融 LLM 推理
- **自適應計算**：根據題目難度動態分配計算資源，實現 accuracy-efficiency trade-off 的 Pareto 最優
- **Reasoning Chain Verifier**：三維度的推理鏈驗證機制，提供更細粒度的品質保證
- **系統整合**：將方向 2（Calibration）、方向 3（KG-RAG）、方向 5（Calculator Tool）整合為一個統一系統
- **實用性**：對於實際部署的金融 LLM 系統，計算成本的降低具有直接的商業價值

### 7.7 目標發表場所

- **首選**：AAAI 2027（Cognitive Computing / Adaptive Systems Track）
- **次選**：IJCAI 2027
- **期刊備選**：Cognitive Science / Artificial Intelligence (Journal)

---

## 論文拆分策略

基於上述七個方向的技術依賴關係、資源需求與產出時間線，建議以下論文拆分策略：

### Paper 1：Calibration & Selective Prediction（最快產出）

- **對應方向**：方向 2
- **產出時間**：2-3 個月
- **核心優勢**：無需 GPU 訓練，僅需推論 + 統計分析
- **目標場所**：ACL / EMNLP 2026
- **內容**：
  - 完整的 Calibration 分析（ECE, MCE, Reliability Diagram）
  - 四種信心估計方法的對比
  - Topic-wise Overconfidence 分析
  - Selective Prediction Trade-off 分析
  - FinDAP 訓練對 Calibration 的影響分析
- **預期頁數**：8-10 頁（主會議長文）
- **優先順序**：最高優先，建議立即開始

### Paper 2：Structured Reasoning + Tool Augmentation（組合論文）

- **對應方向**：方向 1 + 方向 5
- **產出時間**：4-6 個月
- **核心優勢**：方向 1 的 Stage Pipeline + 方向 5 的 Calculator Tool 自然結合在 Stage 4
- **目標場所**：ACL / EMNLP 2026
- **內容**：
  - 五階段認知管道設計與實驗
  - Stage-wise Error Profiling
  - Financial Calculator Tool 設計與整合
  - 三方比較（Pure LLM vs Generic Calculator vs Financial Calculator）
  - 整合系統的端到端評估
- **預期頁數**：8-10 頁（主會議長文）
- **優先順序**：在 Paper 1 之後開始，可與 Paper 1 部分平行

### Paper 3：Preference Learning for Financial Reasoning Quality

- **對應方向**：方向 4
- **產出時間**：5-8 個月（需要 GPU 訓練）
- **核心優勢**：直接建立在 FinDAP 的技術基礎上，學術脈絡清晰
- **目標場所**：NeurIPS 2026 / EMNLP 2026
- **內容**：
  - 多維度推理品質評分框架
  - 偏好對建構與 Type B 創新
  - DPO/RPO 訓練與消融實驗
  - 推理品質評估與人工盲審
  - Self-correction 能力分析
- **預期頁數**：8-10 頁
- **優先順序**：可與 Paper 2 平行，但需要 GPU 資源

### Paper 4：KG-RAG + Error Remediation（系統論文）

- **對應方向**：方向 3 + 方向 6
- **產出時間**：6-10 個月（需要 KG 建構）
- **核心優勢**：KG-RAG 作為 Error Remediation 中 Knowledge Gap 修復的核心組件
- **目標場所**：ACL / AAAI 2027
- **內容**：
  - CFA Knowledge Graph 建構方法論
  - KG-RAG vs Standard RAG 對比
  - Error Pattern Mining 與 CFA Error Pattern Atlas
  - Targeted Remediation 系統設計
  - 閉環系統的端到端評估
- **預期頁數**：10-12 頁（可能需要 long paper + appendix）
- **優先順序**：在 Paper 2 和 Paper 3 之後開始

### Paper 5（可選）：Dual-Process Financial Reasoning（系統整合論文）

- **對應方向**：方向 7
- **產出時間**：10-14 個月（需要所有前置方向的基礎設施）
- **核心優勢**：整合所有前期工作，展示統一框架的力量
- **目標場所**：AAAI / IJCAI 2027
- **內容**：
  - Dual-Process 架構設計
  - System 1 / System 2 的自適應分配
  - Reasoning Chain Verifier
  - 計算效率分析
  - 與人類認知模式的對比

---

## 各方向可行性與資源需求比較

| 方向 | GPU 訓練 | 資料就緒程度 | 實作複雜度 | 首次結果時間 | 新穎貢獻等級 |
|------|----------|-------------|-----------|-------------|-------------|
| 方向 1：Structured Reasoning Decomposition | 否（僅推論） | 高（FinEval + CFA_Extracted 已就緒，需約 200 題人工標註） | 中等（五階段 Pipeline 設計需仔細工程化） | 3-4 個月 | 高（認知科學 x NLP 交叉，Stage-wise 分析首創） |
| 方向 2：Calibration & Selective Prediction | 否（僅推論 + 統計） | 高（所有資料已就緒，僅需主題標註 10-15 小時） | 低（成熟的統計方法，無需複雜系統） | 2-3 個月 | 中高（首個金融專業考試 Calibration 研究，監管政策含義強） |
| 方向 3：KG-RAG | 否（僅推論） | 中（需建構 KG，預計 30-50 小時 + API 費用） | 高（KG 建構 + Graph Retrieval + RAG 整合） | 5-7 個月 | 高（結構化知識 vs 非結構化檢索的系統性比較） |
| 方向 4：Preference Learning | 是（需多 GPU FSDP 或 LoRA） | 中高（FinTrain 已就緒，需 GPT-4 評分 + 偏好對建構） | 高（FinDAP 框架的修改 + DPO/RPO 訓練） | 5-8 個月 | 很高（Type B 偏好對創新，推理品質 > 答案正確性） |
| 方向 5：Calculator Tool Augmentation | 否（僅推論） | 高（FinEval 已就緒，需開發計算器工具 40-60 小時） | 中等（工具開發 + ReAct 框架整合） | 3-5 個月 | 中高（領域特定工具增強，模擬真實考試環境） |
| 方向 6：Error Pattern Mining | 否（僅推論 + 分析） | 高（需先收集錯誤回答，其餘資料已就緒） | 中等（錯誤分類器設計 + 修復策略實現） | 4-6 個月 | 高（自動化錯誤診斷 + 針對性修復閉環） |
| 方向 7：Dual-Process Reasoning | 否（僅推論） | 中低（依賴方向 2/3/5 的基礎設施） | 高（多系統整合 + 自適應閾值最佳化） | 8-12 個月 | 很高（認知科學啟發 + 自適應計算 + 系統整合） |

### 資源需求總結

**最低資源需求路線（無 GPU 訓練）**：
- 方向 2 -> 方向 1 + 5 -> 方向 6 -> 方向 3
- 僅需推論用 GPU（1-2 張 A100 或等效）+ API 費用
- 可產出 3-4 篇論文

**完整路線（含 GPU 訓練）**：
- 方向 2 -> 方向 1 + 5 -> 方向 4 -> 方向 3 + 6 -> 方向 7
- 需要多 GPU 訓練資源（方向 4）+ 推論 GPU + API 費用
- 可產出 4-5 篇論文

**API 費用預估總計**：
- GPT-4 API（錯誤分類、品質評分、KG 建構）：800-1,500 美元
- 商業模型推論（GPT-4o, Claude, Gemini）：400-800 美元
- 總計：1,200-2,300 美元

**人工標註時間預估總計**：
- 方向 1（Stage ground truth）：40-60 小時
- 方向 2（主題分類校驗）：10-15 小時
- 方向 3（KG 校驗）：30-50 小時
- 方向 4（人工盲審）：20-30 小時
- 方向 6（錯誤分類校驗）：30-40 小時
- 總計：130-195 小時（需具備 CFA 知識背景）

---

## 時間線規劃

```
Month  1-3:   Paper 1（方向 2：Calibration）-- 研究與撰寫
               同步開始方向 1 的 Stage ground truth 建構
               同步開始方向 5 的 Financial Calculator 工具開發

Month  3-6:   Paper 1 投稿
               Paper 2（方向 1 + 5）-- 研究與撰寫
               同步開始方向 4 的偏好對建構（GPT-4 評分）

Month  6-9:   Paper 2 投稿
               Paper 3（方向 4：Preference Learning）-- 訓練與實驗
               同步開始方向 3 的 KG 建構

Month  9-12:  Paper 3 投稿
               Paper 4（方向 3 + 6：KG-RAG + Error Remediation）-- 研究與撰寫

Month 12-15:  Paper 4 投稿
               Paper 5（方向 7：Dual-Process，若選擇執行）

Month 15-18:  Paper 5 投稿（若執行）
               博士論文整合撰寫
```

---

## 各方向之間的技術依賴與協同關係

```
方向 2 (Calibration)
  |
  +--> 信心估計方法 --> 方向 7 (System 1 的觸發條件)
  |
方向 1 (Structured Reasoning)
  |
  +--> Stage 4 整合 --> 方向 5 (Calculator Tool)
  |
  +--> Stage-wise Error Profile --> 方向 6 (Error Pattern Mining)
  |
方向 3 (KG-RAG)
  |
  +--> 知識檢索組件 --> 方向 6 (Knowledge Gap 修復策略)
  |                  --> 方向 7 (System 2 的知識檢索)
  |
方向 4 (Preference Learning)
  |
  +--> 高品質推理模型 --> 方向 7 (System 2 的推理引擎)
  |
方向 5 (Calculator Tool)
  |
  +--> 計算組件 --> 方向 6 (Calculation Error 修復策略)
  |             --> 方向 7 (System 2 的計算組件)
  |
方向 6 (Error Pattern Mining)
  |
  +--> Error Pattern Atlas --> 方向 7 (錯誤類型預測用於 System 分配)
  |
方向 7 (Dual-Process) <-- 整合所有前期方向的輸出
```

這種設計確保每個方向既可以作為獨立論文發表，又能作為後續方向的技術組件。任何一個方向的缺失不會阻斷其他方向的執行，但完成後能顯著增強其他方向的效果。

---

## 結語

本文件提出的七個研究方向共同構成一個完整的博士研究藍圖。其核心思想是：從「理解 LLM 的失敗模式」出發（方向 1、2、6），設計「針對性的改進策略」（方向 3、4、5），最終「整合為一個統一的自適應系統」（方向 7）。每個方向都有明確的新穎貢獻、可操作的實驗設計、具體的資料需求，以及清晰的目標發表場所。建議優先執行方向 2（Calibration）以快速產出首篇論文，建立學術信心與研究動能，隨後按照時間線規劃依序推進其餘方向。

---

**最後更新**：2026 年 1 月
**文件定位**：博士研究核心規劃文件，建議每季度依據研究進展進行修訂
