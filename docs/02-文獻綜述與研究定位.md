# 文獻綜述與研究定位

> 本文件為 CFA+LLM 研究專案的核心文獻綜述，系統性地分析現有工作、彙整模型表現數據、
> 嚴格論證研究空白，並提供完整的資源索引。所有技術術語、論文標題及作者姓名保留英文原文。

---

## 一、CFA+LLM 已有工作逐篇深度分析

本節針對與 CFA 考試及金融領域 LLM 直接相關的五篇核心論文，逐一進行深度分析。
每篇論文均涵蓋以下面向：研究問題（Research Question）、方法（Method）、
關鍵結果（Key Results）、局限性（Limitations），以及我們的切入機會（Our Entry Points）。

---

### 1.1 Paper 1: Evaluating Large Language Models for Financial Reasoning: A CFA-Based Benchmark Study

**arXiv: 2509.04468**

#### 研究問題

該論文旨在回答：現有大型語言模型在 CFA 特許金融分析師考試題目上的推理能力究竟如何？
能否透過 Retrieval-Augmented Generation (RAG) 系統有效提升模型在金融推理任務上的表現？

#### 方法

- 使用 1,560 道 CFA Level I 至 Level III 官方模擬考題作為評估基準
- 採用 Zero-shot prompting 作為基線方法
- 建構 RAG 系統，將外部金融知識文本作為檢索來源，輔助模型回答

#### 關鍵結果

- RAG 系統顯著提升了模型在各級別題目上的準確率
- 知識缺口（knowledge gap）被識別為模型失敗的主要原因
- 按級別來看，Level I 表現最佳，Level II 明顯下降，Level III 表現最差
- 此結果與 CFA 考試本身的難度梯度一致：Level I 著重知識記憶，Level II 強調應用分析，
  Level III 要求綜合判斷與論述

#### 局限性

1. **RAG 實作細節不足**：論文雖然報告了 RAG 的正面效果，但對於檢索策略、
   chunk 大小、embedding 模型選擇、top-k 設定等關鍵超參數缺乏系統性說明
2. **缺乏 RAG 策略的系統性比較**：未對不同 RAG 架構（naive RAG、advanced RAG、
   modular RAG）進行消融實驗（ablation study）
3. **資料集未公開**：使用的 1,560 道題目未以公開資料集形式釋出，限制了後續研究的可重現性

#### 我們的切入機會

- 建構公開的 CFA RAG 系統，提供完整的實作細節與消融實驗
- 系統性比較不同 RAG 策略（包括 naive RAG、sentence-window retrieval、
  auto-merging retrieval、knowledge graph RAG 等）在 CFA 題目上的效果差異
- 結合公開可用的 CFA 資料集（如 flare-cfa、CFA_Extracted 等），
  建立可重現的實驗基準

---

### 1.2 Paper 2: Advanced Financial Reasoning at Scale: A Comprehensive Evaluation of Large Language Models on CFA Level III

**arXiv: 2507.02954**

#### 研究背景

由 NYU Stern 商學院與 GoodFin 合作完成，聚焦於 CFA 最高級別（Level III）的評估，
這是目前已知最全面的 CFA Level III LLM 評估研究。

#### 方法

- 在 CFA Level III 題目上評估 23 個先進大型語言模型
- 涵蓋選擇題（MCQ）與論述題（essay）兩種題型
- 採用修訂後的嚴格評分標準（revised strict scoring），以更貼近實際 CFA 評分方式

#### 關鍵結果

| 排名 | 模型 | Level III 準確率 |
|------|------|-----------------|
| 1 | o4-mini | 79.1% |
| 2 | Gemini 2.5 Flash | 77.3% |
| 3 | Gemini 2.5 Pro | ~75% |
| 4 | Claude Opus | ~75% |

- 即使是最佳模型（o4-mini），仍有超過 20% 的錯誤率
- 論述題的表現普遍低於選擇題，顯示模型在結構化長文本生成方面仍有不足

#### 局限性

1. **僅涵蓋 Level III**：未對 Level I 和 Level II 進行評估，
   無法呈現跨級別的完整表現圖景
2. **未測試 Multi-Agent 架構**：所有評估均為單一模型直接回答，
   未探索多智能體協作的可能性
3. **缺乏推理策略的系統性比較**：未對 Chain-of-Thought (CoT)、
   Tree-of-Thought (ToT)、Self-Consistency、ReAct 等不同推理策略進行比較
4. **缺乏可解釋性分析**：未深入分析模型答錯的原因類型及分布

#### 我們的切入機會

- 設計跨級別（Level I-III）的完整評估框架
- 引入 Multi-Agent 協作機制，模擬真實金融分析師團隊的工作模式
- 系統性比較不同推理策略在 CFA 各級別題目上的效果

---

### 1.3 Paper 3: FinDAP -- Demystifying Domain-adaptive Post-training for Financial LLMs (EMNLP 2025 Oral)

**arXiv: 2501.04961**

#### 研究背景

由 Salesforce AI Research 團隊發表，作者包括 Zixuan Ke、Yifei Ming、
Xuan-Phi Nguyen、Caiming Xiong、Shafiq Joty。該論文被 EMNLP 2025 接受為
oral presentation，代表了金融領域 LLM 適應性訓練的最高水準研究之一。

#### 方法

FinDAP 提出了一套系統性的金融領域 LLM 後訓練框架，包含四大組成部分：

1. **FinCap**：金融能力定義與分類體系
2. **FinRec**：金融訓練資料推薦與篩選方法
3. **FinTrain**：三階段漸進式訓練流程
4. **FinEval**：全面的金融能力評估基準

三階段訓練流程具體為：

- **Stage 1: Joint CPT + SFT** -- 以 Llama-3-8B-Instruct 為基礎模型，
  同時進行持續預訓練（Continual Pre-Training）與監督式微調（Supervised Fine-Tuning），
  使用混合金融文本資料
- **Stage 2: Advanced Curriculum** -- 在 Stage 1 的 checkpoint 基礎上，
  進行進階課程式學習，引入更複雜的金融教材與習題資料
- **Stage 3: Offline RL with RPO** -- 使用 Robust Policy Optimization (RPO)
  進行離線強化學習，結合雙重信號（dual signal）進行偏好對齊（preference alignment）

最終釋出 Llama-Fin-8b 模型。

#### 關鍵結果

- Llama-Fin-8b 在多個金融基準測試上優於同量級的通用模型
- 三階段訓練的每一階段都帶來可量測的效能提升
- RPO 相較於標準 DPO 在金融推理任務上表現更穩健
- 開源了完整的訓練框架、資料集與模型權重

#### 局限性

1. **聚焦於領域適應，而非深度 CFA 問題求解**：FinDAP 的目標是通用金融能力提升，
   並非專門針對 CFA 考試的深度問題求解策略
2. **未引入 Multi-Agent 架構**：訓練與評估均為單一模型範式
3. **缺乏推理策略的系統性比較**：未探索不同 prompting 策略
   （如 CoT、few-shot、self-consistency）對金融推理的影響差異
4. **模型規模受限**：僅基於 8B 參數模型，未探索更大規模模型的潛力

#### 我們的切入機會

- 以 FinDAP 的訓練框架與資料集為基礎，進一步針對 CFA 考試進行專門優化
- 在 Llama-Fin-8b 基礎上，疊加 Multi-Agent 推理與 RAG 增強
- 利用 FinDAP 已開源的資源，降低研究的起步門檻

---

### 1.4 Paper 4: FinRobot -- AI Agent for Equity Research and Valuation with Large Language Models

**arXiv: 2411.08804**

#### 研究問題

該論文探索如何利用 Multi-Agent Chain-of-Thought (CoT) 系統進行股票研究，
將量化分析（quantitative analysis）與質性分析（qualitative analysis）整合於
統一的智能體架構中。

#### 方法

- 設計多智能體協作系統（Multi-Agent CoT），各智能體分別負責不同的分析面向
- 整合量化數據（財務報表、技術指標）與質性資訊（新聞、研報、行業分析）
- 透過 CoT 推理鏈將各智能體的分析結果串聯，形成完整的投資研究報告

#### 關鍵結果

- Multi-Agent 架構在股票研究任務上顯著優於單一模型的直接回答
- 分工明確的智能體設計有效降低了單一模型的認知負荷
- 量化與質性分析的整合提升了研究報告的全面性與準確性

#### 局限性

- 專注於股票研究領域，未針對考試類型任務進行設計
- 智能體角色設計基於投資分析師工作流程，不直接適用於 CFA 考試情境

#### 我們的切入機會

- 借鑑 FinRobot 的 Multi-Agent 設計理念，將其改造為 CFA 考試求解系統
- 設計符合 CFA 知識體系的專業智能體角色（如：Ethics Agent、Quantitative Agent、
  Fixed Income Agent、Equity Agent、Portfolio Management Agent 等）
- 將 FinRobot 的量化-質性整合思路，遷移為 CFA 考試中計算題與概念題的
  分流處理機制

---

### 1.5 Paper 5: FinanceMath -- Knowledge-Intensive Math Reasoning in Finance with Large Language Models

**arXiv: 2311.09797**

#### 研究問題

該論文旨在量化大型語言模型在需要大學程度金融知識的數學推理任務上與人類專家之間的差距。

#### 方法

- 建構包含 1,200 道金融數學問題的基準資料集
- 題目要求結合大學程度的金融知識與數學推理能力
- 以 Chain-of-Thought (CoT) prompting 評估 GPT-4o 等模型

#### 關鍵結果

| 方法 | 準確率 |
|------|--------|
| GPT-4o (CoT) | 60.9% |
| Human Expert | 92.0% |
| **差距** | **31.1%** |

- 人機差距高達 31.1 個百分點，顯示 LLM 在知識密集型數學推理上仍遠落後於人類
- 主要失敗模式包括：公式選擇錯誤、中間計算步驟出錯、金融概念理解偏差

#### 局限性

- 聚焦於金融數學推理，未涵蓋 CFA 考試中的非計算類題目（如倫理、質性分析）
- 未探索 RAG 或 Multi-Agent 等增強策略是否能縮小人機差距

#### 我們的切入機會

- FinanceMath 的結果為我們的研究提供了重要的基線數據：
  即使是最強模型，在金融數學推理上仍有 31% 以上的改進空間
- 可將 FinanceMath 的評估方法論遷移至 CFA 考試情境，
  建立更細緻的錯誤分類體系

---

### 1.6 其他相關工作簡述

除上述五篇核心論文外，以下工作也與本研究高度相關：

| 論文 | arXiv | 簡述 |
|------|-------|------|
| InvestLM | 2309.13064 | 針對投資領域的 LLM 適應性訓練，專注於投資決策輔助 |
| CFGPT | 2309.10654 | 中文金融 GPT，專為中國金融市場設計的領域模型 |
| FLAME | 2501.06211 | 金融 LLM 的全面評估框架，涵蓋多維度金融能力 |
| CFinBench | 2407.02301 | 中文金融基準測試，提供系統性的中文金融能力評估 |

這些工作從不同角度驗證了金融領域 LLM 研究的重要性，但均未針對 CFA 考試場景進行
深入探索，進一步證實了本研究的空白所在。

---

## 二、LLM 表現數據彙整

### 2.1 模型表現綜合矩陣

下表彙整了各主要模型在不同 CFA 級別與金融基準測試上的表現：

| 模型 | CFA Level I | CFA Level II | CFA Level III | FinanceMath | 備註 |
|------|------------|-------------|--------------|-------------|------|
| o4-mini | -- | -- | 79.1% | -- | Level III 最高分 |
| Gemini 2.5 Flash | -- | -- | 77.3% | -- | 第二名 |
| Gemini 2.5 Pro | -- | -- | ~75% | -- | 與 Claude Opus 相近 |
| Claude Opus | -- | -- | ~75% | -- | 與 Gemini 2.5 Pro 相近 |
| GPT-4o | -- | -- | -- | 60.9% | CoT prompting |
| Human Expert | -- | -- | -- | 92.0% | FinanceMath 基準 |
| Llama-Fin-8b | -- | 有評估 | -- | -- | FinDAP 開源模型 |

（「--」表示該論文未提供對應數據）

**注意**：由於各論文使用的資料集、評分標準與實驗設定不同，
跨論文的數值不可直接比較。上表僅供趨勢參考。

### 2.2 Level 越高表現越差的原因分析

CFA 考試三個級別的設計本身即代表了逐級遞增的認知難度。LLM 表現隨級別升高而下降，
其根本原因可從以下四個維度理解：

**1. 知識複雜度遞增**

- Level I：側重個別概念的理解與記憶，多為獨立知識點的直接考察
- Level II：要求跨概念整合，題目常涉及案例分析（vignette-based），
  需要將多個知識點串聯應用
- Level III：要求投資組合層級的綜合判斷，需要整合倫理、經濟、資產配置、
  風險管理等多個領域的知識

**2. 多步推理需求增加**

- Level I：通常一到兩步即可得出答案
- Level II：需要三到五步的連續推理，中間任一步驟出錯即導致最終答案錯誤
- Level III：除多步推理外，還需要在不確定性下做出判斷，
  涉及主觀權衡（trade-off）的能力

**3. 領域知識需求深化**

- 隨級別升高，所需的專業金融知識從「教科書級別」提升至「實務經驗級別」
- Level III 的論述題要求模型具備類似資深分析師的綜合判斷能力，
  這超出了當前 LLM 透過文本學習所能達到的水準

**4. 題型轉變的挑戰**

- Level I 與 Level II 以選擇題為主，LLM 可利用選項間的對比與排除策略
- Level III 引入論述題（essay），要求模型生成結構化的長文本回答，
  這對 LLM 的組織能力與精確表述能力提出更高要求

### 2.3 20%+ 錯誤率的組成分析

即使是表現最佳的 o4-mini（79.1%），仍有超過 20% 的題目回答錯誤。
根據現有文獻的分析，這些錯誤可歸類為以下四種主要類型：

| 錯誤類型 | 說明 | 嚴重程度 |
|---------|------|---------|
| 知識缺口（Knowledge Gaps） | 模型缺乏特定金融概念或公式的知識，導致無法正確回答 | **主要原因** |
| 推理錯誤（Reasoning Errors） | 模型具備相關知識但推理邏輯出錯，如因果關係判斷錯誤、條件遺漏 | 次要原因 |
| 計算錯誤（Calculation Errors） | 在數值運算過程中出現算術或代數錯誤 | 次要原因 |
| 理解錯誤（Comprehension Errors） | 模型誤解題意或忽略關鍵條件，導致回答方向偏離 | 次要原因 |

**知識缺口是首要失敗原因**，這意味著透過 RAG 引入外部知識庫具有最直接的改善潛力。
推理錯誤和計算錯誤則可能需要透過更精細的推理策略（如 CoT、Self-Consistency）
或專門的數學推理模塊來緩解。

---

## 三、研究空白嚴格論證

本節對六個具體的研究空白進行嚴格論證。每個空白均從三個維度進行分析：
為何重要（Why Important）、為何可行（Why Feasible）、為何我們能做（Why We Can）。

---

### 空白 1：缺乏針對 CFA 考試的系統性 Multi-Agent 研究

#### 為何重要

CFA 考試涵蓋十個核心學科領域（Ethics、Quantitative Methods、Economics、
Financial Statement Analysis、Corporate Issuers、Equity Investments、
Fixed Income、Derivatives、Alternative Investments、Portfolio Management），
每個領域都有其獨特的知識體系與推理模式。單一模型在面對如此廣泛的知識覆蓋時，
難以在每個領域都達到專家級表現。Multi-Agent 架構允許為每個領域配置專門的
智能體，透過協作分工來克服單一模型的能力瓶頸。

FinRobot（Paper 4）已在股票研究領域證明了 Multi-Agent 的有效性，
但尚無研究將此架構系統性地應用於 CFA 考試場景。

#### 為何可行

- 成熟的 Multi-Agent 框架已公開可用：AutoGen（Microsoft）、CrewAI、
  LangGraph（LangChain）均提供了完善的多智能體協作基礎設施
- CFA 的學科分類本身就提供了自然的智能體角色劃分依據
- 不需要額外的模型訓練，可透過 prompting 與角色設定實現

#### 為何我們能做

- 本研究已具備 CFA 各級別的題目資料集（flare-cfa、CFA_Extracted、CFA_Level_III）
- 可直接利用開源框架搭建原型系統
- 可與 FinDAP 的 Llama-Fin-8b 結合，測試金融專用模型在 Multi-Agent 架構下的表現
- 實驗所需的計算資源可控（主要是推理成本，非訓練成本）

---

### 空白 2：缺乏推理策略在 CFA 題目上的系統性比較

#### 為何重要

不同的推理策略（prompting strategies）在不同類型的任務上表現差異巨大。
CFA 考試包含多種題型：概念理解題、計算題、案例分析題、論述題，
每種題型可能適合不同的推理策略。然而，目前沒有任何一篇論文系統性地比較了
以下推理策略在 CFA 題目上的效果：

- Zero-shot prompting
- Few-shot prompting
- Chain-of-Thought (CoT) prompting（Wei et al., arXiv: 2201.11903）
- Self-Consistency（Wang et al., arXiv: 2203.11171）
- ReAct（Yao et al., arXiv: 2210.03629）
- Tree-of-Thought (ToT)
- Retrieval-Augmented Generation (RAG)（Lewis et al., arXiv: 2005.11401）

Paper 1 只測試了 Zero-shot 與 RAG，Paper 2 未報告推理策略的消融實驗，
FinDAP 聚焦於訓練而非推理策略。這個空白的填補對於理解「什麼策略最適合
金融推理」具有直接的實踐價值。

#### 為何可行

- 上述所有推理策略均有成熟的實現方式與公開的程式碼
- 實驗設計清晰：在相同的資料集與模型上，系統性地切換推理策略並比較結果
- 不需要額外的模型訓練，僅需推理階段的計算資源

#### 為何我們能做

- 已有公開的 CFA 資料集可供使用
- 可利用 API 呼叫主流模型（GPT-4o、Claude、Gemini）進行實驗
- 實驗框架可基於 lm-evaluation-harness 進行擴展
- 可產出高價值的消融實驗結果，為後續研究者提供策略選擇指南

---

### 空白 3：RAG 在 CFA 場景的深度不足

#### 為何重要

Paper 1 的結果已經證明 RAG 能顯著提升 CFA 題目的準確率，
而知識缺口又是 LLM 回答錯誤的首要原因。這兩個發現共同指向一個結論：
深入研究 RAG 在 CFA 場景的應用具有極高的改善潛力。

然而，Paper 1 在 RAG 的實作細節上嚴重不足，未提供：
- 知識庫的構建方式與來源
- Embedding 模型的選擇與比較
- Chunk 大小與重疊率的超參數分析
- 檢索策略（dense retrieval vs. sparse retrieval vs. hybrid）的比較
- 重排序（re-ranking）策略的影響
- 不同 RAG 架構（naive、advanced、modular）的效果差異

#### 為何可行

- CFA Institute 的官方教材（CFA curriculum）提供了標準化的金融知識來源
- 公開的金融教材、研究報告、法規文件均可作為知識庫素材
- RAG 技術已高度成熟，LlamaIndex、LangChain 等框架提供了完整的工具鏈
- 向量資料庫（如 ChromaDB、Pinecone、Weaviate）的部署成本已大幅降低

#### 為何我們能做

- 本研究已收集 CFA 相關資料集，可作為 RAG 知識庫的基礎素材
- 可設計系統性的消融實驗，逐步測試各超參數的影響
- 實驗成本可控（主要是 embedding 計算與 API 呼叫成本）
- 產出結果可直接指導金融領域 RAG 系統的工程實踐

---

### 空白 4：缺乏跨 Level 的完整評估框架

#### 為何重要

CFA 考試的三個級別（Level I、Level II、Level III）代表了三個截然不同的
認知難度層次。單獨評估某一級別無法揭示：
- 模型能力隨題目難度提升的衰減規律
- 不同增強策略（RAG、CoT、Multi-Agent）在不同難度層次上的邊際效益差異
- 模型在哪個能力維度上最先遭遇瓶頸

Paper 2 僅評估 Level III，FinDAP 的評估主要聚焦於 Level II 難度的題目。
目前沒有任何一項研究在統一的實驗框架下，同時評估 Level I、II、III 的完整表現。

#### 為何可行

- Level I 與 Level II 的選擇題資料可從 flare-cfa、CFA_Extracted 等公開資料集獲取
- Level III 的題目可從 CFA_Level_III 資料集獲取（雖然僅含選擇題部分）
- 統一評估框架可基於 lm-evaluation-harness 進行建構
- FinDAP 的 FinEval 已提供了部分評估基礎設施

#### 為何我們能做

- 本研究已整理了跨級別的 CFA 資料集資源
- 可建構統一的評估管線（evaluation pipeline），確保跨級別比較的公平性
- 可在同一實驗中同時測試模型能力、推理策略與級別難度三個變因的交互效應

---

### 空白 5：缺乏可解釋性與錯誤分析

#### 為何重要

現有所有論文均停留在「報告準確率」的層次，缺乏深入的錯誤分析（error analysis）
與可解釋性（explainability）研究。具體而言，以下問題尚未被回答：

- 模型答錯的題目有什麼共同特徵？（題目長度、涉及學科、推理步數、計算複雜度）
- 不同模型是否在相同的題目上犯錯？（模型間錯誤的相關性）
- 模型的推理過程在哪一步開始偏離正確路徑？
- 錯誤類型（知識缺口、推理錯誤、計算錯誤、理解錯誤）的分布是否隨級別而變化？

這些分析對於設計針對性的改善策略至關重要。如果主要錯誤來自知識缺口，
則應強化 RAG；如果來自推理錯誤，則應改進推理策略；
如果來自計算錯誤，則應引入外部計算工具。

#### 為何可行

- 錯誤分析的方法論已在 NLP 研究中廣泛使用
- 可設計結構化的錯誤分類框架（error taxonomy）
- 可利用 LLM 自身來輔助分析其他模型的錯誤模式（LLM-as-a-judge）
- 可視化工具（如 confusion matrix、error heatmap）可有效呈現分析結果

#### 為何我們能做

- 已有的實驗結果可直接作為錯誤分析的素材
- 可設計自動化的錯誤分類管線，降低人工標註成本
- 錯誤分析的產出具有高論文價值，是 reviewers 普遍期待的實驗內容

---

### 空白 6：缺乏校準與信心分析

#### 為何重要

模型校準（calibration）是指模型對自身預測置信度的準確程度。
在金融決策場景中，校準不良的模型可能帶來嚴重後果：
一個對錯誤答案表現出高置信度的模型，比一個準確率稍低但能正確識別
自身不確定性的模型更加危險。

目前沒有任何研究探討 LLM 在 CFA 題目上的校準表現，具體包括：
- 模型是否傾向於過度自信（overconfident）？
- 模型的置信度與實際準確率之間的對齊程度如何？
- 不同學科領域的校準表現是否存在差異？
- 高置信度的錯誤回答有什麼特徵？

#### 為何可行

- 校準分析的方法論已成熟：Expected Calibration Error (ECE)、
  reliability diagram、Brier score 等指標均可直接使用
- 對於選擇題，可透過 logprob（對數機率）直接獲取模型的置信度
- 對於開放式回答，可透過 verbalized confidence（讓模型自我評估置信度）來近似

#### 為何我們能做

- 實驗設計直觀，只需在現有評估管線中增加置信度提取模塊
- 可產出高影響力的分析結果（金融領域對模型可靠性高度敏感）
- 校準分析的結果可直接指導實際應用中的風險管理策略
  （如：當模型置信度低於某閾值時，自動觸發人工審核）

---

## 四、完整資源索引

### 4.1 論文連結總表

| 論文 | arXiv ID | 連結 |
|------|----------|------|
| CFA Benchmark Study | 2509.04468 | https://arxiv.org/abs/2509.04468 |
| CFA Level III Scale | 2507.02954 | https://arxiv.org/abs/2507.02954 |
| FinDAP | 2501.04961 | https://arxiv.org/abs/2501.04961 |
| FinRobot | 2411.08804 | https://arxiv.org/abs/2411.08804 |
| FinanceMath | 2311.09797 | https://arxiv.org/abs/2311.09797 |
| FLAME | 2501.06211 | https://arxiv.org/abs/2501.06211 |
| CFinBench | 2407.02301 | https://arxiv.org/abs/2407.02301 |
| Chain-of-Thought Prompting | 2201.11903 | https://arxiv.org/abs/2201.11903 |
| ReAct | 2210.03629 | https://arxiv.org/abs/2210.03629 |
| Retrieval-Augmented Generation | 2005.11401 | https://arxiv.org/abs/2005.11401 |
| Self-Consistency | 2203.11171 | https://arxiv.org/abs/2203.11171 |

### 4.2 資料集連結總表

| 資料集 | HuggingFace 連結 |
|--------|-----------------|
| FinEval | https://huggingface.co/datasets/Salesforce/FinEval |
| FinTrain | https://huggingface.co/datasets/Salesforce/FinTrain |
| Llama-Fin-8b（模型） | https://huggingface.co/Salesforce/Llama-Fin-8b |
| CFA_Extracted-chunk_0 | https://huggingface.co/datasets/ZixuanKe/cfa_extracted_qa_gpt4_verify_sup_chunk_0 |
| CFA_Extracted-sft | https://huggingface.co/datasets/ZixuanKe/cfa_extracted_qa_gpt4_verify_sft_without_material_gpt4_answer |
| flare-cfa | https://huggingface.co/datasets/TheFinAI/flare-cfa |
| CFA_Level_III | https://huggingface.co/datasets/alvinming/CFA-Level-III |

### 4.3 程式碼儲存庫

| 儲存庫 | 連結 | 用途 |
|--------|------|------|
| FinDAP | https://github.com/SalesforceAIResearch/FinDap | 金融 LLM 後訓練框架 |
| lm-evaluation-harness | https://github.com/EleutherAI/lm-evaluation-harness | LLM 評估框架 |
| AutoGen | https://github.com/microsoft/autogen | Microsoft Multi-Agent 框架 |
| CrewAI | https://github.com/joaomdmoura/crewAI | Multi-Agent 協作框架 |
| LangGraph | https://github.com/langchain-ai/langgraph | LangChain 圖結構 Agent 框架 |

### 4.4 關鍵論文 BibTeX

```bibtex
@inproceedings{ke2025findap,
  title     = {Demystifying Domain-adaptive Post-training for Financial LLMs},
  author    = {Ke, Zixuan and Ming, Yifei and Nguyen, Xuan-Phi and Xiong, Caiming and Joty, Shafiq},
  booktitle = {Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year      = {2025},
  note      = {Oral Presentation}
}

@article{wei2022chain,
  title   = {Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
  author  = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and
             Ichter, Brian and Xia, Fei and Chi, Ed and Le, Quoc and Zhou, Denny},
  journal = {arXiv preprint arXiv:2201.11903},
  year    = {2022}
}

@article{yao2022react,
  title   = {ReAct: Synergizing Reasoning and Acting in Language Models},
  author  = {Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and
             Narasimhan, Karthik and Cao, Yuan},
  journal = {arXiv preprint arXiv:2210.03629},
  year    = {2022}
}

@article{lewis2020retrieval,
  title   = {Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks},
  author  = {Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and
             Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and
             Yih, Wen-tau and Rockt{\"a}schel, Tim and Riedel, Sebastian and Kiela, Douwe},
  journal = {arXiv preprint arXiv:2005.11401},
  year    = {2020}
}

@article{wang2022self,
  title   = {Self-Consistency Improves Chain of Thought Reasoning in Language Models},
  author  = {Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and
             Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
  journal = {arXiv preprint arXiv:2203.11171},
  year    = {2022}
}
```

---

## 附錄：研究定位總結

### 本研究在現有文獻中的定位

綜合以上分析，本研究的獨特定位可概括為：

**在 CFA 考試場景下，系統性地整合 Multi-Agent 架構、多元推理策略與深度 RAG，
建立跨級別的完整評估框架，並提供可解釋性與校準分析。**

這一定位填補了現有文獻的六個核心空白，且每個空白都已論證其重要性、可行性與我們的執行能力。

### 與現有工作的差異化

| 維度 | Paper 1 | Paper 2 | FinDAP | FinRobot | 本研究 |
|------|---------|---------|--------|----------|--------|
| Multi-Agent | 無 | 無 | 無 | 有（股票） | 有（CFA） |
| 推理策略比較 | 僅 Zero-shot + RAG | 無 | 無 | 僅 CoT | 系統性比較 |
| RAG 深度 | 淺 | 無 | 無 | 無 | 深度消融 |
| 跨 Level 評估 | Level I-III（部分） | 僅 Level III | 主要 Level II | 不適用 | Level I-III（完整） |
| 可解釋性分析 | 無 | 無 | 無 | 無 | 有 |
| 校準分析 | 無 | 無 | 無 | 無 | 有 |

### 預期貢獻

1. **方法論貢獻**：提出首個針對 CFA 考試的 Multi-Agent + RAG 整合框架
2. **實證貢獻**：提供跨級別、跨策略、跨模型的系統性比較數據
3. **分析貢獻**：建立金融 LLM 的錯誤分類體系與校準分析框架
4. **實踐貢獻**：為金融教育與專業認證領域的 AI 輔助工具提供設計指南
5. **開源貢獻**：釋出完整的實驗程式碼、評估管線與分析工具

---

> 文件版本：v1.0
> 最後更新：2026-01-30
> 本文件為研究專案內部文獻綜述，隨研究進展持續更新。
